{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WASYCq5LYyF0",
        "outputId": "47909b84-3851-4c8e-f605-6961200dacc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 11104 entries, 0 to 11103\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   English  11104 non-null  object\n",
            " 1   Tamil    11104 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 173.6+ KB\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('final_translation.csv')\n",
        "df.columns = ['English','Tamil']\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ujPMEJzVeYWG",
        "outputId": "d420588d-803d-4a79-f721-01058200cc76"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Tamil</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Lets try something</td>\n",
              "      <td>ஏதாவது முயற்சி செய்யலாம்</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I have to go to sleep</td>\n",
              "      <td>நான் தூங்க செல்ல வேண்டும்</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Today is June 18th and it is Muiriels birthday</td>\n",
              "      <td>இன்று ஜூன் 18 மற்றும் முரியலின் பிறந்த நாள்</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Muiriel is 20 now</td>\n",
              "      <td>முரியலுக்கு இப்போது 20 வயது</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The password is Muiriel</td>\n",
              "      <td>கடவுச்சொல் முரியல்</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11099</th>\n",
              "      <td>Dont speak to the driver while he is driving</td>\n",
              "      <td>வாகனம் ஓட்டும் போது ஓட்டுனரிடம் பேச வேண்டாம்</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11100</th>\n",
              "      <td>The driver was inattentive and could not stop ...</td>\n",
              "      <td>டிரைவர் கவனக்குறைவாக இருந்ததால் சரியான நேரத்தி...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11101</th>\n",
              "      <td>The driver could not distinguish the signal in...</td>\n",
              "      <td>டிரைவரால் மூடுபனியில் சிக்னலை வேறுபடுத்திப் பா...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11102</th>\n",
              "      <td>The driver tipped his cap</td>\n",
              "      <td>டிரைவர் தொப்பியை சாய்த்தார்</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11103</th>\n",
              "      <td>The driver gestured him out</td>\n",
              "      <td>ஓட்டுனர் சைகையால் வெளியே காட்டினார்</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11104 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 English  \\\n",
              "0                                     Lets try something   \n",
              "1                                  I have to go to sleep   \n",
              "2         Today is June 18th and it is Muiriels birthday   \n",
              "3                                      Muiriel is 20 now   \n",
              "4                                The password is Muiriel   \n",
              "...                                                  ...   \n",
              "11099       Dont speak to the driver while he is driving   \n",
              "11100  The driver was inattentive and could not stop ...   \n",
              "11101  The driver could not distinguish the signal in...   \n",
              "11102                          The driver tipped his cap   \n",
              "11103                        The driver gestured him out   \n",
              "\n",
              "                                                   Tamil  \n",
              "0                               ஏதாவது முயற்சி செய்யலாம்  \n",
              "1                              நான் தூங்க செல்ல வேண்டும்  \n",
              "2            இன்று ஜூன் 18 மற்றும் முரியலின் பிறந்த நாள்  \n",
              "3                            முரியலுக்கு இப்போது 20 வயது  \n",
              "4                                     கடவுச்சொல் முரியல்  \n",
              "...                                                  ...  \n",
              "11099       வாகனம் ஓட்டும் போது ஓட்டுனரிடம் பேச வேண்டாம்  \n",
              "11100  டிரைவர் கவனக்குறைவாக இருந்ததால் சரியான நேரத்தி...  \n",
              "11101  டிரைவரால் மூடுபனியில் சிக்னலை வேறுபடுத்திப் பா...  \n",
              "11102                        டிரைவர் தொப்பியை சாய்த்தார்  \n",
              "11103                ஓட்டுனர் சைகையால் வெளியே காட்டினார்  \n",
              "\n",
              "[11104 rows x 2 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    # Keep only Tamil/English letters and numbers, remove all other characters\n",
        "    return re.sub(r'[^a-zA-Z0-9\\u0B80-\\u0BFF\\s]', '', text)\n",
        "\n",
        "# Apply cleaning function to English and Tamil columns\n",
        "df['English'] = df['English'].apply(clean_text)  # Clean English column\n",
        "df['Tamil'] = df['Tamil'].apply(clean_text)  # Clean Tamil column\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "pTatalI-feBW",
        "outputId": "da895ddd-3b28-4452-c289-4ce54450902e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Tamil</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Lets try something</td>\n",
              "      <td>ஏதாவது முயற்சி செய்யலாம்</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I have to go to sleep</td>\n",
              "      <td>நான் தூங்க செல்ல வேண்டும்</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Today is June 18th and it is Muiriels birthday</td>\n",
              "      <td>இன்று ஜூன் 18 மற்றும் முரியலின் பிறந்த நாள்</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Muiriel is 20 now</td>\n",
              "      <td>முரியலுக்கு இப்போது 20 வயது</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The password is Muiriel</td>\n",
              "      <td>கடவுச்சொல் முரியல்</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11099</th>\n",
              "      <td>Dont speak to the driver while he is driving</td>\n",
              "      <td>வாகனம் ஓட்டும் போது ஓட்டுனரிடம் பேச வேண்டாம்</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11100</th>\n",
              "      <td>The driver was inattentive and could not stop ...</td>\n",
              "      <td>டிரைவர் கவனக்குறைவாக இருந்ததால் சரியான நேரத்தி...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11101</th>\n",
              "      <td>The driver could not distinguish the signal in...</td>\n",
              "      <td>டிரைவரால் மூடுபனியில் சிக்னலை வேறுபடுத்திப் பா...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11102</th>\n",
              "      <td>The driver tipped his cap</td>\n",
              "      <td>டிரைவர் தொப்பியை சாய்த்தார்</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11103</th>\n",
              "      <td>The driver gestured him out</td>\n",
              "      <td>ஓட்டுனர் சைகையால் வெளியே காட்டினார்</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11076 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 English  \\\n",
              "0                                     Lets try something   \n",
              "1                                  I have to go to sleep   \n",
              "2         Today is June 18th and it is Muiriels birthday   \n",
              "3                                      Muiriel is 20 now   \n",
              "4                                The password is Muiriel   \n",
              "...                                                  ...   \n",
              "11099       Dont speak to the driver while he is driving   \n",
              "11100  The driver was inattentive and could not stop ...   \n",
              "11101  The driver could not distinguish the signal in...   \n",
              "11102                          The driver tipped his cap   \n",
              "11103                        The driver gestured him out   \n",
              "\n",
              "                                                   Tamil  \n",
              "0                               ஏதாவது முயற்சி செய்யலாம்  \n",
              "1                              நான் தூங்க செல்ல வேண்டும்  \n",
              "2            இன்று ஜூன் 18 மற்றும் முரியலின் பிறந்த நாள்  \n",
              "3                            முரியலுக்கு இப்போது 20 வயது  \n",
              "4                                     கடவுச்சொல் முரியல்  \n",
              "...                                                  ...  \n",
              "11099       வாகனம் ஓட்டும் போது ஓட்டுனரிடம் பேச வேண்டாம்  \n",
              "11100  டிரைவர் கவனக்குறைவாக இருந்ததால் சரியான நேரத்தி...  \n",
              "11101  டிரைவரால் மூடுபனியில் சிக்னலை வேறுபடுத்திப் பா...  \n",
              "11102                        டிரைவர் தொப்பியை சாய்த்தார்  \n",
              "11103                ஓட்டுனர் சைகையால் வெளியே காட்டினார்  \n",
              "\n",
              "[11076 rows x 2 columns]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define a function to check if any English character is present in the Tamil text\n",
        "def contains_english(text):\n",
        "    # This regex checks if the text contains any character from the English alphabet\n",
        "    return bool(re.search(r'[a-zA-Z]', text))\n",
        "\n",
        "# Apply the function to filter out rows where Tamil contains English words\n",
        "df = df[~df['Tamil'].apply(contains_english)]\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "iXfU6sXgf81u"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the WordLevelTokenizer class (use the class from the previous answer)\n",
        "class WordLevelTokenizer:\n",
        "    def __init__(self, special_tokens=None):\n",
        "        self.word_to_id = {}\n",
        "        self.id_to_word = {}\n",
        "        self.special_tokens = special_tokens or []\n",
        "        self.build_vocab(self.special_tokens)\n",
        "\n",
        "    def build_vocab(self, tokens):\n",
        "        for token in tokens:\n",
        "            self.add_token(token)\n",
        "\n",
        "    def add_token(self, token):\n",
        "        if token not in self.word_to_id:\n",
        "            idx = len(self.word_to_id)\n",
        "            self.word_to_id[token] = idx\n",
        "            self.id_to_word[idx] = token\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        return text.split()\n",
        "\n",
        "    def encode(self, text):\n",
        "        tokens = self.tokenize(text)\n",
        "        return [self.word_to_id.get(token, self.word_to_id.get(\"<UNK>\")) for token in tokens]\n",
        "\n",
        "    def decode(self, token_ids):\n",
        "        return \" \".join(self.id_to_word.get(idx, \"<UNK>\") for idx in token_ids)\n",
        "\n",
        "    def fit_on_texts(self, texts):\n",
        "        for text in texts:\n",
        "            tokens = self.tokenize(text)\n",
        "            self.build_vocab(tokens)\n",
        "\n",
        "    def vocab_size(self):\n",
        "        return len(self.word_to_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "25rq3UOXgEbW"
      },
      "outputs": [],
      "source": [
        "# Initialize tokenizer with special tokens\n",
        "special_tokens = [\"<UNK>\", \"<PAD>\", \"<SOS>\", \"<EOS>\"]\n",
        "tamil_tokenizer = WordLevelTokenizer(special_tokens=special_tokens)\n",
        "english_tokenizer = WordLevelTokenizer(special_tokens=special_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtxzmjXxgHIN",
        "outputId": "c0aa301c-d15d-4407-dbec-77635d551279"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary: 15529\n"
          ]
        }
      ],
      "source": [
        "# Fit tokenizer on the 'text' column\n",
        "tamil_tokenizer.fit_on_texts(df['Tamil'])\n",
        "print(\"Vocabulary:\", len(tamil_tokenizer.word_to_id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZnfG-dVgMYG",
        "outputId": "8b5cc47a-0148-4599-bea4-85be461bcefd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary: 8100\n"
          ]
        }
      ],
      "source": [
        "english_tokenizer.fit_on_texts(df['English'])\n",
        "print(\"Vocabulary:\", len(english_tokenizer.word_to_id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "id": "XIpneaZhgRs2",
        "outputId": "242ba9c4-d97f-4378-e4cb-6f71489375b1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Kamal\\AppData\\Local\\Temp\\ipykernel_3204\\3299460047.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['Tokenized_Tamil'] = df['Tamil'].apply(lambda x: tamil_tokenizer.encode(x))\n",
            "C:\\Users\\Kamal\\AppData\\Local\\Temp\\ipykernel_3204\\3299460047.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['Tokenized_English'] = df['English'].apply(lambda x: english_tokenizer.encode(x))\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Tamil</th>\n",
              "      <th>Tokenized_Tamil</th>\n",
              "      <th>Tokenized_English</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Lets try something</td>\n",
              "      <td>ஏதாவது முயற்சி செய்யலாம்</td>\n",
              "      <td>[4, 5, 6]</td>\n",
              "      <td>[4, 5, 6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I have to go to sleep</td>\n",
              "      <td>நான் தூங்க செல்ல வேண்டும்</td>\n",
              "      <td>[7, 8, 9, 10]</td>\n",
              "      <td>[7, 8, 9, 10, 9, 11]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Today is June 18th and it is Muiriels birthday</td>\n",
              "      <td>இன்று ஜூன் 18 மற்றும் முரியலின் பிறந்த நாள்</td>\n",
              "      <td>[11, 12, 13, 14, 15, 16, 17]</td>\n",
              "      <td>[12, 13, 14, 15, 16, 17, 13, 18, 19]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Muiriel is 20 now</td>\n",
              "      <td>முரியலுக்கு இப்போது 20 வயது</td>\n",
              "      <td>[18, 19, 20, 21]</td>\n",
              "      <td>[20, 13, 21, 22]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The password is Muiriel</td>\n",
              "      <td>கடவுச்சொல் முரியல்</td>\n",
              "      <td>[22, 23]</td>\n",
              "      <td>[23, 24, 13, 20]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11099</th>\n",
              "      <td>Dont speak to the driver while he is driving</td>\n",
              "      <td>வாகனம் ஓட்டும் போது ஓட்டுனரிடம் பேச வேண்டாம்</td>\n",
              "      <td>[3724, 15517, 741, 15520, 1215, 797]</td>\n",
              "      <td>[487, 491, 9, 50, 7118, 481, 89, 13, 1678]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11100</th>\n",
              "      <td>The driver was inattentive and could not stop ...</td>\n",
              "      <td>டிரைவர் கவனக்குறைவாக இருந்ததால் சரியான நேரத்தி...</td>\n",
              "      <td>[15521, 3850, 751, 465, 2632, 2354, 2246]</td>\n",
              "      <td>[23, 7118, 45, 8096, 16, 149, 96, 2074, 49, 56]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11101</th>\n",
              "      <td>The driver could not distinguish the signal in...</td>\n",
              "      <td>டிரைவரால் மூடுபனியில் சிக்னலை வேறுபடுத்திப் பா...</td>\n",
              "      <td>[15522, 15523, 15524, 3612, 502, 2246]</td>\n",
              "      <td>[23, 7118, 149, 96, 2531, 50, 8097, 49, 50, 3566]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11102</th>\n",
              "      <td>The driver tipped his cap</td>\n",
              "      <td>டிரைவர் தொப்பியை சாய்த்தார்</td>\n",
              "      <td>[15521, 15525, 15526]</td>\n",
              "      <td>[23, 7118, 8098, 886, 6047]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11103</th>\n",
              "      <td>The driver gestured him out</td>\n",
              "      <td>ஓட்டுனர் சைகையால் வெளியே காட்டினார்</td>\n",
              "      <td>[15527, 15528, 758, 8712]</td>\n",
              "      <td>[23, 7118, 8099, 216, 695]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11076 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 English  \\\n",
              "0                                     Lets try something   \n",
              "1                                  I have to go to sleep   \n",
              "2         Today is June 18th and it is Muiriels birthday   \n",
              "3                                      Muiriel is 20 now   \n",
              "4                                The password is Muiriel   \n",
              "...                                                  ...   \n",
              "11099       Dont speak to the driver while he is driving   \n",
              "11100  The driver was inattentive and could not stop ...   \n",
              "11101  The driver could not distinguish the signal in...   \n",
              "11102                          The driver tipped his cap   \n",
              "11103                        The driver gestured him out   \n",
              "\n",
              "                                                   Tamil  \\\n",
              "0                               ஏதாவது முயற்சி செய்யலாம்   \n",
              "1                              நான் தூங்க செல்ல வேண்டும்   \n",
              "2            இன்று ஜூன் 18 மற்றும் முரியலின் பிறந்த நாள்   \n",
              "3                            முரியலுக்கு இப்போது 20 வயது   \n",
              "4                                     கடவுச்சொல் முரியல்   \n",
              "...                                                  ...   \n",
              "11099       வாகனம் ஓட்டும் போது ஓட்டுனரிடம் பேச வேண்டாம்   \n",
              "11100  டிரைவர் கவனக்குறைவாக இருந்ததால் சரியான நேரத்தி...   \n",
              "11101  டிரைவரால் மூடுபனியில் சிக்னலை வேறுபடுத்திப் பா...   \n",
              "11102                        டிரைவர் தொப்பியை சாய்த்தார்   \n",
              "11103                ஓட்டுனர் சைகையால் வெளியே காட்டினார்   \n",
              "\n",
              "                                 Tokenized_Tamil  \\\n",
              "0                                      [4, 5, 6]   \n",
              "1                                  [7, 8, 9, 10]   \n",
              "2                   [11, 12, 13, 14, 15, 16, 17]   \n",
              "3                               [18, 19, 20, 21]   \n",
              "4                                       [22, 23]   \n",
              "...                                          ...   \n",
              "11099       [3724, 15517, 741, 15520, 1215, 797]   \n",
              "11100  [15521, 3850, 751, 465, 2632, 2354, 2246]   \n",
              "11101     [15522, 15523, 15524, 3612, 502, 2246]   \n",
              "11102                      [15521, 15525, 15526]   \n",
              "11103                  [15527, 15528, 758, 8712]   \n",
              "\n",
              "                                       Tokenized_English  \n",
              "0                                              [4, 5, 6]  \n",
              "1                                   [7, 8, 9, 10, 9, 11]  \n",
              "2                   [12, 13, 14, 15, 16, 17, 13, 18, 19]  \n",
              "3                                       [20, 13, 21, 22]  \n",
              "4                                       [23, 24, 13, 20]  \n",
              "...                                                  ...  \n",
              "11099         [487, 491, 9, 50, 7118, 481, 89, 13, 1678]  \n",
              "11100    [23, 7118, 45, 8096, 16, 149, 96, 2074, 49, 56]  \n",
              "11101  [23, 7118, 149, 96, 2531, 50, 8097, 49, 50, 3566]  \n",
              "11102                        [23, 7118, 8098, 886, 6047]  \n",
              "11103                         [23, 7118, 8099, 216, 695]  \n",
              "\n",
              "[11076 rows x 4 columns]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Tokenize the Tamil text in your dataframe\n",
        "df['Tokenized_Tamil'] = df['Tamil'].apply(lambda x: tamil_tokenizer.encode(x))\n",
        "df['Tokenized_English'] = df['English'].apply(lambda x: english_tokenizer.encode(x))\n",
        "# Print the dataframe with tokenized Tamil text\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWTVc0hVhHk-",
        "outputId": "a2c4c744-e45d-49a7-cb05-0262f495d2bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "61925\n"
          ]
        }
      ],
      "source": [
        "z = 0\n",
        "t = 0\n",
        "for i in df['Tokenized_Tamil']:\n",
        "    for j in i:\n",
        "        t = t +1\n",
        "        if j == 0:\n",
        "           z=z+1\n",
        "print(z)\n",
        "print(t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmrG-vynhPWG",
        "outputId": "2038f7e0-9b4f-4f72-b64d-d37a274c6254"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(11076, 4)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tamil_idx = []\n",
        "for idx , i in enumerate(df['Tokenized_Tamil']):\n",
        "    if len(i) > 24:\n",
        "        tamil_idx.append(idx)\n",
        "\n",
        "print(len(tamil_idx))\n",
        "\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJmWY13dhi_m",
        "outputId": "088c5737-dc02-4f0e-f367-a8373308f465"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(11073, 4)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df.drop(index=df.index[tamil_idx])\n",
        "\n",
        "df = df.reset_index(drop=True)\n",
        "\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eti-ogtEhr82",
        "outputId": "ace54abc-9d86-45a2-daa7-c69fe6cfd4a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "36\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(11073, 4)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "english_idx = []\n",
        "for idx , i in enumerate(df['Tokenized_English']):\n",
        "    if len(i) > 24:\n",
        "        english_idx.append(idx)\n",
        "\n",
        "print(len(english_idx))\n",
        "\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZi-SXFvh2xW",
        "outputId": "4b401539-3953-48c5-b740-5506d90cb615"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(11037, 4)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df.drop(index=df.index[english_idx])\n",
        "\n",
        "df = df.reset_index(drop=True)\n",
        "\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "WPcwIR4eiHF1",
        "outputId": "da3cf359-e237-469a-dcad-2d03afc8f03e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Tamil</th>\n",
              "      <th>Tokenized_Tamil</th>\n",
              "      <th>Tokenized_English</th>\n",
              "      <th>Padded_English</th>\n",
              "      <th>Padded_Tamil</th>\n",
              "      <th>Padded_Tamil_Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Lets try something</td>\n",
              "      <td>ஏதாவது முயற்சி செய்யலாம்</td>\n",
              "      <td>[4, 5, 6]</td>\n",
              "      <td>[4, 5, 6]</td>\n",
              "      <td>[2, 4, 5, 6, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[2, 4, 5, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[4, 5, 6, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I have to go to sleep</td>\n",
              "      <td>நான் தூங்க செல்ல வேண்டும்</td>\n",
              "      <td>[7, 8, 9, 10]</td>\n",
              "      <td>[7, 8, 9, 10, 9, 11]</td>\n",
              "      <td>[2, 7, 8, 9, 10, 9, 11, 3, 1, 1, 1, 1, 1, 1, 1...</td>\n",
              "      <td>[2, 7, 8, 9, 10, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
              "      <td>[7, 8, 9, 10, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Today is June 18th and it is Muiriels birthday</td>\n",
              "      <td>இன்று ஜூன் 18 மற்றும் முரியலின் பிறந்த நாள்</td>\n",
              "      <td>[11, 12, 13, 14, 15, 16, 17]</td>\n",
              "      <td>[12, 13, 14, 15, 16, 17, 13, 18, 19]</td>\n",
              "      <td>[2, 12, 13, 14, 15, 16, 17, 13, 18, 19, 3, 1, ...</td>\n",
              "      <td>[2, 11, 12, 13, 14, 15, 16, 17, 1, 1, 1, 1, 1,...</td>\n",
              "      <td>[11, 12, 13, 14, 15, 16, 17, 3, 1, 1, 1, 1, 1,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Muiriel is 20 now</td>\n",
              "      <td>முரியலுக்கு இப்போது 20 வயது</td>\n",
              "      <td>[18, 19, 20, 21]</td>\n",
              "      <td>[20, 13, 21, 22]</td>\n",
              "      <td>[2, 20, 13, 21, 22, 3, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
              "      <td>[2, 18, 19, 20, 21, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
              "      <td>[18, 19, 20, 21, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The password is Muiriel</td>\n",
              "      <td>கடவுச்சொல் முரியல்</td>\n",
              "      <td>[22, 23]</td>\n",
              "      <td>[23, 24, 13, 20]</td>\n",
              "      <td>[2, 23, 24, 13, 20, 3, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
              "      <td>[2, 22, 23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1...</td>\n",
              "      <td>[22, 23, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11032</th>\n",
              "      <td>Dont speak to the driver while he is driving</td>\n",
              "      <td>வாகனம் ஓட்டும் போது ஓட்டுனரிடம் பேச வேண்டாம்</td>\n",
              "      <td>[3724, 15517, 741, 15520, 1215, 797]</td>\n",
              "      <td>[487, 491, 9, 50, 7118, 481, 89, 13, 1678]</td>\n",
              "      <td>[2, 487, 491, 9, 50, 7118, 481, 89, 13, 1678, ...</td>\n",
              "      <td>[2, 3724, 15517, 741, 15520, 1215, 797, 1, 1, ...</td>\n",
              "      <td>[3724, 15517, 741, 15520, 1215, 797, 3, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11033</th>\n",
              "      <td>The driver was inattentive and could not stop ...</td>\n",
              "      <td>டிரைவர் கவனக்குறைவாக இருந்ததால் சரியான நேரத்தி...</td>\n",
              "      <td>[15521, 3850, 751, 465, 2632, 2354, 2246]</td>\n",
              "      <td>[23, 7118, 45, 8096, 16, 149, 96, 2074, 49, 56]</td>\n",
              "      <td>[2, 23, 7118, 45, 8096, 16, 149, 96, 2074, 49,...</td>\n",
              "      <td>[2, 15521, 3850, 751, 465, 2632, 2354, 2246, 1...</td>\n",
              "      <td>[15521, 3850, 751, 465, 2632, 2354, 2246, 3, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11034</th>\n",
              "      <td>The driver could not distinguish the signal in...</td>\n",
              "      <td>டிரைவரால் மூடுபனியில் சிக்னலை வேறுபடுத்திப் பா...</td>\n",
              "      <td>[15522, 15523, 15524, 3612, 502, 2246]</td>\n",
              "      <td>[23, 7118, 149, 96, 2531, 50, 8097, 49, 50, 3566]</td>\n",
              "      <td>[2, 23, 7118, 149, 96, 2531, 50, 8097, 49, 50,...</td>\n",
              "      <td>[2, 15522, 15523, 15524, 3612, 502, 2246, 1, 1...</td>\n",
              "      <td>[15522, 15523, 15524, 3612, 502, 2246, 3, 1, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11035</th>\n",
              "      <td>The driver tipped his cap</td>\n",
              "      <td>டிரைவர் தொப்பியை சாய்த்தார்</td>\n",
              "      <td>[15521, 15525, 15526]</td>\n",
              "      <td>[23, 7118, 8098, 886, 6047]</td>\n",
              "      <td>[2, 23, 7118, 8098, 886, 6047, 3, 1, 1, 1, 1, ...</td>\n",
              "      <td>[2, 15521, 15525, 15526, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[15521, 15525, 15526, 3, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11036</th>\n",
              "      <td>The driver gestured him out</td>\n",
              "      <td>ஓட்டுனர் சைகையால் வெளியே காட்டினார்</td>\n",
              "      <td>[15527, 15528, 758, 8712]</td>\n",
              "      <td>[23, 7118, 8099, 216, 695]</td>\n",
              "      <td>[2, 23, 7118, 8099, 216, 695, 3, 1, 1, 1, 1, 1...</td>\n",
              "      <td>[2, 15527, 15528, 758, 8712, 1, 1, 1, 1, 1, 1,...</td>\n",
              "      <td>[15527, 15528, 758, 8712, 3, 1, 1, 1, 1, 1, 1,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11037 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 English  \\\n",
              "0                                     Lets try something   \n",
              "1                                  I have to go to sleep   \n",
              "2         Today is June 18th and it is Muiriels birthday   \n",
              "3                                      Muiriel is 20 now   \n",
              "4                                The password is Muiriel   \n",
              "...                                                  ...   \n",
              "11032       Dont speak to the driver while he is driving   \n",
              "11033  The driver was inattentive and could not stop ...   \n",
              "11034  The driver could not distinguish the signal in...   \n",
              "11035                          The driver tipped his cap   \n",
              "11036                        The driver gestured him out   \n",
              "\n",
              "                                                   Tamil  \\\n",
              "0                               ஏதாவது முயற்சி செய்யலாம்   \n",
              "1                              நான் தூங்க செல்ல வேண்டும்   \n",
              "2            இன்று ஜூன் 18 மற்றும் முரியலின் பிறந்த நாள்   \n",
              "3                            முரியலுக்கு இப்போது 20 வயது   \n",
              "4                                     கடவுச்சொல் முரியல்   \n",
              "...                                                  ...   \n",
              "11032       வாகனம் ஓட்டும் போது ஓட்டுனரிடம் பேச வேண்டாம்   \n",
              "11033  டிரைவர் கவனக்குறைவாக இருந்ததால் சரியான நேரத்தி...   \n",
              "11034  டிரைவரால் மூடுபனியில் சிக்னலை வேறுபடுத்திப் பா...   \n",
              "11035                        டிரைவர் தொப்பியை சாய்த்தார்   \n",
              "11036                ஓட்டுனர் சைகையால் வெளியே காட்டினார்   \n",
              "\n",
              "                                 Tokenized_Tamil  \\\n",
              "0                                      [4, 5, 6]   \n",
              "1                                  [7, 8, 9, 10]   \n",
              "2                   [11, 12, 13, 14, 15, 16, 17]   \n",
              "3                               [18, 19, 20, 21]   \n",
              "4                                       [22, 23]   \n",
              "...                                          ...   \n",
              "11032       [3724, 15517, 741, 15520, 1215, 797]   \n",
              "11033  [15521, 3850, 751, 465, 2632, 2354, 2246]   \n",
              "11034     [15522, 15523, 15524, 3612, 502, 2246]   \n",
              "11035                      [15521, 15525, 15526]   \n",
              "11036                  [15527, 15528, 758, 8712]   \n",
              "\n",
              "                                       Tokenized_English  \\\n",
              "0                                              [4, 5, 6]   \n",
              "1                                   [7, 8, 9, 10, 9, 11]   \n",
              "2                   [12, 13, 14, 15, 16, 17, 13, 18, 19]   \n",
              "3                                       [20, 13, 21, 22]   \n",
              "4                                       [23, 24, 13, 20]   \n",
              "...                                                  ...   \n",
              "11032         [487, 491, 9, 50, 7118, 481, 89, 13, 1678]   \n",
              "11033    [23, 7118, 45, 8096, 16, 149, 96, 2074, 49, 56]   \n",
              "11034  [23, 7118, 149, 96, 2531, 50, 8097, 49, 50, 3566]   \n",
              "11035                        [23, 7118, 8098, 886, 6047]   \n",
              "11036                         [23, 7118, 8099, 216, 695]   \n",
              "\n",
              "                                          Padded_English  \\\n",
              "0      [2, 4, 5, 6, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
              "1      [2, 7, 8, 9, 10, 9, 11, 3, 1, 1, 1, 1, 1, 1, 1...   \n",
              "2      [2, 12, 13, 14, 15, 16, 17, 13, 18, 19, 3, 1, ...   \n",
              "3      [2, 20, 13, 21, 22, 3, 1, 1, 1, 1, 1, 1, 1, 1,...   \n",
              "4      [2, 23, 24, 13, 20, 3, 1, 1, 1, 1, 1, 1, 1, 1,...   \n",
              "...                                                  ...   \n",
              "11032  [2, 487, 491, 9, 50, 7118, 481, 89, 13, 1678, ...   \n",
              "11033  [2, 23, 7118, 45, 8096, 16, 149, 96, 2074, 49,...   \n",
              "11034  [2, 23, 7118, 149, 96, 2531, 50, 8097, 49, 50,...   \n",
              "11035  [2, 23, 7118, 8098, 886, 6047, 3, 1, 1, 1, 1, ...   \n",
              "11036  [2, 23, 7118, 8099, 216, 695, 3, 1, 1, 1, 1, 1...   \n",
              "\n",
              "                                            Padded_Tamil  \\\n",
              "0      [2, 4, 5, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
              "1      [2, 7, 8, 9, 10, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n",
              "2      [2, 11, 12, 13, 14, 15, 16, 17, 1, 1, 1, 1, 1,...   \n",
              "3      [2, 18, 19, 20, 21, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n",
              "4      [2, 22, 23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1...   \n",
              "...                                                  ...   \n",
              "11032  [2, 3724, 15517, 741, 15520, 1215, 797, 1, 1, ...   \n",
              "11033  [2, 15521, 3850, 751, 465, 2632, 2354, 2246, 1...   \n",
              "11034  [2, 15522, 15523, 15524, 3612, 502, 2246, 1, 1...   \n",
              "11035  [2, 15521, 15525, 15526, 1, 1, 1, 1, 1, 1, 1, ...   \n",
              "11036  [2, 15527, 15528, 758, 8712, 1, 1, 1, 1, 1, 1,...   \n",
              "\n",
              "                                     Padded_Tamil_Target  \n",
              "0      [4, 5, 6, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "1      [7, 8, 9, 10, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...  \n",
              "2      [11, 12, 13, 14, 15, 16, 17, 3, 1, 1, 1, 1, 1,...  \n",
              "3      [18, 19, 20, 21, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1,...  \n",
              "4      [22, 23, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1...  \n",
              "...                                                  ...  \n",
              "11032  [3724, 15517, 741, 15520, 1215, 797, 3, 1, 1, ...  \n",
              "11033  [15521, 3850, 751, 465, 2632, 2354, 2246, 3, 1...  \n",
              "11034  [15522, 15523, 15524, 3612, 502, 2246, 3, 1, 1...  \n",
              "11035  [15521, 15525, 15526, 3, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "11036  [15527, 15528, 758, 8712, 3, 1, 1, 1, 1, 1, 1,...  \n",
              "\n",
              "[11037 rows x 7 columns]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Example of the maximum padding length\n",
        "max_pad = 24\n",
        "cls_token = 2\n",
        "sep_token = 3\n",
        "\n",
        "# Function to pad sequences\n",
        "def pad_sequence_source(tokens, max_len, cls_token=2,sep_token = 3):\n",
        "    # Add the cls token at the beginning\n",
        "    padded_tokens = [cls_token] + tokens + [sep_token]\n",
        "    #padded_tokens = padded_tokens + [sep_token]\n",
        "\n",
        "    # Pad the sequence if it's shorter than max_len\n",
        "    if len(padded_tokens) < max_len:\n",
        "        padded_tokens.extend([1] * (max_len - len(padded_tokens)))\n",
        "    # Truncate if it's longer than max_len\n",
        "    else:\n",
        "        padded_tokens = padded_tokens[:max_len]\n",
        "\n",
        "    return padded_tokens\n",
        "\n",
        "def pad_sequence_target(tokens, max_len, cls_token = 2):\n",
        "    # Add the cls token at the beginning\n",
        "    padded_tokens = [cls_token] + tokens\n",
        "\n",
        "    # Pad the sequence if it's shorter than max_len\n",
        "    if len(padded_tokens) < max_len:\n",
        "        padded_tokens.extend([1] * (max_len - len(padded_tokens)))\n",
        "    # Truncate if it's longer than max_len\n",
        "    else:\n",
        "        padded_tokens = padded_tokens[:max_len]\n",
        "\n",
        "    return padded_tokens\n",
        "\n",
        "def pad_sequence_label(tokens, max_len, sep_token = 3):\n",
        "    # Add the cls token at the beginning\n",
        "    padded_tokens = tokens + [sep_token]\n",
        "\n",
        "    # Pad the sequence if it's shorter than max_len\n",
        "    if len(padded_tokens) < max_len:\n",
        "        padded_tokens.extend([1] * (max_len - len(padded_tokens)))\n",
        "    # Truncate if it's longer than max_len\n",
        "    else:\n",
        "        padded_tokens = padded_tokens[:max_len]\n",
        "\n",
        "    return padded_tokens\n",
        "\n",
        "# Apply padding and add CLS token to both English and Tamil columns\n",
        "df['Padded_English'] = df['Tokenized_English'].apply(lambda x: pad_sequence_source(x, max_pad, cls_token,sep_token))\n",
        "df['Padded_Tamil'] = df['Tokenized_Tamil'].apply(lambda x: pad_sequence_target(x, max_pad, cls_token))\n",
        "df['Padded_Tamil_Target'] = df['Tokenized_Tamil'].apply(lambda x: pad_sequence_label(x, max_pad,sep_token))\n",
        "# Verify the result\n",
        "#print(df[['Padded_English', 'Padded_Tamil','Padded_Tamil_Target']].head(-10))\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EF922fPPCCM8",
        "outputId": "3d96bd6c-c651-427d-ef27-34ce4728f9a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train DataFrame:\n",
            "8829\n",
            "\n",
            "Test DataFrame:\n",
            "2208\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Find the midpoint\n",
        "threshold = int(len(df)*0.8)\n",
        "\n",
        "# Split into two halves\n",
        "train = df.iloc[:threshold]\n",
        "test = df.iloc[threshold:]\n",
        "\n",
        "print(\"Train DataFrame:\")\n",
        "print(len(train))\n",
        "print(\"\\nTest DataFrame:\")\n",
        "print(len(test))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "xhaYFGS8kUXX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, dataframe, pad_token=1):\n",
        "        self.dataframe = dataframe\n",
        "        self.pad_token = pad_token  # Padding value, typically 0\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get the tokenized sequences for English and Tamil\n",
        "        english =  self.dataframe.iloc[idx][\"English\"]\n",
        "        tamil =  self.dataframe.iloc[idx][\"Tamil\"]\n",
        "        english_tokens =  torch.tensor(self.dataframe.iloc[idx][\"Padded_English\"],  dtype=torch.long)  # Shape: (T_english,)\n",
        "        tamil_tokens = torch.tensor(self.dataframe.iloc[idx][\"Padded_Tamil\"],  dtype=torch.long)   # Shape: (T_tamil,)\n",
        "        tamil_target_tokens = torch.tensor(self.dataframe.iloc[idx][\"Padded_Tamil_Target\"],  dtype=torch.long)   # Shape: (T_tamil_target,)\n",
        "\n",
        "\n",
        "        def causal_mask(size):\n",
        "              mask = torch.triu(torch.ones((1, size, size)), diagonal=1).type(torch.int)\n",
        "              return mask == 0\n",
        "    # Return the sequence and masks in a dictionary\n",
        "        return {\n",
        "            \"english\": english,\n",
        "            \"tamil\": tamil,\n",
        "            \"english_token\": english_tokens.clone(),\n",
        "            \"tamil_token\": tamil_tokens.clone(),\n",
        "            \"tamil_target\": tamil_target_tokens.clone(),\n",
        "            \"encoder_mask\": (english_tokens != self.pad_token).unsqueeze(0).unsqueeze(0).int().clone(),\n",
        "            \"decoder_mask\": (tamil_tokens != self.pad_token).unsqueeze(0).int() & causal_mask(tamil_tokens.size(0)).clone(),\n",
        "\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueABUeLQkaJe",
        "outputId": "cb437299-d97b-4b6f-903e-1ba816f3af5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 1:\n",
            "  English sequence shape: He will do anything to make money\n",
            "  Tamil sequence shape: பணம் சம்பாதிப்பதற்காக எதையும் செய்வார்\n",
            "  English token shape: tensor([  2, 846,  25,  94, 370,   9,  73, 211,   3,   1,   1,   1,   1,   1,\n",
            "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1])\n",
            "  tamil token shape: torch.Size([32, 24])\n",
            "  Tamil target sequence shape: tensor([ 185, 6418, 1217, 6419,    3,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1])\n",
            "  English pad mask shape: tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0]]], dtype=torch.int32)\n",
            "  Combined Tamil mask shape: tensor([[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0]]], dtype=torch.int32)\n",
            "Batch 1:\n",
            "  English sequence shape: Youre much less likely to get a good position if you dont speak English\n",
            "  Tamil sequence shape: நீங்கள் ஆங்கிலம் பேசவில்லை என்றால் நீங்கள் ஒரு நல்ல பதவியைப் பெறுவதற்கான வாய்ப்புகள் மிகக் குறைவு\n",
            "  English token shape: tensor([   2,   62,  350, 1475, 1860,    9,  380,   31,  326, 2943,   55,   83,\n",
            "          40,  491,  492,    3,    1,    1,    1,    1,    1,    1,    1,    1])\n",
            "  tamil token shape: torch.Size([1, 24])\n",
            "  Tamil target sequence shape: tensor([   52,   554,  8355,   416,    52,    36,    54, 15276,  1679,  2766,\n",
            "          822,  1368,     3,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1])\n",
            "  English pad mask shape: tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0]]], dtype=torch.int32)\n",
            "  Combined Tamil mask shape: tensor([[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0]]], dtype=torch.int32)\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Assuming you have your Dataset class `TranslationDataset` and DataLoader defined\n",
        "# Example DataLoader for your dataset\n",
        "train_dataset = TranslationDataset(train)  # Your dataframe should be defined\n",
        "train_dataloader = DataLoader(train_dataset, batch_size = 32, shuffle=True)  # Set batch_size as needed\n",
        "test_dataset = TranslationDataset(test)  # Your dataframe should be defined\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True)  # Set batch_size as needed\n",
        "\n",
        "# Iterate through batches\n",
        "for batch_idx, batch in enumerate(train_dataloader):\n",
        "    print(f\"Batch {batch_idx + 1}:\")\n",
        "\n",
        "    # Check the shapes of each tensor in the batch\n",
        "    print(f\"  English sequence shape: {batch['english'][0]}\")  # Expected: (batch_size, T_english)\n",
        "    print(f\"  Tamil sequence shape: {batch['tamil'][0]}\")  # Expected: (batch_size, T_tamil)\n",
        "    print(f\"  English token shape: {batch['english_token'][0]}\")  # Expected: (batch_size, T_english)\n",
        "    print(f\"  tamil token shape: {batch['tamil_token'].shape}\")  # Expected: (batch_size, T_english)\n",
        "    print(f\"  Tamil target sequence shape: {batch['tamil_target'][0]}\")  # Expected: (batch_size, T_tamil_target)\n",
        "    print(f\"  English pad mask shape: {batch['encoder_mask'][0]}\")  # Expected: (batch_size, T_english, T_english)\n",
        "    print(f\"  Combined Tamil mask shape: {batch['decoder_mask'][0]}\")  # Expected: (batch_size, T_tamil_target, T_tamil_target)\n",
        "    break\n",
        "    print(\"\\n\")  # Add a newline for better readability between batches\n",
        "\n",
        "# Iterate through batches\n",
        "for batch_idx, batch in enumerate(test_dataloader):\n",
        "    print(f\"Batch {batch_idx + 1}:\")\n",
        "\n",
        "    # Check the shapes of each tensor in the batch\n",
        "    print(f\"  English sequence shape: {batch['english'][0]}\")  # Expected: (batch_size, T_english)\n",
        "    print(f\"  Tamil sequence shape: {batch['tamil'][0]}\")  # Expected: (batch_size, T_tamil)\n",
        "    print(f\"  English token shape: {batch['english_token'][0]}\")  # Expected: (batch_size, T_english)\n",
        "    print(f\"  tamil token shape: {batch['tamil_token'].shape}\")  # Expected: (batch_size, T_english)\n",
        "    print(f\"  Tamil target sequence shape: {batch['tamil_target'][0]}\")  # Expected: (batch_size, T_tamil_target)\n",
        "    print(f\"  English pad mask shape: {batch['encoder_mask'][0]}\")  # Expected: (batch_size, T_english, T_english)\n",
        "    print(f\"  Combined Tamil mask shape: {batch['decoder_mask'][0]}\")  # Expected: (batch_size, T_tamil_target, T_tamil_target)\n",
        "    break\n",
        "    print(\"\\n\")  # Add a newline for better readability between batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSLGhcoFmxla",
        "outputId": "ab96b1ea-0057-4cb3-e3d6-84b72044a3c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Check if CUDA is available and set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9R7ZjgrCJaO7",
        "outputId": "7a1f9deb-88fe-4b62-9b0f-4007c83e26ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary: 15529\n",
            "Vocabulary: 8100\n"
          ]
        }
      ],
      "source": [
        "print(\"Vocabulary:\", len(tamil_tokenizer.word_to_id))\n",
        "print(\"Vocabulary:\", len(english_tokenizer.word_to_id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "omdKlJ5Emxla"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)]\n",
        "\n",
        "class MultiHeadSelfAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model: int, h: int, dropout: float) -> None:\n",
        "        super().__init__()\n",
        "        self.d_model = d_model # Embedding vector size\n",
        "        self.h = h # Number of heads\n",
        "        # Make sure d_model is divisible by h\n",
        "        assert d_model % h == 0, \"d_model is not divisible by h\"\n",
        "\n",
        "        self.d_k = d_model // h # Dimension of vector seen by each head\n",
        "        self.w_q = nn.Linear(d_model, d_model, bias=False) # Wq\n",
        "        self.w_k = nn.Linear(d_model, d_model, bias=False) # Wk\n",
        "        self.w_v = nn.Linear(d_model, d_model, bias=False) # Wv\n",
        "        self.w_o = nn.Linear(d_model, d_model, bias=False) # Wo\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    @staticmethod\n",
        "    def attention(query, key, value, mask, dropout: nn.Dropout):\n",
        "        d_k = query.shape[-1]\n",
        "        # Just apply the formula from the paper\n",
        "        # (batch, h, seq_len, d_k) --> (batch, h, seq_len, seq_len)\n",
        "        attention_scores = (query @ key.transpose(-2, -1)) / math.sqrt(d_k)\n",
        "        if mask is not None:\n",
        "            # Write a very low value (indicating -inf) to the positions where mask == 0\n",
        "            attention_scores.masked_fill_(mask == 0, -1e9)\n",
        "        attention_scores = attention_scores.softmax(dim=-1) # (batch, h, seq_len, seq_len) # Apply softmax\n",
        "        if dropout is not None:\n",
        "            attention_scores = dropout(attention_scores)\n",
        "        # (batch, h, seq_len, seq_len) --> (batch, h, seq_len, d_k)\n",
        "        # return attention scores which can be used for visualization\n",
        "        return (attention_scores @ value), attention_scores\n",
        "\n",
        "    def forward(self, q, k, v, mask):\n",
        "        query = self.w_q(q) # (batch, seq_len, d_model) --> (batch, seq_len, d_model)\n",
        "        key = self.w_k(k) # (batch, seq_len, d_model) --> (batch, seq_len, d_model)\n",
        "        value = self.w_v(v) # (batch, seq_len, d_model) --> (batch, seq_len, d_model)\n",
        "\n",
        "        # (batch, seq_len, d_model) --> (batch, seq_len, h, d_k) --> (batch, h, seq_len, d_k)\n",
        "        query = query.view(query.shape[0], query.shape[1], self.h, self.d_k).transpose(1, 2)\n",
        "        key = key.view(key.shape[0], key.shape[1], self.h, self.d_k).transpose(1, 2)\n",
        "        value = value.view(value.shape[0], value.shape[1], self.h, self.d_k).transpose(1, 2)\n",
        "\n",
        "        # Calculate attention\n",
        "        x, self.attention_scores = MultiHeadSelfAttention.attention(query, key, value, mask, self.dropout)\n",
        "\n",
        "        # Combine all the heads together\n",
        "        # (batch, h, seq_len, d_k) --> (batch, seq_len, h, d_k) --> (batch, seq_len, d_model)\n",
        "        x = x.transpose(1, 2).contiguous().view(x.shape[0], -1, self.h * self.d_k)\n",
        "\n",
        "        # Multiply by Wo\n",
        "        # (batch, seq_len, d_model) --> (batch, seq_len, d_model)\n",
        "        return self.w_o(x)\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff):\n",
        "        super(FeedForward, self).__init__()\n",
        "        self.linear1 = nn.Linear(d_model, d_ff)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(d_ff, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear2(self.relu(self.linear1(x)))\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, n_heads, d_ff, dropout=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.attn = MultiHeadSelfAttention(d_model, n_heads, dropout)\n",
        "        self.ff = FeedForward(d_model, d_ff)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        attn_output = self.attn(x,x,x, mask)\n",
        "        x = self.norm1(x + self.dropout(attn_output))\n",
        "        ff_output = self.ff(x)\n",
        "        x = self.norm2(x + self.dropout(ff_output))\n",
        "        return x\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, n_heads, d_ff, dropout=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.self_attn = MultiHeadSelfAttention(d_model, n_heads, dropout)\n",
        "        self.enc_attn = MultiHeadSelfAttention(d_model, n_heads, dropout)\n",
        "        self.ff = FeedForward(d_model, d_ff)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
        "        self_attn_output = self.self_attn(x ,x, x, tgt_mask)\n",
        "        x = self.norm1(x + self.dropout(self_attn_output))\n",
        "        enc_attn_output = self.enc_attn(x, enc_output, enc_output, src_mask)\n",
        "        x = self.norm2(x + self.dropout(enc_attn_output))\n",
        "        ff_output = self.ff(x)\n",
        "        x = self.norm3(x + self.dropout(ff_output))\n",
        "        return x\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, d_model, n_heads, d_ff, n_layers, dropout=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, d_model)\n",
        "        self.positional_encoding = PositionalEncoding(d_model)\n",
        "        self.layers = nn.ModuleList([EncoderLayer(d_model, n_heads, d_ff, dropout) for _ in range(n_layers)])\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        x = self.embedding(src)\n",
        "        x = self.positional_encoding(x)\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, src_mask)\n",
        "        return x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, d_model, n_heads, d_ff, n_layers, dropout=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_dim, d_model)\n",
        "        self.positional_encoding = PositionalEncoding(d_model)\n",
        "        self.layers = nn.ModuleList([DecoderLayer(d_model, n_heads, d_ff, dropout) for _ in range(n_layers)])\n",
        "        self.fc_out = nn.Linear(d_model, output_dim)\n",
        "\n",
        "    def forward(self, tgt, enc_output, src_mask, tgt_mask):\n",
        "        x = self.embedding(tgt)\n",
        "        x = self.positional_encoding(x)\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, enc_output, src_mask, tgt_mask)\n",
        "\n",
        "        return self.fc_out(x)\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, n_heads, d_ff, n_enc_layers, n_dec_layers, dropout=0.1):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.encoder = Encoder(src_vocab_size, d_model, n_heads, d_ff, n_enc_layers, dropout)\n",
        "        self.decoder = Decoder(tgt_vocab_size, d_model, n_heads, d_ff, n_dec_layers, dropout)\n",
        "\n",
        "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
        "        enc_output = self.encoder(src, src_mask)\n",
        "        output = self.decoder(tgt, enc_output, src_mask, tgt_mask)\n",
        "        return output\n",
        "\n",
        "src_vocab_size = 8100\n",
        "tgt_vocab_size = 15529\n",
        "d_model = 64\n",
        "n_heads = 8\n",
        "d_ff = 512\n",
        "n_enc_layers = 8\n",
        "n_dec_layers = 8\n",
        "dropout = 0.1\n",
        "\n",
        "model = Transformer(src_vocab_size, tgt_vocab_size, d_model, n_heads, d_ff, n_enc_layers, n_dec_layers, dropout).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avIaJ4h0mxla",
        "outputId": "8bdb2703-738a-4223-d7b1-82fc8a10e002"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total model parameters: 3977769\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters())\n",
        "# Assuming 'model' is your PyTorch model\n",
        "total_params = count_parameters(model)\n",
        "print(f\"Total model parameters: {total_params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_tolnaPmxlb",
        "outputId": "e839cefa-6006-4b93-fd1a-f9e7d98ae244"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "English Vocabulary: 8100\n",
            "Tamil Vocabulary: 15529\n"
          ]
        }
      ],
      "source": [
        "print(\"English Vocabulary:\", len(english_tokenizer.word_to_id))\n",
        "print(\"Tamil Vocabulary:\", len(tamil_tokenizer.word_to_id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "aRq93fGu84Fs",
        "outputId": "cf2df1ee-be3d-4eaf-f790-04394e98ec15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Device name: NVIDIA GeForce GTX 1060 6GB\n",
            "Device memory: 5.999755859375 GB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 00:   0%|          | 0/276 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 00: 100%|██████████| 276/276 [00:26<00:00, 10.45it/s, loss=7.870]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:If you have some troubles I recommend you confer with him\n",
            "     TARGET:உங்களுக்கு ஏதேனும் சிக்கல்கள் இருந்தால் அவரிடம் பேச பரிந்துரைக்கிறேன்\n",
            "  PREDICTED:<SOS> நீங்கள் <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 01: 100%|██████████| 276/276 [00:26<00:00, 10.50it/s, loss=7.234]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:Shall I drive you home\n",
            "     TARGET:நான் உன்னை வீட்டிற்கு ஓட்டலாமா\n",
            "  PREDICTED:<SOS> நீங்கள் <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 02: 100%|██████████| 276/276 [00:26<00:00, 10.54it/s, loss=7.110]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:Give me a break If you have something to say stop making faces and say it\n",
            "     TARGET:எனக்கு ஓய்வு கொடுங்கள் நீங்கள் ஏதாவது சொல்ல வேண்டும் என்றால் முகம் காட்டுவதை நிறுத்திவிட்டு சொல்லுங்கள்\n",
            "  PREDICTED:<SOS> நீங்கள் நீங்கள் <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 03: 100%|██████████| 276/276 [00:26<00:00, 10.51it/s, loss=7.125]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:Even if I grant that what you say is true it is no excuse\n",
            "     TARGET:நீங்கள் சொல்வது உண்மை என்று நான் ஒப்புக்கொண்டாலும் அது மன்னிக்க முடியாது\n",
            "  PREDICTED:<SOS> நீங்கள் நான் நான் நான் நான் நான் நான் <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 04: 100%|██████████| 276/276 [00:25<00:00, 10.64it/s, loss=6.835]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:I would have liked to see the ending of the film but I had to leave the theater\n",
            "     TARGET:நான் படத்தின் முடிவைப் பார்க்க விரும்பினேன் ஆனால் நான் தியேட்டரை விட்டு வெளியேற வேண்டியிருந்தது\n",
            "  PREDICTED:<SOS> நான் நான் நான் ஒரு நான் ஒரு என் நான் ஒரு என் வேண்டும் <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 05: 100%|██████████| 276/276 [00:25<00:00, 10.76it/s, loss=6.460]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:What is missing\n",
            "     TARGET:என்ன காணவில்லை\n",
            "  PREDICTED:<SOS> நீங்கள் ஒரு <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 06: 100%|██████████| 276/276 [00:25<00:00, 10.70it/s, loss=6.550]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:Black smoke came out of the chimney\n",
            "     TARGET:புகைபோக்கியில் இருந்து கருப்பு புகை வந்தது\n",
            "  PREDICTED:<SOS> இந்த ஒரு வெளிநாட்டு ஒரு நல்ல <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 07: 100%|██████████| 276/276 [00:26<00:00, 10.45it/s, loss=6.421]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:Procrastination is the thief of time\n",
            "     TARGET:தள்ளிப்போடுவது காலத்தின் திருடன்\n",
            "  PREDICTED:<SOS> ஒரு ஒரு என் <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 08: 100%|██████████| 276/276 [00:26<00:00, 10.60it/s, loss=6.090]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:What a waste of water\n",
            "     TARGET:என்ன தண்ணீர் வீணாகிறது\n",
            "  PREDICTED:<SOS> அவர் ஒரு ஒரு <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 09: 100%|██████████| 276/276 [00:26<00:00, 10.58it/s, loss=6.533]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:The king will appear in person tomorrow evening\n",
            "     TARGET:நாளை மாலை ராஜா நேரில் ஆஜராவார்\n",
            "  PREDICTED:<SOS> இந்த இந்த இந்த சில <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 10: 100%|██████████| 276/276 [00:26<00:00, 10.49it/s, loss=6.245]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:What time is dinner\n",
            "     TARGET:இரவு உணவு எத்தனை மணிக்கு\n",
            "  PREDICTED:<SOS> இந்த என்ன <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 11: 100%|██████████| 276/276 [00:26<00:00, 10.59it/s, loss=5.999]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:Have you begun studying English\n",
            "     TARGET:நீங்கள் ஆங்கிலம் படிக்க ஆரம்பித்து விட்டீர்களா\n",
            "  PREDICTED:<SOS> நீங்கள் என்ன முடியாது <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 12: 100%|██████████| 276/276 [00:26<00:00, 10.50it/s, loss=5.397]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:Well what\n",
            "     TARGET:நாம் என்ன செய்வோம்\n",
            "  PREDICTED:<SOS> நீங்கள் என்ன <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 13: 100%|██████████| 276/276 [00:25<00:00, 10.68it/s, loss=5.773]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:Summer has come\n",
            "     TARGET:கோடை காலம் வந்துவிட்டது\n",
            "  PREDICTED:<SOS> என் இல்லை <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 14: 100%|██████████| 276/276 [00:25<00:00, 10.75it/s, loss=5.514]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:You may take this book as long as you keep it clean\n",
            "     TARGET:இந்த புத்தகத்தை நீங்கள் சுத்தமாக வைத்திருக்கும் வரை நீங்கள் அதை எடுத்துக் கொள்ளலாம்\n",
            "  PREDICTED:<SOS> நீங்கள் இந்த நாட்களில் நீங்கள் இந்த நாட்களில் நீங்கள் என்ன நல்லது <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 15: 100%|██████████| 276/276 [00:25<00:00, 10.74it/s, loss=5.582]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:English law prohibits children under 16 from buying cigarettes\n",
            "     TARGET:16 வயதுக்குட்பட்ட குழந்தைகள் சிகரெட் வாங்குவதை ஆங்கிலேய சட்டம் தடை செய்கிறது\n",
            "  PREDICTED:<SOS> இந்த நாட்களில் நல்ல வேலை மற்றும் நல்ல ஆனால் அது <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 16: 100%|██████████| 276/276 [00:25<00:00, 10.69it/s, loss=5.660]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:Salt preserves fish from spoilage\n",
            "     TARGET:உப்பு மீன்களை கெட்டுப்போகாமல் பாதுகாக்கிறது\n",
            "  PREDICTED:<SOS> அவர் மிகவும் மிகவும் இல்லை <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 17: 100%|██████████| 276/276 [00:25<00:00, 10.83it/s, loss=5.331]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:As far as English is concerned nobody can beat me\n",
            "     TARGET:ஆங்கிலத்தைப் பொறுத்த வரை என்னை யாராலும் வெல்ல முடியாது\n",
            "  PREDICTED:<SOS> எனக்கு தனது தனது அவர் என்னை ஒரு நாள் எனக்கு ஆச்சரியமாக <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 18: 100%|██████████| 276/276 [00:25<00:00, 10.75it/s, loss=5.419]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:An Englishman is an alien in the United States\n",
            "     TARGET:அமெரிக்காவில் ஒரு ஆங்கிலேயர் வேற்றுகிரகவாசி\n",
            "  PREDICTED:<SOS> ஒரு நல்ல காரணமாக நாங்கள் ஒரு நல்ல இருந்தது <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 19: 100%|██████████| 276/276 [00:25<00:00, 10.85it/s, loss=5.427]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:After a couple of drinks the guy was feeling no pain\n",
            "     TARGET:இரண்டு பானங்களுக்குப் பிறகு பையன் வலியை உணரவில்லை\n",
            "  PREDICTED:<SOS> ஒரு விதியாக ஒரு பெரிய உள்ள உள்ள உள்ள உள்ள உள்ள உள்ள உள்ள மணிக்கு அவர் மிகவும் இல்லை <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 20: 100%|██████████| 276/276 [00:25<00:00, 10.75it/s, loss=4.862]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:Dozens of young people attended the demonstration\n",
            "     TARGET:ஆர்ப்பாட்டத்தில் நூற்றுக்கணக்கான இளைஞர்கள் கலந்து கொண்டனர்\n",
            "  PREDICTED:<SOS> ஒவ்வொரு நாள் பள்ளி கலந்து கொண்டனர் <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 21: 100%|██████████| 276/276 [00:25<00:00, 10.72it/s, loss=5.211]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:I delighted in going to his farm during the summer vacation\n",
            "     TARGET:கோடை விடுமுறையில் அவருடைய பண்ணைக்குச் செல்வதில் மகிழ்ச்சி அடைந்தேன்\n",
            "  PREDICTED:<SOS> அவரது அவரது அவரது வீட்டில் நான் விரும்புகிறேன் <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 22: 100%|██████████| 276/276 [00:26<00:00, 10.50it/s, loss=4.804]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:A fire was seen to blaze up far away\n",
            "     TARGET:வெகு தொலைவில் நெருப்பு எரிவது தெரிந்தது\n",
            "  PREDICTED:<SOS> தீ ஏற்பட்டால் ஒரு நாள் இந்த வழியில் <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 23: 100%|██████████| 276/276 [00:26<00:00, 10.53it/s, loss=4.808]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:I gazed at the sea for hours\n",
            "     TARGET:மணிக்கணக்கில் கடலைப் பார்த்தேன்\n",
            "  PREDICTED:<SOS> நான் பணம் நேரத்தில் செல்ல வேண்டும் <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 24: 100%|██████████| 276/276 [00:26<00:00, 10.59it/s, loss=4.629]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:Concert tickets are on sale at this office\n",
            "     TARGET:இந்த அலுவலகத்தில் கச்சேரி டிக்கெட் விற்பனை செய்யப்படுகிறது\n",
            "  PREDICTED:<SOS> இந்த இந்த நாட்களில் அவர் இந்த வழியில் உள்ளன <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 25: 100%|██████████| 276/276 [00:25<00:00, 10.68it/s, loss=4.640]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:English is a language abounding in idiomatic expressions\n",
            "     TARGET:ஆங்கிலம் என்பது மொழியியல் வெளிப்பாடுகள் நிறைந்த மொழி\n",
            "  PREDICTED:<SOS> ஒரு வெளிநாட்டு மொழியைக் நேரம் இருக்கும் <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 26: 100%|██████████| 276/276 [00:26<00:00, 10.60it/s, loss=4.455]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:The value of the yen has soared\n",
            "     TARGET:யென் மதிப்பு உயர்ந்துள்ளது\n",
            "  PREDICTED:<SOS> பொதுவாக நிலையத்தில் மீது உள்ளதா <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 27: 100%|██████████| 276/276 [00:26<00:00, 10.44it/s, loss=4.203]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:There must be another way\n",
            "     TARGET:வேறு வழி இருக்க வேண்டும்\n",
            "  PREDICTED:<SOS> ஒவ்வொரு உதவ வேண்டும் <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 28: 100%|██████████| 276/276 [00:25<00:00, 10.68it/s, loss=4.318]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:The prince succeeded to the throne\n",
            "     TARGET:இளவரசர் வெற்றி பெற்று அரியணை ஏறினார்\n",
            "  PREDICTED:<SOS> பாலம் உள்ள மணிக்கு தொடங்கியது <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 29: 100%|██████████| 276/276 [00:26<00:00, 10.57it/s, loss=4.454]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:What time does boarding begin\n",
            "     TARGET:போர்டிங் எந்த நேரத்தில் தொடங்குகிறது\n",
            "  PREDICTED:<SOS> எத்தனை மணிக்கு நேரம் மணிக்கு <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 30: 100%|██████████| 276/276 [00:25<00:00, 10.69it/s, loss=4.045]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:Can you see something red down below\n",
            "     TARGET:கீழே ஏதாவது சிவப்பு நிறத்தைக் காண முடியுமா\n",
            "  PREDICTED:<SOS> நீங்கள் மிகவும் கடினமாக உழைக்கிறீர்கள் முடியுமா <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 31: 100%|██████████| 276/276 [00:26<00:00, 10.57it/s, loss=3.950]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:Thank you very much for coming so far as see me off\n",
            "     TARGET:இவ்வளவு தூரம் என்னைப் பார்க்க வந்ததற்கு மிக்க நன்றி\n",
            "  PREDICTED:<SOS> நீங்கள் என்னை மிகவும் கடினமாக உழைக்கிறீர்கள் என்னை மிகவும் கடினமாக இருக்கிறது <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 32: 100%|██████████| 276/276 [00:25<00:00, 10.62it/s, loss=4.101]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:My heart is trembling\n",
            "     TARGET:என் இதயம் நடுங்குகிறது\n",
            "  PREDICTED:<SOS> என் மீது என் இல்லை <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 33: 100%|██████████| 276/276 [00:26<00:00, 10.55it/s, loss=4.020]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:A penny for your thoughts\n",
            "     TARGET:உங்கள் எண்ணங்களுக்கு ஒரு பைசா\n",
            "  PREDICTED:<SOS> உங்கள் ஆரோக்கியத்திற்கு வெளிர் இருந்தது <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 34: 100%|██████████| 276/276 [00:26<00:00, 10.53it/s, loss=3.821]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:The strong yen was a fatal blow to the company\n",
            "     TARGET:வலுவான யென் நிறுவனத்திற்கு ஒரு மரண அடியாக இருந்தது\n",
            "  PREDICTED:<SOS> நிறுவனம் கடுமையான மற்றும் வெளிநாட்டு மொழியைக் கற்றுக்கொள்வது <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 35: 100%|██████████| 276/276 [00:25<00:00, 10.71it/s, loss=3.704]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:I spoke to him in English and found I could make myself understood\n",
            "     TARGET:நான் அவரிடம் ஆங்கிலத்தில் பேசினேன் என்னைப் புரிந்து கொள்ள முடிந்தது\n",
            "  PREDICTED:<SOS> நான் அவரை இப்போது அவரை நடந்து ஆனால் நான் அவரைப் ஒரு நாள் விரும்புகிறேன் <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 36: 100%|██████████| 276/276 [00:26<00:00, 10.57it/s, loss=4.137]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:There wasnt anybody in the house\n",
            "     TARGET:வீட்டில் யாரும் இல்லை\n",
            "  PREDICTED:<SOS> மலையில் வீடு உள்ளது <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 37: 100%|██████████| 276/276 [00:26<00:00, 10.54it/s, loss=3.580]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:They were dancing with the music\n",
            "     TARGET:அவர்கள் இசையுடன் நடனமாடினார்கள்\n",
            "  PREDICTED:<SOS> அவர்கள் அவர்கள் தெரியவில்லை <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 38: 100%|██████████| 276/276 [00:26<00:00, 10.52it/s, loss=3.709]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:After the movie they fall asleep\n",
            "     TARGET:படம் முடிந்ததும் அவர்கள் தூங்கிவிடுவார்கள்\n",
            "  PREDICTED:<SOS> பணம் சந்தை கலந்து கொண்டனர் <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 39: 100%|██████████| 276/276 [00:25<00:00, 10.66it/s, loss=3.633]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:The noise grew fainter until it wasnt heard anymore\n",
            "     TARGET:சத்தம் இன்னும் கேட்காத வரை மங்கலானது\n",
            "  PREDICTED:<SOS> அவருடைய புதிய அணி சீக்கிரம் தவறவிடுவீர்கள் <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 40: 100%|██████████| 276/276 [00:25<00:00, 10.66it/s, loss=3.454]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:After the movie they fall asleep\n",
            "     TARGET:படம் முடிந்ததும் அவர்கள் தூங்கிவிடுவார்கள்\n",
            "  PREDICTED:<SOS> பங்குச் சந்தை பணம் உள்ளதா <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 41: 100%|██████████| 276/276 [00:25<00:00, 10.63it/s, loss=2.830]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:I waited for him at the station for an hour but he didnt show up\n",
            "     TARGET:நான் அவருக்காக ஸ்டேஷனில் ஒரு மணி நேரம் காத்திருந்தேன் ஆனால் அவர் வரவில்லை\n",
            "  PREDICTED:<SOS> நான் அவரை எங்கள் சொந்த அவரை ஒரு சிறிய பார்த்தோம் ஆனால் நான் விரும்புகிறேன் <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 42: 100%|██████████| 276/276 [00:26<00:00, 10.56it/s, loss=3.046]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:The king will appear in person tomorrow evening\n",
            "     TARGET:நாளை மாலை ராஜா நேரில் ஆஜராவார்\n",
            "  PREDICTED:<SOS> நாளை நாளை நாளை நாளை நாளை காலம் இருக்காது <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 43: 100%|██████████| 276/276 [00:26<00:00, 10.56it/s, loss=3.162]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:I need to find out exactly what went wrong\n",
            "     TARGET:என்ன தவறு நடந்தது என்பதை நான் கண்டுபிடிக்க வேண்டும்\n",
            "  PREDICTED:<SOS> நான் என்ன செய்ய வேண்டும் என்று நான் நினைக்கிறேன் <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 44: 100%|██████████| 276/276 [00:26<00:00, 10.55it/s, loss=2.760]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:I will be able to see you tomorrow unless something unexpected turns up\n",
            "     TARGET:எதிர்பாராமல் ஏதாவது நடந்தால் நாளை உங்களைப் பார்க்க முடியும்\n",
            "  PREDICTED:<SOS> நாளை நாட்களில் நான் அதை நாட்களில் நீங்கள் என்னை வந்து இருக்கும் <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 45: 100%|██████████| 276/276 [00:26<00:00, 10.44it/s, loss=3.031]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:As I reached the station I got off the bus\n",
            "     TARGET:நிலையத்தை அடைந்ததும் பேருந்தை விட்டு இறங்கினேன்\n",
            "  PREDICTED:<SOS> நான் வீட்டை விட்டு வெளியே விமான நிலையத்திற்கு எடுத்தார் <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 46: 100%|██████████| 276/276 [00:26<00:00, 10.55it/s, loss=3.049]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:Dont beat around the bush tell me who is to blame\n",
            "     TARGET:அடிக்காதே யார் குற்றம் சொல்லுங்கள்\n",
            "  PREDICTED:<SOS> என்னிடம் பணம் செலவழிக்க விரும்பவில்லை <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 47: 100%|██████████| 276/276 [00:26<00:00, 10.54it/s, loss=2.855]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:Has the movie started yet\n",
            "     TARGET:படம் இன்னும் தொடங்கவில்லையா\n",
            "  PREDICTED:<SOS> திடீரென்று அது ரத்து வந்தது <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 48: 100%|██████████| 276/276 [00:25<00:00, 10.70it/s, loss=2.518]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:I managed to catch the 8 oclock train by running all the way to the station\n",
            "     TARGET:8 மணி ரயிலை ஸ்டேஷன் வரை ஓடிப் பிடிக்க முடிந்தது\n",
            "  PREDICTED:<SOS> ரயில் நிலையத்தை வழியில் நான் தோலில் நனைந்திருப்பேன் <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 49: 100%|██████████| 276/276 [00:26<00:00, 10.57it/s, loss=2.863]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:We must put safety before anything else\n",
            "     TARGET:நாம் எதற்கும் முன் பாதுகாப்பை வைக்க வேண்டும்\n",
            "  PREDICTED:<SOS> அந்த திட்டத்தை நாம் வேலை செய்ய வேண்டும் <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 50: 100%|██████████| 276/276 [00:26<00:00, 10.53it/s, loss=2.672]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:Could you tell me the way to the station\n",
            "     TARGET:நிலையத்திற்கு செல்லும் வழியை சொல்ல முடியுமா\n",
            "  PREDICTED:<SOS> விமான நிலையத்திற்கு நிலையத்திற்கு நிலையத்திற்கு செல்வது என்று சொல்லுங்கள் <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 51: 100%|██████████| 276/276 [00:25<00:00, 10.69it/s, loss=2.716]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:The sound became fainter and fainter until at last it disappeared\n",
            "     TARGET:சத்தம் மங்கலாகவும் மங்கலாகவும் ஆனது கடைசியில் அது மறைந்துவிட்டது\n",
            "  PREDICTED:<SOS> கடந்த மற்றும் மற்றும் மற்றும் கடைசி மற்றும் மற்றும் மற்றும் மற்றும் அவரது எடுத்தார் சாப்பிடுகிறோம் <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 52: 100%|██████████| 276/276 [00:26<00:00, 10.59it/s, loss=2.552]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:I have been to the station\n",
            "     TARGET:நான் நிலையத்திற்கு சென்றிருக்கிறேன்\n",
            "  PREDICTED:<SOS> நான் தோலில் கண்டேன் <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 53: 100%|██████████| 276/276 [00:26<00:00, 10.53it/s, loss=2.238]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:Stop being lazy and find something to do\n",
            "     TARGET:சோம்பேறியாக இருப்பதை நிறுத்திவிட்டு ஏதாவது செய்ய வேண்டும்\n",
            "  PREDICTED:<SOS> தவறான உள்ள மற்றும் உள்ள மற்றும் விரைவாக மிகவும் கடினமாக உழைக்கிறீர்கள் <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 54: 100%|██████████| 276/276 [00:25<00:00, 10.66it/s, loss=2.073]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:It was not until I reached home that I missed my purse\n",
            "     TARGET:நான் வீட்டை அடைந்த பிறகுதான் என் பணப்பையை தவறவிட்டேன்\n",
            "  PREDICTED:<SOS> நான் வீட்டிற்கு செல்லும் போது என் வீட்டில் சொல்ல முடியவில்லை <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 55: 100%|██████████| 276/276 [00:26<00:00, 10.48it/s, loss=2.184]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:The coast was warned against a tsunami\n",
            "     TARGET:கடலோர பகுதிகளில் சுனாமி எச்சரிக்கை விடுக்கப்பட்டுள்ளது\n",
            "  PREDICTED:<SOS> கியோட்டோ எதிராக மாணவர்கள் பெரும் <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 56: 100%|██████████| 276/276 [00:25<00:00, 10.73it/s, loss=2.014]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:Not knowing what to see I asked him for advice\n",
            "     TARGET:என்ன பார்ப்பது என்று தெரியாமல் அவரிடம் ஆலோசனை கேட்டேன்\n",
            "  PREDICTED:<SOS> நான் அவரை அவளை அழைத்துச் சென்று விட்டார் <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 57: 100%|██████████| 276/276 [00:26<00:00, 10.61it/s, loss=2.192]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:English words are often borrowed by other languages\n",
            "     TARGET:ஆங்கில வார்த்தைகள் பெரும்பாலும் பிற மொழிகளால் கடன் வாங்கப்படுகின்றன\n",
            "  PREDICTED:<SOS> ஆங்கிலம் பெரும்பாலும் ஆங்கிலம் அடிக்கடி அடிக்கடி முன்னேற்றம் இப்போது உள்ளன <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 58: 100%|██████████| 276/276 [00:26<00:00, 10.54it/s, loss=1.915]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:Musicians are usually sensitive to criticism\n",
            "     TARGET:இசைக்கலைஞர்கள் பொதுவாக விமர்சனங்களுக்கு உணர்திறன் உடையவர்கள்\n",
            "  PREDICTED:<SOS> உள்ளூர் மரபுகள் வழிநடத்தப்பட்ட செய்கிறார்கள் <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 59: 100%|██████████| 276/276 [00:26<00:00, 10.44it/s, loss=2.088]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:There was an unfortunate incident at home\n",
            "     TARGET:வீட்டில் ஒரு அசம்பாவிதம் நடந்தது\n",
            "  PREDICTED:<SOS> வீட்டில் வழி உள்ளதா <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 60: 100%|██████████| 276/276 [00:25<00:00, 10.63it/s, loss=1.779]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:Something went off with a loud noise\n",
            "     TARGET:ஏதோ பெரிய சத்தத்துடன் கிளம்பியது\n",
            "  PREDICTED:<SOS> ஒரு நாள் முழுவதும் தண்ணீரில் போட்டார் <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 61: 100%|██████████| 276/276 [00:26<00:00, 10.57it/s, loss=1.622]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:Please remember to post the letter on your way home\n",
            "     TARGET:உங்கள் வீட்டிற்கு செல்லும் வழியில் கடிதத்தை இடுகையிட மறக்காதீர்கள்\n",
            "  PREDICTED:<SOS> உங்கள் வீட்டிற்கு செல்லும் வழியில் உள்ள செல்ல வேண்டாம் <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 62: 100%|██████████| 276/276 [00:25<00:00, 10.64it/s, loss=1.690]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:Tourists take over this island in the summer\n",
            "     TARGET:கோடை காலத்தில் சுற்றுலாப் பயணிகள் இந்தத் தீவைக் கைப்பற்றுகிறார்கள்\n",
            "  PREDICTED:<SOS> இந்த கோடையில் பிறகு இந்த கோடையில் சென்றனர் <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 63: 100%|██████████| 276/276 [00:25<00:00, 10.62it/s, loss=1.473]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:The roof slopes sharply\n",
            "     TARGET:கூரை கூர்மையாக சரிகிறது\n",
            "  PREDICTED:<SOS> குடும்பத்தினர் அனைவரும் கப்பலில் <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 64: 100%|██████████| 276/276 [00:26<00:00, 10.43it/s, loss=1.409]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:We have five days to go before the summer vacation\n",
            "     TARGET:கோடை விடுமுறைக்கு இன்னும் ஐந்து நாட்கள் உள்ளன\n",
            "  PREDICTED:<SOS> இந்த நாட்களில் முன் பள்ளி முன் செல்ல வேண்டும் <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 65: 100%|██████████| 276/276 [00:25<00:00, 10.71it/s, loss=1.447]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:For how many nights\n",
            "     TARGET:எத்தனை இரவுகளுக்கு\n",
            "  PREDICTED:<SOS> பல எத்தனை சாண்ட்விச்கள் உள்ளன <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 66: 100%|██████████| 276/276 [00:26<00:00, 10.60it/s, loss=1.165]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:Does depreciation of the yen give rise to inflation\n",
            "     TARGET:யென் மதிப்பு குறைவது பணவீக்கத்தை ஏற்படுத்துமா\n",
            "  PREDICTED:<SOS> நெருக்கமாகப் ஏரியின் எல்லையில் படிக்கிறீர்கள் <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 67: 100%|██████████| 276/276 [00:26<00:00, 10.40it/s, loss=1.494]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:It will take me 20 minutes to get to the station by taxi\n",
            "     TARGET:டாக்ஸியில் ஸ்டேஷனுக்குச் செல்ல எனக்கு 20 நிமிடங்கள் ஆகும்\n",
            "  PREDICTED:<SOS> நிலையத்திற்குச் செல்ல எவ்வளவு நேரம் ஆகும் <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 68: 100%|██████████| 276/276 [00:26<00:00, 10.51it/s, loss=1.243]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:How many nights would you like the room for\n",
            "     TARGET:எத்தனை இரவுகளுக்கு அறையை விரும்புகிறீர்கள்\n",
            "  PREDICTED:<SOS> எத்தனை முறை கண்ணாடியில் நீந்துவது என்று எனக்குத் தெரியும் <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 69: 100%|██████████| 276/276 [00:26<00:00, 10.57it/s, loss=1.269]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:He can speak either English or French\n",
            "     TARGET:அவர் ஆங்கிலம் அல்லது பிரஞ்சு பேசக்கூடியவர்\n",
            "  PREDICTED:<SOS> ஒவ்வொரு மாணவரும் ஆங்கிலம் அவளால் ஆங்கிலம் அவளால் என்ன <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 70: 100%|██████████| 276/276 [00:26<00:00, 10.57it/s, loss=1.231]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:We need a detailed description of what happened\n",
            "     TARGET:என்ன நடந்தது என்பது பற்றிய விரிவான விளக்கம் தேவை\n",
            "  PREDICTED:<SOS> ஆனால் நாம் சிறிது நேரம் ஒரு நல்ல பயணம் <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 71: 100%|██████████| 276/276 [00:25<00:00, 10.62it/s, loss=1.044]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:We have two television sets\n",
            "     TARGET:எங்களிடம் இரண்டு தொலைக்காட்சிப் பெட்டிகள் உள்ளன\n",
            "  PREDICTED:<SOS> நாங்கள் அனைவரும் ஏற்கனவே இருக்கிறோம் <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 72: 100%|██████████| 276/276 [00:26<00:00, 10.43it/s, loss=1.003]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:Please telephone me when you have made up your mind what you want to do\n",
            "     TARGET:நீங்கள் என்ன செய்ய விரும்புகிறீர்கள் என்பதை நீங்கள் தீர்மானித்தவுடன் தயவுசெய்து எனக்கு தொலைபேசி\n",
            "  PREDICTED:<SOS> நீங்கள் சொன்னது உங்கள் வீட்டுப்பாடத்தை என்றால் நீங்கள் என்ன செய்கிறீர்கள் என்று நான் உங்களுக்கு கொஞ்சம் ரொட்டியை <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 73: 100%|██████████| 276/276 [00:26<00:00, 10.44it/s, loss=1.109]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:Something happened and he couldnt keep his promise\n",
            "     TARGET:ஏதோ நடந்தது அவனால் வாக்குறுதியைக் காப்பாற்ற முடியவில்லை\n",
            "  PREDICTED:<SOS> அவர் தனது இறைச்சி வைத்து போல் இருக்க மறக்காதீர்கள் <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 74: 100%|██████████| 276/276 [00:26<00:00, 10.55it/s, loss=1.031]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:Dont speak to the driver while he is driving\n",
            "     TARGET:வாகனம் ஓட்டும் போது ஓட்டுனரிடம் பேச வேண்டாம்\n",
            "  PREDICTED:<SOS> கணிதம் என்பது தைரியமாக இடத்தில் எதிரி அவர் அடிக்கடி வந்தார் <EOS>\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "from torch.utils.data import random_split\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import WordLevel\n",
        "from tokenizers.trainers import WordLevelTrainer\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "\n",
        "\n",
        "\n",
        "epochs = 75\n",
        "lr = 10**-4\n",
        "\n",
        "def causal_mask(size):\n",
        "    mask = torch.triu(torch.ones((1, size, size)), diagonal=1).type(torch.int)\n",
        "    return mask == 0\n",
        "\n",
        "def greedy_decode(model, source, source_mask, tokenizer_src, tokenizer_tgt, max_len, device):\n",
        "    sos_idx, eos_idx = 2, 3\n",
        "    encoder_output = model.encoder(source.to(device), source_mask.to(device))\n",
        "    decoder_input = torch.empty(1, 1).fill_(sos_idx).type_as(source).to(device)\n",
        "\n",
        "    while decoder_input.size(1) < max_len:\n",
        "        decoder_mask = causal_mask(decoder_input.size(1)).type_as(source_mask).to(device)\n",
        "        out = model.decoder(decoder_input, encoder_output, source_mask, decoder_mask)\n",
        "        next_word = torch.max(out[:, -1], dim=1)[1]\n",
        "        decoder_input = torch.cat([decoder_input, next_word.view(1, 1).to(device)], dim=1)\n",
        "        if next_word == eos_idx: break\n",
        "\n",
        "    return decoder_input.squeeze(0)\n",
        "\n",
        "\n",
        "def run_validation(model, validation_ds, tokenizer_src, tokenizer_tgt, max_len, device, print_msg, num_examples=1):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    source_texts, expected, predicted = [], [], []\n",
        "    try:\n",
        "      console_width = os.get_terminal_size().columns\n",
        "    except OSError:\n",
        "      console_width = 80\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for count, batch in enumerate(validation_ds, start=1):\n",
        "            encoder_input, encoder_mask = batch[\"english_token\"].to(device), batch[\"encoder_mask\"].to(device)\n",
        "            assert encoder_input.size(0) == 1, \"Batch size must be 1 for validation\"\n",
        "            model_out = greedy_decode(model, encoder_input, encoder_mask, tokenizer_src, tokenizer_tgt, max_len, device)\n",
        "\n",
        "            source_text = batch[\"english\"][0]\n",
        "            target_text = batch[\"tamil\"][0]\n",
        "            model_out_text = tokenizer_tgt.decode(model_out.detach().cpu().numpy())\n",
        "\n",
        "            source_texts.append(source_text)\n",
        "            expected.append(target_text)\n",
        "            predicted.append(model_out_text)\n",
        "\n",
        "            print_msg(f\"{'-'*console_width}\\n{'SOURCE:':>12}{source_text}\\n{'TARGET:':>12}{target_text}\\n{'PREDICTED:':>12}{model_out_text}\")\n",
        "            if count == num_examples: break\n",
        "\n",
        "def train_model():\n",
        "\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.has_mps or torch.backends.mps.is_available() else \"cpu\"\n",
        "    print(\"Using device:\", device)\n",
        "    if device == 'cuda':\n",
        "        print(f\"Device name: {torch.cuda.get_device_name(device.index)}\")\n",
        "        print(f\"Device memory: {torch.cuda.get_device_properties(device.index).total_memory / 1024 ** 3} GB\")\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = lr, eps=1e-9)\n",
        "\n",
        "    initial_epoch = 0\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss(ignore_index= 1).to(device)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        torch.cuda.empty_cache()\n",
        "        model.train()\n",
        "        batch_iterator = tqdm(train_dataloader, desc=f\"Processing Epoch {epoch:02d}\")\n",
        "        for batch in batch_iterator:\n",
        "            encoder_input = batch['english_token'].to(device)\n",
        "            decoder_input = batch['tamil_token'].to(device)\n",
        "            encoder_mask = batch['encoder_mask'].to(device)\n",
        "            decoder_mask = batch['decoder_mask'].to(device)\n",
        "\n",
        "            output = model(encoder_input, decoder_input, encoder_mask, decoder_mask)\n",
        "\n",
        "            label = batch['tamil_target'].to(device)\n",
        "\n",
        "            loss = loss_fn(output.view(-1, (len(tamil_tokenizer.word_to_id))), label.view(-1))\n",
        "            batch_iterator.set_postfix({\"loss\": f\"{loss.item():6.3f}\"})\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        run_validation(model, test_dataloader, english_tokenizer, tamil_tokenizer, 24, device, lambda msg: batch_iterator.write(msg))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "    train_model()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVhUJM7VKoH9"
      },
      "outputs": [],
      "source": [
        "'''\"english\": english,\n",
        "\"tamil\": tamil,\n",
        "\"english_token\": english_tokens.clone(),\n",
        "\"tamil_token\": tamil_tokens.clone(),\n",
        "\"tamil_target\": tamil_target_tokens.clone(),\n",
        "\"encoder_mask\": (english_tokens != self.pad_token).unsqueeze(0).unsqueeze(0).int().clone(),\n",
        "\"decoder_mask\": (tamil_tokens != self.pad_token).unsqueeze(0).int() & causal_mask(tamil_tokens.size(0)).clone(), '''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "  PREDICTED:<SOS> விமான நிலையத்திற்கு எப்படி முயற்சி செய்யுங்கள் <EOS>\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import os\n",
        "\n",
        "def causal_mask(size, device):\n",
        "    mask = torch.triu(torch.ones((1, size, size), device=device), diagonal=1).int()\n",
        "    return mask == 0\n",
        "\n",
        "def greedy_decode1(model, source, source_mask, max_len, device):\n",
        "    sos_idx, eos_idx = 2, 3\n",
        "    # Move encoder input to device\n",
        "    encoder_output = model.encoder(source, source_mask)\n",
        "    decoder_input = torch.empty(1, 1, device=device).fill_(sos_idx).long()\n",
        "\n",
        "    while decoder_input.size(1) < max_len:\n",
        "        decoder_mask = causal_mask(decoder_input.size(1), device)\n",
        "        out = model.decoder(decoder_input, encoder_output, source_mask, decoder_mask)\n",
        "        next_word = torch.max(out[:, -1], dim=1)[1]\n",
        "        decoder_input = torch.cat([decoder_input, next_word.view(1, 1)], dim=1)\n",
        "        if next_word.item() == eos_idx:\n",
        "            break\n",
        "\n",
        "    return decoder_input.squeeze(0)\n",
        "\n",
        "def run_validation1(model, encoder_input, encoder_mask, max_len, device):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    predicted = []\n",
        "    \n",
        "    try:\n",
        "        console_width = os.get_terminal_size().columns\n",
        "    except OSError:\n",
        "        console_width = 80\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Ensure encoder input and mask are on the device\n",
        "        encoder_input = encoder_input.to(device)\n",
        "        encoder_mask = encoder_mask.to(device)\n",
        "        \n",
        "        assert encoder_input.size(0) == 1, \"Batch size must be 1 for validation\"\n",
        "        model_out = greedy_decode1(model, encoder_input, encoder_mask, max_len, device)\n",
        "    \n",
        "        model_out_text = tamil_tokenizer.decode(model_out.detach().cpu().numpy())\n",
        "        predicted.append(model_out_text)\n",
        "\n",
        "        print(f\"{'-'*console_width}\\n{'PREDICTED:':>12}{model_out_text}\")\n",
        "\n",
        "# Example sentence and pre-processing\n",
        "sentence = \"how much time does it take to reach the airport\"\n",
        "sentence = english_tokenizer.encode(sentence)\n",
        "sentence = pad_sequence_source(sentence, 20, cls_token=2, sep_token=3)\n",
        "sentence = torch.tensor(sentence, dtype=torch.long).to('cuda')  # Move tensor to CUDA\n",
        "encoder_input = sentence.unsqueeze(0).to('cuda')  # Ensure batch dimension and move to CUDA\n",
        "encoder_mask = (sentence != 1).unsqueeze(0).unsqueeze(0).int().to('cuda')  # Move mask to CUDA\n",
        "\n",
        "# Running validation on CUDA\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "run_validation1(model, encoder_input, encoder_mask, 24, device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#from pathlib import Path\n",
        "#from config import get_config, latest_weights_file_path \n",
        "#from model import build_transformer\n",
        "#from tokenizers import Tokenizer\n",
        "#from datasets import load_dataset\n",
        "#from dataset import BilingualDataset\n",
        "#import torch\n",
        "#import sys\n",
        "\n",
        "def translate(sentence: str):\n",
        "    # Define the device, tokenizers, and model\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Using device:\", device)\n",
        "    # if the sentence is a number use it as an index to the test set\n",
        "    \n",
        "    label = \"\"\n",
        "    if type(sentence) == int or sentence.isdigit():\n",
        "        id = int(sentence)\n",
        "        ds = load_dataset(f\"{config['datasource']}\", f\"{config['lang_src']}-{config['lang_tgt']}\", split='all')\n",
        "        ds = BilingualDataset(ds, tokenizer_src, tokenizer_tgt, config['lang_src'], config['lang_tgt'], config['seq_len'])\n",
        "        sentence = ds[id]['src_text']\n",
        "        label = ds[id][\"tgt_text\"]\n",
        "    seq_len = config['seq_len']\n",
        "\n",
        "    # translate the sentence\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Precompute the encoder output and reuse it for every generation step\n",
        "        source = tokenizer_src.encode(sentence)\n",
        "        source = torch.cat([\n",
        "            torch.tensor([tokenizer_src.token_to_id('[SOS]')], dtype=torch.int64), \n",
        "            torch.tensor(source.ids, dtype=torch.int64),\n",
        "            torch.tensor([tokenizer_src.token_to_id('[EOS]')], dtype=torch.int64),\n",
        "            torch.tensor([tokenizer_src.token_to_id('[PAD]')] * (seq_len - len(source.ids) - 2), dtype=torch.int64)\n",
        "        ], dim=0).to(device)\n",
        "        source_mask = (source != tokenizer_src.token_to_id('[PAD]')).unsqueeze(0).unsqueeze(0).int().to(device)\n",
        "        encoder_output = model.encode(source, source_mask)\n",
        "\n",
        "        # Initialize the decoder input with the sos token\n",
        "        decoder_input = torch.empty(1, 1).fill_(tokenizer_tgt.token_to_id('[SOS]')).type_as(source).to(device)\n",
        "\n",
        "        # Print the source sentence and target start prompt\n",
        "        if label != \"\": print(f\"{f'ID: ':>12}{id}\") \n",
        "        print(f\"{f'SOURCE: ':>12}{sentence}\")\n",
        "        if label != \"\": print(f\"{f'TARGET: ':>12}{label}\") \n",
        "        print(f\"{f'PREDICTED: ':>12}\", end='')\n",
        "\n",
        "        # Generate the translation word by word\n",
        "        while decoder_input.size(1) < seq_len:\n",
        "            # build mask for target and calculate output\n",
        "            decoder_mask = torch.triu(torch.ones((1, decoder_input.size(1), decoder_input.size(1))), diagonal=1).type(torch.int).type_as(source_mask).to(device)\n",
        "            out = model.decode(encoder_output, source_mask, decoder_input, decoder_mask)\n",
        "\n",
        "            # project next token\n",
        "            prob = model.project(out[:, -1])\n",
        "            _, next_word = torch.max(prob, dim=1)\n",
        "            decoder_input = torch.cat([decoder_input, torch.empty(1, 1).type_as(source).fill_(next_word.item()).to(device)], dim=1)\n",
        "\n",
        "            # print the translated word\n",
        "            print(f\"{tokenizer_tgt.decode([next_word.item()])}\", end=' ')\n",
        "\n",
        "            # break if we predict the end of sentence token\n",
        "            if next_word == tokenizer_tgt.token_to_id('[EOS]'):\n",
        "                break\n",
        "\n",
        "    # convert ids to tokens\n",
        "    return tokenizer_tgt.decode(decoder_input[0].tolist())\n",
        "    \n",
        "#read sentence from argument\n",
        "translate(sys.argv[1] if len(sys.argv) > 1 else \"I am not a very good a student.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WASYCq5LYyF0",
        "outputId": "47909b84-3851-4c8e-f605-6961200dacc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 11104 entries, 0 to 11103\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   English  11104 non-null  object\n",
            " 1   Tamil    11104 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 173.6+ KB\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('C:\\\\Users\\\\Kamal\\\\Downloads\\\\final_translation.csv')\n",
        "df.columns = ['English','Tamil']\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ujPMEJzVeYWG",
        "outputId": "d420588d-803d-4a79-f721-01058200cc76"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Tamil</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Lets try something</td>\n",
              "      <td>ஏதாவது முயற்சி செய்யலாம்</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I have to go to sleep</td>\n",
              "      <td>நான் தூங்க செல்ல வேண்டும்</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Today is June 18th and it is Muiriels birthday</td>\n",
              "      <td>இன்று ஜூன் 18 மற்றும் முரியலின் பிறந்த நாள்</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Muiriel is 20 now</td>\n",
              "      <td>முரியலுக்கு இப்போது 20 வயது</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The password is Muiriel</td>\n",
              "      <td>கடவுச்சொல் முரியல்</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11099</th>\n",
              "      <td>Dont speak to the driver while he is driving</td>\n",
              "      <td>வாகனம் ஓட்டும் போது ஓட்டுனரிடம் பேச வேண்டாம்</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11100</th>\n",
              "      <td>The driver was inattentive and could not stop ...</td>\n",
              "      <td>டிரைவர் கவனக்குறைவாக இருந்ததால் சரியான நேரத்தி...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11101</th>\n",
              "      <td>The driver could not distinguish the signal in...</td>\n",
              "      <td>டிரைவரால் மூடுபனியில் சிக்னலை வேறுபடுத்திப் பா...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11102</th>\n",
              "      <td>The driver tipped his cap</td>\n",
              "      <td>டிரைவர் தொப்பியை சாய்த்தார்</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11103</th>\n",
              "      <td>The driver gestured him out</td>\n",
              "      <td>ஓட்டுனர் சைகையால் வெளியே காட்டினார்</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11104 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 English  \\\n",
              "0                                     Lets try something   \n",
              "1                                  I have to go to sleep   \n",
              "2         Today is June 18th and it is Muiriels birthday   \n",
              "3                                      Muiriel is 20 now   \n",
              "4                                The password is Muiriel   \n",
              "...                                                  ...   \n",
              "11099       Dont speak to the driver while he is driving   \n",
              "11100  The driver was inattentive and could not stop ...   \n",
              "11101  The driver could not distinguish the signal in...   \n",
              "11102                          The driver tipped his cap   \n",
              "11103                        The driver gestured him out   \n",
              "\n",
              "                                                   Tamil  \n",
              "0                               ஏதாவது முயற்சி செய்யலாம்  \n",
              "1                              நான் தூங்க செல்ல வேண்டும்  \n",
              "2            இன்று ஜூன் 18 மற்றும் முரியலின் பிறந்த நாள்  \n",
              "3                            முரியலுக்கு இப்போது 20 வயது  \n",
              "4                                     கடவுச்சொல் முரியல்  \n",
              "...                                                  ...  \n",
              "11099       வாகனம் ஓட்டும் போது ஓட்டுனரிடம் பேச வேண்டாம்  \n",
              "11100  டிரைவர் கவனக்குறைவாக இருந்ததால் சரியான நேரத்தி...  \n",
              "11101  டிரைவரால் மூடுபனியில் சிக்னலை வேறுபடுத்திப் பா...  \n",
              "11102                        டிரைவர் தொப்பியை சாய்த்தார்  \n",
              "11103                ஓட்டுனர் சைகையால் வெளியே காட்டினார்  \n",
              "\n",
              "[11104 rows x 2 columns]"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    # Keep only Tamil/English letters and numbers, remove all other characters\n",
        "    return re.sub(r'[^a-zA-Z0-9\\u0B80-\\u0BFF\\s]', '', text)\n",
        "\n",
        "# Apply cleaning function to English and Tamil columns\n",
        "df['English'] = df['English'].apply(clean_text)  # Clean English column\n",
        "df['Tamil'] = df['Tamil'].apply(clean_text)  # Clean Tamil column\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "pTatalI-feBW",
        "outputId": "da895ddd-3b28-4452-c289-4ce54450902e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Tamil</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Lets try something</td>\n",
              "      <td>ஏதாவது முயற்சி செய்யலாம்</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I have to go to sleep</td>\n",
              "      <td>நான் தூங்க செல்ல வேண்டும்</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Today is June 18th and it is Muiriels birthday</td>\n",
              "      <td>இன்று ஜூன் 18 மற்றும் முரியலின் பிறந்த நாள்</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Muiriel is 20 now</td>\n",
              "      <td>முரியலுக்கு இப்போது 20 வயது</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The password is Muiriel</td>\n",
              "      <td>கடவுச்சொல் முரியல்</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11099</th>\n",
              "      <td>Dont speak to the driver while he is driving</td>\n",
              "      <td>வாகனம் ஓட்டும் போது ஓட்டுனரிடம் பேச வேண்டாம்</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11100</th>\n",
              "      <td>The driver was inattentive and could not stop ...</td>\n",
              "      <td>டிரைவர் கவனக்குறைவாக இருந்ததால் சரியான நேரத்தி...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11101</th>\n",
              "      <td>The driver could not distinguish the signal in...</td>\n",
              "      <td>டிரைவரால் மூடுபனியில் சிக்னலை வேறுபடுத்திப் பா...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11102</th>\n",
              "      <td>The driver tipped his cap</td>\n",
              "      <td>டிரைவர் தொப்பியை சாய்த்தார்</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11103</th>\n",
              "      <td>The driver gestured him out</td>\n",
              "      <td>ஓட்டுனர் சைகையால் வெளியே காட்டினார்</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11076 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 English  \\\n",
              "0                                     Lets try something   \n",
              "1                                  I have to go to sleep   \n",
              "2         Today is June 18th and it is Muiriels birthday   \n",
              "3                                      Muiriel is 20 now   \n",
              "4                                The password is Muiriel   \n",
              "...                                                  ...   \n",
              "11099       Dont speak to the driver while he is driving   \n",
              "11100  The driver was inattentive and could not stop ...   \n",
              "11101  The driver could not distinguish the signal in...   \n",
              "11102                          The driver tipped his cap   \n",
              "11103                        The driver gestured him out   \n",
              "\n",
              "                                                   Tamil  \n",
              "0                               ஏதாவது முயற்சி செய்யலாம்  \n",
              "1                              நான் தூங்க செல்ல வேண்டும்  \n",
              "2            இன்று ஜூன் 18 மற்றும் முரியலின் பிறந்த நாள்  \n",
              "3                            முரியலுக்கு இப்போது 20 வயது  \n",
              "4                                     கடவுச்சொல் முரியல்  \n",
              "...                                                  ...  \n",
              "11099       வாகனம் ஓட்டும் போது ஓட்டுனரிடம் பேச வேண்டாம்  \n",
              "11100  டிரைவர் கவனக்குறைவாக இருந்ததால் சரியான நேரத்தி...  \n",
              "11101  டிரைவரால் மூடுபனியில் சிக்னலை வேறுபடுத்திப் பா...  \n",
              "11102                        டிரைவர் தொப்பியை சாய்த்தார்  \n",
              "11103                ஓட்டுனர் சைகையால் வெளியே காட்டினார்  \n",
              "\n",
              "[11076 rows x 2 columns]"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define a function to check if any English character is present in the Tamil text\n",
        "def contains_english(text):\n",
        "    # This regex checks if the text contains any character from the English alphabet\n",
        "    return bool(re.search(r'[a-zA-Z]', text))\n",
        "\n",
        "# Apply the function to filter out rows where Tamil contains English words\n",
        "df = df[~df['Tamil'].apply(contains_english)]\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "iXfU6sXgf81u"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the WordLevelTokenizer class (use the class from the previous answer)\n",
        "class WordLevelTokenizer:\n",
        "    def __init__(self, special_tokens=None):\n",
        "        self.word_to_id = {}\n",
        "        self.id_to_word = {}\n",
        "        self.special_tokens = special_tokens or []\n",
        "        self.build_vocab(self.special_tokens)\n",
        "\n",
        "    def build_vocab(self, tokens):\n",
        "        for token in tokens:\n",
        "            self.add_token(token)\n",
        "\n",
        "    def add_token(self, token):\n",
        "        if token not in self.word_to_id:\n",
        "            idx = len(self.word_to_id)\n",
        "            self.word_to_id[token] = idx\n",
        "            self.id_to_word[idx] = token\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        return text.split()\n",
        "\n",
        "    def encode(self, text):\n",
        "        tokens = self.tokenize(text)\n",
        "        return [self.word_to_id.get(token, self.word_to_id.get(\"<UNK>\")) for token in tokens]\n",
        "\n",
        "    def decode(self, token_ids):\n",
        "        return \" \".join(self.id_to_word.get(idx, \"<UNK>\") for idx in token_ids)\n",
        "\n",
        "    def fit_on_texts(self, texts):\n",
        "        for text in texts:\n",
        "            tokens = self.tokenize(text)\n",
        "            self.build_vocab(tokens)\n",
        "\n",
        "    def vocab_size(self):\n",
        "        return len(self.word_to_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "25rq3UOXgEbW"
      },
      "outputs": [],
      "source": [
        "# Initialize tokenizer with special tokens\n",
        "special_tokens = [\"<UNK>\", \"<PAD>\", \"<SOS>\", \"<EOS>\"]\n",
        "tamil_tokenizer = WordLevelTokenizer(special_tokens=special_tokens)\n",
        "english_tokenizer = WordLevelTokenizer(special_tokens=special_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtxzmjXxgHIN",
        "outputId": "c0aa301c-d15d-4407-dbec-77635d551279"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary: 15529\n"
          ]
        }
      ],
      "source": [
        "# Fit tokenizer on the 'text' column\n",
        "tamil_tokenizer.fit_on_texts(df['Tamil'])\n",
        "print(\"Vocabulary:\", len(tamil_tokenizer.word_to_id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZnfG-dVgMYG",
        "outputId": "8b5cc47a-0148-4599-bea4-85be461bcefd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary: 8100\n"
          ]
        }
      ],
      "source": [
        "english_tokenizer.fit_on_texts(df['English'])\n",
        "print(\"Vocabulary:\", len(english_tokenizer.word_to_id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "id": "XIpneaZhgRs2",
        "outputId": "242ba9c4-d97f-4378-e4cb-6f71489375b1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Tamil</th>\n",
              "      <th>Tokenized_Tamil</th>\n",
              "      <th>Tokenized_English</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Lets try something</td>\n",
              "      <td>ஏதாவது முயற்சி செய்யலாம்</td>\n",
              "      <td>[4, 5, 6]</td>\n",
              "      <td>[4, 5, 6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I have to go to sleep</td>\n",
              "      <td>நான் தூங்க செல்ல வேண்டும்</td>\n",
              "      <td>[7, 8, 9, 10]</td>\n",
              "      <td>[7, 8, 9, 10, 9, 11]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Today is June 18th and it is Muiriels birthday</td>\n",
              "      <td>இன்று ஜூன் 18 மற்றும் முரியலின் பிறந்த நாள்</td>\n",
              "      <td>[11, 12, 13, 14, 15, 16, 17]</td>\n",
              "      <td>[12, 13, 14, 15, 16, 17, 13, 18, 19]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Muiriel is 20 now</td>\n",
              "      <td>முரியலுக்கு இப்போது 20 வயது</td>\n",
              "      <td>[18, 19, 20, 21]</td>\n",
              "      <td>[20, 13, 21, 22]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The password is Muiriel</td>\n",
              "      <td>கடவுச்சொல் முரியல்</td>\n",
              "      <td>[22, 23]</td>\n",
              "      <td>[23, 24, 13, 20]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11099</th>\n",
              "      <td>Dont speak to the driver while he is driving</td>\n",
              "      <td>வாகனம் ஓட்டும் போது ஓட்டுனரிடம் பேச வேண்டாம்</td>\n",
              "      <td>[3724, 15517, 741, 15520, 1215, 797]</td>\n",
              "      <td>[487, 491, 9, 50, 7118, 481, 89, 13, 1678]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11100</th>\n",
              "      <td>The driver was inattentive and could not stop ...</td>\n",
              "      <td>டிரைவர் கவனக்குறைவாக இருந்ததால் சரியான நேரத்தி...</td>\n",
              "      <td>[15521, 3850, 751, 465, 2632, 2354, 2246]</td>\n",
              "      <td>[23, 7118, 45, 8096, 16, 149, 96, 2074, 49, 56]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11101</th>\n",
              "      <td>The driver could not distinguish the signal in...</td>\n",
              "      <td>டிரைவரால் மூடுபனியில் சிக்னலை வேறுபடுத்திப் பா...</td>\n",
              "      <td>[15522, 15523, 15524, 3612, 502, 2246]</td>\n",
              "      <td>[23, 7118, 149, 96, 2531, 50, 8097, 49, 50, 3566]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11102</th>\n",
              "      <td>The driver tipped his cap</td>\n",
              "      <td>டிரைவர் தொப்பியை சாய்த்தார்</td>\n",
              "      <td>[15521, 15525, 15526]</td>\n",
              "      <td>[23, 7118, 8098, 886, 6047]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11103</th>\n",
              "      <td>The driver gestured him out</td>\n",
              "      <td>ஓட்டுனர் சைகையால் வெளியே காட்டினார்</td>\n",
              "      <td>[15527, 15528, 758, 8712]</td>\n",
              "      <td>[23, 7118, 8099, 216, 695]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11076 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 English  \\\n",
              "0                                     Lets try something   \n",
              "1                                  I have to go to sleep   \n",
              "2         Today is June 18th and it is Muiriels birthday   \n",
              "3                                      Muiriel is 20 now   \n",
              "4                                The password is Muiriel   \n",
              "...                                                  ...   \n",
              "11099       Dont speak to the driver while he is driving   \n",
              "11100  The driver was inattentive and could not stop ...   \n",
              "11101  The driver could not distinguish the signal in...   \n",
              "11102                          The driver tipped his cap   \n",
              "11103                        The driver gestured him out   \n",
              "\n",
              "                                                   Tamil  \\\n",
              "0                               ஏதாவது முயற்சி செய்யலாம்   \n",
              "1                              நான் தூங்க செல்ல வேண்டும்   \n",
              "2            இன்று ஜூன் 18 மற்றும் முரியலின் பிறந்த நாள்   \n",
              "3                            முரியலுக்கு இப்போது 20 வயது   \n",
              "4                                     கடவுச்சொல் முரியல்   \n",
              "...                                                  ...   \n",
              "11099       வாகனம் ஓட்டும் போது ஓட்டுனரிடம் பேச வேண்டாம்   \n",
              "11100  டிரைவர் கவனக்குறைவாக இருந்ததால் சரியான நேரத்தி...   \n",
              "11101  டிரைவரால் மூடுபனியில் சிக்னலை வேறுபடுத்திப் பா...   \n",
              "11102                        டிரைவர் தொப்பியை சாய்த்தார்   \n",
              "11103                ஓட்டுனர் சைகையால் வெளியே காட்டினார்   \n",
              "\n",
              "                                 Tokenized_Tamil  \\\n",
              "0                                      [4, 5, 6]   \n",
              "1                                  [7, 8, 9, 10]   \n",
              "2                   [11, 12, 13, 14, 15, 16, 17]   \n",
              "3                               [18, 19, 20, 21]   \n",
              "4                                       [22, 23]   \n",
              "...                                          ...   \n",
              "11099       [3724, 15517, 741, 15520, 1215, 797]   \n",
              "11100  [15521, 3850, 751, 465, 2632, 2354, 2246]   \n",
              "11101     [15522, 15523, 15524, 3612, 502, 2246]   \n",
              "11102                      [15521, 15525, 15526]   \n",
              "11103                  [15527, 15528, 758, 8712]   \n",
              "\n",
              "                                       Tokenized_English  \n",
              "0                                              [4, 5, 6]  \n",
              "1                                   [7, 8, 9, 10, 9, 11]  \n",
              "2                   [12, 13, 14, 15, 16, 17, 13, 18, 19]  \n",
              "3                                       [20, 13, 21, 22]  \n",
              "4                                       [23, 24, 13, 20]  \n",
              "...                                                  ...  \n",
              "11099         [487, 491, 9, 50, 7118, 481, 89, 13, 1678]  \n",
              "11100    [23, 7118, 45, 8096, 16, 149, 96, 2074, 49, 56]  \n",
              "11101  [23, 7118, 149, 96, 2531, 50, 8097, 49, 50, 3566]  \n",
              "11102                        [23, 7118, 8098, 886, 6047]  \n",
              "11103                         [23, 7118, 8099, 216, 695]  \n",
              "\n",
              "[11076 rows x 4 columns]"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Tokenize the Tamil text in your dataframe\n",
        "df['Tokenized_Tamil'] = df['Tamil'].apply(lambda x: tamil_tokenizer.encode(x))\n",
        "df['Tokenized_English'] = df['English'].apply(lambda x: english_tokenizer.encode(x))\n",
        "# Print the dataframe with tokenized Tamil text\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2AAAAIqCAYAAABCJikaAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAqRdJREFUeJzs3Xd4VfX9B/D3OXdnDzIIGYRhCEjYS2RVZWodqI9VKiqKpaBVqcX2J8pQEWzdWmoLjorFYsUJIspSAREk7E0gQshO7s2685zfHzf3kEtuQpKb3JG8X8/DU/M9557z+dyR3k++S5BlWQYRERERERG1OdHfARAREREREXUULMCIiIiIiIh8hAUYERERERGRj7AAIyIiIiIi8hEWYERERERERD7CAoyIiIiIiMhHWIARERERERH5CAswIiIiIiIiH2EBRkRERERE5CMswIjIJ7p27QpBEJR/oigiPDwcycnJGDduHP74xz9i165djV5j7NixEAQBW7Zs8U3Ql+HK6cyZM27tgRYnANxzzz0QBAHvvPOOv0NpE59//jlGjRqFiIgI5T3W2PNf973Y1H9jx471WT6X09B7zxPXa9/cf025dl2uxwUj1/PZXj8fDXnnnXcgCALuuecef4dC1KGo/R0AEXUsI0eORI8ePQAANTU1KC4uxt69e7Flyxb87W9/w5gxY7By5Up069atzWLo2rUrzp49i5ycHHTt2rXN7uMr77zzDu69915Mnz69w32BBIDs7GxMnToVkiThV7/6FTp37gxBEJCYmNjgY6ZPn16vLT8/Hxs2bGjweK9evZoV15YtWzBu3DiMGTPGr8X41Vdf7bH9o48+QlVVldtnsq6wsLC2Do3amKsglmXZz5EQUV0swIjIp+6///56f22VZRnr16/HI488gq1bt+Kqq67Cjh07kJ6e7nbee++9h+rqaqSmpvow4oZ9++23sNls6NKli79DuawlS5bgiSeeQOfOnf0dSqv75JNPYLPZ8Je//AXPPvtskx7jqVDdsmWLUoC1p0L2/vvvx/3331+vfcuWLaiqqvL4mSQiorbDAoyI/E4QBEyePBlXXXUVhg4dihMnTuD+++/Ht99+63ZeoBReLt27d/d3CE3WuXPndll8AUBubi4AoGfPnn6OhIiI6PI4B4yIAkZUVBRefvllAMCmTZuwZ88et+MNza2yWCx44YUXMGjQIISHh0Or1SIxMRFDhgzBn/70J5SWlgK4ON/h7NmzAID09HS3OS+u627ZskWZ81NdXY2nnnoKmZmZCAkJcRuy2JR5OFu3bsX48eMRExODkJAQDB06FP/+9789nnu5uWMLFiyAIAhYsGCBWwz33nsvAODdd99tcM7S5eaArV69Gtdccw1iYmKg0+mQlpaG++67D8ePH/d4ft3cN2/ejPHjxyM6OhoGgwEDBw7Ee++91+Bz0hi73Y7ly5fjqquuQmRkJPR6PXr27ImHH34Y58+f9/h8vP322wCAe++9t03na507dw4PPfQQevbsCb1ej8jISIwcORL/+Mc/4HA43M4dO3Ysxo0bB8D5Hqj7utR9DxUVFeHVV1/F5MmTkZ6eDoPBgIiICAwePBhLly6F2Wxu9Tyaojmvw+U4HA7MmjULgiCgb9+++OWXX9zu869//Qtjx45V3nvp6emYNWuW23kudT+bNpsNS5cuRZ8+fWAwGBAbG4tbbrkFR44c8Tr/pqipqcHf/vY3DB8+HFFRUdDr9cjIyMCf/vQnlJSU1Du/7nyrqqoq/PnPf0aPHj2g0+mQmJiI6dOnN/rcfvrppxg1ahTCw8MRGRmJMWPG4Msvv8SZM2fqva9cnw2Xpszva0lMRNQy7AEjooAyadIkxMTEoLS0FBs3bsSgQYMaPV+SJEyZMgXffvstIiIiMGrUKERFRaGoqAgnTpzACy+8gDvvvBMxMTHo0aMHpk+frsx9mTp1qts8l0vnDJnNZowdOxaHDx/G6NGj0a9fP49frBqydu1avP766+jVqxcmTJiAvLw8fP/997j77ruRnZ2Nv/3tb817cjy49dZbsXPnTvzwww/o3r2723yfpsxZkmUZ99xzD9577z2o1WqMHj0a8fHx+Pnnn/H222/jww8/xP/+9z9MnDjR4+NXrlyJZ555BgMHDsTEiRNx5swZ7Ny5E9OnT0dpaSkeeeSRJudisVhw/fXX45tvvoFer8e4ceMQERGB7du347XXXsN//vMfbNiwAQMHDgQA9O/fH9OnT8f333+PU6dOuc1lau58rcv56aefMHHiRJSWliI1NRU33XQTjEYjtmzZgu3bt2Pt2rX47LPPoNVqAQATJ06EXq/Hhg0bkJCQ4Pb8derUSfnvDRs24A9/+AO6dOmCHj16YPjw4SgqKsKPP/6IJ554Ap9++ik2b94MnU7Xqvk0prmvQ2MqKytx++23Y/369bjuuuvw0UcfISIiAgBQUVGBX//619iyZQvCwsIwaNAgxMXF4cCBA1i+fDnWrFmDjRs3YsCAAfWua7PZMHnyZGzfvh2jR49GZmYmdu3ahbVr12Lz5s3Yu3dvm87vzMvLw8SJE3HgwAHExMRgyJAhCA8Px88//4wXXngBa9aswZYtW5CWllbvsUajEVdddRVyc3MxatQoXHnlldixYwfee+89bN26Ffv27UNkZKTbY5YtW4Z58+YBAIYNG4Zu3brh5MmTuP766/GnP/2p3j1cn413330XQP05jZfO72tJTETkBZmIyAfS0tJkAPLbb7992XOvvfZaGYA8bdo0t/YxY8bIAOTNmzcrbVu3bpUByAMGDJBNJlO9a/30009ycXGxx1hycnI83n/z5s0yABmAnJWVJV+4cKHRnC69jitOAPJzzz3ndmzLli2ywWCQAchfffXVZfOr6+mnn5YByE8//bRb+9tvvy0DkKdPn+7xcbIsy9OnT/f4/P/973+XAcidOnWS9+7dq7RLkqTcLyoqSi4sLPSYu0ajkT///HOP8URGRsrV1dUNxnSpefPmyQDk7t27uz2nVqtVnjFjhgxATk9Ply0WS5Nya666r3tdZrNZyfd3v/udbLValWOnTp2Su3btKgOQ//KXv3i83pgxYxq85+HDh+UdO3bUay8tLZXHjx8vA5CXLVtW7/jl3sNN0dBnsqWvw6XP3blz5+T+/fvLAOR7773X7XmTZVm+8847ZQDy9ddfLxcUFLgde+mll2QAcs+ePWW73a60132NBgwY4PbZrKmpkSdMmCADkGfOnNkqz4UnkiTJI0eOlAHIM2bMcPu9Y7PZ5Llz58oA5HHjxrk9zvW5ACBPmDBBNhqNyrHS0lLlubr0d8bPP/8sq1QqWaVSyR9//LHbsf/+97+yKIoyADktLa1erJ7ez60RExF5h0MQiSjguHoImtLbVFBQAADK0JxLDR48GLGxsS2O5fXXX290Nb3GDBgwAH/+85/d2saMGYPf//73ANAqPWDe+utf/woAeOqpp9C/f3+lXRAEPP3008jKykJ5eTn++c9/enz8Qw89hOuvv96t7Z577kGvXr1gNBqxe/fuJsVhNpvxxhtvAABeeuklt94LjUaDV199FQkJCcjJycFHH33UjAy9t2bNGpw9exZJSUl4+eWXodFolGPdunVTnsPXXnut2UMGMzMzMXz48Hrt0dHReO2115T7+0prvQ779+/H8OHDkZ2djUWLFmHlypVuz9uRI0fwn//8B0lJSfjggw8QHx/v9vhHHnkEkydPxokTJ7B+/fp613cNPa372dTr9Vi4cCEA4JtvvmlR/k2xYcMG/PDDD+jfvz+WL1/u9ntHrVZj2bJluPLKK7F582YcPHiw3uNDQ0Px9ttvKz2BgPP1fuKJJzzG/vrrr8PhcOD222/HzTff7Hbstttuwy233OJ1Ts2NiYi8wwKMiAKOJEkA4DaHoSEDBw6ESqXCypUr8cYbb+DChQutFkd8fDxGjRrV4sfffffdHttdw4G+//77enOHfOncuXM4deqUW0x1CYKgzC/bvHmzx2vccMMNHtszMzMBoMnzR3bv3o3KykrExMR4vGZISAjuuOOORmNpK645eXfccYfHoYC33HILoqOjUVFRUW/eYlM4HA58++23WLx4MX7/+9/j3nvvxT333KOs6Hjs2DGv4m+O1ngdNmzYgKuvvhqFhYX497//jfnz59c7Z926dZBlGZMmTfL4hxMAyjy+7du31zuWmpqKfv361Wtv7vuuJb788ksAwNSpU6FW15/JIYoiRo8eDcBz7IMHD/a4IE5DsW/duhUAcNddd3mMp6H25mhuTETkHc4BI6KAU1xcDACIiYm57Lndu3fHSy+9hMcffxxz5szBnDlzkJaWhhEjRuD666/HbbfdpszLaS5v55Bcuoz+pe01NTUoKSmp99d/X3F9qYqNjXX7y3ddrpUeG/oC1tDKlK7rNbVHyHX9hp6zpsTSVi4XmyAISE9PR1lZWbNjO3HiBG6++WYcOnSowXNMJlOzrumN1ngdrr/+etjtdrz//vsNFgenT58GAKxYsQIrVqxoNKaioqJ6bZd731kslkav6Q1X7PPnz/dYXNbVktgv/cycO3cOQMO/j1pjrltrfY6JqGlYgBFRQJFlGXv37gUA9O3bt0mPeeihh3D77bfjs88+w/fff4/vv/8eq1evxurVq/H000/ju+++a9ES7AaDodmPaS65GRukunoGA4kociCFN2699VYcOnRIWUyhd+/eiIiIgEajgdVq9eniG61l+vTpWLFiBebPn4+rrrrKYzHnei/379/fY09WXcOGDavX5s/3nSv2q6+++rJbUfTp06deW0tjb2hEQFNGClwOP8dEvsUCjIgCyrp161BWVgYAGD9+fJMfl5CQgAceeAAPPPAAAODo0aO47777sGPHDjzxxBPKamC+lJOT47HdtQS0Xq93m5/m6qmrqKjw+DjX8vmtxbWBdElJCUwmk8deMNdf+9t6s2nX9Rt6znwZy6Vc93Pd3xNX3M2J7ejRo9i/fz/i4+Oxdu3aesPZTpw40YJovdMar8M///lPhIWF4ZVXXsGoUaPwzTff1FuVMiUlBQAwcuRIvP76660Rus+4Yr/xxhvxxz/+sc3v16VLF5w+fRpnzpxB79696x1vbBsMIgpM/JMHEQUMo9GIRx99FABw3XXXuS0K0Vy9evVSlm3Ozs52O+YqdOx2e4uv3xTvv/++x3bXHllXX32125du1xdaT/sYVVdXNzjnpqX5JCcnK3/B97Q/mCzLSrtrT6u2MnjwYISFhaG0tBSfffZZveM1NTVYvXq1T2K5lGsu0ocffuhxKNbatWtRVlaG8PBwt20TLve6uPanS0pK8jiXqKH3T1tqjddBEAS8/PLLePLJJ3H+/HmMHj263mdw0qRJAIDPPvss6Ia3uWJfs2ZNs3qwW8o1n+yDDz7weLyhdgDKwidt/buOiJqHBRgR+Z0sy1i/fj2GDh2KEydOoHPnzg2uunepTZs2Yd26dbDZbPWu+cUXXwBAvb14kpOTAaDReTetYc+ePVi2bJlb2/fff6+sMucqNl2uvfZaAMAbb7zhNr+mqqoKM2fO9LgxLXAxn8OHDzc7Rtdf8BcvXox9+/Yp7bIs45lnnkF2djaioqKUnsW2otfrMXv2bADA3Llz3Xr7bDYb/vCHPyA/Px/p6em49dZb2zSWS912221ITU1FXl4eHnvsMbcvszk5OZg7dy4A51BYvV6vHHO9LidOnKj3/gSAK664AiqVCgcOHKi3+fbnn3+Ol156qQ2yaVxrvg6LFy/GsmXLUFRUhHHjxmHHjh3KsQEDBmDq1Kn45ZdfcMsttzS4MfCqVauUlU4DxY033oghQ4Zg165duPfeez3O8yorK8Py5ctbpfCZM2cORFHE6tWr8emnn7od+/jjj/G///2vwcf66ncdETUPhyASkU/961//Ur5sWiwWFBcX4+eff1Z6A8aOHYuVK1d63MDUk/379+PRRx9FREQEBg4ciKSkJNTU1ODnn3/G2bNnERkZiUWLFrk9ZurUqdi8eTOmTZuG8ePHIzo6GgDw+OOPIyMjo9Vyffjhh/HnP/8Z7733HrKyspCXl4fvvvsOkiThD3/4AyZPnux2/u23346XX34Zu3fvRp8+fXD11VdDkiTs3r0bWq0W9913H1auXFnvPsOHD0dSUhL27t2LgQMHom/fvtBoNMjIyMDjjz/eaIwPPvggtm/fjn//+98YPHgwxowZo2zEfOzYMRgMBnzwwQeIi4trteelIQsXLsTu3bvx7bffIjMzE+PGjUN4eDh27NiB3NxcxMbGYs2aNS1eVKWldDodPvroI0ycOBF///vfsW7dOgwfPhwVFRXYtGkTzGYzJkyYgKefftrtcampqRg8eDB2796Nvn37YvDgwdDr9ejUqROef/55dOrUCXPmzMErr7yCa665BqNGjUJSUhKOHTuGn3/+GU8++SSeeeYZn+YKtO7r8PjjjyM8PBy///3vcd111+Gzzz7Dr371KwDA22+/jfLycqxfvx4ZGRno168f0tPTIcsyzpw5g3379sFqteLIkSNISEho67QBOIvG5cuXN3j8zTffxMCBA/HJJ59gypQpePfdd/HRRx+hX79+SE1NhdVqxenTp3HgwAE4HA7cc889Hns3m2PQoEF45pln8Je//AU33XQThg8frmzEvGvXLsydOxd/+9vfPL4eU6dOxV//+ldce+21+NWvfqWsOLl06VKvtucgIi/5bQcyIupQXBud1v0XGhoqJyUlyWPGjJHnzp0r79q1q9FreNqo+OTJk/KCBQvka665Rk5NTZX1er0cHR0tZ2VlyU888YT8yy+/1LuOw+GQlyxZIvfp00fW6/VKPK7rNmUD3bo5NbQR8+bNm+Vvv/1Wvuaaa+TIyEjZYDDIgwcPlt95550Gr1lWVibPmTNHTk5OljUajdylSxd55syZckFBQYMbMcuyLB84cED+9a9/LcfFxSkbs9aN/3KbFX/wwQfy2LFj5aioKFmj0cgpKSnyPffcIx89erRZuTf1fg2x2Wzym2++KQ8fPlwODw+XtVqt3L17d/mhhx6Sz50716r3ulRDGzG75ObmyrNnz5a7desma7VaOTw8XB4xYoT897//XbbZbB4fc/bsWfnOO++UO3fuLKvV6nob5kqSJK9YsUIeNGiQHBYWJkdGRspXX321vHr1almWG95Ity03Ypbllr0OjT1377//vqxWq2W9Xu+2cbfD4ZA/+OADefLkyXJCQoKs0Wjk2NhY+corr5Tvvfdeee3atW4bODfls9lYHA3x9PvJ07+6v3vMZrO8fPlyedy4cXJsbKysVqvl+Ph4uX///vLs2bPlDRs2uN3jchum5+TkNLihsizL8scffyyPHDlSDg0NlcPDw+Wrr75a/uSTT+Rt27bJAOQRI0bUe0xNTY38pz/9Se7Ro4es1WqVPFzvG29jIqKWEWTZBwOYiYiIiKjVLVq0CE8//TQeeughvPrqq/4Oh4iagHPAiIiIiALYiRMnlNVh6/rss8+wZMkSCILgcTN1IgpMnANGREREFMBWrVqF5557DgMGDEBKSgpsNhuOHTuGY8eOAQAWLFjgtgInEQU2FmBEREREAWzixIk4ceIEdu7ciSNHjsBsNiM2NhY33HADfv/732PixIn+DpGImoFzwIiIiIiIiHyEc8CIiIiIiIh8hAUYERERERGRj3AOWAtJkoS8vDyEh4dDEAR/h0NERERERH4iyzIqKiqQlJQEUWy8j4sFWAvl5eUhJSXF32EQEREREVGA+OWXX5CcnNzoOSzAWig8PByA80mOiIjwczREREREROQvJpMJKSkpSo3QGBZgLeQadhgREcECjIiIiIiImjQ1iYtwEBERERER+QgLMCIiIiIiIh9hAUZEREREROQjLMCIiIiIiIh8hAUYERERERGRj7AAIyIiIiIi8hEWYERERERERD7CAoyIiIiIiMhHWIARERERERH5SMAVYEuWLMGQIUMQHh6O+Ph43HTTTTh27JjbOWazGbNnz0ZsbCzCwsIwdepUFBQUuJ2Tm5uLKVOmICQkBPHx8Xj88cdht9vdztmyZQsGDhwInU6HHj164J133mnr9IiIiIiIqAMLuAJs69atmD17Nnbu3ImNGzfCZrNh/PjxqKqqUs559NFH8fnnn2PNmjXYunUr8vLycMsttyjHHQ4HpkyZAqvViu3bt+Pdd9/FO++8g6eeeko5JycnB1OmTMG4ceOQnZ2NRx55BPfffz82bNjg03yJiIiIiKjjEGRZlv0dRGOKiooQHx+PrVu3YvTo0TAajYiLi8MHH3yAW2+9FQBw9OhRZGZmYseOHRg+fDjWr1+P66+/Hnl5eUhISAAALF++HPPmzUNRURG0Wi3mzZuHL7/8EgcPHlTudccdd6C8vBxfffXVZeMymUyIjIyE0WhERERE2yRPREREREQBrzm1gdpHMbWY0WgEAMTExAAA9uzZA5vNhmuvvVY5p1evXkhNTVUKsB07dqBv375K8QUAEyZMwKxZs3Do0CEMGDAAO3bscLuG65xHHnnEYxwWiwUWi0X52WQyAQDsdrsytFEURYiiCEmSIEmScq6r3eFwoG6921C7SqWCIAj1hkyqVCoAzh6+prSr1WrIsuzWLggCVCpVvRgbamdOzIk5MSfmxJyYE3NiTsyJOTWe06XHGxPQBZgkSXjkkUcwcuRIXHnllQCA/Px8aLVaREVFuZ2bkJCA/Px85Zy6xZfruOtYY+eYTCbU1NTAYDC4HVuyZAkWLlxYL8a9e/ciNDQUABAXF4fu3bsjJycHRUVFyjnJyclITk7G8ePHlYISALp164b4+HgcPHgQNTU1SnuvXr0QFRWFvXv3ur3xsrKyoNVqsXv3brcYBg8eDKvViv379yttKpUKQ4YMgdFoxNGjR5V2g8GAfv36obi4GKdPn1baIyMjkZmZiby8PJw7d05pZ07MiTkxJ+bEnJgTc2JOzIk5NZ5T3elSlxPQQxBnzZqF9evX4/vvv0dycjIA4IMPPsC9997r1hsFAEOHDsW4ceOwdOlSzJw5E2fPnnWbz1VdXY3Q0FCsW7cOkyZNwhVXXIF7770Xf/7zn5Vz1q1bhylTpqC6urpeAeapBywlJQUlJSVKNyP/esCcmBNzYk7MiTkxJ+bEnJhTx8vJZDIhNjY2uIcgzpkzB1988QW2bdumFF8AkJiYCKvVivLycrdesIKCAiQmJirn7Nq1y+16rlUS655z6cqJBQUFiIiIqFd8AYBOp4NOp6vXrlaroVa7P42uF/BSrheqqe2XXrcl7YIgeGxvKMbmtjMn5tRQO3NiTgBzaijG5rYzJ+YEMKeGYmxuO3NiTkDr59TQcU8CbhVEWZYxZ84crF27Fps2bUJ6errb8UGDBkGj0eDbb79V2o4dO4bc3FyMGDECADBixAgcOHAAhYWFyjkbN25EREQEevfurZxT9xquc1zXICIiIiIiam0BNwTx97//PT744AN8+umnyMjIUNojIyOVnqlZs2Zh3bp1eOeddxAREYGHHnoIALB9+3YAzq7A/v37IykpCcuWLUN+fj5++9vf4v7778dzzz0HwLkM/ZVXXonZs2fjvvvuw6ZNm/Dwww/jyy+/xIQJEy4bJ1dBJCIiIiIioHm1QcAVYIIgeGx/++23cc899wBwbsQ8d+5c/Oc//4HFYsGECRPw5ptvKsMLAeDs2bOYNWsWtmzZgtDQUEyfPh3PP/+8W/fgli1b8Oijj+Lw4cNITk7G/PnzlXtcDgsw8qfc3FwUFxd7fZ1OnTohNTW1FSIiIiIi6riCugALFizAyF9yc3ORmZmJ6upqr68VEhKCI0eOsAgjIiIi8kK72geMiNwVFxejuroaT76+Amk9Mi7/gAacPXkMz8yZgeLiYhZgRERERD7CAowoSKX1yEBGVn9/h0FEREREzRBwqyASERERERG1VyzAiIiIiIiIfIQFGBERERERkY+wACMiIiIiIvIRFmBEREREREQ+wgKMiIiIiIjIR1iAERERERER+QgLMCIiIiIiIh9hAUZEREREROQjLMCIiIiIiIh8hAUYERERERGRj7AAIyIiIiIi8hEWYERERERERD7CAoyIiIiIiMhHWIARERERERH5CAswIiIiIiIiH2EBRkRERERE5CMswIiIiIiIiHyEBRgREREREZGPsAAjIiIiIiLyERZgREREREREPsICjIiIiIiIyEdYgBEREREREfkICzAiIiIiIiIfYQFGRERERETkIyzAiIiIiIiIfIQFGBERERERkY+wACMiIiIiIvIRFmBEREREREQ+wgKMiIiIiIjIR1iAERERERER+QgLMCIiIiIiIh9hAUZEREREROQjLMCIiIiIiIh8hAUYERERERGRj7AAIyIiIiIi8hEWYERERERERD7CAoyIiIiIiMhHWIARERERERH5CAswIiIiIiIiH2EBRkRERERE5CMswIiIiIiIiHyEBRgREREREZGPBFwBtm3bNtxwww1ISkqCIAj45JNP3I4LguDx3wsvvKCc07Vr13rHn3/+ebfr7N+/H6NGjYJer0dKSgqWLVvmi/SIiIiIiKgDC7gCrKqqCv369cMbb7zh8fiFCxfc/q1cuRKCIGDq1Klu5y1atMjtvIceekg5ZjKZMH78eKSlpWHPnj144YUXsGDBArz11lttmhsREREREXVsan8HcKlJkyZh0qRJDR5PTEx0+/nTTz/FuHHj0K1bN7f28PDweue6rFq1ClarFStXroRWq0WfPn2QnZ2NF198ETNnzvQ+CSIiIiIiIg8CrgBrjoKCAnz55Zd499136x17/vnnsXjxYqSmpuLOO+/Eo48+CrXame6OHTswevRoaLVa5fwJEyZg6dKlKCsrQ3R0dL3rWSwWWCwW5WeTyQQAsNvtsNvtAABRFCGKIiRJgiRJyrmudofDAVmWL9uuUqkgCIJy3brtAOBwOJrUrlarIcuyW7sgCFCpVPVibKidOQVeTsq1ZBmy6zGCAEEUIUsSUCfGi+0OoE4zROd1NBoNJElScuDrxJyYE3NiTsyJOTEn5tT8nC493pigLsDeffddhIeH45ZbbnFrf/jhhzFw4EDExMRg+/bt+POf/4wLFy7gxRdfBADk5+cjPT3d7TEJCQnKMU8F2JIlS7Bw4cJ67Xv37kVoaCgAIC4uDt27d0dOTg6KioqUc5KTk5GcnIzjx4/DaDQq7d26dUN8fDwOHjyImpoapb1Xr16IiorC3r173d54WVlZ0Gq12L17t1sMgwcPhtVqxf79+5U2lUqFIUOGwGg04ujRo0q7wWBAv379UFxcjNOnTyvtkZGRyMzMRF5eHs6dO6e0M6fAywkARo4ciQibCZWnDgAANBEx0CemwlJ4DjZTqXK+NiYRuk6JqMk7A0d1hdKuT0gBANx3330oKSlRYuXrxJyYE3NiTsyJOTEn5tT8nKqqqtBUgly3xAswgiBg7dq1uOmmmzwe79WrF6677jq89tprjV5n5cqVePDBB1FZWQmdTofx48cjPT0d//jHP5RzDh8+jD59+uDw4cPIzMysdw1PPWApKSkoKSlBREQEAP71gDn5Jqd9+/Zh6NChWP7FFlxxZZbrQLN7wI4f2I/f3zAO27dvR//+/f2aU3t8nZgTc2JOzIk5MSfm1HFyMplMiI2NhdFoVGqDhgRtD9h3332HY8eO4cMPP7zsucOGDYPdbseZM2eQkZGBxMREFBQUuJ3j+rmheWM6nQ46na5eu1qtVoY2urhewEu5Xqimtl963Za0C4Lgsb2hGJvbzpz8k5PD4XAWV5fEJHg419nuOXabzQZRFOvdm68Tc2JOzKmxdubEnJgTc2qsvSPm1NBxTwJuFcSmWrFiBQYNGoR+/fpd9tzs7GyIooj4+HgAwIgRI7Bt2zbYbDblnI0bNyIjI8Pj8EMiIiIiIqLWEHAFWGVlJbKzs5GdnQ0AyMnJQXZ2NnJzc5VzTCYT1qxZg/vvv7/e43fs2IGXX34Z+/btw+nTp7Fq1So8+uijmDZtmlJc3XnnndBqtZgxYwYOHTqEDz/8EK+88goee+wxn+RIREREREQdU8ANQdy9ezfGjRun/OwqiqZPn4533nkHALB69WrIsozf/OY39R6v0+mwevVqLFiwABaLBenp6Xj00UfdiqvIyEh8/fXXmD17NgYNGoROnTrhqaee4hL0RERERETUpgKuABs7dqzbxDdPZs6c2WCxNHDgQOzcufOy98nKysJ3333XohiJiIiIiIhaIuCGIBIREREREbVXLMCIiIiIiIh8hAUYERERERGRj7AAIyIiIiIi8hEWYERERERERD7CAoyIiIiIiMhHWIARERERERH5CAswIiIiIiIiH2EBRkRERERE5CMswIiIiIiIiHyEBRgREREREZGPsAAjIiIiIiLyERZgREREREREPsICjIiIiIiIyEdYgBEREREREfkICzAiIiIiIiIfYQFGRERERETkIyzAiIiIiIiIfIQFGBERERERkY+wACMiIiIiIvIRFmBEREREREQ+wgKMiIiIiIjIR1iAERERERER+QgLMCIiIiIiIh9hAUZEREREROQjLMCIiIiIiIh8hAUYERERERGRj7AAIyIiIiIi8hEWYERERERERD7CAoyIiIiIiMhHWIARERERERH5CAswIiIiIiIiH2EBRkRERERE5CMswIiIiIiIiHyEBRgREREREZGPsAAjIiIiIiLyERZgREREREREPsICjIiIiIiIyEdYgBEREREREfkICzAiIiIiIiIfYQFGRERERETkIyzAiIiIiIiIfIQFGBERERERkY+wACMiIiIiIvIRFmBEREREREQ+EnAF2LZt23DDDTcgKSkJgiDgk08+cTt+zz33QBAEt38TJ050O6e0tBR33XUXIiIiEBUVhRkzZqCystLtnP3792PUqFHQ6/VISUnBsmXL2jo1IiIiIiLq4AKuAKuqqkK/fv3wxhtvNHjOxIkTceHCBeXff/7zH7fjd911Fw4dOoSNGzfiiy++wLZt2zBz5kzluMlkwvjx45GWloY9e/bghRdewIIFC/DWW2+1WV5ERERERERqfwdwqUmTJmHSpEmNnqPT6ZCYmOjx2JEjR/DVV1/hp59+wuDBgwEAr732GiZPnoy//vWvSEpKwqpVq2C1WrFy5UpotVr06dMH2dnZePHFF90KNSIiIiIiotYUcAVYU2zZsgXx8fGIjo7Gr371KzzzzDOIjY0FAOzYsQNRUVFK8QUA1157LURRxI8//oibb74ZO3bswOjRo6HVapVzJkyYgKVLl6KsrAzR0dH17mmxWGCxWJSfTSYTAMBut8NutwMARFGEKIqQJAmSJCnnutodDgdkWb5su0qlgiAIynXrtgOAw+FoUrtarYYsy27tgiBApVLVi7GhduYUeDkp15JlyK7HCAIEUYQsSUCdGC+2O4A6zRCd19FoNJAkScmBrxNzYk7MiTkxJ+bEnJhT83O69Hhjgq4AmzhxIm655Rakp6fj1KlT+Mtf/oJJkyZhx44dUKlUyM/PR3x8vNtj1Go1YmJikJ+fDwDIz89Henq62zkJCQnKMU8F2JIlS7Bw4cJ67Xv37kVoaCgAIC4uDt27d0dOTg6KioqUc5KTk5GcnIzjx4/DaDQq7d26dUN8fDwOHjyImpoapb1Xr16IiorC3r173d54WVlZ0Gq12L17t1sMgwcPhtVqxf79+5U2lUqFIUOGwGg04ujRo0q7wWBAv379UFxcjNOnTyvtkZGRyMzMRF5eHs6dO6e0M6fAywkARo4ciQibCZWnDgAANBEx0CemwlJ4DjZTqXK+NiYRuk6JqMk7A0d1hdKuT0gBANx3330oKSlRYuXrxJyYE3NiTsyJOTEn5tT8nKqqqtBUgly3xAswgiBg7dq1uOmmmxo85/Tp0+jevTu++eYbXHPNNXjuuefw7rvv4tixY27nxcfHY+HChZg1axbGjx+P9PR0/OMf/1COHz58GH369MHhw4eRmZlZ7z6eesBSUlJQUlKCiIgIAPzrAXNqeU4OScKBkhoYrRL0KgF6lYgInRopoSq3Hi1BELBv3z4MHToUy7/YgiuuzHIdaHYP2PED+/H7G8Zh+/bt6N+/f6vn1B5fJ+bEnJgTc2JOzIk5MSdPsZtMJsTGxsJoNCq1QUOCrgfsUt26dUOnTp1w8uRJXHPNNUhMTERhYaHbOXa7HaWlpcq8scTERBQUFLid4/q5obllOp0OOp2uXrtarYZa7f40ul7AS7leqKa2X3rdlrQLguCxvaEYm9vOnLzPqcLqwOdnK5Fbaat3bpdQNW7sGo4Irfu9HQ6Hs7i6JCbBQz7Ods+x22w2iKJYLya+TsyJOTGnxtqZE3NiTsypsfaOmFNDxz0+pslnBqhz586hpKQEnTt3BgCMGDEC5eXl2LNnDwYNGgQA2LRpEyRJwrBhw5Rz/u///g82mw0ajQYAsHHjRmRkZHgcfkjBLTc3F8XFxV5fp1OnTkhNTW2FiC46YbTgy7OVMDtkaESgd7QOVocMs0NGXpUd56vsePtoOW7oGo5uEdrLX5CIiIiIAlrAFWCVlZU4efKk8nNOTg6ys7MRExODmJgYLFy4EFOnTkViYiJOnTqFP/3pT+jRowcmTJgAAMjMzMTEiRPxwAMPYPny5bDZbJgzZw7uuOMOJCUlAQDuvPNOLFy4EDNmzMC8efNw8OBBvPLKK3jppZf8kjO1ndzcXGRmZqK6utrra4WEhODIkSOtVoTtKqzBpvPO8cIJBhVu7BqBGP3Fv7qUWRz4JMeEghoH/nvKhJGJBlydGNIq9yYiIiIi/wi4Amz37t0YN26c8vNjjz0GAJg+fTr+/ve/Y//+/Xj33XdRXl6OpKQkjB8/HosXL3YbHrhq1SrMmTMH11xzDURRxNSpU/Hqq68qxyMjI/H1119j9uzZGDRoEDp16oSnnnqKS9C3Q8XFxaiursaTr69AWo+MFl/n7MljeGbODBQXF7dKAVZcY8eWPGfxNThOj7FJoVDXrkzoEq1T4bdXRGHT+Sr8XGzGD/k1CNd47hYnIiIiouAQcAXY2LFj3Sa+XWrDhg2XvUZMTAw++OCDRs/JysrCd9991+z4KDil9chARlZ/f4cBAJBkGetyKyHJQPcIDa7pEqosL38ptShgfEoYwjQitl2oxsZzlRgMDkUkIiIiClaeZ+wTUZvZU2RGXrUdWlHAhJSwBouvukYkGNAzUguHDOxDJ4RGxfogUiIiIiJqbSzAiHyo3OLAtgvOoYfjuoTUW92wIYIgYEpaGGJ0KpgFNe5Y8g803E9MRERERIGKBRiRj8iyjK9+qYRNAlLC1Ogfq2/W4/UqETenh0OUJfQYNgY1IewFIyIiIgo2LMCIfCSnwoYzFTaoBWBSSniThh5eKs6gRh+UAgCqQ2NQY5cu8wgiIiIiCiQswIh85KfCGgBA/056t+XmmysR1Tj2w7eAIOKUydboojVEREREFFhYgBH5QLHZjpwKGwBgcJzBq2sJAD59fh4gSzBaJRSZHa0QIRERERH5AgswIh/YU2QGAPSM1CJK5/1eXmXnzyKkqgQAcKbCBrvEXjAiIiKiYMACjKiN1dglHCx1FmCD45q38EZjDNWlMKgE2CRnEUZEREREgY8FGFEb21dihk0C4g0qpIZpWu26AoDukc7rFdQ4UGHjghxEREREgY4FGFEbkmQZPxe5er8MLVr5sDGRWhXiahf0OMMFOYiIiIgCHgswojZ0vNwKk01CiFpA72hdm9wjLVwNEYDJJqHUwl4wIiIiokDGAoyoDf1c7Oz9GtBJD7XYur1fLjqViKRQNQDnXDCJvWBEREREAYsFGFEbqbA5kFvpXBwjK7b1Ft/wpEuoGhoRMDtk5FdzWXoiIiKiQMUCjKiNHC2zAnAWR5Fa75eeb4xaFJQFPn6p5LL0RERERIGKBRhRGzlabgEAZLbR3K9LJRhUCFELsMvAL5V2n9yTiIiIiJqHBRhRGyi3OHC+ylkE9YryTQEmCAK6hjt7wS5U22FxcEEOIiIiokDDAoyoDbh6v1LDNAjT+O5jFqUVEaEVIQPIZS8YERERUcBhAUbUBo6UOQuwtlp6viGCIKBr7VywwhoHqu3sBSMiIiIKJCzAiFpZqdmBghoHRABXRGl9fv9wrYgYnfOjnVth8/n9iYiIiKhhLMCIWtmR2uGHXcM1CFH75yOWVjsXrMQiocLKXjAiIiKiQMECjKgVybKMw2W+Xf3QkxC1iHiDc+n7s5U2yNycmYiIiCggsAAjakXFZgdKzA6oBKCnH4Yf1pUapoYAwGiVUM5eMCIiIqKAwAKMqBWdMDo3X+4aroFe5d+Pl04lonNIbS9YBXvBiIiIiAIBCzCiVnTK5CzAekb6b/hhXclhGqgEoMouo8Ts8Hc4RERERB0eCzCiVlJtl5TNl7tFaPwcjZNGFNAlVA0AOFtph8ReMCIiIiK/YgFG1EpO1/Z+xRtUiNCq/BzNRUkhamhEwOyQUVjDXjAiIiIif1L7OwCi9uJU7fyvHhH+XXzjUipRQHKoBjkVNuRW2hBnUEElCK12/dzcXBQXF3t9nU6dOiE1NbUVIiIiIiIKXCzAiFqBQ5ZxunbT4+6RgVWAAUBiiAp51XZYHDIuVNmRHNY6QyRzc3ORmZmJ6upqr68VEhKCI0eOsAgjIiKido0FGFErOF/pLG4MagGdQwLvYyUKAlLD1DhhtOF8lR2JrRRjcXExqqur8eTrK5DWI6PF1zl78hiemTMDxcXFLMCIiIioXQu8b4pEQehk7fyv7hFaiK04vK81xelV+KXSDrNDRn61vVWvndYjAxlZ/Vv1mkRERETtERfhIGoFrvlf3QNs/lddgiAgJcz5N5e8ajtkBGahSERERNSesQAj8lKZxYESiwMigPTwwFh+viFxehX0KgE2CTAbovwdDhEREVGHwwKMyEuu3q/kMA306sD+SAmCgOTafcGqQ2Kg1un9HBERERFRxxLY3xaJgsApZf5XYPd+ucQZVNCJAmSVGkNvudvf4RARERF1KCzAiLxgk2TkVtYuPx/A87/qEgUBybVzwcbc8xC4NTMRERGR77AAI/LC+UobHDIQrhERq1f5O5wmizeoIDpsiIhLxAWE+jscIiIiog6DBRiRF3JqN1/uGq6BEKDLz3siCgIM1WUAgLMIhyzLfo6IiIiIqGNgAUbkhTMVzvlfXQN89UNPdGYjLFWVqBK0OFNbSBIRERFR22IBRtRC1TYJBTXOGVRdw4Nj/lddoixhz2f/AQDsLqrxczREREREHQMLMKIWOlO7+EacXoVQTXB+lLav/icgyzhlsqHEbPd3OERERETtXnB+ayQKAGdql59PD5LVDz0p+SUHcXD2fu0pMvs5GiIiIqL2jwUYUQvIsqzMmwrG+V91paECAHCg1AyzXfJzNERERETtGwswohYos0gw2SSoBCAlLLgLsGhYEKdXwSYB2SXsBSMiIiJqSyzAiFogp3b1wy6hGmjE4Fl+3hMBwJB4AwDg52Izl6QnIiIiakMBV4Bt27YNN9xwA5KSkiAIAj755BPlmM1mw7x589C3b1+EhoYiKSkJd999N/Ly8tyu0bVrVwiC4Pbv+eefdztn//79GDVqFPR6PVJSUrBs2TJfpEfthGv4YXqQDz90yYzWQacSYLJKOFvJJemJiIiI2krAFWBVVVXo168f3njjjXrHqqur8fPPP2P+/Pn4+eef8fHHH+PYsWP49a9/Xe/cRYsW4cKFC8q/hx56SDlmMpkwfvx4pKWlYc+ePXjhhRewYMECvPXWW22aG7UPkiwj1zX/K6J9FGAaUUBmlA4AcKDE4udoiIiIiNovtb8DuNSkSZMwadIkj8ciIyOxceNGt7bXX38dQ4cORW5uLlJTU5X28PBwJCYmerzOqlWrYLVasXLlSmi1WvTp0wfZ2dl48cUXMXPmzNZLhtqlvCo7LJIMvUpAgiHgPkItlhWrQ3aJGcfKLbjOEQq9KuD+PkNEREQU9IL+26PRaIQgCIiKinJrf/7557F48WKkpqbizjvvxKOPPgq12pnujh07MHr0aGi1F5cPnzBhApYuXYqysjJER0fXu4/FYoHFcrFnwGQyAQDsdjvsduf+SaIoQhRFSJIESbq4mpyr3eFwuM2vaahdpVJBEATlunXbAcDhcDSpXa1WQ5Zlt3ZBEKBSqerF2FB7sOekXEuWIbseIwgQRBGyJAF15zsp7Q6g7jSo2jleGo0GkiQhx+R8H6SGaSC2k5zsdjvitECsToUSiwOHS2qQFaO7bOyyLDtjqhsLAEGlcr7+dWKHAAiiCrIsAZLs1u66hysWIPjfe+3x88ScmBNzYk7MiTkxJ8+xX3q8MUFdgJnNZsybNw+/+c1vEBERobQ//PDDGDhwIGJiYrB9+3b8+c9/xoULF/Diiy8CAPLz85Genu52rYSEBOWYpwJsyZIlWLhwYb32vXv3IjQ0FAAQFxeH7t27IycnB0VFRco5ycnJSE5OxvHjx2E0GpX2bt26IT4+HgcPHkRNTY3S3qtXL0RFRWHv3r1ub7ysrCxotVrs3r3bLYbBgwfDarVi//79SptKpcKQIUNgNBpx9OhRpd1gMKBfv34oLi7G6dOnlfbIyEhkZmYiLy8P586dU9qDPScAGDlyJCJsJlSeOgAA0ETEQJ+YCkvhOdhMpcr52phE6DoloibvDBzVFUq7PiEFAHDfffehpKQEOUIpIIYgXu38oLWHnFyx9ky8AiUWYOe5MlhPX3wfNJSTWq1GbGysWyyCKCKsRxYc1RWoOX8xdlGrR2jXXrCbymAu+OXicxASruRUN5Zgf++1x88Tc2JOzIk5MSfmxJw851RVVYWmEmQvljyzWCzQ6XSXP7GFBEHA2rVrcdNNN9U7ZrPZMHXqVJw7dw5btmxxK8AutXLlSjz44IOorKyETqfD+PHjkZ6ejn/84x/KOYcPH0afPn1w+PBhZGZm1ruGpx6wlJQUlJSUKPfmXw8CL6d9+/Zh6NChWP7FFlxxZZbrQLN7i44f2I/f3zAO32/fjm3qrrDLwIxekYgzaII+p+3bt6N///4AgBpJwJuHyiADuLdnOGL1qkZj37dvH4YMGYK31m27GAua3wN2/OAB/G7KGOzcuVOJJdjfe+3x88ScmBNzYk7MiTkxJ8+xm0wmxMbGwmg0NlqXAF72gCUlJWHatGm4//770bdvX28u1Sw2mw233347zp49i02bNl02yWHDhsFut+PMmTPIyMhAYmIiCgoK3M5x/dzQvDGdTuex2FSr1crQRhfXC3gp1wvV1PZLr9uSdkEQPLY3FGNz24MhJ4fD4SxELolJ8HCus91z7DabDSbRALsMhKoFdNKrmx17Q+3+zEkUReXe4QC6R2hx0mTFYaMd48Lc3/OXxigIgvOXlKdYBAHw8D4QBBHwEI7D4XCLxSWY33vt8fPEnJhTQzE2t505MSeAOTUUY3PbmZP/c2rouCdezbIPDw/Ha6+9hv79+2PEiBFYuXIlqqurvbnkZbmKrxMnTuCbb75BbGzsZR+TnZ0NURQRHx8PABgxYgS2bdsGm+3ictsbN25ERkaGx+GHRC5lcBYkqWEaZT5We9M31pnjwVIzJO4JRkRERNSqvCrAcnJysH79etxyyy3Yu3cvHnjgAXTu3Bm/+93v6o3xbKrKykpkZ2cjOztbuUd2djZyc3Nhs9lw6623Yvfu3Vi1ahUcDgfy8/ORn58Pq9W5Me6OHTvw8ssvY9++fTh9+jRWrVqFRx99FNOmTVOKqzvvvBNarRYzZszAoUOH8OGHH+KVV17BY4895s3TQR1AKfQAgNR2sv+XJz0itDCoBVTZZeSYuCcYERERUWvyqgATBAETJkzAmjVrcO7cOSxbtgxdunTBW2+9hWHDhmHAgAH4+9//rqwY2BS7d+/GgAEDMGDAAADAY489hgEDBuCpp57C+fPn8dlnn+HcuXPo378/OnfurPzbvn07AOdQwdWrV2PMmDHo06cPnn32WTz66KNue3xFRkbi66+/Rk5ODgYNGoS5c+fiqaee4hL01Ci1VgdjnR6w9kolCugd7czzSDn3BCMiIiJqTa22CmKnTp0wd+5czJ07Fz/88ANWrFiBNWvWYM6cOXj88cdx2223YdasWRg6dGij1xk7dqzbxLdLXW7NkIEDB2Lnzp2XjTcrKwvffffdZc8jcknNGgxJEBCmFhGj8zw+uL3oFaXDniIzThitsEsy1GL7HG5JRERE5GttstNqeHg4QkJC3FYweffddzFixAhMmTIFhYWFbXFbojbVbfDVAJzDD9vr/C+X5FA1wjQiLA4ZZyo4DJGIiIiotbRaAVZZWYm33noLQ4cOxYABA/Dmm2/iiiuuwIoVK1BaWopdu3bh1ltvxfr16/Hggw+21m2JfKbb4JEAgLR2PPzQRRAEZEQ5Nyo/ymGIRERERK3G6yGIO3fuxD//+U+sWbMGlZWVCAsLw8yZM/Hggw8q+/kAzo3WPvzwQ2i1Wnz22Wfe3pbIp2QISOk7CED7XoCjLg5DJCIiImp9XhVgffv2xeHDhyHLMgYMGIAHH3wQd955J8LCwhp8TJ8+fbBq1SpvbkvkczaNAWqNFjrZjihtm4zcDTiuYYiVNglnKmzoEan1d0hEREREQc+rAuz06dO499578eCDD2LIkCFNesxdd92FESNGeHNbIp+zaUMAADGwtPv5Xy6uYYh7isw4Wm5hAUZERETUCrwqwC5cuICIiIhmPSYlJQUpKSne3JbI52waVwFm9nMkvqUMQyy3wp7CYYhERERE3vJqLFVoaChMJhMkSfJ4XJIkmEwmOBwOb25D5FcOWYZd49yAObqDFWDKaogSV0MkIiIiag1eFWALFy5EfHw8SkpKPB4vKSlBQkICnn32WW9uQ+RXFVYJEASU55+HAR3rjwl1V0M8UsbVEImIiIi85VUB9sUXX+Caa65BXFycx+NxcXG49tpr8emnn3pzGyK/MtmcPbxn9u5ERxyA1ytKBwA4abLCITW+EToRERERNc6rAuz06dPo1atXo+dkZGQgJyfHm9sQ+ZXJ6izAcn7e4edI/KNLqBohagEWh4zcSg5DJCIiIvKGVwWYzWaDKDZ+CUEQYDZ3rHkz1H5IsuwcgghnD1hHJAoCetaugHjCaPVzNERERETBzasCrEePHti0aVOj52zatAnp6ene3IbIb6psMiQAgmRHUc5xf4fjNz0jncMQTxitkGUOQyQiIiJqKa8KsFtuuQXZ2dl46qmn6q106HA4MH/+fGRnZ+O2227zKkgifzHanO9rja2mQxceaeEaaESgwiahoKZjLURCRERE1Jq82gds7ty5WL16NZ599lmsXr0a48aNQ5cuXXD+/Hls3rwZp06dQmZmJv74xz+2VrxEPuWa/6Wx1vg5Ev/SiALSw7U4brTiuNGCxBCvfnUQERERdVhefYsKCwvDtm3bMGvWLKxduxYnT55UjomiiFtvvRVvvvkmwsLCvA6UyNdkWVYKMLWtYxdgANAz0lmAnSi3YnTnUH+HQ0RERBSUvP4zdlxcHD766CMUFBRg9+7dMBqNiIqKwuDBgxEfH98aMRL5RbVdhkMGRAFQ27mQTI9ILQQARWYHyi0OROlU/g6JiIiIKOi02jiihIQETJkypbUuR+R3rt6vCI3YIff/upRBLSIlTIPcShtOGK0YEm/wd0hEREREQcerRTiI2jNj7QbMEVp+TFy4HD0RERGRd7zuATt8+DBef/11/PTTTygvL6+3GiLg3Avs1KlT3t6KyGec87+c7+UIrYhqP8cTKHpGavHt+Sr8UmlDjV3ydzhEREREQcerAmzr1q2YOHEiLBYL1Go1EhISoFbXv2RHXr6bgpPZIcMmAQKAcI2IfH8HFCCidCrE6VUoMjtwkr1gRERERM3mVQH2xBNPwG6341//+hemT58OlYqT8ql9cM3/CteIEAXOAKurZ5QWRfk1OGG0oqu/gyEiIiIKMl5Nbtm3bx/uuOMO3HfffSy+qF0x1c7/Cuf8r3quiNQBAHIqrHBweRIiIiKiZvHq22VoaCiXmqd2qaLOCojkLsGgQrhGhE0CSqHzdzhEREREQcWrb5eTJ0/Gd99911qxEAUEmySjxuGct8gesPoEQVBWQyxEiJ+jISIiIgouXn27fOGFF1BeXo6HH34Y1dVcJ47ah4ra4Yd6lQCNyCF2nrgKsCIYIIgsUomIiIiayqtFOO644w6EhYXhjTfewDvvvIMrrrgCERER9c4TBAHffvutN7ci8hll+CF7vxqUGqaBTiXA4lAh5cpB/g6HiIiIKGh4VYBt2bJF+e/Kykr8/PPPHs8TuIocBRFXD1h4G8z/ys3NRXFxsVfXOHLkSCtF03IqUUD3CC0Ol1nQe+xEf4dDREREFDS8KsAkiRuxUvsiy7JSgLX2Ahy5ubnIzMxsteG6lZWVrXKdluoZ6SrAJgOovwE7EREREdXnVQFG1N5U2WVIMqASAIO6dXtui4uLUV1djSdfX4G0Hhktvs7OzV9jxdJFMJvNrRhd83WL0ECQZcR17QF7SY5fYyEiIiIKFq1WgFVWVuL48eOoqqrCqFGjWuuyRD5Vd/n5tho6m9YjAxlZ/Vv8+LMnjrVeMF7QqUTEwIwSGGDVhfk7HCIiIqKg4PUYqzNnzuDGG29EdHQ0hgwZgnHjxinHfvjhB/Tu3dttrhhRIOMGzM0TjxoAYAFGRERE1ERefcvMzc3F8OHDsW7dOtx4440YMWIEZFlWjg8bNgzFxcX4z3/+43WgRL7g6gFriwU42qO42gLMrtbD6pAvczYRERERefUt8+mnn0ZZWRm2bt2Kjz76CNddd53bcbVajVGjRuGHH37wKkgiX7A4ZFik2g2YWYA1iR4O/HLwZ0AQUGrhQhxEREREl+PVt8wNGzbg5ptvxlVXXdXgOWlpaTh//rw3tyHyCdfqh6FqASpuwNxkh7esBwAWYERERERN4FUBVlpaiq5duzZ6jizLsFgs3tyGyCdMVmcBwflfzeMqwMotEhwShyESERERNcarb5oJCQk4ceJEo+ccOHAAqamp3tyGyCfaav+v9q7w9DGIditkAGVW7g1IRERE1Bivvmled911+OKLL7B//36Px7/77jts2rQJkydP9uY2RG1OkmVU2Tj/q6V0Vuem0KVmDkMkIiIiaoxX3zSffPJJGAwGjB49Gs8++yxOnjwJAFi/fj3mz5+PiRMnolOnTnj88cdbJViitlJlkyED0IiATsX5X82ltTgLsDKLA5LMYYhEREREDfFqI+auXbtiw4YNuOOOOzB//nwIggBZlnH99ddDlmWkpqbio48+QufOnVsrXqI24Rp+GNaGGzC3Z2pbDdQCYJcBk1VClE7l75CIiIiIApJXBRjg3OvrxIkT+Pzzz/Hjjz+itLQUERERGDZsGG688UZotdrWiJOoTVXauP+XNwQAMXoVCmscKLU4WIARERERNcDrAgxw7vd188034+abb26NyxH5XN0eMGqZGF1tAWaWkB4usyeRiIiIyAN+26QOzybJMDuc85ZYgLVclE6ECMAiyai2cx4YERERkSde9YAtWrSoSecJgoD58+d7cyuiNuMafqhXCdBwA+YWUwkConQiSi0SSiwOhLKYJSIiIqrHqwJswYIFjR53LcrBAowCGed/tZ4YnQqlFgmlZgdSwzT+DoeIiIgo4HhVgG3evNlju9FoxM8//4xXX30V1157LWbPnu3NbYjaFOd/tZ4YvQow2VBll2FxSNCp+JwSERER1eXVt6MxY8Z4/PfrX/8aCxYswI8//oj169cjPz+/ydfctm0bbrjhBiQlJUEQBHzyySdux2VZxlNPPYXOnTvDYDDg2muvxYkTJ9zOKS0txV133YWIiAhERUVhxowZqKysdDtn//79GDVqFPR6PVJSUrBs2bIWPw8UvGRZZg9YK9KIAiJqn8dSs+TnaIiIiIgCT5t+4+zZsyduvvlmPP/8801+TFVVFfr164c33njD4/Fly5bh1VdfxfLly/Hjjz8iNDQUEyZMgNlsVs656667cOjQIWzcuBFffPEFtm3bhpkzZyrHTSYTxo8fj7S0NOzZswcvvPACFixYgLfeeqvlyVJQskgybJJzGfVQDed/tYYYvfPXSonF4edIiIiIiAJPqyxD35j4+HgcO3asyedPmjQJkyZN8nhMlmW8/PLLePLJJ3HjjTcCAN577z0kJCTgk08+wR133IEjR47gq6++wk8//YTBgwcDAF577TVMnjwZf/3rX5GUlIRVq1bBarVi5cqV0Gq16NOnD7Kzs/Hiiy+6FWrU/lXanKv1hagFiFw2vVXE6FQ4U2GHySrBLslQc2ETIiIiIkWbFmAWiwVfffUVoqKiWuV6OTk5yM/Px7XXXqu0RUZGYtiwYdixYwfuuOMO7NixA1FRUUrxBQDXXnstRFHEjz/+iJtvvhk7duzA6NGj3TaJnjBhApYuXYqysjJER0d7zMVisSg/m0wmAIDdbofdbgcAiKIIURQhSRIk6eLwK1e7w+GALMuXbVepVBAEQblu3XYAcDgcTWpXq9WQZdmtXRAEqFSqejE21B7sOSnXkmXIrscIAgRRhCxJqLA44wlTC5AlqbbdAdRdRb22gNBoNJAkScmhuTm5FqRxiwWAoFI5n6s6sUMABFEFWZYASXZrV+4NeMwJct3zBZ/npBecBW21XUZpjQ1xelWTc6obS7C/99rj54k5MSfmxJyYE3NiTp5jv/R4Y7wqwN577z2P7Xa7HefPn8fq1atx9OhRPPzww97cRuGaS5aQkODWnpCQoBzLz89HfHy823G1Wo2YmBi3c9LT0+tdw3XMUwG2ZMkSLFy4sF773r17ERoaCgCIi4tD9+7dkZOTg6KiIuWc5ORkJCcn4/jx4zAajUp7t27dEB8fj4MHD6KmpkZp79WrF6KiorB37163N15WVha0Wi12797tFsPgwYNhtVqxf/9+pU2lUmHIkCEwGo04evSo0m4wGNCvXz8UFxfj9OnTSntkZCQyMzORl5eHc+fOKe3BnhMAjBw5EhE2EypPHQAAaCJioE9MhaXwHIz2UEAdAk3ZeVjtIdB1SkRN3hk4qiuU6+gTUgAA9913H0pKSpRYm5uTWq1GbGysWyyCKCKsRxYc1RWoOX8xdlGrR2jXXrCbymAu+OXicxASruTURQ+POdlMpcr52phEv+QUk5CJarsdhaVlMNRcaHJOdWMJ9vdee/w8MSfmxJyYE3NiTszJc05VVVVoKkGuW+I1kyiKSi9DXa5LCoKA3/zmN1ixYgV0Ol2zry8IAtauXYubbroJALB9+3aMHDkSeXl56Ny5s3Le7bffDkEQ8OGHH+K5557Du+++W2/YY3x8PBYuXIhZs2Zh/PjxSE9Pxz/+8Q/l+OHDh9GnTx8cPnwYmZmZ9WLx1AOWkpKCkpISREREKM8H/3oQWDnt27cPQ4cOxfIvtuCKK7NcByCIIiSHAz8WWSEB6B+tQYhGbLC36PiB/fj9DeOwfft29O/fv0U57du3D0OGDMFb67ZdjAXN7wHbuPYjLHlkJp59938YMWacW07N6QFry5wqHQL2l1ogCsDQWI1zeGcjOR0/eAC/mzIGO3fuVGIJ9vdee/w8MSfmxJyYE3NiTszJc+wmkwmxsbEwGo1KbdAQr3rA3n77bY/toigiOjoagwYNciuUvJWYmAgAKCgocLtuQUGB8qUtMTERhYWFbo+z2+0oLS1VHp+YmIiCggK3c1w/u865lE6n81hEqtVqqNXuT6PrBbyU64Vqavul121JuyAIHtsbirG57cGQk8PhcBYil8RUIwmQAKgEIESrUv6YIIieY7fZbBBFsd69mxq7a188T7EIggB4eM4EQQQ8hONwOCAD9a/jIX9nu29zChNlaEXAKgEmh4BonarOYxrOyVMswfzea4+fJ+bEnBqKsbntzIk5AcypoRib286c/J9TQ8c9PqbJZ3owffp0bx7ebOnp6UhMTMS3336rFFwmkwk//vgjZs2aBQAYMWIEysvLsWfPHgwaNAgAsGnTJkiShGHDhinn/N///R9sNhs0GudmsRs3bkRGRobH4YfUPtXd/8tTTy61nCAIiNGpkF/jQInZ4VaAEREREXVkbb4KYnNVVlbi5MmTys85OTnIzs5GTEwMUlNT8cgjj+CZZ55Bz549kZ6ejvnz5yMpKUkZppiZmYmJEyfigQcewPLly2Gz2TBnzhzccccdSEpKAgDceeedWLhwIWbMmIF58+bh4MGDeOWVV/DSSy/5I2Xyk8oWbMB85MiRFt/Pm8cGoxi9swArtTguLtZBRERE1MF5VYBt27atxY8dPXq0x/bdu3dj3Lhxys+PPfYYAGdv2zvvvIM//elPqKqqwsyZM1FeXo6rr74aX331FfR6vfKYVatWYc6cObjmmmsgiiKmTp2KV199VTkeGRmJr7/+GrNnz8agQYPQqVMnPPXUU1yCvoOpsje9ACspzAcEAdOmTfP6vpduCt5eRWpFqATAJjl7GyO07AUjIiIi8qoAGzt2bIv/qn3pZLu612xsXRBBELBo0SIsWrSowXNiYmLwwQcfNHr/rKwsfPfdd00LltodSZZRVbsHWKj68u/hSqMRkGXMWfw39BsyrEX33Ln5a6xYusht0/D2TKwdhlhkdqDY7GABRkRERAQvC7CnnnoKP/74IzZs2ICePXti5MiRSEhIQEFBAbZv347jx49jwoQJGD58eGvFS9QqauwyZDgX4NCrmv5HhC7p3ZGR1b9F9zx7oukbkrcXcYaLBVh6OIchEhEREXlVgF1zzTV4/vnn8dZbb2HGjBluX65kWcY///lP/OEPf8D//d//4eqrr/Y6WKLWUskFOHwiUitCXTsM0WiVEMXFOIiIiKiDa/rqAx7Mnz8fU6ZMwf3331/vS6wgCJg5cyYmTZqE+fPnexUkUWtzzf8KVXv1EaDLEAUBsXpn0VVs9jzsmIiIiKgj8erb5549ezxuWlxXZmZmvV2vifytsnb+V5iGvV9trVNtAVZidkBq+b7vRERERO2CVwWYVqvF3r17Gz1n79690Gq13tyGqFXJsoyq2iGIoc1Ygp5aJlIrQiMCdhkot0qXfwARERFRO+bVt8/x48fjq6++wvPPPw+r1ep2zGq1YsmSJdiwYQMmTJjgVZBEranGIUMCIAqAoRkLcFDLCIKg9IIV13AYIhEREXVsXi3C8cILL+C7777D//3f/+GVV17B4MGDER8fj8LCQuzevRuFhYVISkrCsmXLWiteIq8pC3CouQCHr3TSq3Ch2rkps0OWoeLzTkRERB2UVwVYcnIydu/ejSeeeAL//e9/8eWXXyrH9Ho9fvvb3+L5559HYmKi14EStZZKZfghiwBfCdeI0IoCrJKMcoukLMxBRERE1NF4VYABQGJiIt555x3885//xLFjx2A0GhEZGYkrrriCc78oIFUpC3Bw/pevuIYh5lXbUVRjZwFGREREHZbXBZiLRqPBlVde2VqXI2oTsixzCXo/iTM4C7BSiwS7JEMtsgeSiIiIOp5WKcDy8/Px8ccf4+jRo6iursa//vUvAEBRURFycnLQt29fGAyG1rgVkVfMDhkO2bn6TIiaBYAvhaoFGFQCahwySswOJIS02t9/iIiIiIKG19+A3nzzTcydOxcWiwWAc6iRqwArLCzEiBEjsHz5cjzwwAPe3orIa675XyEagQtw1Dpy5IhPHisIAuIMKuRW2lHEAoyIiIg6KK++AX3++eeYM2cOBg8ejKeeegrr16/H8uXLleN9+vRBVlYWPvnkExZgFBCq7LXzvzj8ECWF+YAgYNq0aV5fq7KysknnxemdBZjRKsHikKHjNgBERETUwXi9DH1qaio2b96M0NBQ7Nmzp945ffv2xXfffefNbYhajbIEPRfgQKXRCMgy5iz+G/oNGdaia+zc/DVWLF0Es9ncpPP1ahERGhEmm4Risx1dQjUtui8RERFRsPKqAMvOzsZvf/tbhIaGNnhOly5dUFBQ4M1tiFqFLMuoUpagZwHm0iW9OzKy+rfosWdPHGv2YzoZVDDZJBTVOFiAERERUYfj1bdQSZKg0TT+BaqwsBA6nc6b2xC1Coskwy4DArgAhz910qsgwDkctLq2ICYiIiLqKLwqwDIyMhodXmi327Ft2zb07dvXm9sQtQrX/l8GtQCRC3D4jUYUEK1z/uopMjv8HA0RERGRb3lVgN11113Yu3cvFi5cWO+Yw+HAH//4R5w+fRp33323N7chahXV3P8rYMTVbsRcVOOALMt+joaIiIjId7yaA/bQQw/h888/x6JFi7Bq1Sro9XoAwO23347du3fjzJkzGD9+PGbMmNEqwRJ54+L8L/Z++Vu0XgWVyQaLJMPEYYhERETUgXjVFaDRaLBhwwY88cQTKCkpwcGDByHLMj766COUlpZi3rx5+Oyzz7jfEgUE1xL07AHzP5UgILZOLxgRERFRR+H1TqharRbPPvssnnnmGRw7dgylpaWIiIhAZmYmVCpVa8RI5DUZAswOZwEWwgIsIMTpVSiscaDE7ECkv4MhIiIi8hGvCrBu3bph0qRJeOONNyAIAnr16tVacRG1KrvauRKnRgS03Pw3IERqRWhEwCYBVm2Yv8MhIiIi8gmvugKKi4sRERHRWrEQtRlHbQHG4YeBQxAExOmdfwOy6Pl7hIiIiDoGr76NZmVl4fjx460VC1GbcfWAcQPmwBJncA5TtupCoQsL93M0RERERG3Pq2+j8+bNw+eff47Nmze3VjxEbcJVgHED5sASqhZgUAmAIOLKX13v73CIiIiI2pxXc8DKysowfvx4jB8/HjfddBOGDBmChIQEj6seci8w8icOQQxMgiAgzqBCbqUd/Sff6u9wiIiIiNqcVwXYPffcA0EQIMsy/ve//+F///sfALgVYLIsQxAEFmDkN9FJqZBFFQQABvaABZw4vbMA6zb4aphxwd/hEBEREbWpZhdgJpMJer0eWq0Wb7/9dlvERNSqOl/RB4Bz+KHIPekCjl4tQm2thl0bgnw5xN/hEBEREbWpZhdg0dHRWLBgAebPn4/p06cDAH788Uf8+OOPePjhh1s9QCJvJfbsDYDDDwOZzmyCXRuCCwj1dyhEREREbarZ30hlWYYsy25tX331FR599NFWC4qoNXW+4koAQIiGvV+BSmepgN1mRYWgRVGN3d/hEBEREbUZdglQu+cagsgesMAlyhKO//AtAOBwmcXP0RARERG1HX4jpXbNDgGxKekAuAdYoMte71zE51CZpV4vOxEREVF7wW+k1K5VQgMAEB12aEQOQQxkR7ZtgEqWYLJKOFfFYYhERETUPrEAo3atAloAgMpu9nMkdDl2ixkJqAYAHCrlMEQiIiJqn1q0D9j777+PnTt3Kj+fPHkSADB58mSP5wuCgC+//LIltyLySkVtD5jazi/0waAzqpCHMBwtt+C65FCo2GtJRERE7UyLCrCTJ08qRVddX331lcfzBe69RH5SqfSAsQALBjGwIEwtotIu4ZTJiiuidP4OiYiIiKhVNbsAy8nJaYs4iFqdLMvsAQsyAoDeMTrsKqzB4TILCzAiIiJqd5pdgKWlpbVFHEStzmiV4BBE2K0WqBxWf4dDTdQ72lmAnTBaYXZI0Ks4VZWIiIjaD36zoXaroHZD34JTx8BBsMEjwaBCrF4FhwwcL2fhTERERO0LCzBqtwprC7ALJw75ORJqDkEQ0CfaOfSQqyESERFRe8MCjNqtwhoHACD/OAuwYNO7tgA7W2lDhdXh52iIiIiIWg8LMGq3itgDFrSidCokhzqnqB4uYy8YERERtR8swKhdsjgklFslAOwBC1Z9Ypy9YCzAiIiIqD1hAUbtUlHt8EOdbEe1sczP0VBL9IrSQRSAghoHimt7M4mIiIiCHQswapdcC3CEw+bnSKilDGoR3SKcG2kfYi8YERERtRNBWYB17doVgiDU+zd79mwAwNixY+sd+93vfud2jdzcXEyZMgUhISGIj4/H448/Drudf2VvL1wLcISDy5gHM2U1xDILZFn2czRERERE3mv2RsyB4KeffoLDcXFltIMHD+K6667DbbfdprQ98MADWLRokfJzSEiI8t8OhwNTpkxBYmIitm/fjgsXLuDuu++GRqPBc88955skqE25esDC2AMW1HpEaqEVBZisEs5V2ZESpvF3SEREREReCcoesLi4OCQmJir/vvjiC3Tv3h1jxoxRzgkJCXE7JyIiQjn29ddf4/Dhw3j//ffRv39/TJo0CYsXL8Ybb7wBq5U9JsFOlmUUmV1DEPl6BjONKCAjqnYYIvcEIyIionYgKHvA6rJarXj//ffx2GOPQRAEpX3VqlV4//33kZiYiBtuuAHz589XesF27NiBvn37IiEhQTl/woQJmDVrFg4dOoQBAwbUu4/FYoHFcvELoMlkAgDY7XZl6KIoihBFEZIkQZIk5VxXu8PhcBtG1VC7SqWCIAj1hkSqVCoAcOv9a6xdrVZDlmW3dkEQoFKp6sXYUHsw5lRmccAmASoBCJHtzmvJMmTXYwQBgihCliSg7rA2pd0B1B3tJjrfVxqNBgJw8TqiCEEQLv588Ulw/m+d56turG7XACCoVM7nqu75AiCIKsiyBEiyW7vr+XG7TjvJSZKkep+n3lFaHCi14Gi5BWMTddCqVQH73rtcezB+npgTc2JOzIk5MSfmdPmcmjOVKegLsE8++QTl5eW45557lLY777wTaWlpSEpKwv79+zFv3jwcO3YMH3/8MQAgPz/frfgCoPycn5/v8T5LlizBwoUL67Xv3bsXoaGhAJw9c927d0dOTg6KioqUc5KTk5GcnIzjx4/DaDQq7d26dUN8fDwOHjyImpoapb1Xr16IiorC3r173d54WVlZ0Gq12L17t1sMgwcPhtVqxf79+5U2lUqFIUOGwGg04ujRo0q7wWBAv379UFxcjNOnTyvtkZGRyMzMRF5eHs6dO6e0B2NORWIooOmMMNggAhg5ciQibCZUnjoAANBExECfmApL4TnYTKXKdbQxidB1SkRN3hk4qiuUdn1CCgDgvvvuQxc9lOsYunSDOjQCVTmHnIVPrZC0XhDVGuU8F1EAYmNj3a4hiCLCemTBUV2BmvMXXw9Rq0do116wm8pgLvjl4nMQEg7U5lT3Ou0lp5KSEuW94HrvOYrOQSuHwuxQY2P2UQxIim7wvWc2m3H8+HG391hkZCS0Wi2Ki4vdfqFGR0dDFEWUlJS45RQbG4uoqCgUFxdfjLEDf56YE3NiTsyJOTEn5nT5nKqqqtBUghzkM9snTJgArVaLzz//vMFzNm3ahGuuuQYnT55E9+7dMXPmTJw9exYbNmxQzqmurkZoaCjWrVuHSZMm1buGpx6wlJQUlJSUKMMb+deDwMjph4Ia7Ci0oG+0Fp1LT2Lo0KFY/sUWXHFllusBze4t2vjxGix97HdY/PYajBgzzpVss3qLNn7yEZ59+H4s+ffai9dA83uLNq79CEsemYln3/3fxesEeU7HDx7A76aMwc6dO9G/f//aW158720+X4Wfii3oGaHBzenhHt9j58+fR+/evWGz2dx6w+12OyRJglardYvdZrNBluV67VarFaGhoTh48CCSk5OV9o76eWJOzIk5MSfmxJyY0+VzMplMiI2NhdFodJv65ElQ94CdPXsW33zzjdKz1ZBhw4YBgFKAJSYmYteuXW7nFBQUAAASExM9XkOn00Gn09VrV6vVUKvdn0bXC3gp1wvV1PZLr9uSdkEQPLY3FGNz2wMxp2KL80MTH6IBSms/GIIA4ZKYBA/5ONs9x26z2SAD9a/TQK7w0C7LsudrCILH8wVBBDxc3uFweL5OkOckiqLHz1PfTgb8VGzBqQobLBJgEOu/x0pKSlBdXY0nX1+BtB4ZnuNvgrMnj+GZOTNQWlqKrl271supo32evG1nTsypoXbmxJwA5tRQjM1tZ07+z6mh4x4f0+QzA9Dbb7+N+Ph4TJkypdHzsrOzAQCdO3cGAIwYMQLPPvssCgsLER8fDwDYuHEjIiIi0Lt37zaNmdqeawXEeIMKJZc5l4JDvEGNeIMKhTUOHC23YEAnQ4PnpvXIQEZWf98FR0RERNQMQbkKIgBIkoS3334b06dPd6s4T506hcWLF2PPnj04c+YMPvvsM9x9990YPXo0srKcQ9DGjx+P3r1747e//S327duHDRs24Mknn8Ts2bM99nJR8DA7JBitzm7meENQ/32BLuHaE+wgV0MkIiKiIBa0Bdg333yD3Nxc3HfffW7tWq0W33zzDcaPH49evXph7ty5mDp1qtscMZVKhS+++AIqlQojRozAtGnTcPfdd7vtG0bBqci1AbNGhEEdtG9v8qBPjB4CgPNVdpRZHJc9n4iIiCgQBW0Xwfjx490myLmkpKRg69atl318Wloa1q1b1xahkR/VHX5I7UuYRkTXcA1yKmw4VGrB1Z1DLv8gIiIiogDDLgJqVy4WYEH7twVqRJ8Y1zBEs8c/wBAREREFOhZg1K64hiCyAGufrojUQSMC5VYJ56uavuEhERERUaBgAUbthiTLKDJzCGJ7plUJyIjiYhxEREQUvFiAUbtRbpFgkwC1AETrWIC1V31rhyEeKbPAJnEYIhEREQUXFmDUbrjmf8UZ1BAFwc/RUFtJDdMgUivCIsk4Xs5eMCIiIgouLMCo3bhYgLH3qz0TBAFX1vaCHeAwRCIiIgoyLMCo3SjkAhwdRt8YPQDgTIUNJiv3BCMiIqLgwQKM2o1CM5eg7yiidCqkhDlfZy7GQURERMGEBRi1C2a7BJNVAgDE6zkEsSPIqu0FO8A9wYiIiCiIsACjdqHQ7ByGFqERoVfzbd0RZEQ59wQrs3BPMCIiIgoe/KZK7UJRDYcfdjRalYBetXuC7S81+zkaIiIioqZhAUbtQmENN2DuiFyLcRwts8IObj1AREREgY8FGLULXAGxY0oJUyNaJ8IqychHiL/DISIiIrosFmAU9CRZ5hDEDkoQBPSPdfaCnUOYn6MhIiIiujwWYBT0yiwO2GVALQBROr6lO5q+MXqIAmASdOic0dff4RARERE1it9WKei5hh/GGdQQBc4D6mhCNCIyIrUAgKE3T/NzNERERESNYwFGQY8LcFC/Ts5hiP0n3waZi3EQERFRAOOEGQp6hZz/1eGlhWlgkG1AWDgsUqW/wyEiIiJqEHvAKOgV1A5BTGAB1mEJgoBkOAsvsyHKv8EQERERNYIFGAW1KpuESpsEgD1gHV0SquCw2WDXGFBV+54gIiIiCjQswCioFdQOP4zVqaBVce5PR6aDhMNb1gMALlTb/RwNERERkWcswCio5dd+0U4IYe8XATv+uwIAUGR2wC7Jfo6GiIiIqD4WYBTUXD1gCVwBkQDk7NkOld0CSb743iAiIiIKJCzAKKgVsAeMLmGoLgMA5Fc7IMvsBSMiIqLAwgKMgpbZLqHc6lxsgSsgkovObIJKAMwOGWUWLsZBREREgYUFGAUt1xCzCK0Ig5pvZXISICsFORfjICIiokDDb60UtFz7fyWy94su0TnEOSew3Cqh2s5eMCIiIgocLMAoaHH+FzVErxYRrXP+estnLxgREREFEBZgFLQuroDIAozqS6otzAtquCQ9ERERBQ4WYBSUbJKMErNzCGJCCJegp/oitSJC1AIkmb1gREREFDhYgFFQKqyxQwYQqhYQxgU4yANBENAl1NkLlldth8Ql6YmIiCgA8JsrBSVl/pdBDUEQ/BwNBapOehW0ImCTgKLaRVuIiIiI/IkFGAUlZf4XF+CgRoiCgM61vWDnq+3cmJmIiIj8jgUYBaWC6tr5X1yAgy4j0aCGSgBq7NyYmYiIiPyPBRgFHYcso8js7AFLZA8YXYZaFJRC/XwVF+MgIiIi/2IBRkGnuMYBhwzoVAIitXwL0+UlhaogADDZJFTY2AtGRERE/sNvrxR0LnABDmomnUpEJ71zu4LzlTY/R0NEREQdGQswCjoXqp1foJNCOfyQmi45zPl+KbFIqGYvGBEREfkJCzAKOnm183iSOP+LmiFELSJW5/yV9wvnghEREZGfsACjoGJ1yCg2O1dA7MweMGqm5DANAKDY7ECNnb1gRERE5HsswCioFNTYIQMI14gI16j8HQ4FmTCNiOjaXrBz7AUjIiIiP2ABRkElr8o5/6szhx9SCyXX9pwW1ThgdrAXjIiIiHyLBRgFFdcKiCzAqKUitCpEakXI4L5gRERE5HsswCio5NUWYFwBkbzh6gUrqHbA4pD9HA0RERF1JEH3LXbBggVYuHChW1tGRgaOHj0KADCbzZg7dy5Wr14Ni8WCCRMm4M0330RCQoJyfm5uLmbNmoXNmzcjLCwM06dPx5IlS6BWB93T0aFU2SSYrM4hY4nsAWuXjhw54pPHRmpFRGhEmGwSzlXZ0D1C2+L7EhERETVHUH6L7dOnD7755hvl57qF06OPPoovv/wSa9asQWRkJObMmYNbbrkFP/zwAwDA4XBgypQpSExMxPbt23HhwgXcfffd0Gg0eO6553yeCzWda/hhJ70KOhU7b9uTksJ8QBAwbdo0r69VWVl52XMEQUBKmBqHyqwoqHYgOVTie4qIiIh8IigLMLVajcTExHrtRqMRK1aswAcffIBf/epXAIC3334bmZmZ2LlzJ4YPH46vv/4ahw8fxjfffIOEhAT0798fixcvxrx587BgwQJotfxLeKDKq+YCHO1VpdEIyDLmLP4b+g0Z1qJr7Nz8NVYsXQSz2dyk86N0qou9YJV2dI/kZ5+IiIjaXlB+kz1x4gSSkpKg1+sxYsQILFmyBKmpqdizZw9sNhuuvfZa5dxevXohNTUVO3bswPDhw7Fjxw707dvXbUjihAkTMGvWLBw6dAgDBgzweE+LxQKLxaL8bDKZAAB2ux12u7NnRhRFiKIISZIgSRdXV3O1OxwOyLJ82XaVSgVBEJTr1m0HnL14TWlXq9WQZdmtXRAEqFSqejE21B5IOeVVXizA6l6nsZyUa8kyZNe1BAGCKEKWJKBOjBfbHUDdaUGi8zoajQYCcPE6oghBEC7+fPFJcP6vVH+FPUEQ3K8BQFCpnM9V3fMFQBBVkGUJkGS3dldObtdpJzklp3fHFX36tiinsyeOKZdzi7+RnJResBoHkgx26FUCIMsQBAGSJLm9z9rb54k5MSfmxJyYE3NiTq2X06XHGxN0BdiwYcPwzjvvICMjAxcuXMDChQsxatQoHDx4EPn5+dBqtYiKinJ7TEJCAvLz8wEA+fn5bsWX67jrWEOWLFlSb+4ZAOzduxehoaEAgLi4OHTv3h05OTkoKipSzklOTkZycjKOHz8Oo9GotHfr1g3x8fE4ePAgampqlPZevXohKioKe/fudXvjZWVlQavVYvfu3W4xDB48GFarFfv371faVCoVhgwZAqPRqMyPAwCDwYB+/fqhuLgYp0+fVtojIyORmZmJvLw8nDt3TmkPlJxkAOe06YCgQrhkxu7d+5qUEwCMHDkSETYTKk8dAABoImKgT0yFpfAcbKZS5XxtTCJ0nRJRk3cGjuoKpV2fkAIAuO+++9BFD+U6hi7doA6NQFXOIWeRUCskrRdEtUY5z0UUgNjYWLdrCKKIsB5ZcFRXoOb8xdhFrR6hXXvBbiqDueAXpV0VEq7kVPc6zAmI0Dk3WU7QwS3OxnKKVGsQZq9CpToUZ/KLkGwuAODMqaSkRHlftrfPE3NiTsyJOTEn5sScWjenqqoqNJUg1y3xglB5eTnS0tLw4osvwmAw4N5773XrqQKAoUOHYty4cVi6dClmzpyJs2fPYsOGDcrx6upqhIaGYt26dZg0aZLH+3jqAUtJSUFJSQkiIiIA8K8HbZlTmcWBFccroBKAR7Ni3HpWGstp3759GDp0KJZ/sQVXXJnlOtDs3qKNH6/B0sd+h8Vvr8GIMeNcyTart2jjJx/h2Yfvx5J/r714DTS/t2jj2o+w5JGZePbd/128DnPCxk8+wjMPzcDz73/iFsvlcjJZ7DhYbocAYECMBrlHDmDm5NHYtWsX+vfvr5zenj5PzIk5MSfmxJyYE3Nq3ZxMJhNiY2NhNBqV2qAhQdcDdqmoqChcccUVOHnyJK677jpYrVaUl5e79YIVFBQoc8YSExOxa9cut2sUFBQoxxqi0+mg0+nqtavV6nqrJ7pewEu5Xqimtje0KmNz2gVB8NjeUIzNbfdVToUm55s+MUQNtSheLAiaEKPD4XB+ab8kJsHDuc52z7HbbDbIQP3rNJArPLTLsuz5GoLg8XxBEAEPl3c4HJ6vw5w8XgMNtAFApF6DKK2EcquEczUSIAiQZRmiKNZ7X7aXz1NdzIk5AcypoRib286cmBPAnBqKsbntwZZTc1ZTD/plvyorK3Hq1Cl07twZgwYNgkajwbfffqscP3bsGHJzczFixAgAwIgRI3DgwAEUFhYq52zcuBERERHo3bu3z+OnpsnjBszUhlLDnMMXC2sccKg0fo6GiIiI2rOg+zb7xz/+ETfccAPS0tKQl5eHp59+GiqVCr/5zW8QGRmJGTNm4LHHHkNMTAwiIiLw0EMPYcSIERg+fDgAYPz48ejduzd++9vfYtmyZcjPz8eTTz6J2bNne+zhosCQV8UCjNpOuFZEtFZEmVVCdUisv8MhIiKidizovs2eO3cOv/nNb1BSUoK4uDhcffXV2LlzJ+Li4gAAL730EkRRxNSpU902YnZRqVT44osvMGvWLIwYMQKhoaGYPn06Fi1a5K+U6DKsDhkFtT1gyWHsnaC2kRKmQVmpBRZ9BGJTuvk7HCIiImqngq4AW716daPH9Xo93njjDbzxxhsNnpOWloZ169a1dmjURi5U2yABCNeIiNAE/ahZClDhWhHROhFlFgnXzJzr73CIiIioneK3WQp452qHH6aEaZS9vYjagmsuWL+JU1EVfH+fIiIioiDAAowC3rnaDZiTQ/mFmNpWmEaE1lIBUaXCKUT6OxwiIiJqh1iAUUCTZBnnqzj/i3wnpKoEAJCPEBTVNH1XeyIiIqKmYAFGAa2wxgGrJEOnEtBJ38DeVEStSG234MA3nwOCgO/zq/0dDhEREbUzLMAooNUdfihy/hf5yDfLlwKyjGPlVuRXsxeMiIiIWg8LMApo56pcBRiHH5LvFJ4+hkQ4e7++u1Dl52iIiIioPWEBRgFLlmX84uoB4/wv8rHuMEIAcMpkw/naPwQQEREReYsFGAWscquEKrsMlQB0DuEKiORbobCjb4wOAPDdBc4FIyIiotbBAowClmv+V2KIGmqR87/I965KDIEoAGcqbMitYC8YEREReY8FGAUs1/yvFM7/Ij+J0qnQP1YPANh2oQqyLPs5IiIiIgp2LMAoYP1Syf2/yP9GJBigEoBzVXacYS8YEREReYkFGAWkapuEUosDANAllPO/yH/CtSoM7OTqBatmLxgRERF5hQUYBaRfaocfdtKrYFDzbUr+NTwhBBoRuFBtx0mT1d/hEBERURDjN1sKSGdrh3qlcvghBYBQjYjBcQYAzhUR2QtGRERELcUCjAKSqwDrGs4CjALD0HgDdKKAwhoHjpWzF4yIiIhahgUYBZwKqwMlFgcEsAeMAodBLWJI/MVeMIm9YERERNQCLMAo4Jyt3f8rIUQNPed/UQAZEq+HXiWgxOLAoVKLv8MhIiKiIMRvtxRwXEt9d2XvFwUYnUrEiITaXrD8atgl9oIRERFR87AAo4Aiy7Iy/yuN878oAA2MMyBMI8JklZBdYvZ3OERERBRkWIBRQCmzSKiwSVAJ3ICZApNGFDAy0dkLtj2/GlYHe8GIiIio6ViAUUA5U+FcXa5LqAYaUfBzNESeZcXqEa0TUW2X8VNRjb/DISIioiCi9ncARHW5FuBIC9cgNzcXxcXFXl3vyJEjrREWkRuVIGBU51B8dqYCuwpqMLCTnhuGExERUZOwAKOAUXf+l76qFJlZmaiurm6Va1dWVrbKdYhcMqO02GlQobDGgR0FNfhVl1B/h0RERERBgAUYBYyCGgfMDhlaUYBsLER1dTWefH0F0npktPiaOzd/jRVLF8Fs5mIJ1LoEQcCYzqFYc9qEPUXOXrAoncrfYREREVGAYwFGAeNs7fyvlDA1RKOzLa1HBjKy+rf8mieOtUJkRJ51i9AgLUyDs5U2bLtQjV93Dfd3SERERBTgOGmBAoay/1e41s+REDWNIAgYVzv08HCZBReqbH6OiIiIiAIdCzAKCDZJxi+VrgKMy89T8EgMUePKGB0AYFNeFWSZy9ITERFRwzgEkdpEc1cwLIIediEeetmO3CP7cZSrF1IQGd05BEfLLPil0o6TJit6Rur8HRIREREFKBZg1Opyc3ORmdm8FQxv+NMSXHXH/dj6v/fx6HOPK+1cvZCCQYRWhSHxBuwoqMHm89XoFqGFSuA+dkRERFQfCzBqdcXFxc1awVAGUBabDgnAtddehymjv+fqhRR0hiUYkF1iRqnFgZ+LzBgSb/B3SERERBSAWIBRm2nqCoY1dgklxRYIAPpc0R0qUeDqhRR09CoRYzqH4qtfKvH9hWr0jtYhVMNptkREROSO3w7I78osEgAgQitCJXLYFgWvrFgdEg1qWCQZW/Kq/B0OERERBSAWYOR3ZRYHACCam9hSkBMFAeNTnMvSHyi14DyXpSciIqJLsAAjv3JIMoxWZw9YtI5vRwp+SaEaZNUuS7/xlypIXJaeiIiI6uA3XvKrcqsEGYBeJcCg4vBDah/GJIVCpxKQX2PHvhIuJENEREQXsQAjv7o4/FCEwGW7qZ0I1YgY1TkEALAlrxqVNsnPEREREVGgYAFGfiPLsrIAB+d/UXszsJMeiSFqWBwyNvxSCZlDEYmIiAgswMiPauwyrJIMEc4VEInaE1EQMDk1DKIAnDBacbTc6u+QiIiIKADwWy/5TWnt8MNIrQgVhx9SOxRvUOOqBOdQxK/PVaKaQxGJiIg6PBZg5DcltQVYjJ7DD6n9GpFgQJxehRq7jG/Oc28wIiKijo4FGPmFxSGh0uacExPD+V/UjqlEAZPTwiAAOFxmwdEyi79DIiIiIj9iAUZ+UWJ2DsWK0IjQcvl5auc6h2gwPMEAAFj/SyWMVoefIyIiIiJ/YQFGflGqDD/kW5A6hqs7hyCpdlXEz85UwMFVEYmIiDokfvsln7NJMoxWZw9YLIcfUgehEgT8ums4dKKA81V2fH+h2t8hERERkR+wACOfKzU7e79C1QL0ar4FqeOI0qkwKTUMALCjoAZnKrg0PRERUUej9ncAzbVkyRJ8/PHHOHr0KAwGA6666iosXboUGRkZyjljx47F1q1b3R734IMPYvny5crPubm5mDVrFjZv3oywsDBMnz4dS5YsgVoddE9J0OHqh9SR9YrWoV+FFftKLPjsTAWmZ0QhUtvwZyE3NxfFxcVe37dTp05ITU31+jpERETknaCrNrZu3YrZs2djyJAhsNvt+Mtf/oLx48fj8OHDCA0NVc574IEHsGjRIuXnkJAQ5b8dDgemTJmCxMREbN++HRcuXMDdd98NjUaD5557zqf5dDR2SUa5hcMPKfAdOXLE62s0VPRcmxyGC9V2FNY48L/TJkzrGeVxMZrc3FxkZmaiutr74YohISE4cuQIizAiIiI/C7oC7KuvvnL7+Z133kF8fDz27NmD0aNHK+0hISFITEz0eI2vv/4ahw8fxjfffIOEhAT0798fixcvxrx587BgwQJotdo2zaEjK7dKkAHoVQJC1Fz9kAJPSWE+IAiYNm2a19dqqOjRiAKmdovAu8fKUVjjwJe5FbipaziESzYkLy4uRnV1NZ58fQXSemSgpc6ePIZn5sxAcXExCzAiIiI/C7oC7FJGoxEAEBMT49a+atUqvP/++0hMTMQNN9yA+fPnK71gO3bsQN++fZGQkKCcP2HCBMyaNQuHDh3CgAED6t3HYrHAYrm4f4/JZAIA2O122O12AIAoihBFEZIkQZIk5VxXu8PhgFxn5bOG2lUqFQRBUK5btx1w9uA1pV2tVkOWZbd2QRCgUqnqxdhQe0tyAgCNRgPIMmTXvUURgiCgpMaZU4xWACQJcu35qHPtujEJwMVrABBUKuf96p4vAIKogixLgCS7tbueH7frCAIEUYQsSUDdleiUdgdQd4E6UVBycrtObU7yJc87mJN/cqpzObf4m5lTpdEIAcBDz7yIvoOGuN0XnlYubKD97KnjWPKHmSgsLERSUlLtLS9+nkJFGb9ODcV/cypxrNyKH/JrMCJe5/Z5cv13WvcrcEWfvi3OCbIMQRAgSZLb7xV//Y5oj7/3mBNzYk7MiTl17JwuPd6YoC7AJEnCI488gpEjR+LKK69U2u+8806kpaUhKSkJ+/fvx7x583Ds2DF8/PHHAID8/Hy34guA8nN+fr7Hey1ZsgQLFy6s1753715l6GNcXBy6d++OnJwcFBUVKeckJycjOTkZx48fVwpGAOjWrRvi4+Nx8OBB1NTUKO29evVCVFQU9u7d6/bGy8rKglarxe7du91iGDx4MKxWK/bv36+0qVQqDBkyBEajEUePHlXaDQYD+vXrh+LiYpw+fVppj4yMRGZmJvLy8nDu3DmlvSU5AcB9992HCJsJlacOOO/bpRuEkHCUmm2AoIKhOAeVBWaEpPWCqNYo57mIAhAbG4sueijHBFFEWI8sOKorUHP+YuyiVo/Qrr1gN5XBXPDLxecgJBwAMHLkSLfraCJioE9MhaXwHGymUuV8bUwidJ0SUZN3Bo7qCqVdn5Ci5FT3OoYu3aAOjUBVziFnkVCLOfknpwidBgCQoINbnC3NaUivbogxCG452atMHnOyGUvq5yRkYOTIkSgpKVE+s54+Tz3FcBzTJOD7/GrUlOQjvLJQuY7r/zDC7FVe5QQ4c6obiz9/R7TH33vMiTkxJ+bEnDp2TlVVVWgqQZY9/Uk3OMyaNQvr16/H999/j+Tk5AbP27RpE6655hqcPHkS3bt3x8yZM3H27Fls2LBBOae6uhqhoaFYt24dJk2aVO8annrAUlJSUFJSgoiICAD864GrPTs7G8OHD8ebn23CFVdmuQ6gxCLhWLkVOhEYGKNxDrdq4C/2Gz/5CM8+fD+W/HstRowZdzHOZvasbFz7EZY8MhPPvvu/i9dpQW/Rxo/XYOljv8Pit9dcvE4zeyGYU9vmtPGTj/DMQzPw/PufuMXir5yOHzyA300Zg507d6J///61t/T8edp8oQZ7ii0QBeCWtFB0DXcWk/v27cPgwYPxz/XfXfwstSCn4wf3Y+bk0di1a5cSCxCcf2G8XDtzYk7MiTkxJ+bkj5xMJhNiY2NhNBqV2qAhQdsDNmfOHHzxxRfYtm1bo8UXAAwbNgwAlAIsMTERu3btcjunoKAAABqcN6bT6aDT6eq1q9Xqeisnul7AS7leqKa2N7QiY3PaBUHw2N5QjM1tbyh2m83m/KJc53hR7fDDTgY1xEtj8nAdWZYhA27XcOXk6XxBEAEP4TgcDs/X8ZCPs73hnDxep4HngDn5JydP10ADbQDaPCdRFC/7O+Ka5DBU2WUcLbfi09wq3NkzEp1DNBfnhF3yWWp2ToIAWZY9xuKv3xHt8fcec2JOzIk5AcypoRib2x5sOTVnJfWg24RJlmXMmTMHa9euxaZNm5Cenn7Zx2RnZwMAOnfuDAAYMWIEDhw4gMLCi0N9Nm7ciIiICPTu3btN4u7o7JKMstrVD+O4/DyRG1EQcH1aONLCNLBJwH9PmZT98oiIiKh9CboCbPbs2Xj//ffxwQcfIDw8HPn5+cjPz1fGap46dQqLFy/Gnj17cObMGXz22We4++67MXr0aGRlOYfwjB8/Hr1798Zvf/tb7Nu3Dxs2bMCTTz6J2bNne+zlIu+VmJ29GyFqAaGaoHvbEbU5tSjglm7hSDCoUGOXsfqkETWeutWIiIgoqAXdN+G///3vMBqNGDt2LDp37qz8+/DDDwEAWq0W33zzDcaPH49evXph7ty5mDp1Kj7//HPlGiqVCl988QVUKhVGjBiBadOm4e6773bbN4xaV1HtX/PZ+0XUMJ1KxO3dIxGjU8Fkk7AbCYhMSPJ3WERERNSKgm4O2OXWDElJScHWrVsve520tDSsW7eutcKiRlgcMoxW5/DDTgYWYESNCdWI+E2PCKw6YUS5VY0H3voEDrH+8v9EREQUnIKuB4yCT7HZufhGhEaEXsW3HNHlhGtVuLNnJAyyHbEp6TBGpcDiCNoFa4mIiKgOfhumNldU4xx+yN4voqaL0KowGAUoy8uFpNbiYKkFFgd7woiIiIIdCzBqU9V2CVV2GQKATpz/RdQsBjjwz5k3Q3RYYXbIOFBiRY2dRRgREVEwYwFGbcrV+xWlE6ERBT9HQxR8yvJyEVn2C/QqARZJxoFSC6pZhBEREQUtFmDUZmQABbWbL8cbgm69F6KAoZLs6BujQ4hagE0CDpRYUGFjEUZERBSMWIBRm7HqwmCTAI0IxOj4ViPyhlYl4MoYHcLUAuwycLDUgnILN2smIiIKNvxWTG3GrI8CACQY1BAFDj8k8pZGFNAnRodIrQhJBg6XWVFU28tMREREwYHjwqhNRCelwqYNAQAkcPVD6sCOHDnSqo9ViwJ6R2txwmhDsdmB40YbrJKMpBA1BP6hg4iIKOCxAKM2MeTmaYAgIEorQq9mRyt1PCWF+YAgYNq0aV5fq7Ky0u1nURBwRaQGGhG4UO3AmQo7zHYZ3SI0LMKIiIgCHAswanUSgEG/vhMAkBDCtxh1TJVGIyDLmLP4b+g3ZFiLrrFz89dYsXQRzGZzvWOCICA9XAOdSsCZCjvyaxwwO2RkRGmh5oqjREREAYvfjqnVFcGAiLg4CA47YnR6f4dD5Fdd0rsjI6t/ix579sSxRo8LgoAuoRroVSKOG60ot0rYX2pBZpQWBvY8ExERBST+PzS1unMIAwDozUYuvkHkA7F6FfrG6KARgRq7jH0lFpSauUIiERFRIGIBRq2q2GxHiWAAAOhrjH6OhqjjCNOI6B+rR7hGhEMGjpRbkVthgyzL/g6NiIiI6mABRq3qx4IaAMChTV9CJdn8HA1Rx+LcK0yLziHOlUd/qbLjUJkVDpErkRIREQUKFmDUakxWBw6VWQAAW999zc/REHVMoiCgW4QWPSM1EAXAaJVQHtMVmWMm+js0IiIiAgswakW7i8yQZCBaNuOXA3v8HQ5RhxZvUKNfrA6hagGyqMbdL/0bhxENi0Pyd2hEREQdGgswahVmu4TsYudS2V1h8nM0RAQAIWoRWbE6GKpKAQDnhHCsOFKOU0arnyMjIiLquFiAUav4udgMqyQjTq9CJ9Tfs4iI/EMUBIRWFeGfD94Mg2yDySZhzWkTPjtTgSobe8OIiIh8jQUYec0mydhd5Fx8Y1iCAVx4nijwnP7pe1yFfAyNd35GD5dZ8NaRMvxUWAMHV0okIiLyGRZg5LUDJWZU22VEaERkRuv8HQ4RNUAFGb/qEoq7MyKRYFDB4pDx7fkqrDxSjtMmDkskIiLyBbW/A6DgZnFI+CG/GoCz90vFjZeJAl7nEA2mZ0ThQIkFWy9UocTiwH9PmZAWpsGYpBAkhWo8Pi43NxfFxcVe379Tp05ITU31+jpERETBiAUYeeXHwhpU2WVE65ybwBJRcBAFAf066ZERpcUP+dX4udiMs5U2vHfciJ6RWozqHIJ4w8X/i8jNzUVmZiaqq6u9vndISAiOHDnCIoyIiDokFmDUYiarA7tqN14emxQKlcjeL6Jgo1eLuCY5DIPjDfj+QjUOllpwwmjFCaMVPSO1uCrBgM6hGhQXF6O6uhpPvr4CaT0yWny/syeP4Zk5M1BcXMwCjIiIOiQWYNRi312ohl0GkkPVuCJS6+9wiMgLkVoVpqSFY1iCsxA7Wm5VCrGu4RrEwNnDndYjAxlZ/f0bLBERURBjAUYtUlBtx4FSCwDgV11CIXDuF1G70Emvxk3pESgx27GjoAaHSi04U2HDGSEej6z5DmZ9JByyzPmeRERELcQCjJpNlmVsOl8FAOgdrWtwwj4RBa9YvRrXp4Xj6sQQ/FRUg+zCaiR074VKALsLzYgzqJAYokaImovpEhERNQf/n5Oa7WCpBWcrbVAJwOjOIf4Oh4jaUJROheuSwzAa5/Hli09BdNhgl4EL1Q7sLbbgQIkF+dV22CXuJUZERNQULMCoWYxWB7455+z9ujoxBFE6lZ8jIiJf0EDG9+//HdElp9E7WosYnfP/Pkw2CadMNuwqNONImQVFNSzGiIiIGsMhiNRksixj3dlKWCQZXULVGJZg8HdIRNQMR44c8fqxAoBonQrROudGzkU1dhSZHai2yyi1SCi1SBBgQ6RWRLROhSidCINK4DxRIiKiWizAqMn21O4TpBGBKanhEPmFiigolBTmA4KAadOmeX2tyspK5b91KgHJYRokh2lQZZNQZHag1OxAjUNGuVVCuVUCKgCN6FxlMUIjwqbWQ61rnT0DW2NjaG4KTUREvsYCjJqk1OzAltqFN8YmhSJGz6GHRMGi0mgEZBlzFv8N/YYMa9E1dm7+GiuWLoLZbPZ4PFQjIlQjomu4BjV2CaUWB8osEkxWCTYJKDY7UGx2ADFpWPBdDrZDwtkck7M3TevsKYvWqRCuEZvUW9ZaG0NzU2giIvI1FmB0WWa7hI9zTLDLQNdwDQZ2ap2/XhORb3VJ797iPbzOnjjW5HMNahFd1CK6hAKSLKPCJsFolVBplVButkKlVqMSwLFya73HqgTnwh+RWlHpNYvQiojQqhChFRGuESEKQqtsDM1NoYmIyB9YgFGjHLKMT85UoNjsQJhGxJTUMM7lIKImEwUBkVoVIrXOXvOj+4/gj7+9Ff/96lvEJKejzOJAucWBMqsDRosEhwyUmB0oMTsA2OpdTwCcRRjicfszb6JTv6sQk9QZIWoRBrXAodFERBTwWIBRg2RZxoZfKnGmwjnv69ZuEQjXcughEbWcAMBUlI84mDEw3n0hH0mWYbJKKLM4YLJKMNqc/2uySjBaHaiwSpDgXHkRgh4DJt+GGgDHjRcLNYNKQIhagEEtIkQtIFTDRUCIiCiwsACjBu0sqMH+/2/vzsOjqNLFj3+r16RDSICQsEmCsskWFAQRQtgUcERcZgSvMuBlwAVF5N5RMy4BHQVcuFz5MTAgGr06gjqsg4IIIRkEwSCg7FsgKGsEkpC1u+v8/uh0k6azETppSN7P8/TTyTmnq9+qU92pN3Xq1G+FaMDwmPo0scnuIoSoPgZNI9xqLPP2FrpS5DpcCdnO/YeZ8d4c7hv/LJb6DclzuM6e5TsV+U4Fhfql5QI2k4bNbCDEZCDErBEiN5AWQggRIHJELXwopdhyJp+Uk66L2we1CKF1mCXAUQkh6jqDphFqNhJqNnKaPFI/+n+Mengk7Vo1RSlFkQ55Dp08hyp+dv2sK7joUFx0OAHnpeU1upFRMz/mEGHYzhfSONg1vb4MYxRCCFGdJAETXpRSrPs1l7SzrpnOekUF062x3O9LCOFfV3NPstJer2kaViNYjUYaWC+VK6UocCpyHYpcu06uQyfPrijUFbrRTId+QzkCHDmaA7gmAYkIMhIRZCIy2EjjYBORwSbqmeWMmRBCCP+QBEx4OHXFqoyL7DlfCMCA5iH0iJTkSwjhP/68Jxl435esNJqmEWzSCDa5Eis3h67Yt/8AnyyYxxN//gt6SDiZBQ7sOpzOd3I638nu85eWE2o20MRmoqnNRDObiSY2E0EyjFEIIUQVSAImALhQ6GTlsRx+zXVgAO6OrkenhjLdvBDCv/xxTzKo+L5kFTEZNMz2fDYtWsDsPz/Bre1iUMp1A+mz+Q7OFjjJLH7+rcBJjl0nJ6uIg1mXps5vYDXQzGamWYiJ5iFmIoNl+KIQQoiKSQJWxyml2HWukLW/5FKkK0yaoot+lqKjGfx4tGrLvNqhRUKI2u9q7kkGV3ZfsoqU9p0VDNxQ/HCgkYOFLCxkFz/na2bOF+qcLyxkd/GoAbMBmthcyVjzEBPNbGZCZOiiEEKIy0gCVodlFTlZ/2uu52aojU1OXrmvLyePHPDL8isaGiSEEIF0NcMhbeENadGhKzd0upWWXW6jZeduEBrG8YsOjl90eNrVMxuICjYSGWwiIshIQ6troo+yhi9mZGSQmZlZ5XUCiIiIkBtLCyHENUwSsDqowKGz+XQ+aWfzcSrXFM1xTW1YTuzj5JEDvPz/FhLdul2Vl3+1Q4OEEKIm+Gs45LFD+3mtXxs2pO0gLLotv+baOZHrILPAyUW7zkW7zuFs75tKBxs1Qi0GQs0GQs1Ggk0a+TlZvDH1dbJ/y6TgYrbrkZNNUUEeTrsdR1Gh69leiO5wlBEN2Gw29u7de9VJmCSDQghRPSQBq0Ny7To7fytg65l8CpwKgBvqmRjYvB5NbCZ+POFqF9263TUzNEgIIarb1Q6HBNdw7no4iG0URGwj1/WzRU7FmXxH8cPJb4UOzhfoXHTorvuV5Ts5k+8E3MmZhd/9eVpl3xBQaJc9OwoLOf3LMf6VaSS04AIGDYyahlFzTePv/t317CrzfnbVZ2dd4K3p75Cfl0thbg55WRfIyzpH3oXz5GefJz8nC6XrFQTpv2RQCCFqE0nAajmlFKfyHGzLLGDv+UKK8y4igoz0axbCTfXNaHLRuBBCXLXyrn+NLH6A65qyfEwUYKQQIwWYcGAgMyubtB0/0eWOeKy2EBzKNTutrsAn1dE0QEMVf30Xf7VjsFlo2rYT2UB2btlnySpm4a6Jr5ZdrRSa0jHojuKHE4PTUeJ3ByfTDzL96cfIzMyUBEwIIUqQBKwWcQ8XUUAOZk5j4zQ28jSzp019VUhLcmian0f2Ydhe4vUyeYYQQlw5f0+t/z9frqbrHX18ypVS6LhOfukKFK7kTBUnaErBscMHmfmXybyQkEDzG1qi0Fx1aChAR/Mq073KL9Wfz8pi06bN9BgwGFv9MOy6wqGDXbneE01DaUacBiNOrD6xAtgatOS1TRmsVzrb9pynntngeYSYXcMvQ8wG6pkMmA3FZ+oMl87YlfznoD+GQ4IMiRRCXBvqfAI2Z84c3n77bU6dOkVsbCyzZ8+mR48egQ7riiil2H30F574y2u06HwbN3bvTf3GTTz19oJ8dq1byaZF7/PL7u3lLMlFJs8QQojKq6mp9TVNwwjgyUt8Ry9k/5rOoa2pjLsvpcpxlHT7l6vpGOOdDOrKlYw5dEWR++F0/wz24p8LHE7QDDg0A78VOvmt0HlF7+0eJolSZGcV4XTaUE4dpXR0pxOlO13PSnl+dzoc6A47Tocd3el0PTscOIvLDMDQIUMIrRfiNSzTQImf3eXFMWhltDGWbI87abxUXubYkuKKU6dOc+HChRLFqtTmRhQmdIwojCiv5foroZQEV4iaVacTsMWLFzN58mTmzZtHz549mTVrFoMHD2b//v1ERkZWvIBrxMZTeXx3IZh7np9+qVDpWAovYi28iKXoIk1vi+XO22aXuxyZPEMIIaruWphavyaSQYOmYTGCxahhK2cZ+37awTO/H8ralI3c0KY9F+06uXadnJLPDp1cu8KhK59hlnrxmT7QCK4fXuV1udyxIuBcod+WV3VBoDWpuNllivLzKMrPpSgvF/vhY3TMslIvOAizQcOkue5xZyrxs/uMousqQdeZUlWc7CkFWdnZLHj/I5y6wmA0YTAaix8m18N06WelO9EdjkvJrdPhSnqdDuwF+SiHnT8/N4nIiIZYDBoWg4bZWPxswOt3uWeeqMvqdAI2c+ZMxo0bx2OPPQbAvHnzWLVqFR988AEvvvhigKOrvKY2MwaVx8G07+h8c3tubNmMULMBgxYCRFV6OTJ5hhBC1A7XQjKoAYUXc8jY+zMhuK5HMwMNix+Xcw2BLDlM0jVU8tDhIzz//PO8tuAfxLRt7zlPpJT7dapEYlHiGdcIEXfZob27WfHJBxhMJowmMwaTGWPxz5rBlXQYTSYMJrMnATG6ExKTOxkxYTZbuKVbN8wWa/H7XBrKWXKoZ3nsdjuZv2US1rARJpO5nJYaStNQmqH4uj+wBNuwBNugYWMAMh2QmWMvZxkVMXPHI09exeu9bcsDMioeSWNQCmOJM3vun4MtZuqHBGM2aJgN2qUzkiXPPHLpTKX7TCYU7wsl+p8y9gWnAqdSl5710n/PzS+gyO7w7Jf6ZX2tFZ+RNBTvlRoKg8+zwmqxEBoS7DUBjjsxNho0z+8G9zWdJU6GqhLPFy5cIC8vr/h3731Mef2slVLm4nQ6MRqNnvLy9lTfukvvGmyzEVa/fulttUtP7m2uF29b9z9W9OIh1DkXcykoLCz1c1RyuPSlRSuv99MAs9nEva0b0Tj4+klrrp9I/ayoqIht27aRkJDgKTMYDAwaNIjNmzf7tC8sLKSw8NJ/zLKysgA4d+4cjuLpgA0GAwaDAV3X0UvMDuUudxYPlaio3Gg0ommaZ7kly8H14SmpoWage84eXn76ISZP+x+0M61dFZrm/Sl2K6P82OEDGAwGju7bQ0hQUIXty1uOyWSq/HJKceyw615k/ohF1qlurFNGWbHIOvllnY4fOehaxt7dlY9F1qlOr9Oe7T8A8Oijj2I2eycZdrsdTdMwmS4dhiilcDgcZZbv2ZyCPetclddp78ZkNi9eyPDRj3NjmxhPuV7c7vIzMrqyA3YMaOAAHJC+ax/LPnofwC/r9Mxrb9OmQ+cKY3edCDS4Dkw1A0qD9IMHWPXFp5itQdhCwzBZgzBbgjBZLRjMFoxmK9bgYEyWIAxGI0rpruMNXcdgMKB03ZWUKB17YSG33NGXho0iXCFQfHFh8RBQTzbjjk/TQLnGWSpcv/929gz7du3EGhyCJTgEi82GJciGOTgEc1AQ1mAb5uB6GE0VHHrm2uF8Xvltrje5Dj+uk7HiJuW6mkP/Ep+R3AI4e62MmCpi7/5zmGOalnr8XVPH5dnZ2QBery2LpirTqhY6ceIEzZs3Z9OmTfTq1ctT/vzzz5OSksKWLVu82k+ZMoWpU6fWdJhCCCGEEEKI68Tx48dp0aJFuW3q7BmwK5WQkMDkyZM9v+u6zrlz52jUqFGF07hnZ2dzww03cPz4ceqXOF0raifp77pD+rpukf6uO6Sv6xbp77qluvpbKUVOTg7NmjWrsG2dTcAiIiIwGo2cPn3aq/z06dM0aeJ7UazVasVq9Z5qNzw8/Ires379+vLBrkOkv+sO6eu6Rfq77pC+rlukv+uW6ujvsLCwSrUz+PVdryMWi4Vu3bqxbt06T5mu66xbt85rSKIQQgghhBBC+EudPQMGMHnyZEaPHk337t3p0aMHs2bNIjc31zMrohBCCCGEEEL4U51OwEaMGMHZs2d59dVXOXXqFF27dmX16tVERVV+6vbKsFqtJCYm+gxhFLWT9HfdIX1dt0h/1x3S13WL9Hfdci30d52dBVEIIYQQQgghalqdvQZMCCGEEEIIIWqaJGBCCCGEEEIIUUMkARNCCCGEEEKIGiIJmBBCCCGEEELUEEnAqtmcOXOIiYkhKCiInj17snXr1kCHJPwgNTWVYcOG0axZMzRNY9myZV71SileffVVmjZtSnBwMIMGDeLgwYOBCVZclWnTpnHbbbcRGhpKZGQk9913H/v37/dqU1BQwIQJE2jUqBH16tXjwQcf9LnJu7g+zJ07ly5dunhu0NmrVy++/vprT730de01ffp0NE1j0qRJnjLp79pjypQpaJrm9Wjfvr2nXvq69vn111959NFHadSoEcHBwXTu3Jm0tDRPfSCP1SQBq0aLFy9m8uTJJCYm8uOPPxIbG8vgwYM5c+ZMoEMTVyk3N5fY2FjmzJlTav1bb73Fe++9x7x589iyZQshISEMHjyYgoKCGo5UXK2UlBQmTJjA999/z9q1a7Hb7dx1113k5uZ62jz33HOsXLmSL774gpSUFE6cOMEDDzwQwKhFVbVo0YLp06ezbds20tLSGDBgAMOHD2f37t2A9HVt9cMPP/D3v/+dLl26eJVLf9cuHTt25OTJk57Hxo0bPXXS17XL+fPn6d27N2azma+//po9e/bw7rvv0qBBA0+bgB6rKVFtevTooSZMmOD53el0qmbNmqlp06YFMCrhb4BaunSp53dd11WTJk3U22+/7Sm7cOGCslqt6rPPPgtAhMKfzpw5owCVkpKilHL1rdlsVl988YWnzd69exWgNm/eHKgwhR81aNBAvf/++9LXtVROTo5q06aNWrt2rYqPj1fPPvusUko+27VNYmKiio2NLbVO+rr2eeGFF1SfPn3KrA/0sZqcAasmRUVFbNu2jUGDBnnKDAYDgwYNYvPmzQGMTFS39PR0Tp065dX3YWFh9OzZU/q+FsjKygKgYcOGAGzbtg273e7V3+3bt6dly5bS39c5p9PJokWLyM3NpVevXtLXtdSECRP43e9+59WvIJ/t2ujgwYM0a9aMG2+8kUceeYSMjAxA+ro2WrFiBd27d+cPf/gDkZGR3HLLLSxYsMBTH+hjNUnAqklmZiZOp5OoqCiv8qioKE6dOhWgqERNcPev9H3to+s6kyZNonfv3nTq1Alw9bfFYiE8PNyrrfT39evnn3+mXr16WK1WnnjiCZYuXUqHDh2kr2uhRYsW8eOPPzJt2jSfOunv2qVnz54kJSWxevVq5s6dS3p6OnFxceTk5Ehf10JHjhxh7ty5tGnThjVr1vDkk08yceJEPvroIyDwx2qman8HIYSoJSZMmMCuXbu8rhsQtU+7du3YsWMHWVlZfPnll4wePZqUlJRAhyX87Pjx4zz77LOsXbuWoKCgQIcjqtnQoUM9P3fp0oWePXsSHR3N559/TnBwcAAjE9VB13W6d+/Om2++CcAtt9zCrl27mDdvHqNHjw5wdHIGrNpERERgNBp9ZtA5ffo0TZo0CVBUoia4+1f6vnZ5+umn+de//kVycjItWrTwlDdp0oSioiIuXLjg1V76+/plsVho3bo13bp1Y9q0acTGxvK///u/0te1zLZt2zhz5gy33norJpMJk8lESkoK7733HiaTiaioKOnvWiw8PJy2bdty6NAh+WzXQk2bNqVDhw5eZTfffLNn2Gmgj9UkAasmFouFbt26sW7dOk+ZruusW7eOXr16BTAyUd1atWpFkyZNvPo+OzubLVu2SN9fh5RSPP300yxdupT169fTqlUrr/pu3bphNpu9+nv//v1kZGRIf9cSuq5TWFgofV3LDBw4kJ9//pkdO3Z4Ht27d+eRRx7x/Cz9XXtdvHiRw4cP07RpU/ls10K9e/f2uWXMgQMHiI6OBq6BY7Vqn+ajDlu0aJGyWq0qKSlJ7dmzR40fP16Fh4erU6dOBTo0cZVycnLU9u3b1fbt2xWgZs6cqbZv366OHTumlFJq+vTpKjw8XC1fvlz99NNPavjw4apVq1YqPz8/wJGLK/Xkk0+qsLAwtWHDBnXy5EnPIy8vz9PmiSeeUC1btlTr169XaWlpqlevXqpXr14BjFpU1YsvvqhSUlJUenq6+umnn9SLL76oNE1T33zzjVJK+rq2KzkLolLS37XJf/3Xf6kNGzao9PR09d1336lBgwapiIgIdebMGaWU9HVts3XrVmUymdQbb7yhDh48qD799FNls9nUJ5984mkTyGM1ScCq2ezZs1XLli2VxWJRPXr0UN9//32gQxJ+kJycrACfx+jRo5VSrulNX3nlFRUVFaWsVqsaOHCg2r9/f2CDFlVSWj8D6sMPP/S0yc/PV0899ZRq0KCBstls6v7771cnT54MXNCiyv7zP/9TRUdHK4vFoho3bqwGDhzoSb6Ukr6u7S5PwKS/a48RI0aopk2bKovFopo3b65GjBihDh065KmXvq59Vq5cqTp16qSsVqtq3769mj9/vld9II/VNKWUqv7zbEIIIYQQQggh5BowIYQQQgghhKghkoAJIYQQQgghRA2RBEwIIYQQQgghaogkYEIIIYQQQghRQyQBE0IIIYQQQogaIgmYEEIIIYQQQtQQScCEEEIIIYQQooZIAiaEEEIIIYQQNUQSMCGEuAKaptGvX7+AvX+/fv3QNC1g71/X+bv/T5w4QUhICG+++abfllldSlv3KVOmoGkaGzZs8NsyReUdPXoUTdMYM2aMV/mYMWPQNI2jR496yvbv34/JZOJvf/tbzQYphPAhCZgQ4pqgadoVPSqrtAOR6uY+KKrsIyYmpsZiqwnubf79998HOpQrVtP7y0svvYTNZmPixIle5TExMRXuNzW5T9dF7uSyso8pU6YEOuRytWvXjocffpipU6eSk5MT6HCEqNNMgQ5ACCEAEhMTfcpmzZpFVlZWqXXXsvDw8FJjnjp1KmFhYUyaNMmnvah7Dh48yMcff8xLL71EvXr1fOqNRiMvv/xyma+/Fvabp59+mpEjR9KyZctAh+J3pZ2Z27FjB8uXLyc+Pt6nPhBn8po3b87evXsJCwurVPvnn3+eTz75hPfee4+XXnqpmqMTQpRFEjAhxDWhtP8eJyUlkZWVdc3/Z/ly4eHhpcY8derUMutE3TN//nx0XWfUqFGl1ptMpmt+X4mIiCAiIiLQYZQpJiaGmJiYKg2R7Nevn09SlZSUxPLly+nXr9810Tdms5n27dtXun3nzp3p0qULCxYsICEhAYNBBkIJEQjyyRNCXHcyMzOZNGkSrVq1wmq1EhkZyUMPPcSuXbu82sXExPDRRx8B0KpVK89QoZIHVUuXLuXhhx+mdevW2Gw2wsLCiIuL45///GeNrc+xY8cYO3YszZs3x2Kx0KJFC8aOHUtGRkall7F48WKsViuxsbGcPHnSU56amsqwYcOIiIjAarXSpk0bXn75ZfLy8rxev2HDBs8wqrS0NO68805CQ0MJCwvj/vvvr9bhbtUd45IlS+jevTvBwcFERUUxbtw4zp8/7zk4d6vM/uJ2+vRpRo8eTUREBMHBwdx+++1XdJCv6zofffQRXbt2pU2bNpV+XVnc1wba7XamTJlCTEwMVquVtm3blnnNT2ZmJuPHjycyMhKbzcZtt93G0qVLSUpKQtM0kpKSKnzfsq4BS05OZujQoTRr1gyr1UpUVBRxcXHMnz+/1OVc7fYMtCv5Hil53dbevXu55557CA8Pp0GDBjz88MNkZmYCsHnzZgYOHEj9+vVp0KABf/rTn8jNzS1zWZX10EMPcezYMZKTk69qnYUQVSdnwIQQ15WzZ8/Sq1cvDh8+TL9+/Rg5ciTp6el8+eWXrFq1ijVr1tCnTx8AJk2aRFJSEjt37uTZZ5/1DNkqedCdkJCAxWKhT58+NG3alLNnz7JixQp+//vf89577/HMM89U6/ocOHCAPn36cPbsWYYNG0bHjh3ZtWsXH3zwAStXrmTjxo20bdu23GXMnj2bZ599lri4OFasWOEZjjR37lwmTJhAeHg4w4YNIzIykrS0NN544w2Sk5NJTk7GYrF4LeuHH37grbfeon///jz++ONs376dZcuW8fPPP7Nr1y6CgoL8uv7VHeMHH3zA2LFjqV+/Pn/84x8JCwvjq6++4s4778Rut2M2mz1tK7O/AFy4cIE+ffoQFhbGqFGjOHPmDIsXL2bw4MFs27aNTp06VbjeP//8M2fPnuXBBx+s+sYrxcMPP8zWrVsZOnQoRqORzz//nAkTJmA2mxk3bpyn3cWLF4mPj2fPnj3ccccd9O3bl19++YWRI0cyePDgq4ph1apVDBs2jPDwcIYPH+75XO3cuZP/+7//Y/z48V7t/bE9A60q3yPp6enccccddO/enT/96U+kpaWxaNEijh8/zvTp07nrrru48847GT9+PBs2bGDhwoXous4HH3xwVbH26tULgHXr1jFw4MCrWpYQooqUEEJco6Kjo9XlX1OPPfaYAlRCQoJX+apVqxSgWrdurZxOp6d89OjRClDp6emlvsfhw4d9ynJyclTnzp1VWFiYys3N9aoDVHx8fJXWB1DR0dFeZf3791eA+vvf/+5VPmfOHAWoAQMGeJXHx8d7bZO//OUvClD333+/ys/P95Tv3r1bmUwmFRsbqzIzM72WMW3aNAWod955x1OWnJysAAWoRYsWebUfNWqUAtRnn31WqfV0b/PNmzeX2666Yzx//ryqV6+eCgkJUQcOHPCU2+12NWDAgFL7o6L9xf3+Tz31lNd+9v777ytAPf744+Wus5u7fxcsWFBqfXR0tDIajSoxMbHUx9y5c73au/eLnj17qqysLE/5vn37lMlkUu3atfNq//LLLytAjR8/3qv822+/9azjhx9+6LPul+/7iYmJClDJycmesgceeEABaseOHT7rdXk/+2t7liU6OrrKn9fSfPjhhwpQiYmJXuVX8j2Snp7uWe9Zs2Z5ynVdV3fffbcCVHh4uFq2bJmnrqioSHXp0kWZTCZ16tQpn2WNHj3a673L24+zsrIUoPr27XuFay+E8BdJwIQQ16zLE7DCwkIVFBSkGjVq5JMYKaXUnXfeqQCVmprqKavogLos7777rgLUhg0bvMr9mYAdO3ZMAapDhw5K13Wvtk6nU7Vv314BKiMjw1PuPtB2OBxq7NixClDjxo1TDofD6/UTJ0702RYll924cWPVrVs3T5k7uSntoMxdN3ny5EqtZ2UTsOqOMSkpSQFq4sSJPu03bdpU5QQsJCRE5eTkeJXb7XZlMpnUrbfeWt4qeyQkJChArVixotR6975f1iM2NtarvXu/WL9+vc+y3HXZ2dmespiYGGWxWLwO5t3uuusuvyRg+/fvL38jKP9tz7LUVAJWltK+R9xJ00033eTzuf/4448VoPr37++zrNdee82nj6uSgCmlVFBQkLrxxhsrtQ5CCP+TIYhCiOvGvn37KCgooH///thsNp/6/v37s3btWnbs2EFcXFyllnnmzBmmT5/O119/zbFjx8jPz/eqP3HihF9iL82OHTsAiI+P95la32Aw0LdvX/bt28eOHTu44YYbvOoffPBBli9fzksvvcRf//pXn2W7p4Bfs2YN69at86k3m83s27fPp7xbt24+ZS1atABcQ8X8qbpj3LlzJ4BnSGpJPXv2xGSq2p/Atm3b+sxaaDKZiIqKqvQ2+u2334DyZzK0Wq0UFBRcUWwVbZvQ0FCys7M5evQoHTp0ICoqyqd97969+eabb67ofUsaOXIkS5Ys4fbbb+c//uM/GDhwIHFxcWVO1uGP7Xn06FFatWpVat2xY8dKvXVFenq6324BUZXvkS5duvjE1bRpUwC6du3q095d54/vpIYNG3quNRNC1DxJwIQQ143s7GyAUg8a4dIBirtdRc6dO8dtt91GRkYGvXv3ZtCgQYSHh2M0Gj3TTRcWFvon+FJczfqkpqYSFBTE3XffXeprz507B8Abb7xxRTHVr1/fp8ydqDidzitaVkWqO0b3douMjPRpbzAYqjx7X2nv746hstsoODgY4IoTrIpUZtuUt12g7P2xsv7whz+wbNkyZs6cybx585gzZw6aptG/f3/effddn+TCH9uzrFs/zJo1i/Dw8FInqfDXNP5V/R4pr6/Kq7Pb7Vcdc35+fqn/xBJC1AxJwIQQ1w33Qcnp06dLrT916pRXu4osXLiQjIwMXn/9dZ/7LU2fPp3ly5dfRbQVu5r1WbduHYMGDWLIkCGsXr2aO+64o9RlZ2dnExoa6s+w/aa6Y3Qv/8yZMz51uq6TmZlJ8+bN/f6+ldG4cWPgUhJak8rbLlD2/nglhg8fzvDhw8nJyeG7775jyZIlLFy4kCFDhrBv3z6/38OsrNs7JCUlERMTU61Txgf6e+RK6bpOVlYWHTt2DHQoQtRZMg29EOK60b59e4KCgvjhhx98pigHPNNWl/wPu9FoBEo/e3P48GHAdbB4uX//+99+iLh87jhTU1NRSnnVKaVITU31alfSLbfcwvr167FYLAwZMoTvvvvOq75nz57ApWF+16LqjjE2NhbAZ9sAbN26FYfD4VNe3v7iT507dwZg//791fo+palfvz4xMTEcOnSo1CRs06ZNfnuv0NBQhgwZwvz58xkzZgynT59my5Ytflv+tSDQ3yNX6uDBg+i67tkHhRA1TxIwIcR1w2KxeO6TM23aNK+61atXs2bNGlq3bk3v3r095Q0bNgTg+PHjPsuLjo4GYOPGjV7l//jHP/jqq6/8Hb6Pli1b0r9/f3bv3u0ztfT8+fPZu3cvAwYM8Ln+yy02Npb169djtVoZMmSI13o89dRTmEwmnnnmmVLvJ3bhwgW2b9/u3xW6QtUd4/Dhw6lXrx4LFy70HCQDOBwOXnnllVJfU97+4k9xcXEYDIaAJSOPPPIIRUVFPsP2NmzYwJo1a65q2ampqaUmsO5kz9+3Mgi0QH+PXCn3PhcfHx/gSISou2QIohDiujJjxgxSUlL461//yqZNm+jZsydHjx7liy++wGaz8eGHH2IwXPrf0oABA3jnnXcYP348Dz74ICEhIURHRzNq1ChGjRrFjBkzeOaZZ0hOTiY6OpqdO3eybt06HnjgAZYsWVLt6zN37lz69OnDuHHjWLlyJR06dGD37t2sWLGCxo0bM3fu3HJf36VLF9avX8/AgQMZOnQoX331FXFxcXTq1Im//e1vPPnkk7Rr1467776bm266iZycHI4cOUJKSgpjxoxh3rx51bZur7/+umeo3eVefPHFao8xPDycmTNnMn78eLp168bIkSM99wGzWq00a9bMa1+B8vcXf2rQoAHx8fFs3LiRgoKCUpMSh8NR7tC5kSNH0r59+yq9/wsvvMA///lP5s2bx65du4iLi+OXX37h888/Z9iwYaxcudJn21TWxIkTOXHiBH369CEmJgZN09i4cSNbt27l9ttvL3VSlOvZtfA9ciXWrl2LyWTinnvuCXQoQtRZkoAJIa4rjRs3ZsuWLbz++ussX76cf//734SFhXHfffeRmJjoc9PWoUOH8tZbb7FgwQLeffdd7HY78fHxjBo1ihYtWpCSksLzzz/Pt99+i8Ph4NZbb+Wbb77h+PHjNXLg1K5dO9LS0pg6dSqrV69m1apVNG7cmMcee4zExETPf9fL07lzZ58krG/fvowbN46uXbsyc+ZMUlNTWblyJWFhYbRs2ZLnnnuO0aNHV+u6lfff/zFjxtC+fftqj3HcuHE0aNCAN998k6SkJMLCwrj33nuZMWMG0dHR3HTTTV7ty9tf/O2JJ55gxIgRrFixgoceesin3ul0MnXq1DJf37Vr1yonYKGhoaSmppKQkMDy5ctJS0ujY8eOfPbZZxw5coSVK1dW+lrKyyUkJLBkyRK2bdvGmjVrMJvNxMTEMGPGDJ566inPMM/a4lr4HqmsvLw8li1bxj333EOzZs0CHY4QdZamLr/wQAghhKjlDh06RJs2bXjooYdYvHhxQGKw2+20a9eOm266ibVr1wYkhtI8+uijfPrpp+zZs4ebb7450OEIP3r//fcZN24cKSkp9O3bN9DhCFFnyTVgQgghaq3z58/7TAGen5/Pc889B8B9990XgKhczGYz06ZN49tvv/XrxBeVdfLkSZ+ylJQUFi1aRLt27ST5qmUcDgdvvvkm9957ryRfQgSYDEEUQghRa6WkpDB27FjuuusuWrZsSWZmJuvXr+fo0aMMGDCAESNGBDS+ESNGkJGR4bkxc026++67CQ4OpmvXroSEhLBnzx5Wr16N0Whk9uzZNR6PqF4ZGRn88Y9/rJbhtEKIKyNDEIUQQtRaBw8e5JVXXmHTpk2cPXsWgNatWzNixAj++7//u9bNyHclZs2axaeffsrhw4fJyckhPDyc3r17k5CQ4LlFgBBCCP+TBEwIIYQQQgghaohcAyaEEEIIIYQQNUQSMCGEEEIIIYSoIZKACSGEEEIIIUQNkQRMCCGEEEIIIWqIJGBCCCGEEEIIUUMkARNCCCGEEEKIGiIJmBBCCCGEEELUEEnAhBBCCCGEEKKG/H96LxPqgbxn2AAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoQAAAGQCAYAAAA3GHFfAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAQhpJREFUeJzt3Xd4VFXixvF30iGQBAKEnrCA9KKASImhSVGRIlJUNiCCBQtYQBZZQFSKyloeFwQFLLsisNJ+iID0YgMFKYKIVGmGlhhayvn9wc7dDDNJBphkAvf7eZ55nsy9Z+4995w7M29uOeMwxhgBAADAtgL8XQEAAAD4F4EQAADA5giEAAAANkcgBAAAsDkCIQAAgM0RCAEAAGyOQAgAAGBzBEIAAACbIxACAADYHIEQBUpcXJwcDofbo0iRIqpXr56GDRumEydO+LuaV2XGjBlyOBzq06ePv6tyzaZPn66GDRsqPDzc6qN9+/Z5LLtv3z6PfZrboyC1k7NO3mjRosVVbe+VcLZpXFzcVWyN/zm3edWqVf6uSr4aNWqUHA6HRo0a5e+qAG6C/F0BwJNmzZqpSpUqkqTMzEwdPnxYGzZs0Lhx4/TRRx9p7dq1+stf/uLnWvrXqFGjNHr0aI0cOTJfv2AWLVqkhx56SGFhYWrTpo2io6MlSUWKFPFYvkiRIkpMTHSb/uuvv2r9+vUKDw9Xt27d3OY3b978iuo1Y8YM9e3bV4mJiZoxY8YVvdaX2rdv7zGoffjhh5Kkdu3aqXTp0vlcK+S1ffv2qVKlSoqNjc32nyOgICMQokB6+OGH3Y4QHT16VAkJCfrll180ZMgQzZkzxz+Vs7nZs2dLkt5++231798/1/IlSpTwGNBmzJih9evXZzv/evXCCy94nO4MhC+88IJatGiRjzUCgNxxyhjXjdKlS+v555+XJC1fvtzPtbGvAwcOSJKqVq3q55oAAHyFQIjrivNUW3p6usf5Z8+e1bhx43TLLbeoaNGiKly4sGrVqqUXX3xRp06dcik7Z84cORwOlSxZUocOHXJb1pIlSxQYGKjIyEjt3r3bmt6nTx85HA7NmDFDW7ZsUdeuXVWyZEkVKlRIdevW1VtvvaWMjIwr3rbvvvtO3bt3V9myZRUSEqJSpUqpY8eOWrZsmVtZh8Oh0aNHS5JGjx591dfeXUl7Obd75cqVkqSWLVvm6fV+O3fuVN++fRUbG6vQ0FAVL15crVu31qxZs9zKxsXFqW/fvpIuHYnL2h5Zj8bt379f48ePV6tWrVSxYkWFhoYqKipKzZs313vvvafMzEyfb4c3rqQfvFlWp06d5HA41LJlS50+fdqad+7cOb3xxhu67bbbFBUVpbCwMFWrVk1DhgzxeG1u1uteU1NTNWzYMFWpUkWhoaEqXbq0EhMT9fvvv1/r5nvl1KlTGjlypOrXr2+1UZ06dfTyyy/r7NmzbuWzXq/3xx9/aODAgapQoYJCQkJUoUIFPfnkky5tk5UxRtOmTVPDhg1VuHBhRUdHq0OHDtqwYYNWrVrltl/16dNHlSpVknRpH/Pm+tArrROQ5wxQgMTGxhpJZvr06R7njxgxwkgyjRs3dpt34sQJU79+fSPJREREmHvuucfce++9pkSJEkaSqVSpktm7d6/La5588kkjyTRv3tykpaVZ0w8dOmRKlixpJJnPPvvM5TWJiYlGknnsscdMWFiYiYuLMz169DBt27Y1ISEhRpLp1q2byczMdHnd9OnTjSSTmJjoVvcpU6aYgIAAI8ncfPPNplevXqZp06ZGkpFkRo0a5VaHevXqGUmmXr16JjEx0XpMnTo1hxa++vaaOnWqSUxMNDExMUaSadeu3RWv01N7xMbGus37v//7PxMWFmYkmWrVqpmePXuaVq1amcDAQCPJPPTQQy7ln332WdOsWTMjyVSuXNmlPcaOHWuVGzNmjLVtrVu3Nj179jQJCQlWv3Xt2tWt34wxVj9cC+cyVq5c6TL9avbbvXv3emy7o0ePmoYNGxpJ5sEHHzQXLlyw5v3++++mTp06RpIpXry4adOmjenSpYv1nouLizP79u1zWZ6zjzp37mzq1q1roqKiTMeOHU2nTp1MqVKlrDqcPn3aJ22Rne3bt5sKFSoYSaZMmTKmffv2pmPHjta+WL9+fbc6jBw50tpXypcvb2JiYkzXrl3NnXfeaSIjI40k06hRI3Px4kW39T322GNGkgkICDAJCQmmZ8+eplatWiYwMNA8++yzRpJJSEiwyk+dOtXce++9RpIJDw932f+yvt+vpU5AXiMQokDxFAgzMjLMoUOHzDvvvGNCQ0NNYGCgWbhwodtre/ToYYXFpKQka3pKSorp0KGDkWSaNm3q8poLFy6YW2+91UgyQ4cONcYYk5aWZpo3b24kmYEDB7qtxxkIJZnHH3/cJUhu27bNCpKTJ092eV12gfCnn34yQUFBxuFwmI8++shl3hdffGGFlaVLl7rMc365jBw50r0hvXA17WWMMQkJCVf0ZZ6d7ALh0aNHrS/Hl19+2SWgff/996ZYsWJGkpkyZYrH5XkK3E7fffed2bp1q9v033//3QrYs2bNcpufl4HwavrBUyDcvn279f558cUXXcpnZmZagblfv34mOTnZmpeWlmaFnJYtW7q8ztmmzn8Azpw5Y807efKkFWRfffVVn7SFJ2fPnjWVK1e2titryE1NTTW9evUykkzfvn1dXud8f0gyffr0MefPn7fmHThwwJQrV85IMv/+979dXjd//nwjyRQpUsSsX7/eZd4bb7xhLTNrIDQm+5DuizoB+YFAiALF+YWW3aNRo0Zm3bp1bq/bv3+/CQgIMA6Hw2zZssVt/qFDh6wjTpd/yO/du9cUK1bMOBwOs2jRIjNkyBAjyTRo0MDlA9vJGQjLlCljzp075zb/nXfeMZJM1apVXaZnF1j69etnHZ3y5IknnjCSzB133OEy/VoC4bW0V14HQudRvAYNGnh83euvv35F7eutJUuWGEnmvvvuc5uXV4Hwavvh8vCxfPlyExUVZYKDg820adPclrN48WLrSFrWf2CcMjIyTO3atY0kl8DsbNPw8HBz+PBht9fNnDnTSDKtWrW6kqa4okA4adIkI8ncfffdHuenpKSYUqVKmaCgIHPy5ElruvP9Ub58eZOamur2unHjxnk82tyqVSsjyQwbNszj+ho1anTNgfBK6wTkB64hRIHUrFkzJSYmWo+77rpLFSpU0Pfff6/Bgwe7XNMnSWvWrFFmZqZuvvlm1a1b12155cqVU7t27STJugbOKS4uzrrLtVevXnrttdcUGRmpWbNmKTQ0NNs6du/eXWFhYW7TnUOs7N69W4cPH851W51jsWV3HV6/fv0kSWvXrr2qaxM9uZb2ymvO9vA0VI30v/bwtn0vd+HCBS1cuFB///vf9eijj6pv377q06eP3nvvPUnSrl27rq7iV8EX/fDhhx+qffv2yszM1KJFi6xrKbNatGiRJOnee+9VUJD74BIBAQG6/fbbJUkbNmxwm9+wYUOVKVPGbXqNGjUkKU+vI3TWvUePHh7nFylSRA0bNlR6erq+//57t/mtW7dW4cKF3aZ7qnt6erq1/Q888IDH9d1///1XtgEeXEmdgPzCsDMokDwNO5Oenq6///3vGjt2rBISErRr1y4VLVpU0v8+QJ0XdntSuXJll7JZ3XPPPXr44Yc1depUSdKUKVNyHecwu3UVLVpU0dHROnHihA4dOqSyZcvmuJzc6u6s9/nz53XixAmVKlUqx+V541rbKy/lVreoqCgVL15cJ0+e9Kp9s/rmm2/Uo0cP605pT5KTk6+swtfgWvvh0KFD1vtkxYoV2Y7d+Ntvv0mSRowYoREjRuRYpz/++MNtWsWKFT2WjYiIkHRp38wrzrr37t1bvXv3zrHstdY9KSnJep7doN++GAzcn+0JZIdAiOtGUFCQXn75ZU2dOlVHjhzRRx99pIEDB/pk2SdOnNDixYut59988426d+9+zcs1xlzzMuAbZ8+eVefOnXXs2DH17dtXjz32mKpUqaKIiAgFBgbql19+UbVq1a6rPitVqpTq16+vxYsXa9CgQVqyZIk1UHhWzrunmzdvbgXM7NSqVcttWkCA/04mOevevn17xcTE5Fg2NjbWbZqv636lvyrjiT/bE8gOgRDXlYCAAMXFxSkpKUk///yzNb1cuXKS/nc0wRPnPGdZJ2OMevfurUOHDqlz585as2aN/vGPf6hFixa65557sl3e3r17PU5PSUmxhvAoX758rttUrlw57dmzR7/99ptq166dbb3DwsJUvHjxXJfnjWtpr7xWrlw57dy5M9u6nTlzRidPnrTKemvNmjU6duyYbrnlFk2bNs1t/uWXIeSHa+2HkJAQzZ8/X/fff7/mzJmjhIQEffXVV26/hFKhQgVJUqdOnfTcc8/5qvr5okKFCtq5c6f69evn8RdtfCk6OlqhoaG6cOGC9u/fr5o1a7qV4VdIcKPi3xRcVzIzM60P5Kw/lXb77bcrICBAmzdv1pYtW9xed+TIEX355ZeSLo2fl9W4ceO0ePFi1ahRQ5988ok1jl2fPn20f//+bOsye/ZsXbhwwW36xx9/LEmqUqWKV4HFOZ5Zdr/W4Qwv8fHxLtd/hYSESMp+TMacXEt75TVnezh/2eNyzvaoWrWqS/vm1h7OEJnd6bpPPvnkqup7LXzRD8HBwZo5c6b69Omj7du3Kz4+3m2/7dChg6RL++z1dARU+l/dPY0/6WvBwcFq0qSJJOnf//63xzKffvqpx+nX8n4ECgICIa4b6enpevHFF5WUlCRJLkfvKlasqPvuu0/GGD3yyCMug+ympqZqwIABOn/+vJo2baqmTZta89asWaMRI0aocOHCmj17tsLDw3X33Xfr2Wef1alTp9S9e3elpaV5rM/hw4f13HPPudzo8fPPP+ull16SJA0ePNir7Xr66acVFBSkefPmuYWSpUuXWjc7XH5kx3n0cfv27V6tJ6urba/80L9/f0VEROiHH37Qq6++6hJgfvzxR7388suSZP1qjZOzPXbs2OFxuc4L9pcvX+5WZsqUKfrss898tg3e8lU/BAYGatq0aXriiSf066+/Kj4+Xr/88os1v1OnTmrUqJG+++479e3b1+O1dqdOndLkyZMLXKAZMGCAYmNjNXv2bA0dOlQpKSluZY4ePWpd/3utnnrqKUmXfprxm2++cZn31ltv6dtvv/X4upIlSyokJERHjx61/vkAriv+u8EZcOccdqZZs2YuA7vefffd1sC0kszw4cPdXpuUlGSNJRcZGWk6d+5sunXrZo0LePkAv8ePHzdly5Z1G/fQGGMuXrxobrvtNiPJDBo0yGWec9iZRx991ISFhZlKlSqZnj17mnbt2lljBnbp0uWKBqZ+7733rIGpb7nlFnP//febZs2aGYfDYST3gamNuTReX3h4uNVeffr0Mf369fM47IgnV9peTnk97IwxxixcuNAabqV69eqmV69epnXr1iYoKMjjmHPGXBpT0tmfN998s/nrX/9q+vXrZyZMmGCV6dSpk5FkQkJCTNu2bU3Pnj1N9erVjcPhMMOHD8+2Ps797lo4l3F5u11NP+Q0xMmwYcOMJBMTE2N++ukna/rvv/9ujRsYHh5umjZtanr27Gm6du1q6tevbw36nXUopdyG8vFmqJWc2qJGjRqmcePG2T6cQ91s27bNxMXFGUkmKirK3H777eb+++83nTt3NjVr1jQOh8PExMS4rCO3YZlWrlzpcfgYY4wZMGCAkWQCAwNNixYtTK9evUzt2rVNYGCgGTx4sMdhoIwxplu3bkaSqVChgunVq5fp16+f6devn0/qBOQ1AiEKlOzGIQwJCTGxsbGmR48eOQaR1NRUM3bsWFO/fn1TuHBhExYWZmrUqGH+9re/uYxRlpGRYdq2bZvjl93+/ftN8eLFjSQzd+5ca7ozEE6fPt388MMPpmPHjiY6OtqEhoaaWrVqmYkTJ3oc6y23L9dvvvnGdOvWzZQuXdoEBQWZ6Ohoc9ddd7kNSJ3VmjVrTJs2bUyxYsWsQHkl4/B5215Z5UcgNMaYHTt2mMTERFO+fHkTHBxsoqKiTMuWLc3MmTOzXebWrVvNPffcY0qWLGm1R9Yv14sXL5rXXnvN1KlTxxQuXNgUL17ctG3b1ixdujTHcJOXgdCYK++H3ILY2LFjjSRTrFgx8+2331rTz58/byZPnmxatmxpoqOjTVBQkClVqpSpX7++GThwoFmyZInLcvI6EOb2yBqEk5OTzYQJE0yTJk2sMRfLlCljGjVqZJ5//nmzYcMGl3VcS/jKzMw0U6dONbfccosJCwszUVFRpm3btmbNmjXmo48+MpJMr1693F534sQJ88gjj5iKFSua4OBgt/2GQIiCzGHMdXZBCeBnffr00Ycffqjp06fnyW/4Aii4HnroIU2fPl1vvPGGnnnmGX9XB/AZriEEACCL7du3KzU11WVaZmampk6dqhkzZigsLEy9evXyU+2AvMGwMwAAZPHaa69p1qxZuvnmm1WuXDmlpqZqx44d2rdvnwIDA/XPf/7T4y+3ANczAiEAAFn06NFDycnJ2rRpkzZv3qz09HSVKlVKPXr00KBBg3Tbbbf5u4qAz3ENIQAAgM1xDSEAAIDNEQgBAABs7qqvIczMzNThw4dVtGhRn/zYNwAAAHzLGKOUlBSVLVtWAQHZHwe86kB4+PBh6wfTAQAAUHAdPHjQ+olPT646EBYtWtRaQURExNUuBgAAAHkkOTlZFSpUsHJbdq46EDpPE0dERBAIAQAACrDcLu/jphIAAACbIxACAADYHIEQAADA5giEAAAANkcgBAAAsDkCIQAAgM0RCAEAAGyOQAgAAGBzBEIAAACbIxACAADYHIEQAADA5giEAAAANkcgBAAAsDkCIQAAgM0RCAEAAGyOQAgAAGBzBEIAAACbIxACAADYHIEQAADA5giEAAAANkcgBAAAsDkCIQAAgM0RCAEAAGyOQAgAAGBzBEIAAACbIxACAADYHIEQAADA5oL8XQHkj5MnTyo1NdXf1cgX4eHhKl68uL+rAQDAdYNAaAMnT57Uq6+8orT0dH9XJV8EBwXpb8OHEwoBAPASgdAGUlNTlZaerjtLlFB0cHC+rfdEWpq+SErK1/U615mamkogBADASwRCG4kODlZMaKht1gsAALzDTSUAAAA2RyAEAACwOQIhAACAzREIAQAAbI5ACAAAYHMEQgAAAJsjEAIAANgcgRAAAMDmCIQAAAA2RyAEAACwOQIhAACAzREIAQAAbI5ACAAAYHMEQgAAAJsjEAIAANgcgRAAAMDmCIQAAAA2RyAEAACwOQIhAACAzREIAQAAbI5ACAAAYHMEQgAAAJsjEAIAANgcgRAAAMDmCIQAAAA2RyAEAACwOQIhAACAzREIAQAAbI5ACAAAYHMEQgAAAJsjEAIAANgcgRAAAMDmCIQAAAA2RyAEAACwOQIhAACAzREIAQAAbI5ACAAAYHMEQgAAAJsjEAIAANgcgRAAAMDmCIQAAAA2RyAEAACwOQIhAACAzREIAQAAbI5ACAAAYHMEQgAAAJsjEAIAANgcgRAAAMDmCIQAAAA2RyAEAACwOQIhAACAzREIAQAAbI5ACAAAYHMEQgAAAJsjEAIAANgcgRAAAMDmCIQAAAA2d90EwosXL+rgwYO6ePGiv6sC2BrvRQC48Vw3gfDYsWN6/fXXdezYMX9XBbA13osAcOO5bgIhAAAA8gaBEAAAwOYIhAAAADZHIAQAALA5AiEAAIDNEQgBAABsjkAIAABgcwRCAAAAmyMQAgAA2ByBEAAAwOYIhAAAADZHIAQAALA5AiEAAIDNEQgBAABsjkAIAABgcwRCAAAAmyMQAgAA2ByBEAAAwOYIhAAAADZHIAQAALA5AiEAAIDNEQgBAABsjkAIAABgcwRCAAAAmyMQAgAA2ByBEAAAwOYIhAAAADZHIAQAALA5AiEAAIDNEQgBAABsjkAIAABgcwRCAAAAmyMQAgAA2ByBEAAAwOYIhAAAADZHIAQAALA5AiEAAIDNEQgBAABsjkAIAABgcwRCAAAAmyMQAgAA2ByBEAAAwOYIhAAAADZHIAQAALA5AiEAAIDNEQgBAABsjkAIAABgcwRCAAAAmyMQAgAA2ByBEAAAwOYIhAAAADZHIAQAALA5AiEAAIDNEQgBAABsjkAIAABgcwRCAAAAmwvydwUA3HjmzJmjtWvXWs/j4+PVrVs3t3Jz587VqlWrrOctWrRQly5d3MrNmzdPK1eutJ63bNlSnTt3diu3YsUKzZ8/33reqVMntWrVyq3c8uXLtWDBAuv5Pffco9atW7uV27lzpyZNmmQ9f+yxx1S9enW3cr/++qveeecd6/mTTz6pKlWqXFW5ffv26R//+If1fPDgwYqLi7vqdR4+fFgTJkyQMUYOh0NDhgxR2bJl3cqdPXtW7733nk6fPq2oqCg98sgjKly4sFu548ePa9y4ccrIyFBgYKBeeOEFlSpV6qqXd/LkSY0fP14XLlxQaGiohg4dquLFi7uVO3/+vD7++GOdOHFC0dHR6t27t8LCwtzKJScna+LEiUpNTVV4eLieeeYZRUREXHEZScrMzNSePXuUnJysiIgIVa5cWQEB7sdRvN1Wb8ulp6dr7dq11rbGx8crKKjgfF172xe+5G1feFvO17zts4Lctw5jjLmaFyYnJysyMlJnzpzx+EbytYMHD+r111/Xc889pwoVKuT5+m4kzrbrXaaMYkJD8229xy5c0MdHjuTrep3rZD/JO7m9F59++ulsX/vWW29RLody/qrbSy+9pBMnTriViY6O1t///nfr+aBBg+TpK8PhcOjNN9+84uU988wzysjIcCsXGBioiRMnWs9ff/11HTx40K1chQoV9Nxzz1nPhw4dqvPnz7uVCwsL0/jx470uI0lbtmzRvHnzdPLkSWta8eLF1blzZ9WrV++Kt9XbcvPnz9eqVauUmZlpTQsICFCLFi3UqVMnt9fnN2/7wpe87Qtvy/mat33mr771Nq9xyhiAz+QUQLLOv7zc5f/BZ1cuMDDQq3LFihXzqlxUVJRX5W6++WavyjVu3Piqy11eJj4+3mfrDAwMVIcOHVzazzk/a1CpUaOGBg0apBo1akiSTpw4oZdeekmSaxgMDQ1Vly5dFPrff/SMMRo0aNAVLS9rGIyIiNADDzxgfVllZGTomWeekeQaQBo1aqQhQ4aoUaNGkv73z4nkGvRKly6t/v37q3Tp0pIuHdEaOnSoV2WkS8Fi+vTpKlu2rAYPHqwJEyZo8ODBKlu2rKZPn64tW7Zc0bZ6W27+/PlasWKFwsPD1bNnT40ZM0Y9e/ZUeHi429Fvf/C2L3zJ277wtpyvedtnBb1vJU4ZA/CROXPmWH937dpVCQkJ1vPVq1fr888/lyQNGzbMmn7fffepefPm1vN169Zp9uzZkqQRI0ZY07t3765mzZpZz9evX69Zs2ZJksuX0MMPP6w6depYz7du3ar3339fkvTee+9Z0/v166e6detaz3/66Sd98MEHkqTPPvvMmp71KGifPn1cvvS++uorq9yQIUNUrlw5SdL999+v33//XRMmTJB06TS2N+WcXnjhBZUpU0aS1K1bNx05ckTjxo2TJJfT6zktK+vp+uHDh1undNu3b6/jx4/rlVdekXTptLMzqIwdO9Y6ffnoo4/q7NmzGjZsmE6cOKF9+/ZZYXDEiBEqUaKEpEun+JOSkjRmzBgZY7Rv3z6vlnfo0CErDI4cOdI6RXzrrbfq5MmTGj16tDIyMnT48GErgIwfP946Lfnggw+qW7duGjp0qA4ePKjjx49bQW/MmDFWsKxdu7aSk5M1YsQIl6OCOZU5ffq05s2bp1q1aqlfv37WPytxcXHq16+fPvjgA82fP1+VK1f2aluTkpK8KpecnKxVq1apaNGiGjVqlHUasUmTJmrUqJFGjRqlVatW6a677vLLKcbz58971Rfnz5/32enjzMxMr/qiVq1aXpWrU6eOT08fp6ene9Vn7dq1K9B96+T1mi9cuKALFy5Yz5OTk/OkQrk5duyYX9Z7PbNjm9lxm/NLdm2bNYRkDYPO585AePbsWWt61jDofO4MhFk/Y7KGQedzZyDMevoqaxi8/PmOHTusv7OGwcufb9iwwfr78lPiWZ8vXLjQ+tsZzDw9z/qff07lnJxh0NPzuXPnerUsZzgPDAx0u76vVKlSCgwMVEZGhnUNYo0aNdyuZStcuLCqVaumXbt2Wdc0hoaGWmHQqUSJEgoNDdWFCxescrkt77XXXpN06cjg5dcLFi9eXEWLFlVKSooVcBs1auQWMsLCwtSgQQNt2rTJCsylS5d2OyUWERGhmJgYa7/Nrcxrr72mP//8U4mJiW7hISAgQG3atNGbb76pt99+26ttddYtt3ITJ05UZmamx1AQFBSkDh06aNasWVq7dq1atmyp/Pbxxx9Lyr0vPv74Y/Xv398n69yzZ49OnjyZa1+sXbvWq3J79uxR1apVfVI36dJnnjd99vHHHxfovrXq4m3BsWPHavTo0XlZF684d0ogJ+wnBZ+3/6lffprYyeFwuFzPdvlpYifntTNOl58mdoqIiHAJoZefJnaqW7eufvrpJ+v55adsnRo2bKiNGzdeUbnLTxM7NW3a1CWoervOtm3beizXunVrLV261Hrerl07j+XatWunXbt2Wc/vvPPObMtlvUnH2+V17NjRY7m77rpLM2fOtPo3uy/Jli1batOmTdbRxpyWN23aNK/KnDt3TpJ7MHdyTk9JSbG2yRPntqalpXlVLjU1VZJUq1Ytj+Vq166tWbNmebwOMT8415tbX/iyfs73Y2594VxnbuV8fSDLuV5v+6yg9q2T14Fw2LBh1jUd0qWG9cdF+71791ZMTEy+r/d6duzYMdsFJPaTvOOr/SnrhdU58XTTgSS3mxtOnTrlsVzWMChJp0+f9lju8i+LH3/8UX369HErlzUMStK3336r+++/361c1mDmbbm1a9d6vBs7axi8knUuXbpU7du3dyu3fPlyl+dLlizRo48+6lZuyZIlLs+/+OILtWjRItdy3i5v4cKFuvXWW93KLVq0SNL/Qv/KlSv14IMPupVz3nnuPOK5cOFC1a5dO9vlOdeZU5lChQrpzz//1JEjRzze3X3kyBFJUtGiRXX27NlctzU4OFhpaWm5lgsPD9fFixe1fft2NWnSxK3ctm3bJF26CcUfoqOjdeTIkVz7wpf1cx7Jza0vnOvMrZyvb4B1rtebPjty5EiB7VsnrwNhaGiodQGxP8XExHD3KHLFfpL/4uPjrdPGq1evdruG0Klw4cLWaeN169a5XUPolPWI3fr1692uIXSqUKGCddp469atbtcQOtWsWdM6bfzTTz+5XUPolPVo3MGDB132o6ynpzt27GidNv79999dTtn+/vvv1t+dOnWyThvnVM7pyJEjLkc6nF9mktSlSxfrtHFOy+rWrZvmzJmjjIwMHT9+3OW08fHjx62Q/eSTT+qdd97Rzz//rLNnz7qc0jx79qx1NG/w4MH6xz/+oQsXLigpKcnltHFSUpJ1OZGzXG7Le/755/Xaa68pOTlZJ0+edDltfPLkSevo25AhQzR+/Hh9//336tatm8upyvPnz2vTpk2SLl13+corr+jo0aPWcCNOycnJLpc55Fbm+eef11tvvaVly5a5XI8mXfon5quvvlJ0dLSeeuopDR8+PNdtfeGFFzRmzJhcyz3zzDMaOXKkFi1apEaNGrmcWkxPT9fixYsVEBCQ7VHkvNa7d28NHTo0177o3bu3z9ZZuXJlFS9ePNe+iI+P15o1a3ItV7lyZZ/VTbr0mbdgwYJc+6x3794aNmxYge1bJ24qAeAT3bp1swLh559/bl0zeLmxY8dad7jOnj3bumbwcmPGjLHKzZo1S7NmzXI7TSxduvHDWc55A8nlp4kl6ZFHHrHKOW8gufw0sST16NHDCoTOG0guP00sSW3atLECofNat8tP2UpSq1atrECYUzkn5zVnl58mli7dxOEMhDktKz4+3rqO8JVXXlFgYKBat26t5cuXuxxxrVKliqKjo3XixAkNGzZM1apVU7t27bRkyRIrqERHRysuLs5q+zFjxig0NNQq5wyDDodDcXFxXi2vfPny1lG90aNHq2jRorrrrru0aNEiKwwGBgaqbNmyVuAfOnSoGjRooJYtW2rlypVWAKlQoYJKlSqlsLAwnT9/XiNGjFBMTIy1PGfQcwaY3MpERUWpc+fOmj59uj744AO1adNGZcqU0ZEjR/TVV19p+/bt6tu3r4oUKeLVtpYoUcKrchEREWrRooVWrFihUaNGqUOHDqpdu7a2bdumxYsXKyUlRa1atfLbTQdhYWFe9YUvxyMMCAjwqi+CgoK8Kufr8QiDgoK86rOwsLAC3bdOjENoA4xDCF9iHELGIbycXcYhjI6OVqdOnRiHsACMQ+ipL7wt52s3yjiEBEIbIBDCl7x5L/JLJfxSCb9Uwi+V+BK/VHL1CISwEAjhS7wXAeD6wS+VAAAAwCsEQgAAAJsjEAIAANgcgRAAAMDmCIQAAAA2RyAEAACwOQIhAACAzREIAQAAbI5ACAAAYHMEQgAAAJsjEAIAANgcgRAAAMDmCIQAAAA2RyAEAACwOQIhAACAzREIAQAAbI5ACAAAYHMEQgAAAJsjEAIAANgcgRAAAMDmCIQAAAA2RyAEAACwOQIhAACAzREIAQAAbI5ACAAAYHMEQgAAAJsjEAIAANgcgRAAAMDmCIQAAAA2RyAEAACwOQIhAACAzREIAQAAbI5ACAAAYHMEQgAAAJsjEAIAANgcgRAAAMDmCIQAAAA2RyAEAACwOQIhAACAzREIAQAAbI5ACAAAYHMEQgAAAJsjEAIAANgcgRAAAMDmCIQAAAA2RyAEAACwOQIhAACAzREIAQAAbI5ACAAAYHMEQgAAAJsjEAIAANgcgRAAAMDmCIQAAAA2RyAEAACwOQIhAACAzV03gTAmJkbPPfecYmJi/F0VwNZ4LwLAjSfI3xXwVkhIiCpUqODvagC2x3sRAG48180RQgAAAOQNAiEAAIDNEQgBAABsjkAIAABgcwRCAAAAmyMQAgAA2ByBEAAAwOYIhAAAADZHIAQAALA5AiEAAIDNEQgBAABsjkAIAABgcwRCAAAAmyMQAgAA2ByBEAAAwOYIhAAAADZHIAQAALA5AiEAAIDNEQgBAABsjkAIAABgcwRCAAAAmyMQAgAA2ByBEAAAwOYIhAAAADZHIAQAALA5AiEAAIDNEQgBAABsjkAIAABgcwRCAAAAmyMQAgAA2ByBEAAAwOYIhAAAADZHIAQAALA5AiEAAIDNEQgBAABsjkAIAABgcwRCAAAAmyMQAgAA2ByBEAAAwOYIhAAAADZHIAQAALA5AiEAAIDNEQgBAABsjkAIAABgcwRCAAAAmyMQAgAA2ByBEAAAwOYIhAAAADZHIAQAALA5AiEAAIDNEQgBAABsjkAIAABgcwRCAAAAmyMQAgAA2ByBEAAAwOYIhAAAADZHIAQAALA5AiEAAIDNBfm7Asg/J9LS/LK+/Fxvfm8jAAA3AgKhDYSHhys4KEhfJCX5Zf35vd7goCCFh4fn6zoBALieOYwx5mpemJycrMjISJ05c0YRERG+rhd87OTJk0pNTfV3NfJFeHi4ihcv7u9qAADgd97mNY4Q2kTx4sUJSQAAwCNuKgEAALA5AiEAAIDNEQgBAABsjkAIAABgcwRCAAAAmyMQAgAA2ByBEAAAwOYIhAAAADZHIAQAALA5AiEAAIDNEQgBAABsjkAIAABgcwRCAAAAmyMQAgAA2ByBEAAAwOYIhAAAADZHIAQAALA5AiEAAIDNEQgBAABsjkAIAABgcwRCAAAAmyMQAgAA2ByBEAAAwOYIhAAAADZHIAQAALA5AiEAAIDNEQgBAABsLuhqX2iMkSQlJyf7rDIAAADwHWdOc+a27Fx1IExJSZEkVahQ4WoXAQAAgHyQkpKiyMjIbOc7TG6RMRuZmZk6fPiwihYtKofD4TY/OTlZFSpU0MGDBxUREXE1q4CP0BcFB31RcNAXBQd9UXDQFwWHr/rCGKOUlBSVLVtWAQHZXyl41UcIAwICVL58+VzLRUREsFMVEPRFwUFfFBz0RcFBXxQc9EXB4Yu+yOnIoBM3lQAAANgcgRAAAMDm8iwQhoaGauTIkQoNDc2rVcBL9EXBQV8UHPRFwUFfFBz0RcGR331x1TeVAAAA4MbAKWMAAACbIxACAADYHIEQAADA5giEAAAANpdngfDdd99VXFycwsLC1LhxY3333Xd5tSr815o1a9SxY0eVLVtWDodD8+bNc5lvjNHf//53lSlTRoUKFVKbNm20e/du/1T2BjZ27Fg1atRIRYsWValSpdS5c2ft2rXLpcz58+c1cOBARUdHq0iRIrr33nt17NgxP9X4xjVp0iTVrVvXGti1SZMmWrx4sTWffvCfcePGyeFwaNCgQdY0+iN/jBo1Sg6Hw+VRvXp1az79kL9+//13Pfjgg4qOjlahQoVUp04dbdy40ZqfX9/deRIIP/vsMz3zzDMaOXKkfvjhB9WrV0/t2rXT8ePH82J1+K/U1FTVq1dP7777rsf5EyZM0Ntvv63Jkyfr22+/VXh4uNq1a6fz58/nc01vbKtXr9bAgQP1zTffaNmyZUpLS1Pbtm2VmppqlRk8eLAWLlyo2bNna/Xq1Tp8+LC6du3qx1rfmMqXL69x48Zp06ZN2rhxo1q1aqVOnTpp+/btkugHf/n+++/13nvvqW7dui7T6Y/8U6tWLR05csR6rFu3zppHP+SfU6dOqVmzZgoODtbixYu1Y8cOvfHGGypWrJhVJt++u00euPXWW83AgQOt5xkZGaZs2bJm7NixebE6eCDJzJ0713qemZlpSpcubV577TVr2unTp01oaKj59NNP/VBD+zh+/LiRZFavXm2MudTuwcHBZvbs2VaZn3/+2UgyX3/9tb+qaRvFihUz77//Pv3gJykpKaZq1apm2bJlJiEhwTz99NPGGN4X+WnkyJGmXr16HufRD/lr6NChpnnz5tnOz8/vbp8fIbx48aI2bdqkNm3aWNMCAgLUpk0bff31175eHby0d+9eHT161KVfIiMj1bhxY/olj505c0aSVLx4cUnSpk2blJaW5tIX1atXV8WKFemLPJSRkaGZM2cqNTVVTZo0oR/8ZODAgbrrrrtc2l3ifZHfdu/erbJly+ovf/mLHnjgAR04cEAS/ZDfFixYoIYNG+q+++5TqVKldPPNN2vq1KnW/Pz87vZ5IExKSlJGRoZiYmJcpsfExOjo0aO+Xh285Gx7+iV/ZWZmatCgQWrWrJlq164t6VJfhISEKCoqyqUsfZE3tm7dqiJFiig0NFSPPvqo5s6dq5o1a9IPfjBz5kz98MMPGjt2rNs8+iP/NG7cWDNmzNCXX36pSZMmae/evYqPj1dKSgr9kM9+++03TZo0SVWrVtWSJUv02GOP6amnntKHH34oKX+/u4N8ujQALgYOHKht27a5XJ+D/FWtWjVt3rxZZ86c0Zw5c5SYmKjVq1f7u1q2c/DgQT399NNatmyZwsLC/F0dW+vQoYP1d926ddW4cWPFxsZq1qxZKlSokB9rZj+ZmZlq2LChXn31VUnSzTffrG3btmny5MlKTEzM17r4/AhhiRIlFBgY6HZH0rFjx1S6dGlfrw5ecrY9/ZJ/nnjiCf3f//2fVq5cqfLly1vTS5curYsXL+r06dMu5emLvBESEqIqVaqoQYMGGjt2rOrVq6e33nqLfshnmzZt0vHjx3XLLbcoKChIQUFBWr16td5++20FBQUpJiaG/vCTqKgo3XTTTfr11195X+SzMmXKqGbNmi7TatSoYZ3Cz8/vbp8HwpCQEDVo0EDLly+3pmVmZmr58uVq0qSJr1cHL1WqVEmlS5d26Zfk5GR9++239IuPGWP0xBNPaO7cuVqxYoUqVarkMr9BgwYKDg526Ytdu3bpwIED9EU+yMzM1IULF+iHfNa6dWtt3bpVmzdvth4NGzbUAw88YP1Nf/jHn3/+qT179qhMmTK8L/JZs2bN3IYl++WXXxQbGyspn7+7fXqLyn/NnDnThIaGmhkzZpgdO3aYAQMGmKioKHP06NG8WB3+KyUlxfz444/mxx9/NJLMxIkTzY8//mj2799vjDFm3LhxJioqysyfP9/89NNPplOnTqZSpUrm3Llzfq75jeWxxx4zkZGRZtWqVebIkSPW4+zZs1aZRx991FSsWNGsWLHCbNy40TRp0sQ0adLEj7W+Mb3wwgtm9erVZu/eveann34yL7zwgnE4HGbp0qXGGPrB37LeZWwM/ZFfnn32WbNq1Sqzd+9es379etOmTRtTokQJc/z4cWMM/ZCfvvvuOxMUFGReeeUVs3v3bvOvf/3LFC5c2HzyySdWmfz67s6TQGiMMe+8846pWLGiCQkJMbfeeqv55ptv8mpV+K+VK1caSW6PxMREY8yl29dHjBhhYmJiTGhoqGndurXZtWuXfyt9A/LUB5LM9OnTrTLnzp0zjz/+uClWrJgpXLiw6dKlizly5Ij/Kn2Deuihh0xsbKwJCQkxJUuWNK1bt7bCoDH0g79dHgjpj/zRo0cPU6ZMGRMSEmLKlStnevToYX799VdrPv2QvxYuXGhq165tQkNDTfXq1c2UKVNc5ufXd7fDGGN8e8wRAAAA1xN+yxgAAMDmCIQAAAA2RyAEAACwOQIhAACAzREIAQAAbI5ACAAAYHMEQgAAAJsjEAIAANgcgRC25XA41KJFC7+tv0WLFnI4HH5bv935uv8PHz6s8PBwvfrqqz5bZl7xtO2jRo2Sw+HQqlWrfLZMeG/fvn1yOBzq06ePy/Q+ffrI4XBo37591rRdu3YpKChI//znP/O3krihEQjhcw6H44oe3vL0wZjXnB/S3j7i4uLyrW75wdnm33zzjb+rcsXye38ZPny4ChcurKeeesplelxcXK77TX7u03bkDLvePkaNGuXvKueoWrVq6tWrl0aPHq2UlBR/Vwc3iCB/VwA3npEjR7pNe/PNN3XmzBmP8wqyqKgoj3UePXq0IiMjNWjQILfysJ/du3fro48+0vDhw1WkSBG3+YGBgXrxxRezfX1B2G+eeOIJ9ezZUxUrVvR3VXzO05HLzZs3a/78+UpISHCb748jneXKldPPP/+syMhIr8oPGTJEn3zyid5++20NHz48j2sHOyAQwuc8/Xc9Y8YMnTlzpsD/5325qKgoj3UePXp0tvNgP1OmTFFmZqZ69+7tcX5QUFCB31dKlCihEiVK+Lsa2YqLi1NcXNxVndJu0aKFW8ibMWOG5s+frxYtWhSIvgkODlb16tW9Ll+nTh3VrVtXU6dO1bBhwxQQwAk/XBv2IPhVUlKSBg0apEqVKik0NFSlSpVS9+7dtW3bNpdycXFx+vDDDyVJlSpVsk7tZP2Qnzt3rnr16qUqVaqocOHCioyMVHx8vP7zn//k2/bs379f/fr1U7ly5RQSEqLy5curX79+OnDggNfL+OyzzxQaGqp69erpyJEj1vQ1a9aoY8eOKlGihEJDQ1W1alW9+OKLOnv2rMvrV61aZZ322rhxo+644w4VLVpUkZGR6tKlS56enszrOn7++edq2LChChUqpJiYGPXv31+nTp2ywoKTN/uL07Fjx5SYmKgSJUqoUKFCuu22264odGRmZurDDz9U/fr1VbVqVa9flx3ntaVpaWkaNWqU4uLiFBoaqptuuinba8aSkpI0YMAAlSpVSoULF1ajRo00d+5czZgxQw6HQzNmzMh1vdldQ7hy5Up16NBBZcuWVWhoqGJiYhQfH68pU6Z4XM61tqe/XcnnSNbr/n7++WfdfffdioqKUrFixdSrVy8lJSVJkr7++mu1bt1aERERKlasmB5++GGlpqZmuyxvde/eXfv379fKlSuvaZsBiSOE8KM//vhDTZo00Z49e9SiRQv17NlTe/fu1Zw5c7Ro0SItWbJEzZs3lyQNGjRIM2bM0JYtW/T0009bp9iyhoBhw4YpJCREzZs3V5kyZfTHH39owYIF6tatm95++209+eSTebo9v/zyi5o3b64//vhDHTt2VK1atbRt2zZNmzZNCxcu1Lp163TTTTfluIx33nlHTz/9tOLj47VgwQLr9NGkSZM0cOBARUVFqWPHjipVqpQ2btyoV155RStXrtTKlSsVEhLisqzvv/9eEyZMUMuWLfXII4/oxx9/1Lx587R161Zt27ZNYWFhPt3+vK7jtGnT1K9fP0VEROivf/2rIiMj9cUXX+iOO+5QWlqagoODrbLe7C+SdPr0aTVv3lyRkZHq3bu3jh8/rs8++0zt2rXTpk2bVLt27Vy3e+vWrfrjjz907733Xn3jedCrVy9999136tChgwIDAzVr1iwNHDhQwcHB6t+/v1Xuzz//VEJCgnbs2KGmTZvq9ttv16FDh9SzZ0+1a9fumuqwaNEidezYUVFRUerUqZP1vtqyZYs+/vhjDRgwwKW8L9rT367mc2Tv3r1q2rSpGjZsqIcfflgbN27UzJkzdfDgQY0bN05t27bVHXfcoQEDBmjVqlX64IMPlJmZqWnTpl1TXZs0aSJJWr58uVq3bn1NywJkgHwQGxtrLt/d+vbtaySZYcOGuUxftGiRkWSqVKliMjIyrOmJiYlGktm7d6/HdezZs8dtWkpKiqlTp46JjIw0qampLvMkmYSEhKvaHkkmNjbWZVrLli2NJPPee++5TH/33XeNJNOqVSuX6QkJCS5t8re//c1IMl26dDHnzp2zpm/fvt0EBQWZevXqmaSkJJdljB071kgyr7/+ujVt5cqVRpKRZGbOnOlSvnfv3kaS+fTTT73aTmebf/311zmWy+s6njp1yhQpUsSEh4ebX375xZqelpZmWrVq5bE/cttfnOt//PHHXfaz999/30gyjzzySI7b7OTs36lTp3qcHxsbawIDA83IkSM9PiZNmuRS3rlfNG7c2Jw5c8aavnPnThMUFGSqVavmUv7FF180ksyAAQNcpn/11VfWNk6fPt1t2y/f90eOHGkkmZUrV1rTunbtaiSZzZs3u23X5f3sq/bMTmxs7FW/Xz2ZPn26kWRGjhzpMv1KPkf27t1rbfebb75pTc/MzDR33nmnkWSioqLMvHnzrHkXL140devWNUFBQebo0aNuy0pMTHRZd0778ZkzZ4wkc/vtt1/h1gPuCITIF5cHwgsXLpiwsDATHR3tFtSMMeaOO+4wksyaNWusabl9wWfnjTfeMJLMqlWrXKb7MhDu37/fSDI1a9Y0mZmZLmUzMjJM9erVjSRz4MABa7rziz89Pd3069fPSDL9+/c36enpLq9/6qmn3Noi67JLlixpGjRoYE1zhi1PXxLOec8884xX2+ltIMzrOs6YMcNIMk899ZRb+Q0bNlx1IAwPDzcpKSku09PS0kxQUJC55ZZbctpky7Bhw4wks2DBAo/znft+do969eq5lHfuFytWrHBblnNecnKyNS0uLs6EhIS4hAuntm3b+iQQ7tq1K+dGML5rz+zkVyDMjqfPEWeIq1y5stv7/qOPPjKSTMuWLd2W9dJLL7n18dUEQmOMCQsLM3/5y1+82gYgJ5wyhl/s3LlT58+fV8uWLVW4cGG3+S1bttSyZcu0efNmxcfHe7XM48ePa9y4cVq8eLH279+vc+fOucw/fPiwT+ruyebNmyVJCQkJbkPpBAQE6Pbbb9fOnTu1efNmVahQwWX+vffeq/nz52v48OF6+eWX3ZbtHPJlyZIlWr58udv84OBg7dy50216gwYN3KaVL19e0qVTe76U13XcsmWLJFmXEGTVuHFjBQVd3UfZTTfd5HZXcFBQkGJiYrxuoxMnTkjK+U7h0NBQnT9//orqllvbFC1aVMnJydq3b59q1qypmJgYt/LNmjXT0qVLr2i9WfXs2VOff/65brvtNt1///1q3bq14uPjs735xBftuW/fPlWqVMnjvP3793scqmrv3r0+G/Lpaj5H6tat61avMmXKSJLq16/vVt45zxefScWLF7euVQSuBYEQfpGcnCxJHr/EpP99YDrL5ebkyZNq1KiRDhw4oGbNmqlNmzaKiopSYGCgNbzEhQsXfFN5D65le9asWaOwsDDdeeedHl978uRJSdIrr7xyRXWKiIhwm+YMThkZGVe0rNzkdR2d7VaqVCm38gEBAVd9d6yn9Tvr4G0bFSpUSJKuOPDlxpu2yaldpOz3R2/dd999mjdvniZOnKjJkyfr3XfflcPhUMuWLfXGG2+4hR1ftGd2Qz29+eabioqK8njTha+G7bnaz5Gc+iqneWlpaddc53Pnznn8pxq4UgRC+IXzQ/LYsWMe5x89etSlXG4++OADHThwQGPGjHEb723cuHGaP3/+NdQ2d9eyPcuXL1ebNm3Uvn17ffnll2ratKnHZScnJ6to0aK+rLbP5HUdncs/fvy427zMzEwlJSWpXLlyPl+vN0qWLCnpf6E4P+XULlL2++OV6NSpkzp16qSUlBStX79en3/+uT744AO1b99eO3fu9PkYitkN5zRjxgzFxcXl6RAx/v4cuVKZmZk6c+aMatWq5e+q4AbAsDPwi+rVqyssLEzff/+925AkkqxhKrIegQgMDJTk+ejWnj17JF368rrc2rVrfVDjnDnruWbNGhljXOYZY7RmzRqXclndfPPNWrFihUJCQtS+fXutX7/eZX7jxo0lqUD/Wkhe17FevXqS5NY2kvTdd98pPT3dbXpO+4sv1alTR9KlnxPLbxEREYqLi9Ovv/7qMRRu2LDBZ+sqWrSo2rdvrylTpqhPnz46duyYvv32W58tvyDw9+fIldq9e7cyMzOtfRC4FgRC+EVISIg1TtfYsWNd5n355ZdasmSJqlSpombNmlnTixcvLkk6ePCg2/JiY2MlSevWrXOZ/u9//1tffPGFr6vvpmLFimrZsqW2b9/uNpTElClT9PPPP6tVq1Zu1w861atXTytWrFBoaKjat2/vsh2PP/64goKC9OSTT3ocz/D06dP68ccffbtBVyiv69ipUycVKVJEH3zwgfWlLUnp6ekaMWKEx9fktL/4Unx8vAICAvwWjh544AFdvHjR7TTrqlWrtGTJkmta9po1azwGamf49PXQRf7m78+RK+Xc5xISEvxcE9wIOGUMvxk/frxWr16tl19+WRs2bFDjxo21b98+zZ49W4ULF9b06dNdRt9v1aqVXn/9dQ0YMED33nuvwsPDFRsbq969e6t3794aP368nnzySa1cuVKxsbHasmWLli9frq5du+rzzz/P8+2ZNGmSmjdvrv79+2vhwoWqWbOmtm/frgULFqhkyZKaNGlSjq+vW7euVqxYodatW6tDhw764osvFB8fr9q1a+uf//ynHnvsMVWrVk133nmnKleurJSUFP32229avXq1+vTpo8mTJ+fZto0ZM8Y6NXq5F154Ic/rGBUVpYkTJ2rAgAFq0KCBevbsaY1DGBoaqrJly7r9UkNO+4svFStWTAkJCVq3bp3Onz/vMSSlp6fneKqzZ8+eV/QrFVkNHTpU//nPfzR58mRt27ZN8fHxOnTokGbNmqWOHTtq4cKFV/0rFk899ZQOHz6s5s2bW7/JvG7dOn333Xe67bbbPN7kcz0rCJ8jV2LZsmUKCgrS3Xff7e+q4AZAIITflCxZUt9++63GjBmj+fPna+3atYqMjFTnzp01cuRIt0FsO3TooAkTJmjq1Kl64403lJaWpoSEBPXu3Vvly5fX6tWrNWTIEH311VdKT0/XLbfcoqVLl+rgwYP58kFerVo1bdy4UaNHj9aXX36pRYsWqWTJkurbt69GjhxpHX3ISZ06ddxC4e23367+/furfv36mjhxotasWaOFCxcqMjJSFStW1ODBg5WYmJin25bT0ZE+ffqoevXqeV7H/v37q1ixYnr11Vc1Y8YMRUZG6p577tH48eMVGxurypUru5TPaX/xtUcffVQ9evTQggUL1L17d7f5GRkZGj16dLavr1+//lUHwqJFi2rNmjUaNmyY5s+fr40bN6pWrVr69NNP9dtvv2nhwoVeX4t7uWHDhunzzz/Xpk2btGTJEgUHBysuLk7jx4/X448/bp2Wv1EUhM8Rb509e1bz5s3T3XffrbJly/q7OrgBOMzlFzwBwHXk119/VdWqVdW9e3d99tlnfqlDWlqaqlWrpsqVK2vZsmV+qYMnDz74oP71r39px44dqlGjhr+rAx96//331b9/f61evVq33367v6uDGwDXEAK4Lpw6dcptyI9z585p8ODBkqTOnTv7oVaXBAcHa+zYsfrqq698eiOHt7L+5rXT6tWrNXPmTFWrVo0weINJT0/Xq6++qnvuuYcwCJ/hlDGA68Lq1avVr18/tW3bVhUrVlRSUpJWrFihffv2qVWrVurRo4df69ejRw8dOHDAGqg6P915550qVKiQ6tevr/DwcO3YsUNffvmlAgMD9c477+R7fZC3Dhw4oL/+9a95cvkD7ItTxgCuC7t379aIESO0YcMG/fHHH5KkKlWqqEePHnruueduuDter8Sbb76pf/3rX9qzZ49SUlIUFRWlZs2aadiwYdaQQACQEwIhAACAzXENIQAAgM0RCAEAAGyOQAgAAGBzBEIAAACbIxACAADYHIEQAADA5giEAAAANkcgBAAAsLn/BwN80JixUpa0AAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Plot the distribution of total token length using a histogram\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(df_sorted[\"total_token_length\"], bins=40, kde=True, color=\"skyblue\")\n",
        "plt.title(\"Distribution of Total Token Length\", fontsize=16)\n",
        "plt.xlabel(\"Total Token Length (English + Tamil)\", fontsize=14)\n",
        "plt.ylabel(\"Frequency\", fontsize=14)\n",
        "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
        "plt.show()\n",
        "\n",
        "# Optional: Boxplot for a quick summary of the distribution\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.boxplot(x=df_sorted[\"total_token_length\"], color=\"lightcoral\")\n",
        "plt.title(\"Boxplot of Total Token Length\", fontsize=16)\n",
        "plt.xlabel(\"Total Token Length (English + Tamil)\", fontsize=14)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWTVc0hVhHk-",
        "outputId": "a2c4c744-e45d-49a7-cb05-0262f495d2bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "61925\n"
          ]
        }
      ],
      "source": [
        "z = 0\n",
        "t = 0\n",
        "for i in df['Tokenized_Tamil']:\n",
        "    for j in i:\n",
        "        t = t +1\n",
        "        if j == 0:\n",
        "           z=z+1\n",
        "print(z)\n",
        "print(t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmrG-vynhPWG",
        "outputId": "2038f7e0-9b4f-4f72-b64d-d37a274c6254"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(11076, 4)"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tamil_idx = []\n",
        "for idx , i in enumerate(df['Tokenized_Tamil']):\n",
        "    if len(i) > 24:\n",
        "        tamil_idx.append(idx)\n",
        "\n",
        "print(len(tamil_idx))\n",
        "\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJmWY13dhi_m",
        "outputId": "088c5737-dc02-4f0e-f367-a8373308f465"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(11073, 4)"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df.drop(index=df.index[tamil_idx])\n",
        "\n",
        "df = df.reset_index(drop=True)\n",
        "\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eti-ogtEhr82",
        "outputId": "ace54abc-9d86-45a2-daa7-c69fe6cfd4a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "36\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(11073, 4)"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "english_idx = []\n",
        "for idx , i in enumerate(df['Tokenized_English']):\n",
        "    if len(i) > 24:\n",
        "        english_idx.append(idx)\n",
        "\n",
        "print(len(english_idx))\n",
        "\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZi-SXFvh2xW",
        "outputId": "4b401539-3953-48c5-b740-5506d90cb615"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(11037, 4)"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df.drop(index=df.index[english_idx])\n",
        "\n",
        "df = df.reset_index(drop=True)\n",
        "\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "WPcwIR4eiHF1",
        "outputId": "da3cf359-e237-469a-dcad-2d03afc8f03e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Tamil</th>\n",
              "      <th>Tokenized_Tamil</th>\n",
              "      <th>Tokenized_English</th>\n",
              "      <th>Padded_English</th>\n",
              "      <th>Padded_Tamil</th>\n",
              "      <th>Padded_Tamil_Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Lets try something</td>\n",
              "      <td>ஏதாவது முயற்சி செய்யலாம்</td>\n",
              "      <td>[4, 5, 6]</td>\n",
              "      <td>[4, 5, 6]</td>\n",
              "      <td>[2, 4, 5, 6, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[2, 4, 5, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[4, 5, 6, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I have to go to sleep</td>\n",
              "      <td>நான் தூங்க செல்ல வேண்டும்</td>\n",
              "      <td>[7, 8, 9, 10]</td>\n",
              "      <td>[7, 8, 9, 10, 9, 11]</td>\n",
              "      <td>[2, 7, 8, 9, 10, 9, 11, 3, 1, 1, 1, 1, 1, 1, 1...</td>\n",
              "      <td>[2, 7, 8, 9, 10, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
              "      <td>[7, 8, 9, 10, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Today is June 18th and it is Muiriels birthday</td>\n",
              "      <td>இன்று ஜூன் 18 மற்றும் முரியலின் பிறந்த நாள்</td>\n",
              "      <td>[11, 12, 13, 14, 15, 16, 17]</td>\n",
              "      <td>[12, 13, 14, 15, 16, 17, 13, 18, 19]</td>\n",
              "      <td>[2, 12, 13, 14, 15, 16, 17, 13, 18, 19, 3, 1, ...</td>\n",
              "      <td>[2, 11, 12, 13, 14, 15, 16, 17, 1, 1, 1, 1, 1,...</td>\n",
              "      <td>[11, 12, 13, 14, 15, 16, 17, 3, 1, 1, 1, 1, 1,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Muiriel is 20 now</td>\n",
              "      <td>முரியலுக்கு இப்போது 20 வயது</td>\n",
              "      <td>[18, 19, 20, 21]</td>\n",
              "      <td>[20, 13, 21, 22]</td>\n",
              "      <td>[2, 20, 13, 21, 22, 3, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
              "      <td>[2, 18, 19, 20, 21, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
              "      <td>[18, 19, 20, 21, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The password is Muiriel</td>\n",
              "      <td>கடவுச்சொல் முரியல்</td>\n",
              "      <td>[22, 23]</td>\n",
              "      <td>[23, 24, 13, 20]</td>\n",
              "      <td>[2, 23, 24, 13, 20, 3, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
              "      <td>[2, 22, 23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1...</td>\n",
              "      <td>[22, 23, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11032</th>\n",
              "      <td>Dont speak to the driver while he is driving</td>\n",
              "      <td>வாகனம் ஓட்டும் போது ஓட்டுனரிடம் பேச வேண்டாம்</td>\n",
              "      <td>[3724, 15517, 741, 15520, 1215, 797]</td>\n",
              "      <td>[487, 491, 9, 50, 7118, 481, 89, 13, 1678]</td>\n",
              "      <td>[2, 487, 491, 9, 50, 7118, 481, 89, 13, 1678, ...</td>\n",
              "      <td>[2, 3724, 15517, 741, 15520, 1215, 797, 1, 1, ...</td>\n",
              "      <td>[3724, 15517, 741, 15520, 1215, 797, 3, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11033</th>\n",
              "      <td>The driver was inattentive and could not stop ...</td>\n",
              "      <td>டிரைவர் கவனக்குறைவாக இருந்ததால் சரியான நேரத்தி...</td>\n",
              "      <td>[15521, 3850, 751, 465, 2632, 2354, 2246]</td>\n",
              "      <td>[23, 7118, 45, 8096, 16, 149, 96, 2074, 49, 56]</td>\n",
              "      <td>[2, 23, 7118, 45, 8096, 16, 149, 96, 2074, 49,...</td>\n",
              "      <td>[2, 15521, 3850, 751, 465, 2632, 2354, 2246, 1...</td>\n",
              "      <td>[15521, 3850, 751, 465, 2632, 2354, 2246, 3, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11034</th>\n",
              "      <td>The driver could not distinguish the signal in...</td>\n",
              "      <td>டிரைவரால் மூடுபனியில் சிக்னலை வேறுபடுத்திப் பா...</td>\n",
              "      <td>[15522, 15523, 15524, 3612, 502, 2246]</td>\n",
              "      <td>[23, 7118, 149, 96, 2531, 50, 8097, 49, 50, 3566]</td>\n",
              "      <td>[2, 23, 7118, 149, 96, 2531, 50, 8097, 49, 50,...</td>\n",
              "      <td>[2, 15522, 15523, 15524, 3612, 502, 2246, 1, 1...</td>\n",
              "      <td>[15522, 15523, 15524, 3612, 502, 2246, 3, 1, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11035</th>\n",
              "      <td>The driver tipped his cap</td>\n",
              "      <td>டிரைவர் தொப்பியை சாய்த்தார்</td>\n",
              "      <td>[15521, 15525, 15526]</td>\n",
              "      <td>[23, 7118, 8098, 886, 6047]</td>\n",
              "      <td>[2, 23, 7118, 8098, 886, 6047, 3, 1, 1, 1, 1, ...</td>\n",
              "      <td>[2, 15521, 15525, 15526, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[15521, 15525, 15526, 3, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11036</th>\n",
              "      <td>The driver gestured him out</td>\n",
              "      <td>ஓட்டுனர் சைகையால் வெளியே காட்டினார்</td>\n",
              "      <td>[15527, 15528, 758, 8712]</td>\n",
              "      <td>[23, 7118, 8099, 216, 695]</td>\n",
              "      <td>[2, 23, 7118, 8099, 216, 695, 3, 1, 1, 1, 1, 1...</td>\n",
              "      <td>[2, 15527, 15528, 758, 8712, 1, 1, 1, 1, 1, 1,...</td>\n",
              "      <td>[15527, 15528, 758, 8712, 3, 1, 1, 1, 1, 1, 1,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11037 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 English  \\\n",
              "0                                     Lets try something   \n",
              "1                                  I have to go to sleep   \n",
              "2         Today is June 18th and it is Muiriels birthday   \n",
              "3                                      Muiriel is 20 now   \n",
              "4                                The password is Muiriel   \n",
              "...                                                  ...   \n",
              "11032       Dont speak to the driver while he is driving   \n",
              "11033  The driver was inattentive and could not stop ...   \n",
              "11034  The driver could not distinguish the signal in...   \n",
              "11035                          The driver tipped his cap   \n",
              "11036                        The driver gestured him out   \n",
              "\n",
              "                                                   Tamil  \\\n",
              "0                               ஏதாவது முயற்சி செய்யலாம்   \n",
              "1                              நான் தூங்க செல்ல வேண்டும்   \n",
              "2            இன்று ஜூன் 18 மற்றும் முரியலின் பிறந்த நாள்   \n",
              "3                            முரியலுக்கு இப்போது 20 வயது   \n",
              "4                                     கடவுச்சொல் முரியல்   \n",
              "...                                                  ...   \n",
              "11032       வாகனம் ஓட்டும் போது ஓட்டுனரிடம் பேச வேண்டாம்   \n",
              "11033  டிரைவர் கவனக்குறைவாக இருந்ததால் சரியான நேரத்தி...   \n",
              "11034  டிரைவரால் மூடுபனியில் சிக்னலை வேறுபடுத்திப் பா...   \n",
              "11035                        டிரைவர் தொப்பியை சாய்த்தார்   \n",
              "11036                ஓட்டுனர் சைகையால் வெளியே காட்டினார்   \n",
              "\n",
              "                                 Tokenized_Tamil  \\\n",
              "0                                      [4, 5, 6]   \n",
              "1                                  [7, 8, 9, 10]   \n",
              "2                   [11, 12, 13, 14, 15, 16, 17]   \n",
              "3                               [18, 19, 20, 21]   \n",
              "4                                       [22, 23]   \n",
              "...                                          ...   \n",
              "11032       [3724, 15517, 741, 15520, 1215, 797]   \n",
              "11033  [15521, 3850, 751, 465, 2632, 2354, 2246]   \n",
              "11034     [15522, 15523, 15524, 3612, 502, 2246]   \n",
              "11035                      [15521, 15525, 15526]   \n",
              "11036                  [15527, 15528, 758, 8712]   \n",
              "\n",
              "                                       Tokenized_English  \\\n",
              "0                                              [4, 5, 6]   \n",
              "1                                   [7, 8, 9, 10, 9, 11]   \n",
              "2                   [12, 13, 14, 15, 16, 17, 13, 18, 19]   \n",
              "3                                       [20, 13, 21, 22]   \n",
              "4                                       [23, 24, 13, 20]   \n",
              "...                                                  ...   \n",
              "11032         [487, 491, 9, 50, 7118, 481, 89, 13, 1678]   \n",
              "11033    [23, 7118, 45, 8096, 16, 149, 96, 2074, 49, 56]   \n",
              "11034  [23, 7118, 149, 96, 2531, 50, 8097, 49, 50, 3566]   \n",
              "11035                        [23, 7118, 8098, 886, 6047]   \n",
              "11036                         [23, 7118, 8099, 216, 695]   \n",
              "\n",
              "                                          Padded_English  \\\n",
              "0      [2, 4, 5, 6, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
              "1      [2, 7, 8, 9, 10, 9, 11, 3, 1, 1, 1, 1, 1, 1, 1...   \n",
              "2      [2, 12, 13, 14, 15, 16, 17, 13, 18, 19, 3, 1, ...   \n",
              "3      [2, 20, 13, 21, 22, 3, 1, 1, 1, 1, 1, 1, 1, 1,...   \n",
              "4      [2, 23, 24, 13, 20, 3, 1, 1, 1, 1, 1, 1, 1, 1,...   \n",
              "...                                                  ...   \n",
              "11032  [2, 487, 491, 9, 50, 7118, 481, 89, 13, 1678, ...   \n",
              "11033  [2, 23, 7118, 45, 8096, 16, 149, 96, 2074, 49,...   \n",
              "11034  [2, 23, 7118, 149, 96, 2531, 50, 8097, 49, 50,...   \n",
              "11035  [2, 23, 7118, 8098, 886, 6047, 3, 1, 1, 1, 1, ...   \n",
              "11036  [2, 23, 7118, 8099, 216, 695, 3, 1, 1, 1, 1, 1...   \n",
              "\n",
              "                                            Padded_Tamil  \\\n",
              "0      [2, 4, 5, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
              "1      [2, 7, 8, 9, 10, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n",
              "2      [2, 11, 12, 13, 14, 15, 16, 17, 1, 1, 1, 1, 1,...   \n",
              "3      [2, 18, 19, 20, 21, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n",
              "4      [2, 22, 23, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1...   \n",
              "...                                                  ...   \n",
              "11032  [2, 3724, 15517, 741, 15520, 1215, 797, 1, 1, ...   \n",
              "11033  [2, 15521, 3850, 751, 465, 2632, 2354, 2246, 1...   \n",
              "11034  [2, 15522, 15523, 15524, 3612, 502, 2246, 1, 1...   \n",
              "11035  [2, 15521, 15525, 15526, 1, 1, 1, 1, 1, 1, 1, ...   \n",
              "11036  [2, 15527, 15528, 758, 8712, 1, 1, 1, 1, 1, 1,...   \n",
              "\n",
              "                                     Padded_Tamil_Target  \n",
              "0      [4, 5, 6, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "1      [7, 8, 9, 10, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...  \n",
              "2      [11, 12, 13, 14, 15, 16, 17, 3, 1, 1, 1, 1, 1,...  \n",
              "3      [18, 19, 20, 21, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1,...  \n",
              "4      [22, 23, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1...  \n",
              "...                                                  ...  \n",
              "11032  [3724, 15517, 741, 15520, 1215, 797, 3, 1, 1, ...  \n",
              "11033  [15521, 3850, 751, 465, 2632, 2354, 2246, 3, 1...  \n",
              "11034  [15522, 15523, 15524, 3612, 502, 2246, 3, 1, 1...  \n",
              "11035  [15521, 15525, 15526, 3, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "11036  [15527, 15528, 758, 8712, 3, 1, 1, 1, 1, 1, 1,...  \n",
              "\n",
              "[11037 rows x 7 columns]"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Example of the maximum padding length\n",
        "max_pad = 24\n",
        "cls_token = 2\n",
        "sep_token = 3\n",
        "\n",
        "# Function to pad sequences\n",
        "def pad_sequence_source(tokens, max_len, cls_token=2,sep_token = 3):\n",
        "    # Add the cls token at the beginning\n",
        "    padded_tokens = [cls_token] + tokens + [sep_token]\n",
        "    #padded_tokens = padded_tokens + [sep_token]\n",
        "\n",
        "    # Pad the sequence if it's shorter than max_len\n",
        "    if len(padded_tokens) < max_len:\n",
        "        padded_tokens.extend([1] * (max_len - len(padded_tokens)))\n",
        "    # Truncate if it's longer than max_len\n",
        "    else:\n",
        "        padded_tokens = padded_tokens[:max_len]\n",
        "\n",
        "    return padded_tokens\n",
        "\n",
        "def pad_sequence_target(tokens, max_len, cls_token = 2):\n",
        "    # Add the cls token at the beginning\n",
        "    padded_tokens = [cls_token] + tokens\n",
        "\n",
        "    # Pad the sequence if it's shorter than max_len\n",
        "    if len(padded_tokens) < max_len:\n",
        "        padded_tokens.extend([1] * (max_len - len(padded_tokens)))\n",
        "    # Truncate if it's longer than max_len\n",
        "    else:\n",
        "        padded_tokens = padded_tokens[:max_len]\n",
        "\n",
        "    return padded_tokens\n",
        "\n",
        "def pad_sequence_label(tokens, max_len, sep_token = 3):\n",
        "    # Add the cls token at the beginning\n",
        "    padded_tokens = tokens + [sep_token]\n",
        "\n",
        "    # Pad the sequence if it's shorter than max_len\n",
        "    if len(padded_tokens) < max_len:\n",
        "        padded_tokens.extend([1] * (max_len - len(padded_tokens)))\n",
        "    # Truncate if it's longer than max_len\n",
        "    else:\n",
        "        padded_tokens = padded_tokens[:max_len]\n",
        "\n",
        "    return padded_tokens\n",
        "\n",
        "# Apply padding and add CLS token to both English and Tamil columns\n",
        "df['Padded_English'] = df['Tokenized_English'].apply(lambda x: pad_sequence_source(x, max_pad, cls_token,sep_token))\n",
        "df['Padded_Tamil'] = df['Tokenized_Tamil'].apply(lambda x: pad_sequence_target(x, max_pad, cls_token))\n",
        "df['Padded_Tamil_Target'] = df['Tokenized_Tamil'].apply(lambda x: pad_sequence_label(x, max_pad,sep_token))\n",
        "# Verify the result\n",
        "#print(df[['Padded_English', 'Padded_Tamil','Padded_Tamil_Target']].head(-10))\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EF922fPPCCM8",
        "outputId": "3d96bd6c-c651-427d-ef27-34ce4728f9a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train DataFrame:\n",
            "8829\n",
            "\n",
            "Test DataFrame:\n",
            "2208\n"
          ]
        }
      ],
      "source": [
        "'''import pandas as pd\n",
        "\n",
        "# Find the midpoint\n",
        "threshold = int(len(df)*0.8)\n",
        "\n",
        "# Split into two halves\n",
        "train = df.iloc[:threshold]\n",
        "test = df.iloc[threshold:]\n",
        "\n",
        "print(\"Train DataFrame:\")\n",
        "print(len(train))\n",
        "print(\"\\nTest DataFrame:\")\n",
        "print(len(test))'''\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                 English  \\\n",
            "0                                        Congratulations   \n",
            "1                                                 Action   \n",
            "2                                           Check please   \n",
            "3                                             Never mind   \n",
            "4                                              Forget it   \n",
            "...                                                  ...   \n",
            "11031  Your technical manager arranged a meeting for ...   \n",
            "11032  Yoshio said he would pay as much as 15000 yen ...   \n",
            "11033  Im going to speak to you with utmost candor so...   \n",
            "11034  Every mans work whether it be literature or mu...   \n",
            "11035  Meetings are to be held on the afternoon of Ju...   \n",
            "\n",
            "                                                   Tamil  \\\n",
            "0                                            வாழ்த்துகள்   \n",
            "1                                                 அதிரடி   \n",
            "2                                         சரிபார்க்கவும்   \n",
            "3                                             பரவாயில்லை   \n",
            "4                                             மறந்துவிடு   \n",
            "...                                                  ...   \n",
            "11031  உங்கள் தொழில்நுட்ப மேலாளர் மதியம் 100 மணிக்கு ...   \n",
            "11032  யோஷியோ ஒரு புதிய ஜோடி கூடைப்பந்து காலணிகளுக்கு...   \n",
            "11033  நான் உன்னிடம் மிகுந்த நேர்மையுடன் பேசப் போகிறே...   \n",
            "11034  ஒவ்வொரு மனிதனின் படைப்பும் அது இலக்கியமாக இருந...   \n",
            "11035  ஜூலை 15 செவ்வாய்கிழமை மதியம் ஜூலை 16 புதன்கிழம...   \n",
            "\n",
            "                                         Tokenized_Tamil  \\\n",
            "0                                                  [499]   \n",
            "1                                                [15044]   \n",
            "2                                                 [2603]   \n",
            "3                                                 [5441]   \n",
            "4                                                 [3238]   \n",
            "...                                                  ...   \n",
            "11031  [335, 8698, 8860, 2336, 63, 263, 36, 6837, 597...   \n",
            "11032  [8550, 36, 271, 5835, 8666, 5836, 8667, 5327, ...   \n",
            "11033  [7, 392, 1399, 6931, 7814, 113, 194, 7, 7815, ...   \n",
            "11034  [286, 2750, 3223, 35, 3224, 326, 764, 3225, 32...   \n",
            "11035  [3313, 7276, 11888, 2336, 3313, 11889, 11890, ...   \n",
            "\n",
            "                                       Tokenized_English  \\\n",
            "0                                                  [452]   \n",
            "1                                                 [7901]   \n",
            "2                                            [1956, 650]   \n",
            "3                                            [1692, 549]   \n",
            "4                                             [2336, 17]   \n",
            "...                                                  ...   \n",
            "11031  [1031, 5104, 5105, 3562, 31, 2507, 33, 74, 363...   \n",
            "11032  [4918, 200, 89, 230, 1697, 565, 350, 565, 4987...   \n",
            "11033  [29, 37, 9, 491, 9, 83, 131, 4565, 4061, 129, ...   \n",
            "11034  [286, 2063, 561, 598, 17, 26, 2330, 443, 591, ...   \n",
            "11035  [6569, 68, 9, 26, 3779, 192, 50, 1780, 136, 23...   \n",
            "\n",
            "                                          Padded_English  \\\n",
            "0      [2, 452, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1...   \n",
            "1      [2, 7901, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
            "2      [2, 1956, 650, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1...   \n",
            "3      [2, 1692, 549, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1...   \n",
            "4      [2, 2336, 17, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n",
            "...                                                  ...   \n",
            "11031  [2, 1031, 5104, 5105, 3562, 31, 2507, 33, 74, ...   \n",
            "11032  [2, 4918, 200, 89, 230, 1697, 565, 350, 565, 4...   \n",
            "11033  [2, 29, 37, 9, 491, 9, 83, 131, 4565, 4061, 12...   \n",
            "11034  [2, 286, 2063, 561, 598, 17, 26, 2330, 443, 59...   \n",
            "11035  [2, 6569, 68, 9, 26, 3779, 192, 50, 1780, 136,...   \n",
            "\n",
            "                                            Padded_Tamil  \\\n",
            "0      [2, 499, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1...   \n",
            "1      [2, 15044, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n",
            "2      [2, 2603, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
            "3      [2, 5441, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
            "4      [2, 3238, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
            "...                                                  ...   \n",
            "11031  [2, 335, 8698, 8860, 2336, 63, 263, 36, 6837, ...   \n",
            "11032  [2, 8550, 36, 271, 5835, 8666, 5836, 8667, 532...   \n",
            "11033  [2, 7, 392, 1399, 6931, 7814, 113, 194, 7, 781...   \n",
            "11034  [2, 286, 2750, 3223, 35, 3224, 326, 764, 3225,...   \n",
            "11035  [2, 3313, 7276, 11888, 2336, 3313, 11889, 1189...   \n",
            "\n",
            "                                     Padded_Tamil_Target  total_token_length  \n",
            "0      [499, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1...                   2  \n",
            "1      [15044, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...                   2  \n",
            "2      [2603, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                   3  \n",
            "3      [5441, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                   3  \n",
            "4      [3238, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                   3  \n",
            "...                                                  ...                 ...  \n",
            "11031  [335, 8698, 8860, 2336, 63, 263, 36, 6837, 597...                  41  \n",
            "11032  [8550, 36, 271, 5835, 8666, 5836, 8667, 5327, ...                  42  \n",
            "11033  [7, 392, 1399, 6931, 7814, 113, 194, 7, 7815, ...                  42  \n",
            "11034  [286, 2750, 3223, 35, 3224, 326, 764, 3225, 32...                  43  \n",
            "11035  [3313, 7276, 11888, 2336, 3313, 11889, 11890, ...                  43  \n",
            "\n",
            "[11036 rows x 8 columns]\n"
          ]
        }
      ],
      "source": [
        "# Add a new column for the combined length of English and Tamil tokens\n",
        "df[\"total_token_length\"] = df[\"Tokenized_English\"].apply(len) + df[\"Tokenized_Tamil\"].apply(len)\n",
        "\n",
        "# Sort the DataFrame by the total token length\n",
        "df_sorted = df.sort_values(by=\"total_token_length\")\n",
        "\n",
        "# Reset the index for the sorted DataFrame\n",
        "df_sorted.reset_index(drop=True, inplace=True)\n",
        "\n",
        "print(df_sorted.head(-1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "level1 = df_sorted[:3500]\n",
        "\n",
        "level2 = df_sorted[:7000]\n",
        "\n",
        "level3 = df_sorted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "xhaYFGS8kUXX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, dataframe, pad_token=1):\n",
        "        self.dataframe = dataframe\n",
        "        self.pad_token = pad_token  # Padding value, typically 0\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get the tokenized sequences for English and Tamil\n",
        "        english =  self.dataframe.iloc[idx][\"English\"]\n",
        "        tamil =  self.dataframe.iloc[idx][\"Tamil\"]\n",
        "        english_tokens =  torch.tensor(self.dataframe.iloc[idx][\"Padded_English\"],  dtype=torch.long)  # Shape: (T_english,)\n",
        "        tamil_tokens = torch.tensor(self.dataframe.iloc[idx][\"Padded_Tamil\"],  dtype=torch.long)   # Shape: (T_tamil,)\n",
        "        tamil_target_tokens = torch.tensor(self.dataframe.iloc[idx][\"Padded_Tamil_Target\"],  dtype=torch.long)   # Shape: (T_tamil_target,)\n",
        "\n",
        "\n",
        "        def causal_mask(size):\n",
        "              mask = torch.triu(torch.ones((1, size, size)), diagonal=1).type(torch.int)\n",
        "              return mask == 0\n",
        "    # Return the sequence and masks in a dictionary\n",
        "        return {\n",
        "            \"english\": english,\n",
        "            \"tamil\": tamil,\n",
        "            \"english_token\": english_tokens.clone(),\n",
        "            \"tamil_token\": tamil_tokens.clone(),\n",
        "            \"tamil_target\": tamil_target_tokens.clone(),\n",
        "            \"encoder_mask\": (english_tokens != self.pad_token).unsqueeze(0).unsqueeze(0).int().clone(),\n",
        "            \"decoder_mask\": (tamil_tokens != self.pad_token).unsqueeze(0).int() & causal_mask(tamil_tokens.size(0)).clone(),\n",
        "\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueABUeLQkaJe",
        "outputId": "cb437299-d97b-4b6f-903e-1ba816f3af5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 1:\n",
            "  English sequence shape: The swimmer raised his head and gasped for breath\n",
            "  Tamil sequence shape: நீச்சல்காரன் தலையை உயர்த்தி மூச்சு வாங்கினான்\n",
            "  English token shape: tensor([   2,   23, 6079, 4256,  886, 3429,   16, 5059,   33, 2522,    3,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1])\n",
            "  tamil token shape: torch.Size([32, 24])\n",
            "  Tamil target sequence shape: tensor([15371,  7495, 10653,  8374, 15372,     3,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1])\n",
            "  English pad mask shape: tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0]]], dtype=torch.int32)\n",
            "  Combined Tamil mask shape: tensor([[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0]]], dtype=torch.int32)\n",
            "Batch 1:\n",
            "  English sequence shape: It is difficult for foreigners to get used to Japanese food\n",
            "  Tamil sequence shape: வெளிநாட்டினர் ஜப்பானிய உணவைப் பழக்கப்படுத்துவது கடினம்\n",
            "  English token shape: tensor([   2,  152,   13,  700,   33, 6166,    9,  380, 1337,    9,  539,  501,\n",
            "           3,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1])\n",
            "  tamil token shape: torch.Size([1, 24])\n",
            "  Tamil target sequence shape: tensor([11057,   611,  5591, 11058,   849,     3,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1])\n",
            "  English pad mask shape: tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0]]], dtype=torch.int32)\n",
            "  Combined Tamil mask shape: tensor([[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0],\n",
            "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "          0]]], dtype=torch.int32)\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Assuming you have your Dataset class `TranslationDataset` and DataLoader defined\n",
        "# Example DataLoader for your dataset\n",
        "dataset1 = TranslationDataset(level1)  # Your dataframe should be defined\n",
        "train_dataloader_1 = DataLoader(dataset1, batch_size = 32, shuffle=True)  # Set batch_size as needed  # Your dataframe should be defined\n",
        "test_dataloader_1 = DataLoader(dataset1, batch_size=1, shuffle=True)  # Set batch_size as needed\n",
        "\n",
        "dataset2 = TranslationDataset(level2)  # Your dataframe should be defined\n",
        "train_dataloader_2 = DataLoader(dataset2, batch_size = 32, shuffle=True)  # Set batch_size as needed  # Your dataframe should be defined\n",
        "test_dataloader_2 = DataLoader(dataset2, batch_size=1, shuffle=True)  # Set batch_size as needed\n",
        "\n",
        "dataset3 = TranslationDataset(level3)  # Your dataframe should be defined\n",
        "train_dataloader_3 = DataLoader(dataset3, batch_size = 32, shuffle=True)  # Set batch_size as needed  # Your dataframe should be defined\n",
        "test_dataloader_3 = DataLoader(dataset3, batch_size=1, shuffle=True)  # Set batch_size as needed\n",
        "# Iterate through batches\n",
        "for batch_idx, batch in enumerate(train_dataloader_3):\n",
        "    print(f\"Batch {batch_idx + 1}:\")\n",
        "\n",
        "    # Check the shapes of each tensor in the batch\n",
        "    print(f\"  English sequence shape: {batch['english'][0]}\")  # Expected: (batch_size, T_english)\n",
        "    print(f\"  Tamil sequence shape: {batch['tamil'][0]}\")  # Expected: (batch_size, T_tamil)\n",
        "    print(f\"  English token shape: {batch['english_token'][0]}\")  # Expected: (batch_size, T_english)\n",
        "    print(f\"  tamil token shape: {batch['tamil_token'].shape}\")  # Expected: (batch_size, T_english)\n",
        "    print(f\"  Tamil target sequence shape: {batch['tamil_target'][0]}\")  # Expected: (batch_size, T_tamil_target)\n",
        "    print(f\"  English pad mask shape: {batch['encoder_mask'][0]}\")  # Expected: (batch_size, T_english, T_english)\n",
        "    print(f\"  Combined Tamil mask shape: {batch['decoder_mask'][0]}\")  # Expected: (batch_size, T_tamil_target, T_tamil_target)\n",
        "    break\n",
        "    \n",
        "# Iterate through batches\n",
        "for batch_idx, batch in enumerate(test_dataloader_3):\n",
        "    print(f\"Batch {batch_idx + 1}:\")\n",
        "\n",
        "    # Check the shapes of each tensor in the batch\n",
        "    print(f\"  English sequence shape: {batch['english'][0]}\")  # Expected: (batch_size, T_english)\n",
        "    print(f\"  Tamil sequence shape: {batch['tamil'][0]}\")  # Expected: (batch_size, T_tamil)\n",
        "    print(f\"  English token shape: {batch['english_token'][0]}\")  # Expected: (batch_size, T_english)\n",
        "    print(f\"  tamil token shape: {batch['tamil_token'].shape}\")  # Expected: (batch_size, T_english)\n",
        "    print(f\"  Tamil target sequence shape: {batch['tamil_target'][0]}\")  # Expected: (batch_size, T_tamil_target)\n",
        "    print(f\"  English pad mask shape: {batch['encoder_mask'][0]}\")  # Expected: (batch_size, T_english, T_english)\n",
        "    print(f\"  Combined Tamil mask shape: {batch['decoder_mask'][0]}\")  # Expected: (batch_size, T_tamil_target, T_tamil_target)\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSLGhcoFmxla",
        "outputId": "ab96b1ea-0057-4cb3-e3d6-84b72044a3c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Check if CUDA is available and set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9R7ZjgrCJaO7",
        "outputId": "7a1f9deb-88fe-4b62-9b0f-4007c83e26ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary: 15529\n",
            "Vocabulary: 8100\n"
          ]
        }
      ],
      "source": [
        "print(\"Vocabulary:\", len(tamil_tokenizer.word_to_id))\n",
        "print(\"Vocabulary:\", len(english_tokenizer.word_to_id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "omdKlJ5Emxla"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)]\n",
        "\n",
        "class MultiHeadSelfAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model: int, h: int, dropout: float) -> None:\n",
        "        super().__init__()\n",
        "        self.d_model = d_model # Embedding vector size\n",
        "        self.h = h # Number of heads\n",
        "        # Make sure d_model is divisible by h\n",
        "        assert d_model % h == 0, \"d_model is not divisible by h\"\n",
        "\n",
        "        self.d_k = d_model // h # Dimension of vector seen by each head\n",
        "        self.w_q = nn.Linear(d_model, d_model, bias=False) # Wq\n",
        "        self.w_k = nn.Linear(d_model, d_model, bias=False) # Wk\n",
        "        self.w_v = nn.Linear(d_model, d_model, bias=False) # Wv\n",
        "        self.w_o = nn.Linear(d_model, d_model, bias=False) # Wo\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    @staticmethod\n",
        "    def attention(query, key, value, mask, dropout: nn.Dropout):\n",
        "        d_k = query.shape[-1]\n",
        "        # Just apply the formula from the paper\n",
        "        # (batch, h, seq_len, d_k) --> (batch, h, seq_len, seq_len)\n",
        "        attention_scores = (query @ key.transpose(-2, -1)) / math.sqrt(d_k)\n",
        "        if mask is not None:\n",
        "            # Write a very low value (indicating -inf) to the positions where mask == 0\n",
        "            attention_scores.masked_fill_(mask == 0, -1e9)\n",
        "        attention_scores = attention_scores.softmax(dim=-1) # (batch, h, seq_len, seq_len) # Apply softmax\n",
        "        if dropout is not None:\n",
        "            attention_scores = dropout(attention_scores)\n",
        "        # (batch, h, seq_len, seq_len) --> (batch, h, seq_len, d_k)\n",
        "        # return attention scores which can be used for visualization\n",
        "        return (attention_scores @ value), attention_scores\n",
        "\n",
        "    def forward(self, q, k, v, mask):\n",
        "        query = self.w_q(q) # (batch, seq_len, d_model) --> (batch, seq_len, d_model)\n",
        "        key = self.w_k(k) # (batch, seq_len, d_model) --> (batch, seq_len, d_model)\n",
        "        value = self.w_v(v) # (batch, seq_len, d_model) --> (batch, seq_len, d_model)\n",
        "\n",
        "        # (batch, seq_len, d_model) --> (batch, seq_len, h, d_k) --> (batch, h, seq_len, d_k)\n",
        "        query = query.view(query.shape[0], query.shape[1], self.h, self.d_k).transpose(1, 2)\n",
        "        key = key.view(key.shape[0], key.shape[1], self.h, self.d_k).transpose(1, 2)\n",
        "        value = value.view(value.shape[0], value.shape[1], self.h, self.d_k).transpose(1, 2)\n",
        "\n",
        "        # Calculate attention\n",
        "        x, self.attention_scores = MultiHeadSelfAttention.attention(query, key, value, mask, self.dropout)\n",
        "\n",
        "        # Combine all the heads together\n",
        "        # (batch, h, seq_len, d_k) --> (batch, seq_len, h, d_k) --> (batch, seq_len, d_model)\n",
        "        x = x.transpose(1, 2).contiguous().view(x.shape[0], -1, self.h * self.d_k)\n",
        "\n",
        "        # Multiply by Wo\n",
        "        # (batch, seq_len, d_model) --> (batch, seq_len, d_model)\n",
        "        return self.w_o(x)\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff):\n",
        "        super(FeedForward, self).__init__()\n",
        "        self.linear1 = nn.Linear(d_model, d_ff)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(d_ff, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear2(self.relu(self.linear1(x)))\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, n_heads, d_ff, dropout=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.attn = MultiHeadSelfAttention(d_model, n_heads, dropout)\n",
        "        self.ff = FeedForward(d_model, d_ff)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        attn_output = self.attn(x,x,x, mask)\n",
        "        x = self.norm1(x + self.dropout(attn_output))\n",
        "        ff_output = self.ff(x)\n",
        "        x = self.norm2(x + self.dropout(ff_output))\n",
        "        return x\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, n_heads, d_ff, dropout=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.self_attn = MultiHeadSelfAttention(d_model, n_heads, dropout)\n",
        "        self.enc_attn = MultiHeadSelfAttention(d_model, n_heads, dropout)\n",
        "        self.ff = FeedForward(d_model, d_ff)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
        "        self_attn_output = self.self_attn(x ,x, x, tgt_mask)\n",
        "        x = self.norm1(x + self.dropout(self_attn_output))\n",
        "        enc_attn_output = self.enc_attn(x, enc_output, enc_output, src_mask)\n",
        "        x = self.norm2(x + self.dropout(enc_attn_output))\n",
        "        ff_output = self.ff(x)\n",
        "        x = self.norm3(x + self.dropout(ff_output))\n",
        "        return x\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, d_model, n_heads, d_ff, n_layers, dropout=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, d_model)\n",
        "        self.positional_encoding = PositionalEncoding(d_model)\n",
        "        self.layers = nn.ModuleList([EncoderLayer(d_model, n_heads, d_ff, dropout) for _ in range(n_layers)])\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        x = self.embedding(src)\n",
        "        x = self.positional_encoding(x)\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, src_mask)\n",
        "        return x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, d_model, n_heads, d_ff, n_layers, dropout=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_dim, d_model)\n",
        "        self.positional_encoding = PositionalEncoding(d_model)\n",
        "        self.layers = nn.ModuleList([DecoderLayer(d_model, n_heads, d_ff, dropout) for _ in range(n_layers)])\n",
        "        self.fc_out = nn.Linear(d_model, output_dim)\n",
        "\n",
        "    def forward(self, tgt, enc_output, src_mask, tgt_mask):\n",
        "        x = self.embedding(tgt)\n",
        "        x = self.positional_encoding(x)\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, enc_output, src_mask, tgt_mask)\n",
        "\n",
        "        return self.fc_out(x)\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, n_heads, d_ff, n_enc_layers, n_dec_layers, dropout=0.1):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.encoder = Encoder(src_vocab_size, d_model, n_heads, d_ff, n_enc_layers, dropout)\n",
        "        self.decoder = Decoder(tgt_vocab_size, d_model, n_heads, d_ff, n_dec_layers, dropout)\n",
        "\n",
        "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
        "        enc_output = self.encoder(src, src_mask)\n",
        "        output = self.decoder(tgt, enc_output, src_mask, tgt_mask)\n",
        "        return output\n",
        "\n",
        "src_vocab_size = 8100\n",
        "tgt_vocab_size = 15529\n",
        "d_model = 64\n",
        "n_heads = 8\n",
        "d_ff = 512\n",
        "n_enc_layers = 8\n",
        "n_dec_layers = 8\n",
        "dropout = 0.1\n",
        "\n",
        "model = Transformer(src_vocab_size, tgt_vocab_size, d_model, n_heads, d_ff, n_enc_layers, n_dec_layers, dropout).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avIaJ4h0mxla",
        "outputId": "8bdb2703-738a-4223-d7b1-82fc8a10e002"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total model parameters: 3977769\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters())\n",
        "# Assuming 'model' is your PyTorch model\n",
        "total_params = count_parameters(model)\n",
        "print(f\"Total model parameters: {total_params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_tolnaPmxlb",
        "outputId": "e839cefa-6006-4b93-fd1a-f9e7d98ae244"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "English Vocabulary: 8100\n",
            "Tamil Vocabulary: 15529\n"
          ]
        }
      ],
      "source": [
        "print(\"English Vocabulary:\", len(english_tokenizer.word_to_id))\n",
        "print(\"Tamil Vocabulary:\", len(tamil_tokenizer.word_to_id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "aRq93fGu84Fs",
        "outputId": "cf2df1ee-be3d-4eaf-f790-04394e98ec15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Device name: NVIDIA GeForce GTX 1060 6GB\n",
            "Device memory: 5.999755859375 GB\n",
            "Model loaded from checkpoint.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 00: 100%|██████████| 345/345 [00:31<00:00, 10.83it/s, loss=6.225]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:The sea looks calm and smooth\n",
            "     TARGET:கடல் அமைதியாகவும் மென்மையாகவும் தெரிகிறது\n",
            "  PREDICTED:<SOS> இந்த மாணவர்கள் அவரது அவரது <EOS>\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "from torch.utils.data import random_split\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import WordLevel\n",
        "from tokenizers.trainers import WordLevelTrainer\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "\n",
        "\n",
        "\n",
        "epochs = 1\n",
        "lr = 10**-4\n",
        "\n",
        "def causal_mask(size):\n",
        "    mask = torch.triu(torch.ones((1, size, size)), diagonal=1).type(torch.int)\n",
        "    return mask == 0\n",
        "\n",
        "def greedy_decode(model, source, source_mask, tokenizer_src, tokenizer_tgt, max_len, device):\n",
        "    sos_idx, eos_idx = 2, 3\n",
        "    encoder_output = model.encoder(source.to(device), source_mask.to(device))\n",
        "    decoder_input = torch.empty(1, 1).fill_(sos_idx).type_as(source).to(device)\n",
        "\n",
        "    while decoder_input.size(1) < max_len:\n",
        "        decoder_mask = causal_mask(decoder_input.size(1)).type_as(source_mask).to(device)\n",
        "        out = model.decoder(decoder_input, encoder_output, source_mask, decoder_mask)\n",
        "        next_word = torch.max(out[:, -1], dim=1)[1]\n",
        "        decoder_input = torch.cat([decoder_input, next_word.view(1, 1).to(device)], dim=1)\n",
        "        if next_word == eos_idx: break\n",
        "\n",
        "    return decoder_input.squeeze(0)\n",
        "\n",
        "\n",
        "def run_validation(model, validation_ds, tokenizer_src, tokenizer_tgt, max_len, device, print_msg, num_examples=1):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    source_texts, expected, predicted = [], [], []\n",
        "    try:\n",
        "      console_width = os.get_terminal_size().columns\n",
        "    except OSError:\n",
        "      console_width = 80\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for count, batch in enumerate(validation_ds, start=1):\n",
        "            encoder_input, encoder_mask = batch[\"english_token\"].to(device), batch[\"encoder_mask\"].to(device)\n",
        "            assert encoder_input.size(0) == 1, \"Batch size must be 1 for validation\"\n",
        "            model_out = greedy_decode(model, encoder_input, encoder_mask, tokenizer_src, tokenizer_tgt, max_len, device)\n",
        "\n",
        "            source_text = batch[\"english\"][0]\n",
        "            target_text = batch[\"tamil\"][0]\n",
        "            model_out_text = tokenizer_tgt.decode(model_out.detach().cpu().numpy())\n",
        "\n",
        "            source_texts.append(source_text)\n",
        "            expected.append(target_text)\n",
        "            predicted.append(model_out_text)\n",
        "\n",
        "            print_msg(f\"{'-'*console_width}\\n{'SOURCE:':>12}{source_text}\\n{'TARGET:':>12}{target_text}\\n{'PREDICTED:':>12}{model_out_text}\")\n",
        "            if count == num_examples: break\n",
        "\n",
        "def train_model():\n",
        "\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.has_mps or torch.backends.mps.is_available() else \"cpu\"\n",
        "    print(\"Using device:\", device)\n",
        "    if device == 'cuda':\n",
        "        print(f\"Device name: {torch.cuda.get_device_name(device.index)}\")\n",
        "        print(f\"Device memory: {torch.cuda.get_device_properties(device.index).total_memory / 1024 ** 3} GB\")\n",
        "\n",
        "    checkpoint_path = \"Model_Params.pth\"\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        model.load_state_dict(torch.load(checkpoint_path))\n",
        "        print(\"Model loaded from checkpoint.\")\n",
        "    else :\n",
        "        print(\"Checkpoint not found. Training from scratch.\")\n",
        "\n",
        "    \n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = lr, eps=1e-9)\n",
        "    loss_fn = nn.CrossEntropyLoss(ignore_index= 1).to(device)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        torch.cuda.empty_cache()\n",
        "        model.train()\n",
        "        if epoch <= 5:\n",
        "            train_dataloader = train_dataloader_1\n",
        "        elif epoch > 5 and epoch <= 10:\n",
        "            train_dataloader = train_dataloader_2\n",
        "        elif epoch > 10:\n",
        "            train_dataloader = train_dataloader_3\n",
        "        batch_iterator = tqdm(train_dataloader, desc=f\"Processing Epoch {epoch:02d}\")\n",
        "        for batch in batch_iterator:\n",
        "            encoder_input = batch['english_token'].to(device)\n",
        "            decoder_input = batch['tamil_token'].to(device)\n",
        "            encoder_mask = batch['encoder_mask'].to(device)\n",
        "            decoder_mask = batch['decoder_mask'].to(device)\n",
        "\n",
        "            output = model(encoder_input, decoder_input, encoder_mask, decoder_mask)\n",
        "\n",
        "            label = batch['tamil_target'].to(device)\n",
        "\n",
        "            loss = loss_fn(output.view(-1, (len(tamil_tokenizer.word_to_id))), label.view(-1))\n",
        "            batch_iterator.set_postfix({\"loss\": f\"{loss.item():6.3f}\"})\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        torch.save(model.state_dict(), \"Model_Params.pth\")\n",
        "        run_validation(model, test_dataloader, english_tokenizer, tamil_tokenizer, 24, device, lambda msg: batch_iterator.write(msg))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "    train_model()\n",
        "      \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "encoder.embedding.weight: tensor([[ 1.6955, -0.0610,  0.3888,  ..., -1.9795, -1.8131,  1.1476],\n",
            "        [ 0.1672,  0.0232, -0.6564,  ...,  1.3063,  1.0435,  0.7717],\n",
            "        [-0.5136, -0.3979, -1.2307,  ...,  1.7067, -2.2019, -1.9402],\n",
            "        ...,\n",
            "        [ 1.6157,  0.0438, -0.9753,  ..., -0.5703, -0.1501,  0.0975],\n",
            "        [-0.4921,  0.7696, -0.9313,  ...,  1.1314, -2.2142,  0.8563],\n",
            "        [-0.6695, -0.3574, -0.6683,  ..., -0.8854, -1.1445, -1.4381]],\n",
            "       device='cuda:0')\n",
            "encoder.layers.0.attn.w_q.weight: tensor([[-0.0567,  0.0821, -0.0875,  ..., -0.0977, -0.0841, -0.0432],\n",
            "        [-0.1021,  0.0692, -0.0733,  ...,  0.0938,  0.0524,  0.0397],\n",
            "        [ 0.0235, -0.0201,  0.0374,  ..., -0.1251,  0.1156, -0.0838],\n",
            "        ...,\n",
            "        [ 0.0737,  0.0506, -0.1419,  ..., -0.0698,  0.1279,  0.0745],\n",
            "        [ 0.0740,  0.0544,  0.1057,  ...,  0.0854,  0.0673, -0.1136],\n",
            "        [ 0.0843,  0.1170, -0.0835,  ...,  0.0704,  0.0186,  0.0393]],\n",
            "       device='cuda:0')\n",
            "encoder.layers.0.attn.w_k.weight: tensor([[ 0.1069, -0.0408,  0.0038,  ..., -0.0018,  0.0598,  0.0110],\n",
            "        [ 0.0816,  0.0198, -0.0214,  ...,  0.0369,  0.0876, -0.1020],\n",
            "        [ 0.0734,  0.0371, -0.0056,  ...,  0.0989, -0.0812,  0.0672],\n",
            "        ...,\n",
            "        [ 0.0435,  0.0608,  0.0891,  ...,  0.0109, -0.1030,  0.0729],\n",
            "        [ 0.0672, -0.0453,  0.0694,  ..., -0.0064, -0.0921,  0.0498],\n",
            "        [-0.0052, -0.0330,  0.0469,  ..., -0.0753, -0.0632,  0.1060]],\n",
            "       device='cuda:0')\n",
            "encoder.layers.0.attn.w_v.weight: tensor([[-0.1006, -0.0196,  0.1274,  ...,  0.0859,  0.0321, -0.0812],\n",
            "        [ 0.0118, -0.0860, -0.0590,  ...,  0.0691,  0.0881, -0.0672],\n",
            "        [-0.1369,  0.0638, -0.1298,  ..., -0.1004, -0.0156, -0.1259],\n",
            "        ...,\n",
            "        [ 0.0793,  0.0824,  0.0603,  ...,  0.1173, -0.0952,  0.0088],\n",
            "        [-0.0166, -0.0893, -0.0910,  ...,  0.0438, -0.1001,  0.0974],\n",
            "        [-0.0861, -0.0209,  0.0041,  ..., -0.0049,  0.0595,  0.0882]],\n",
            "       device='cuda:0')\n",
            "encoder.layers.0.attn.w_o.weight: tensor([[ 0.0480, -0.0821, -0.0288,  ...,  0.0156, -0.0541, -0.0812],\n",
            "        [-0.0201, -0.0506, -0.0020,  ...,  0.0842,  0.1293,  0.1143],\n",
            "        [ 0.0519, -0.0516,  0.0178,  ...,  0.0934,  0.0227,  0.0560],\n",
            "        ...,\n",
            "        [ 0.0914, -0.0103,  0.0117,  ...,  0.0791, -0.1074, -0.0237],\n",
            "        [-0.0847,  0.0666, -0.0904,  ..., -0.0958,  0.0601, -0.0372],\n",
            "        [ 0.0890,  0.0655, -0.0157,  ..., -0.0150, -0.0289, -0.1050]],\n",
            "       device='cuda:0')\n",
            "encoder.layers.0.ff.linear1.weight: tensor([[ 0.0468, -0.0308,  0.0554,  ...,  0.0247, -0.0706,  0.0396],\n",
            "        [ 0.0513, -0.0107,  0.0151,  ...,  0.0583, -0.0728,  0.0533],\n",
            "        [-0.0047,  0.0816, -0.0409,  ..., -0.0987,  0.0878, -0.0035],\n",
            "        ...,\n",
            "        [-0.0568,  0.0888, -0.0307,  ..., -0.0123, -0.1176,  0.0445],\n",
            "        [-0.0840,  0.0214, -0.0295,  ..., -0.1303, -0.0249,  0.0771],\n",
            "        [-0.1105,  0.1137, -0.0033,  ...,  0.0037,  0.0274,  0.0664]],\n",
            "       device='cuda:0')\n",
            "encoder.layers.0.ff.linear1.bias: tensor([-0.0831,  0.0098, -0.0347,  0.0551,  0.0495,  0.1200,  0.0420, -0.0205,\n",
            "        -0.0314,  0.1134,  0.0904, -0.1096,  0.1163, -0.1147, -0.0309, -0.0548,\n",
            "         0.0950,  0.1044, -0.1195,  0.0071, -0.0644, -0.1211,  0.0926, -0.0681,\n",
            "        -0.0297, -0.0136, -0.1232, -0.0537,  0.0507,  0.0998, -0.0269,  0.1075,\n",
            "         0.0547,  0.0778,  0.0480,  0.0918,  0.0537,  0.0590,  0.0413, -0.1002,\n",
            "         0.0056,  0.0455, -0.0856, -0.0403,  0.1021, -0.0363, -0.0339, -0.0418,\n",
            "        -0.0354, -0.1021, -0.0750,  0.0002,  0.0096,  0.0929, -0.0673, -0.1086,\n",
            "         0.1086, -0.0662,  0.1166, -0.0528,  0.0422,  0.0692, -0.0636, -0.0776,\n",
            "        -0.0640,  0.0138,  0.0591, -0.1194, -0.1112, -0.1093, -0.0846,  0.0172,\n",
            "         0.1050,  0.0942,  0.0241,  0.0836, -0.0108, -0.0250, -0.0919, -0.0174,\n",
            "         0.0396,  0.0683,  0.1177,  0.0461, -0.0786, -0.0520, -0.0171, -0.0821,\n",
            "        -0.0171, -0.0118,  0.0498, -0.0853,  0.0766, -0.1164,  0.0909,  0.0336,\n",
            "        -0.1027,  0.0909, -0.0313,  0.0909,  0.0432, -0.0463,  0.0981,  0.0736,\n",
            "         0.0503,  0.1208, -0.0657, -0.0455, -0.0110,  0.0890, -0.0053, -0.1161,\n",
            "        -0.0985, -0.0482,  0.1053, -0.0248,  0.0583, -0.0293,  0.0149, -0.0768,\n",
            "         0.0538,  0.0147, -0.0593, -0.0314, -0.0815,  0.0014, -0.0802,  0.1136,\n",
            "        -0.1113,  0.0619, -0.0136, -0.0646,  0.1150, -0.0047, -0.1313,  0.0966,\n",
            "        -0.0619,  0.0580, -0.0899, -0.0242, -0.0940, -0.0507, -0.0194,  0.0563,\n",
            "         0.0815,  0.1038,  0.0643,  0.0951, -0.0839,  0.1077, -0.0262, -0.1001,\n",
            "        -0.1011,  0.0285,  0.0312, -0.0874,  0.0117, -0.0470, -0.0015,  0.0944,\n",
            "        -0.0328,  0.0125,  0.0076,  0.0339,  0.0068, -0.0470,  0.0355, -0.0107,\n",
            "         0.0867,  0.0109, -0.1235, -0.0891,  0.1004, -0.0390,  0.0844,  0.0339,\n",
            "         0.0944, -0.0464, -0.0642, -0.1207, -0.0690, -0.0916, -0.0309,  0.0111,\n",
            "        -0.1117, -0.1097,  0.0500, -0.0957, -0.0756,  0.0196, -0.1305, -0.1185,\n",
            "        -0.0080, -0.0799,  0.0013,  0.0331,  0.0587,  0.0300,  0.0704,  0.0970,\n",
            "        -0.0289,  0.0623,  0.0853, -0.1044,  0.0498, -0.1137,  0.0047, -0.0064,\n",
            "         0.0530,  0.0589,  0.0817,  0.0023, -0.0016,  0.1073, -0.0719,  0.0109,\n",
            "         0.0709, -0.1237,  0.0103,  0.0444,  0.1186,  0.0137, -0.0265, -0.0320,\n",
            "        -0.0201,  0.0546, -0.1107,  0.0698,  0.0446, -0.0740, -0.0716, -0.0928,\n",
            "        -0.0460,  0.1052,  0.0801, -0.0911, -0.0540, -0.0949,  0.0397, -0.0234,\n",
            "        -0.1251, -0.0035,  0.0753,  0.0801, -0.0966,  0.0681,  0.0352, -0.0912,\n",
            "        -0.1175,  0.0815, -0.1104,  0.0608, -0.0066,  0.0847, -0.0400, -0.0966,\n",
            "        -0.0499, -0.1226,  0.0754,  0.0885, -0.1122, -0.0918, -0.0941,  0.0724,\n",
            "         0.0841, -0.0178, -0.0275, -0.1166, -0.0341, -0.1101, -0.0216,  0.0119,\n",
            "        -0.1055, -0.0180,  0.0734,  0.0009, -0.0093,  0.0417,  0.0438, -0.1147,\n",
            "        -0.0777,  0.0012, -0.1090,  0.0788,  0.0426, -0.0201,  0.0866, -0.0577,\n",
            "        -0.1100,  0.0411,  0.0718, -0.1144, -0.0921, -0.0453, -0.0640, -0.0739,\n",
            "         0.0499, -0.0917,  0.1083, -0.0696,  0.0297,  0.0231,  0.0649, -0.0770,\n",
            "        -0.0866, -0.1188, -0.0787,  0.1057, -0.0271,  0.0398,  0.0129,  0.0222,\n",
            "         0.1011,  0.0727,  0.0471, -0.0563, -0.0513, -0.0123,  0.0154,  0.0779,\n",
            "        -0.0577,  0.0205, -0.0285,  0.0724, -0.1125,  0.0283,  0.0715, -0.0024,\n",
            "         0.0647, -0.0980,  0.0093,  0.0062, -0.0338, -0.0602,  0.1079,  0.0322,\n",
            "        -0.0332,  0.0298,  0.0664, -0.0914, -0.0098, -0.0467,  0.0246, -0.1201,\n",
            "        -0.1077,  0.0192, -0.1039,  0.1205,  0.0819, -0.0591, -0.0941,  0.1116,\n",
            "        -0.0289,  0.0481, -0.0011, -0.0141, -0.0059,  0.0777, -0.0961, -0.0136,\n",
            "        -0.0711, -0.0479, -0.0118,  0.0846,  0.0666,  0.0003, -0.1111,  0.0847,\n",
            "        -0.0218,  0.1167, -0.0794,  0.0198, -0.0890,  0.0956, -0.0903,  0.0889,\n",
            "         0.0957, -0.0012,  0.1165, -0.0781, -0.0922, -0.0645, -0.1036, -0.0491,\n",
            "        -0.0435, -0.0832,  0.0701, -0.0288, -0.0221, -0.0028, -0.0329, -0.1104,\n",
            "        -0.0515,  0.0629, -0.0020, -0.0003, -0.0941, -0.0416, -0.0765,  0.0961,\n",
            "         0.0928, -0.0461, -0.0823, -0.0219, -0.0732,  0.0717,  0.0161, -0.0431,\n",
            "         0.0053, -0.0614,  0.0824,  0.0074,  0.0223, -0.0172,  0.0329, -0.0702,\n",
            "         0.0291,  0.0160,  0.0505, -0.0134,  0.0486,  0.0718, -0.0559, -0.0262,\n",
            "         0.0722,  0.0339,  0.0998,  0.0201, -0.0067, -0.0180,  0.0274, -0.1045,\n",
            "         0.0485, -0.0132,  0.0196, -0.0467, -0.0474, -0.0446,  0.0849, -0.0474,\n",
            "        -0.0792,  0.1087,  0.0566, -0.1186,  0.0816,  0.0258,  0.0178, -0.1047,\n",
            "         0.0812, -0.0698,  0.0584,  0.0763,  0.1156, -0.0565,  0.0703,  0.0391,\n",
            "        -0.0702,  0.0359,  0.0086,  0.0038, -0.1112, -0.0688, -0.0333,  0.0410,\n",
            "        -0.1169, -0.1027, -0.0078, -0.0563, -0.0996,  0.1063, -0.0679, -0.0043,\n",
            "        -0.1267, -0.0647,  0.0984,  0.0147,  0.0792,  0.0764,  0.0969,  0.0994,\n",
            "        -0.0872,  0.0304, -0.1057, -0.0828, -0.1135, -0.0147,  0.0765,  0.0251,\n",
            "        -0.0103, -0.0069, -0.1037, -0.1034, -0.1161,  0.0547,  0.0627,  0.0994,\n",
            "        -0.0560, -0.0473, -0.0781,  0.0185,  0.0315, -0.1197,  0.0759, -0.0496,\n",
            "        -0.0640, -0.0538, -0.0439, -0.0809,  0.1136,  0.0886, -0.1036, -0.0951],\n",
            "       device='cuda:0')\n",
            "encoder.layers.0.ff.linear2.weight: tensor([[ 3.5249e-02, -8.4361e-03,  2.4644e-02,  ..., -1.3039e-02,\n",
            "          4.0924e-02, -2.9976e-02],\n",
            "        [-9.5764e-03,  4.3671e-02, -5.5817e-02,  ..., -1.1144e-02,\n",
            "          2.4298e-02,  1.0993e-02],\n",
            "        [ 2.8695e-02, -4.5561e-02,  1.3629e-02,  ...,  7.9270e-05,\n",
            "          2.6903e-02,  3.0382e-02],\n",
            "        ...,\n",
            "        [-1.9291e-02,  1.7144e-02,  1.1924e-02,  ...,  4.0218e-02,\n",
            "         -2.3306e-02, -2.4982e-02],\n",
            "        [-1.9332e-02, -2.9668e-02, -4.7603e-02,  ...,  8.3482e-03,\n",
            "          1.4832e-02,  1.9474e-02],\n",
            "        [ 2.6335e-02, -5.0154e-03,  5.2234e-02,  ..., -3.1118e-03,\n",
            "         -1.3378e-02, -7.5324e-03]], device='cuda:0')\n",
            "encoder.layers.0.ff.linear2.bias: tensor([-0.0298, -0.0409,  0.0011,  0.0008,  0.0100,  0.0053, -0.0359,  0.0058,\n",
            "         0.0414,  0.0087, -0.0066, -0.0324,  0.0162, -0.0089, -0.0230,  0.0231,\n",
            "        -0.0325,  0.0273,  0.0250,  0.0155, -0.0012, -0.0209,  0.0353, -0.0168,\n",
            "         0.0209,  0.0170, -0.0449, -0.0212, -0.0097,  0.0147,  0.0241,  0.0016,\n",
            "        -0.0240, -0.0008, -0.0274,  0.0409, -0.0285, -0.0448, -0.0060, -0.0154,\n",
            "        -0.0118, -0.0327, -0.0101,  0.0099,  0.0375, -0.0251, -0.0100, -0.0231,\n",
            "         0.0049,  0.0012, -0.0135, -0.0274, -0.0390, -0.0167,  0.0285,  0.0363,\n",
            "        -0.0004,  0.0260,  0.0066,  0.0255,  0.0249, -0.0214, -0.0060,  0.0242],\n",
            "       device='cuda:0')\n",
            "encoder.layers.0.norm1.weight: tensor([0.9808, 0.9897, 1.0033, 0.9956, 0.9985, 1.0016, 0.9953, 0.9888, 0.9992,\n",
            "        1.0128, 1.0016, 1.0091, 1.0022, 1.0073, 1.0176, 1.0053, 1.0183, 0.9957,\n",
            "        1.0214, 1.0008, 1.0131, 1.0008, 1.0014, 0.9988, 0.9964, 1.0025, 1.0015,\n",
            "        1.0131, 0.9972, 0.9912, 0.9984, 1.0038, 1.0069, 1.0028, 1.0051, 0.9966,\n",
            "        1.0029, 1.0000, 1.0047, 0.9979, 0.9924, 0.9840, 0.9930, 0.9999, 1.0000,\n",
            "        1.0031, 0.9956, 0.9952, 1.0028, 1.0040, 1.0007, 0.9944, 1.0030, 1.0163,\n",
            "        0.9967, 1.0071, 0.9989, 1.0031, 1.0017, 1.0064, 1.0038, 0.9977, 0.9956,\n",
            "        1.0091], device='cuda:0')\n",
            "encoder.layers.0.norm1.bias: tensor([ 2.8152e-03,  3.3768e-03,  1.0841e-03,  2.7188e-03, -1.5628e-03,\n",
            "         2.4300e-03,  2.1556e-03,  3.8322e-03, -2.2323e-03,  1.5585e-04,\n",
            "        -2.9652e-03, -1.3056e-04,  9.2526e-04, -9.8475e-04, -1.6019e-04,\n",
            "         7.7508e-05,  1.2890e-03, -4.7108e-03,  7.3815e-04, -1.9373e-03,\n",
            "         1.2827e-03, -2.4370e-04,  3.3382e-03, -2.3762e-03,  2.5797e-03,\n",
            "        -9.5337e-04,  2.7441e-03, -2.9723e-03,  2.0580e-03, -3.2720e-03,\n",
            "         2.2302e-03, -6.6576e-04, -2.0692e-03, -3.8471e-03,  3.8549e-03,\n",
            "        -4.2623e-03,  5.1917e-03, -2.8286e-03,  5.3142e-04, -3.5042e-03,\n",
            "         5.2566e-03, -5.0420e-03,  7.9257e-04, -3.2230e-04,  2.9528e-03,\n",
            "        -2.5775e-03,  5.8935e-03, -4.4851e-03,  4.6181e-03, -2.2544e-03,\n",
            "         3.6225e-03, -3.7087e-03, -3.8029e-04, -1.1223e-03,  3.8049e-03,\n",
            "        -1.3261e-03, -1.2420e-04, -3.3885e-03,  1.3315e-03,  1.2733e-04,\n",
            "         3.0942e-03, -3.9522e-03,  8.8791e-03, -1.0775e-03], device='cuda:0')\n",
            "encoder.layers.0.norm2.weight: tensor([0.9909, 0.9968, 1.0034, 0.9988, 1.0003, 1.0044, 0.9944, 0.9926, 0.9946,\n",
            "        1.0119, 1.0009, 1.0129, 1.0016, 1.0025, 1.0174, 1.0039, 1.0148, 0.9967,\n",
            "        1.0200, 1.0078, 1.0087, 1.0095, 0.9982, 1.0009, 0.9994, 1.0046, 0.9955,\n",
            "        1.0267, 0.9979, 0.9979, 1.0007, 1.0044, 1.0071, 1.0023, 1.0011, 0.9952,\n",
            "        1.0048, 1.0048, 1.0048, 1.0007, 1.0004, 0.9888, 0.9999, 1.0008, 1.0070,\n",
            "        1.0019, 0.9966, 0.9981, 1.0046, 1.0029, 1.0048, 0.9982, 1.0054, 1.0141,\n",
            "        0.9982, 1.0105, 0.9945, 1.0051, 1.0019, 1.0070, 1.0037, 1.0010, 1.0035,\n",
            "        1.0100], device='cuda:0')\n",
            "encoder.layers.0.norm2.bias: tensor([ 1.4920e-03,  2.0431e-03,  2.7222e-04,  6.5611e-04, -1.9003e-03,\n",
            "         3.7071e-04,  1.2594e-03,  1.6000e-03, -3.1292e-03, -4.2630e-05,\n",
            "        -1.6802e-03, -1.3052e-04, -8.0293e-04,  4.1856e-04,  2.1109e-04,\n",
            "         5.0573e-05,  1.4101e-03, -4.1157e-03,  3.3330e-04, -6.3567e-04,\n",
            "         2.0099e-03,  4.6232e-04,  2.5751e-03, -2.6733e-03,  9.7359e-04,\n",
            "         7.6368e-05,  1.0943e-03, -1.2492e-03,  1.4819e-03, -2.4553e-03,\n",
            "         3.8545e-05, -8.2210e-04, -1.9709e-03, -3.4269e-03,  1.4168e-03,\n",
            "        -2.7454e-04,  2.3379e-03, -1.8409e-03,  1.1108e-03, -1.9807e-03,\n",
            "         2.4326e-04, -3.6698e-03,  1.8682e-03, -9.7930e-04,  1.7649e-03,\n",
            "        -1.7295e-03,  1.5910e-03, -1.9589e-03,  1.8948e-03, -6.4614e-04,\n",
            "         1.5626e-03, -2.0265e-03, -1.5244e-04, -5.1663e-04,  2.4507e-03,\n",
            "         8.7267e-04, -8.0312e-05, -1.8331e-03,  5.9321e-04,  9.7807e-04,\n",
            "         1.0716e-04, -2.9630e-03,  5.3583e-03, -6.0249e-04], device='cuda:0')\n",
            "encoder.layers.1.attn.w_q.weight: tensor([[-0.0327,  0.0493, -0.0496,  ...,  0.1238,  0.0875,  0.0577],\n",
            "        [-0.0175, -0.0809, -0.0813,  ..., -0.0779,  0.0433,  0.0785],\n",
            "        [ 0.0524,  0.0875, -0.0782,  ..., -0.0900, -0.0624, -0.0605],\n",
            "        ...,\n",
            "        [-0.0883,  0.0119,  0.1020,  ..., -0.1190,  0.0357,  0.1166],\n",
            "        [-0.1098, -0.1125, -0.0331,  ..., -0.1054, -0.1398,  0.0620],\n",
            "        [-0.1266,  0.1102, -0.0699,  ...,  0.0914, -0.0876,  0.0411]],\n",
            "       device='cuda:0')\n",
            "encoder.layers.1.attn.w_k.weight: tensor([[ 0.0586, -0.1270, -0.0635,  ...,  0.1128, -0.0330, -0.0720],\n",
            "        [-0.0601,  0.0327,  0.1060,  ...,  0.0168, -0.0881, -0.0068],\n",
            "        [-0.0104, -0.0718,  0.0310,  ..., -0.0113, -0.0719,  0.0669],\n",
            "        ...,\n",
            "        [ 0.0416,  0.1120, -0.1094,  ...,  0.0298,  0.0301, -0.0369],\n",
            "        [-0.0155,  0.0711, -0.0477,  ..., -0.1023, -0.0672,  0.1461],\n",
            "        [ 0.0740,  0.0455,  0.0103,  ..., -0.1250,  0.1159, -0.0693]],\n",
            "       device='cuda:0')\n",
            "encoder.layers.1.attn.w_v.weight: tensor([[-0.0745, -0.0078,  0.0477,  ...,  0.0976,  0.1074, -0.1026],\n",
            "        [-0.0058, -0.0155,  0.0018,  ...,  0.0754,  0.0045,  0.0749],\n",
            "        [-0.0672,  0.0879, -0.1132,  ...,  0.0137, -0.0623, -0.0674],\n",
            "        ...,\n",
            "        [ 0.0487, -0.0807,  0.0236,  ..., -0.0085, -0.0892,  0.0908],\n",
            "        [ 0.0369,  0.0651,  0.1191,  ..., -0.0012, -0.0046, -0.1105],\n",
            "        [-0.0250,  0.0402, -0.1097,  ...,  0.0536, -0.0929, -0.0519]],\n",
            "       device='cuda:0')\n",
            "encoder.layers.1.attn.w_o.weight: tensor([[ 0.0778,  0.0471, -0.0824,  ..., -0.0793, -0.0337,  0.0317],\n",
            "        [ 0.0448,  0.0664,  0.0251,  ...,  0.0022,  0.0468,  0.0773],\n",
            "        [-0.1000, -0.1224, -0.1031,  ...,  0.0631,  0.0204, -0.0092],\n",
            "        ...,\n",
            "        [ 0.0559,  0.0568,  0.1074,  ..., -0.0699,  0.0720,  0.0039],\n",
            "        [-0.0219,  0.0076,  0.0485,  ..., -0.0339, -0.0178,  0.0292],\n",
            "        [ 0.0677,  0.0182, -0.0952,  ...,  0.1207,  0.1092,  0.0671]],\n",
            "       device='cuda:0')\n",
            "encoder.layers.1.ff.linear1.weight: tensor([[-0.0821, -0.0432, -0.0360,  ...,  0.0028,  0.0797, -0.0315],\n",
            "        [ 0.0026, -0.1065, -0.0640,  ...,  0.0642, -0.0395, -0.0351],\n",
            "        [ 0.0142, -0.0061,  0.0132,  ...,  0.0368, -0.0536,  0.0032],\n",
            "        ...,\n",
            "        [ 0.0825,  0.0059,  0.1295,  ...,  0.0676, -0.0922, -0.0586],\n",
            "        [-0.0287, -0.0559, -0.0651,  ...,  0.0391, -0.0192,  0.0668],\n",
            "        [-0.1187, -0.0706, -0.1042,  ..., -0.0023,  0.0724,  0.1007]],\n",
            "       device='cuda:0')\n",
            "encoder.layers.1.ff.linear1.bias: tensor([-0.0724,  0.0288, -0.0994,  0.0875, -0.0695, -0.0630,  0.0329,  0.0453,\n",
            "        -0.0779, -0.0610, -0.0744, -0.0273,  0.1076,  0.0033,  0.0630, -0.0404,\n",
            "        -0.0719, -0.0607, -0.0554,  0.1078, -0.0136, -0.0632, -0.1123,  0.0427,\n",
            "        -0.0605, -0.0762,  0.0985,  0.1177, -0.0200, -0.0582, -0.1223, -0.1219,\n",
            "         0.0556,  0.0976,  0.0666, -0.1046,  0.0338, -0.0177, -0.0163, -0.0271,\n",
            "         0.1091, -0.0718,  0.0027,  0.0983, -0.0156, -0.1229,  0.1204,  0.0767,\n",
            "        -0.0565, -0.0234,  0.0716,  0.0660,  0.0431,  0.0486, -0.0624,  0.0103,\n",
            "         0.1014,  0.0603,  0.0953, -0.0380,  0.0711,  0.0134,  0.1005,  0.0756,\n",
            "        -0.0415,  0.0072,  0.1249,  0.0153,  0.0039,  0.0458,  0.0046, -0.0172,\n",
            "         0.1022, -0.0626,  0.0015, -0.0087,  0.0944,  0.0105, -0.0483,  0.0096,\n",
            "        -0.0356, -0.0073, -0.0044, -0.0262,  0.0265, -0.0562, -0.0748, -0.1169,\n",
            "         0.0925,  0.0814,  0.0172, -0.0783,  0.1019, -0.0320, -0.0180,  0.0420,\n",
            "        -0.0398, -0.0633,  0.1039,  0.0547,  0.0843,  0.0481, -0.1191,  0.0181,\n",
            "         0.0470, -0.1063,  0.0771,  0.0428, -0.0331,  0.0250,  0.0740,  0.0546,\n",
            "        -0.0389,  0.0468,  0.0997,  0.0631, -0.0293, -0.0268, -0.0665, -0.0585,\n",
            "        -0.1008, -0.0585, -0.0061,  0.0987,  0.0052, -0.1141, -0.0835,  0.1197,\n",
            "         0.1146,  0.0683,  0.0086,  0.0399,  0.0438,  0.1169,  0.0416, -0.0327,\n",
            "        -0.0864, -0.1209, -0.1197,  0.0825,  0.0316,  0.0896,  0.0752,  0.0368,\n",
            "        -0.0984,  0.0721,  0.0701,  0.0427,  0.0339, -0.0362, -0.0015, -0.0421,\n",
            "         0.0662,  0.0290, -0.0691,  0.0233,  0.0777, -0.0252, -0.0348, -0.0262,\n",
            "         0.0013, -0.1172, -0.0166, -0.0317, -0.0453, -0.1067,  0.0742, -0.1056,\n",
            "         0.1218,  0.0014, -0.1060,  0.0185,  0.0889,  0.0800, -0.0184,  0.0869,\n",
            "         0.0250, -0.0342,  0.0861, -0.1271, -0.0076,  0.0184, -0.0193,  0.0485,\n",
            "         0.0381, -0.0910,  0.0007, -0.1079, -0.0226, -0.0108,  0.0095, -0.1194,\n",
            "         0.0772, -0.1091, -0.0860,  0.1170,  0.0438, -0.0471, -0.0102, -0.0627,\n",
            "        -0.0908,  0.0304, -0.0443, -0.0571, -0.0027, -0.0833, -0.1135, -0.0074,\n",
            "         0.0032, -0.0175, -0.0115,  0.0811,  0.1013,  0.0320,  0.0267,  0.0006,\n",
            "         0.0604, -0.0766, -0.0880,  0.0039, -0.0649, -0.1096, -0.0012, -0.0859,\n",
            "        -0.0450,  0.0568,  0.0551, -0.0440, -0.0072,  0.0298,  0.0635,  0.0092,\n",
            "        -0.0116,  0.0979, -0.1133, -0.1207, -0.0618, -0.0351, -0.0207,  0.0676,\n",
            "         0.0794,  0.0698,  0.0590,  0.0732,  0.0398, -0.0573,  0.1205,  0.0816,\n",
            "        -0.0068, -0.1092,  0.0823, -0.0105,  0.0291, -0.1038, -0.0500, -0.1066,\n",
            "         0.0157,  0.0161, -0.1207,  0.0436,  0.0432, -0.1154,  0.0202, -0.0587,\n",
            "         0.0487,  0.0787, -0.0442,  0.0683,  0.0344,  0.0860,  0.0942,  0.0368,\n",
            "        -0.0733, -0.0709, -0.0028, -0.0153,  0.0710, -0.0332, -0.0280,  0.0544,\n",
            "         0.0768,  0.0936,  0.0538, -0.1143, -0.0688, -0.1004,  0.0229, -0.0295,\n",
            "         0.0414, -0.0149,  0.0572, -0.0130,  0.0138,  0.0644,  0.0621, -0.0989,\n",
            "        -0.0071,  0.0639,  0.0382, -0.0432,  0.0536, -0.1248,  0.0268, -0.1190,\n",
            "        -0.0470,  0.1076, -0.0471,  0.0542, -0.0794, -0.1155,  0.0452,  0.0769,\n",
            "        -0.0311,  0.0430, -0.0670,  0.0811, -0.1211,  0.0120,  0.0605,  0.0399,\n",
            "        -0.0762,  0.1120,  0.0532,  0.0086,  0.0219,  0.0789,  0.0578, -0.0595,\n",
            "        -0.0976, -0.0898,  0.1073,  0.0971, -0.0404, -0.0993, -0.0035,  0.0162,\n",
            "         0.0758, -0.1256,  0.0308,  0.0078,  0.0924, -0.0371, -0.0228, -0.0511,\n",
            "        -0.0577,  0.0517, -0.0667,  0.1206, -0.0257, -0.1144,  0.0741, -0.0626,\n",
            "         0.0165,  0.0343, -0.0401, -0.0980, -0.0873, -0.0674, -0.0114, -0.0973,\n",
            "        -0.0857, -0.0005,  0.0079, -0.0087, -0.0804,  0.1056, -0.0525, -0.0159,\n",
            "        -0.1149, -0.1008, -0.0482, -0.1154, -0.1197,  0.0146,  0.0960, -0.0713,\n",
            "         0.0109, -0.0342, -0.0845,  0.0925, -0.0147, -0.0957,  0.0469,  0.0615,\n",
            "         0.1152, -0.1163, -0.0917, -0.0122, -0.1184,  0.0122,  0.0936,  0.0151,\n",
            "        -0.0643,  0.1064, -0.0470, -0.0826,  0.1000, -0.0995, -0.0378, -0.1178,\n",
            "        -0.0508, -0.1132,  0.1029,  0.0059, -0.1051, -0.1082, -0.1163,  0.0404,\n",
            "         0.0826, -0.0677, -0.0899,  0.0222, -0.0175,  0.1015, -0.0264,  0.0185,\n",
            "        -0.0733,  0.0167, -0.0891,  0.1052, -0.1230,  0.0092, -0.0126, -0.1192,\n",
            "        -0.1080, -0.1100, -0.1134, -0.0425, -0.0450, -0.0584, -0.0769,  0.0139,\n",
            "        -0.0665, -0.1173, -0.1071,  0.0108, -0.0912, -0.0694,  0.0451,  0.0880,\n",
            "        -0.0595,  0.0356, -0.0777, -0.0569,  0.0185,  0.0162,  0.0478, -0.0935,\n",
            "         0.0697, -0.0827,  0.0792, -0.0751, -0.0329, -0.0859, -0.0338, -0.0462,\n",
            "        -0.0111, -0.0796, -0.0980, -0.1065,  0.0489, -0.0724,  0.1092,  0.0421,\n",
            "         0.0413,  0.0428,  0.0307, -0.1000,  0.0742, -0.1225, -0.1305, -0.0480,\n",
            "         0.0749, -0.0605, -0.1203,  0.0568, -0.0796, -0.0654, -0.0411, -0.1200,\n",
            "         0.1083, -0.0227,  0.0972,  0.0877,  0.0052, -0.0186, -0.0968,  0.0134,\n",
            "         0.1104, -0.0233,  0.0493, -0.1016,  0.0093,  0.0553, -0.1236, -0.1112,\n",
            "        -0.1256, -0.0332, -0.0861,  0.0870, -0.0734,  0.1030, -0.1088, -0.0730,\n",
            "        -0.0156,  0.0858,  0.0567,  0.0579,  0.0715,  0.0911,  0.0612, -0.1092],\n",
            "       device='cuda:0')\n",
            "encoder.layers.1.ff.linear2.weight: tensor([[-0.0395,  0.0197,  0.0255,  ..., -0.0003, -0.0183, -0.0445],\n",
            "        [-0.0310, -0.0056, -0.0067,  ..., -0.0316, -0.0150,  0.0180],\n",
            "        [-0.0106, -0.0256, -0.0034,  ...,  0.0452,  0.0315,  0.0163],\n",
            "        ...,\n",
            "        [ 0.0125,  0.0386,  0.0186,  ..., -0.0412,  0.0083,  0.0184],\n",
            "        [ 0.0257, -0.0050, -0.0380,  ...,  0.0223,  0.0089, -0.0103],\n",
            "        [ 0.0294,  0.0381,  0.0357,  ..., -0.0361,  0.0393, -0.0302]],\n",
            "       device='cuda:0')\n",
            "encoder.layers.1.ff.linear2.bias: tensor([ 0.0398, -0.0184, -0.0091, -0.0136,  0.0264,  0.0042,  0.0048, -0.0122,\n",
            "        -0.0429,  0.0167, -0.0058,  0.0421, -0.0281,  0.0427,  0.0360,  0.0280,\n",
            "        -0.0377,  0.0017, -0.0262, -0.0450, -0.0288, -0.0179, -0.0316, -0.0018,\n",
            "         0.0409,  0.0300,  0.0154,  0.0078, -0.0005,  0.0406, -0.0176, -0.0298,\n",
            "        -0.0092, -0.0378,  0.0105, -0.0075, -0.0060,  0.0061, -0.0218,  0.0144,\n",
            "        -0.0013, -0.0112,  0.0275, -0.0420, -0.0109,  0.0225, -0.0043,  0.0180,\n",
            "        -0.0095,  0.0294,  0.0142, -0.0170,  0.0288,  0.0258,  0.0226,  0.0009,\n",
            "        -0.0424, -0.0420, -0.0107, -0.0041, -0.0146,  0.0248,  0.0472, -0.0120],\n",
            "       device='cuda:0')\n",
            "encoder.layers.1.norm1.weight: tensor([0.9917, 0.9940, 1.0026, 0.9968, 0.9984, 1.0002, 0.9948, 0.9924, 0.9939,\n",
            "        1.0063, 1.0024, 1.0129, 0.9987, 1.0010, 1.0088, 1.0081, 1.0125, 0.9954,\n",
            "        1.0145, 1.0031, 1.0084, 1.0068, 0.9963, 1.0011, 0.9972, 1.0007, 0.9953,\n",
            "        1.0191, 0.9985, 0.9973, 0.9949, 1.0060, 1.0048, 1.0009, 0.9983, 0.9906,\n",
            "        1.0043, 1.0036, 1.0092, 0.9990, 1.0017, 0.9930, 0.9980, 0.9962, 1.0031,\n",
            "        1.0026, 0.9910, 0.9997, 0.9977, 0.9999, 1.0007, 0.9994, 1.0019, 1.0087,\n",
            "        1.0022, 1.0071, 0.9892, 1.0041, 1.0053, 1.0037, 1.0025, 0.9999, 1.0015,\n",
            "        1.0079], device='cuda:0')\n",
            "encoder.layers.1.norm1.bias: tensor([ 1.2185e-03,  1.8195e-03, -6.5859e-05, -5.3360e-04, -3.1344e-04,\n",
            "         5.0485e-04,  6.3243e-04,  1.9710e-03, -1.2815e-03, -4.7707e-04,\n",
            "        -1.8457e-04,  1.0203e-04,  3.8997e-04,  5.3846e-04, -1.2556e-03,\n",
            "         1.2535e-04,  2.3845e-03, -3.1474e-03,  6.3860e-04, -3.8757e-04,\n",
            "         2.3966e-04,  1.1613e-04,  2.5073e-03, -1.6873e-03,  1.9482e-03,\n",
            "        -1.7612e-03,  1.3358e-04, -1.4921e-03,  2.0940e-03, -3.8132e-03,\n",
            "         2.4372e-03, -1.9966e-04, -2.0459e-03, -2.4375e-03,  2.5426e-03,\n",
            "        -1.5140e-03,  2.5173e-03, -2.5448e-03, -5.6314e-05, -1.9872e-03,\n",
            "         2.3639e-03, -2.6970e-03, -5.1668e-04, -2.3397e-03,  1.0559e-03,\n",
            "        -1.4419e-03,  2.7037e-03, -1.8743e-03,  1.2810e-03, -1.2121e-03,\n",
            "         1.7299e-03, -4.5334e-04, -8.5873e-04, -3.7047e-04,  3.5503e-03,\n",
            "        -3.5510e-04,  1.1281e-03, -1.2570e-03,  8.5528e-04, -1.8605e-04,\n",
            "         1.1444e-03, -2.1300e-03,  6.0681e-03, -7.6077e-04], device='cuda:0')\n",
            "encoder.layers.1.norm2.weight: tensor([0.9973, 0.9956, 1.0026, 1.0004, 1.0019, 1.0022, 0.9972, 0.9942, 0.9983,\n",
            "        1.0054, 1.0034, 1.0141, 0.9974, 0.9997, 1.0086, 1.0070, 1.0089, 0.9988,\n",
            "        1.0146, 1.0089, 1.0045, 1.0092, 0.9949, 1.0061, 0.9996, 1.0033, 0.9973,\n",
            "        1.0152, 0.9996, 1.0006, 0.9995, 1.0059, 1.0058, 1.0021, 1.0025, 1.0008,\n",
            "        0.9986, 0.9998, 1.0153, 0.9994, 0.9992, 0.9949, 1.0028, 0.9985, 1.0059,\n",
            "        1.0042, 0.9956, 0.9997, 0.9985, 0.9998, 1.0057, 0.9939, 1.0071, 1.0086,\n",
            "        1.0077, 1.0033, 0.9918, 1.0048, 1.0067, 1.0049, 1.0016, 0.9999, 1.0035,\n",
            "        1.0103], device='cuda:0')\n",
            "encoder.layers.1.norm2.bias: tensor([ 1.8255e-03,  7.4154e-04,  5.0249e-04, -1.2344e-03, -1.0255e-03,\n",
            "        -3.9780e-04,  1.2364e-03,  1.2053e-03, -1.5651e-03, -9.7765e-04,\n",
            "         8.0187e-04, -4.1867e-04,  3.5334e-04, -3.0439e-04, -4.4479e-05,\n",
            "         1.3141e-04,  1.3162e-03, -1.4214e-03,  8.7931e-04,  4.5351e-04,\n",
            "        -9.3406e-05, -3.3728e-04,  2.7910e-03, -5.7838e-04, -6.7821e-04,\n",
            "         2.0718e-05, -4.9120e-04, -8.6251e-04,  1.6120e-03, -2.0554e-03,\n",
            "         8.8960e-04, -3.9918e-04, -3.7855e-03, -2.7087e-03,  2.0584e-03,\n",
            "        -7.6026e-04,  1.2983e-03, -1.5256e-03, -1.7166e-04, -6.4699e-04,\n",
            "         1.3288e-03, -1.4832e-03, -7.4497e-04, -2.6208e-03,  4.4436e-04,\n",
            "         3.6830e-04,  5.3378e-04, -1.8582e-04, -4.4237e-05, -1.1609e-03,\n",
            "        -7.1312e-04, -1.0734e-03,  1.7460e-04, -7.9169e-05,  8.3025e-04,\n",
            "        -7.1340e-04, -1.4602e-03, -1.6917e-03,  9.8881e-04,  4.4246e-04,\n",
            "        -8.8153e-04, -5.7065e-04,  3.2988e-03, -9.3332e-04], device='cuda:0')\n",
            "encoder.layers.2.attn.w_q.weight: tensor([[-0.1001,  0.0032, -0.0195,  ..., -0.0543, -0.0167,  0.0642],\n",
            "        [ 0.0605,  0.0006,  0.0516,  ..., -0.0752, -0.0190,  0.0944],\n",
            "        [ 0.0371, -0.0808,  0.0273,  ...,  0.0088, -0.0803, -0.1448],\n",
            "        ...,\n",
            "        [-0.0208,  0.1052,  0.1136,  ...,  0.0334,  0.0953, -0.0068],\n",
            "        [-0.0894,  0.0913, -0.0999,  ..., -0.0716, -0.0147, -0.0538],\n",
            "        [ 0.0832,  0.1022,  0.0611,  ..., -0.1107,  0.0601, -0.0604]],\n",
            "       device='cuda:0')\n",
            "encoder.layers.2.attn.w_k.weight: tensor([[ 0.0275, -0.0645,  0.1176,  ...,  0.0155,  0.1343,  0.0693],\n",
            "        [-0.0315, -0.0868, -0.0035,  ..., -0.0983, -0.0488,  0.1044],\n",
            "        [ 0.1355,  0.0982, -0.0875,  ...,  0.0918, -0.0358, -0.0993],\n",
            "        ...,\n",
            "        [-0.1049,  0.0568, -0.1012,  ...,  0.0726,  0.0486,  0.0677],\n",
            "        [ 0.0910,  0.0073, -0.0569,  ...,  0.0058, -0.0668,  0.0345],\n",
            "        [-0.0212,  0.0943,  0.0199,  ..., -0.1207, -0.0709, -0.0095]],\n",
            "       device='cuda:0')\n",
            "encoder.layers.2.attn.w_v.weight: tensor([[ 0.0147, -0.0718,  0.0558,  ...,  0.0437,  0.0049, -0.0502],\n",
            "        [ 0.0160, -0.0227,  0.1207,  ..., -0.0020,  0.0718,  0.0830],\n",
            "        [ 0.1094, -0.0663,  0.0911,  ..., -0.0027, -0.0468, -0.0718],\n",
            "        ...,\n",
            "        [-0.0669,  0.1180,  0.0939,  ...,  0.0746,  0.0519, -0.0900],\n",
            "        [ 0.0779,  0.0707, -0.0890,  ..., -0.0880,  0.0853, -0.1039],\n",
            "        [-0.0034,  0.0043, -0.0609,  ...,  0.0602,  0.0295,  0.0347]],\n",
            "       device='cuda:0')\n",
            "encoder.layers.2.attn.w_o.weight: tensor([[ 0.0942,  0.0754,  0.0359,  ..., -0.0452, -0.0062, -0.0832],\n",
            "        [-0.1183,  0.0256, -0.0620,  ...,  0.0290, -0.0774, -0.1175],\n",
            "        [ 0.0758,  0.0339, -0.1185,  ...,  0.0980,  0.0983,  0.0463],\n",
            "        ...,\n",
            "        [-0.0706, -0.0921,  0.1166,  ..., -0.1063,  0.0173,  0.0317],\n",
            "        [-0.0903, -0.0587,  0.0150,  ..., -0.0894, -0.0420,  0.1250],\n",
            "        [ 0.0122,  0.1046, -0.0227,  ..., -0.0235,  0.0417, -0.0877]],\n",
            "       device='cuda:0')\n",
            "encoder.layers.2.ff.linear1.weight: tensor([[ 0.1331,  0.1214,  0.0862,  ...,  0.0333, -0.0579, -0.0525],\n",
            "        [ 0.0988, -0.1002, -0.0668,  ..., -0.0494,  0.0015, -0.1062],\n",
            "        [ 0.1136,  0.0915,  0.0190,  ...,  0.0020, -0.0417, -0.0098],\n",
            "        ...,\n",
            "        [ 0.1170, -0.0441,  0.0637,  ..., -0.0464,  0.0686, -0.0112],\n",
            "        [ 0.0025,  0.0593, -0.0423,  ..., -0.0699, -0.1228,  0.0323],\n",
            "        [-0.1169, -0.0866,  0.0209,  ...,  0.0443,  0.1151,  0.1048]],\n",
            "       device='cuda:0')\n",
            "encoder.layers.2.ff.linear1.bias: tensor([ 0.0429, -0.0370,  0.0361,  0.0448,  0.0965, -0.0367,  0.0350,  0.1064,\n",
            "         0.1116,  0.1194, -0.0485, -0.1130, -0.0242,  0.1110,  0.0220,  0.0844,\n",
            "        -0.0125,  0.1041, -0.1101,  0.0604, -0.1168, -0.1064,  0.0674,  0.0227,\n",
            "         0.0927, -0.0023,  0.1008, -0.0735, -0.0990,  0.0608,  0.0168, -0.0723,\n",
            "        -0.1115, -0.1096,  0.0509, -0.0665,  0.1097,  0.0740,  0.1031, -0.0862,\n",
            "         0.0928, -0.1093,  0.0574,  0.0853, -0.1166, -0.0113, -0.0718,  0.0146,\n",
            "         0.0533,  0.0800, -0.0627, -0.1119,  0.0019, -0.0313,  0.0876, -0.0585,\n",
            "        -0.0319,  0.0213, -0.0910, -0.1238, -0.0719, -0.0968,  0.1196,  0.0032,\n",
            "        -0.0444, -0.0797,  0.0379,  0.0795, -0.0838, -0.0508,  0.0740, -0.0173,\n",
            "        -0.0645,  0.0995, -0.0576,  0.0646,  0.0153,  0.1039,  0.0252, -0.0852,\n",
            "        -0.0745, -0.1178, -0.0088, -0.0098,  0.0738, -0.0138,  0.0813,  0.0240,\n",
            "        -0.0740, -0.1041,  0.0897,  0.0590, -0.0892,  0.0629, -0.1029, -0.1168,\n",
            "        -0.1144,  0.0970, -0.0358, -0.0808, -0.0454,  0.0396, -0.0003,  0.0426,\n",
            "         0.0026,  0.0016, -0.0522, -0.0326, -0.0972,  0.1067, -0.0330, -0.0438,\n",
            "         0.1119, -0.1226, -0.1019,  0.0424,  0.0048,  0.0477, -0.0265, -0.0053,\n",
            "        -0.0876,  0.0719, -0.0355,  0.0529, -0.1079, -0.1089, -0.1123, -0.1211,\n",
            "        -0.1086, -0.1300, -0.1191,  0.0068, -0.0649,  0.0462, -0.0111, -0.0227,\n",
            "         0.0158,  0.0370,  0.0871,  0.0259, -0.0829,  0.0234, -0.0826, -0.0790,\n",
            "        -0.0392,  0.0533,  0.0166,  0.0167, -0.0184, -0.0786,  0.0444,  0.0170,\n",
            "         0.1161,  0.0872, -0.0725, -0.1195, -0.0245,  0.0610,  0.1128, -0.0291,\n",
            "         0.0993, -0.0349,  0.0291,  0.0296, -0.0128, -0.0849, -0.0731,  0.0613,\n",
            "        -0.0350, -0.0423,  0.0991, -0.1093, -0.1259, -0.0405,  0.0015, -0.0194,\n",
            "         0.1191, -0.1264,  0.0063, -0.0316, -0.0283,  0.1017,  0.0254,  0.0984,\n",
            "        -0.0750,  0.0839,  0.1094,  0.0659, -0.1115, -0.0911,  0.0208,  0.1012,\n",
            "         0.0005,  0.0277,  0.0022, -0.0890,  0.1181,  0.1049, -0.0987, -0.0054,\n",
            "        -0.1220,  0.1225, -0.0891, -0.0113, -0.0404, -0.1153,  0.0634,  0.1140,\n",
            "         0.0137, -0.0204, -0.1223, -0.0881, -0.0529,  0.0871,  0.1143,  0.0889,\n",
            "        -0.1115,  0.0414,  0.0070, -0.0373,  0.0444, -0.0603,  0.1108,  0.1052,\n",
            "        -0.0054,  0.1071, -0.0576, -0.0239,  0.0734, -0.0499,  0.0679,  0.0899,\n",
            "        -0.0008,  0.0946,  0.0408, -0.0289, -0.0575, -0.0227,  0.0429, -0.0995,\n",
            "         0.0775, -0.0774, -0.1065, -0.0759, -0.0244,  0.0479,  0.0670, -0.0235,\n",
            "         0.0459, -0.0129,  0.0981,  0.0464, -0.1141,  0.0992, -0.1060, -0.0133,\n",
            "         0.0341, -0.1116,  0.0039, -0.0434, -0.0367, -0.0051,  0.0548,  0.0508,\n",
            "         0.0355, -0.0441,  0.0526, -0.0229,  0.0807, -0.0655,  0.0702,  0.0204,\n",
            "         0.0646,  0.0470,  0.0990, -0.0988, -0.0397,  0.0800, -0.0729, -0.0443,\n",
            "        -0.0240, -0.0726,  0.0556, -0.0642, -0.0723, -0.0782, -0.1282, -0.0236,\n",
            "        -0.0718, -0.0311, -0.0095, -0.0365, -0.0812, -0.0535,  0.0414, -0.0261,\n",
            "         0.0693,  0.0610,  0.0339,  0.0497,  0.0464, -0.0232, -0.1072, -0.1000,\n",
            "        -0.0360, -0.0941,  0.0618, -0.0690, -0.1131, -0.0099, -0.0916, -0.0083,\n",
            "         0.0138,  0.0741,  0.0353, -0.0883,  0.1077, -0.0137,  0.1090,  0.0344,\n",
            "        -0.0730,  0.0057, -0.0317,  0.0505, -0.0080, -0.0171,  0.0605,  0.0990,\n",
            "        -0.1115, -0.1262, -0.0925, -0.0270, -0.0708, -0.0870,  0.0426,  0.0081,\n",
            "         0.1011, -0.0686, -0.1238,  0.1017, -0.0779,  0.0496, -0.0137, -0.0864,\n",
            "         0.1127,  0.0544, -0.0311, -0.0222, -0.0175,  0.0944,  0.0608,  0.0151,\n",
            "         0.1053,  0.0588,  0.0339, -0.0678, -0.0128, -0.1017, -0.1222, -0.1022,\n",
            "         0.0567,  0.0442, -0.0776, -0.0736, -0.0828, -0.0602,  0.0388, -0.1208,\n",
            "         0.0481, -0.1172,  0.0997, -0.0576,  0.0136,  0.0975,  0.0069,  0.0537,\n",
            "        -0.0223, -0.0809,  0.0018,  0.0109,  0.0999,  0.0561, -0.0088, -0.0358,\n",
            "         0.0282,  0.0076, -0.0478, -0.1015, -0.0859, -0.0067,  0.0163, -0.0819,\n",
            "        -0.1048,  0.0679,  0.0557,  0.0205, -0.1076,  0.0449, -0.0892, -0.0744,\n",
            "         0.0020,  0.1045,  0.1155, -0.0936, -0.0439,  0.1193, -0.0536,  0.0250,\n",
            "        -0.0011,  0.0727, -0.0514,  0.0096,  0.0692,  0.0232, -0.0265,  0.1062,\n",
            "        -0.0679,  0.1002,  0.0096,  0.0957,  0.0941,  0.0735, -0.1067, -0.0849,\n",
            "        -0.0671,  0.0815,  0.0386,  0.0319, -0.0271, -0.0681,  0.0369,  0.0502,\n",
            "         0.0535,  0.0370,  0.0284, -0.1171, -0.0756, -0.0222, -0.0877, -0.0378,\n",
            "         0.0210, -0.0797, -0.0541, -0.0350, -0.0885,  0.1223, -0.0847, -0.1057,\n",
            "         0.1162,  0.1151,  0.0212,  0.1029, -0.0416,  0.0459, -0.1222, -0.1102,\n",
            "        -0.0194, -0.0259, -0.1043,  0.0678,  0.1195, -0.0515,  0.0929, -0.0266,\n",
            "        -0.0216,  0.0223,  0.1166, -0.0181, -0.0412,  0.0119,  0.0254,  0.1073,\n",
            "         0.0313, -0.0993,  0.0065,  0.0230, -0.0127,  0.1181, -0.0439, -0.1140,\n",
            "        -0.0108,  0.0216, -0.1085, -0.0730,  0.1015, -0.0722,  0.1157, -0.0729,\n",
            "         0.0860,  0.0994,  0.0067,  0.0396, -0.0602, -0.1174,  0.0875,  0.0637,\n",
            "         0.0063, -0.0720,  0.1100,  0.0147, -0.1123, -0.0497, -0.0310,  0.1119,\n",
            "        -0.0494, -0.1126,  0.0774, -0.0100,  0.0399,  0.0370, -0.0396, -0.1094],\n",
            "       device='cuda:0')\n",
            "encoder.layers.2.ff.linear2.weight: tensor([[-0.0248, -0.0311, -0.0086,  ..., -0.0260,  0.0290,  0.0394],\n",
            "        [-0.0245,  0.0226, -0.0004,  ..., -0.0303,  0.0214, -0.0065],\n",
            "        [ 0.0214, -0.0010, -0.0202,  ..., -0.0053,  0.0260,  0.0216],\n",
            "        ...,\n",
            "        [-0.0509,  0.0444, -0.0109,  ...,  0.0091, -0.0418, -0.0090],\n",
            "        [ 0.0078, -0.0348, -0.0002,  ..., -0.0265, -0.0329,  0.0344],\n",
            "        [ 0.0280,  0.0041, -0.0435,  ...,  0.0417,  0.0268,  0.0042]],\n",
            "       device='cuda:0')\n",
            "encoder.layers.2.ff.linear2.bias: tensor([ 0.0339,  0.0050, -0.0413,  0.0070,  0.0308, -0.0158,  0.0219,  0.0201,\n",
            "        -0.0170, -0.0352, -0.0021, -0.0254,  0.0136,  0.0362,  0.0318,  0.0242,\n",
            "         0.0281, -0.0104, -0.0033, -0.0240, -0.0153,  0.0163,  0.0437, -0.0151,\n",
            "         0.0333, -0.0435,  0.0149,  0.0110,  0.0277, -0.0201, -0.0008,  0.0422,\n",
            "         0.0357, -0.0198, -0.0410, -0.0024,  0.0075,  0.0428, -0.0033,  0.0418,\n",
            "        -0.0120, -0.0123, -0.0415, -0.0290,  0.0295,  0.0003,  0.0188,  0.0135,\n",
            "         0.0354, -0.0405,  0.0356,  0.0149,  0.0172,  0.0071, -0.0290,  0.0048,\n",
            "         0.0173,  0.0136,  0.0114, -0.0017, -0.0284, -0.0201,  0.0063,  0.0162],\n",
            "       device='cuda:0')\n",
            "encoder.layers.2.norm1.weight: tensor([0.9918, 0.9965, 0.9993, 0.9990, 0.9987, 1.0055, 0.9881, 0.9926, 0.9999,\n",
            "        1.0024, 1.0027, 1.0106, 0.9957, 0.9985, 1.0098, 1.0061, 1.0091, 0.9964,\n",
            "        1.0111, 1.0056, 1.0031, 1.0050, 0.9999, 1.0024, 0.9940, 1.0033, 0.9985,\n",
            "        1.0134, 0.9982, 1.0003, 0.9994, 1.0073, 1.0044, 1.0036, 1.0014, 0.9907,\n",
            "        0.9969, 1.0003, 1.0121, 0.9994, 0.9972, 0.9947, 1.0015, 0.9965, 1.0055,\n",
            "        0.9998, 0.9955, 0.9995, 0.9985, 1.0013, 1.0006, 0.9930, 1.0034, 1.0052,\n",
            "        1.0025, 1.0057, 0.9944, 1.0041, 1.0055, 1.0044, 1.0039, 0.9993, 1.0049,\n",
            "        1.0078], device='cuda:0')\n",
            "encoder.layers.2.norm1.bias: tensor([ 2.5457e-03,  1.2426e-03,  7.5522e-04, -2.8037e-04, -6.8676e-04,\n",
            "         7.0203e-04, -4.3879e-04,  1.2135e-03, -2.2055e-03,  8.0470e-04,\n",
            "         2.8021e-04,  2.7361e-04,  6.2677e-04, -9.5609e-04, -1.3536e-04,\n",
            "        -5.9269e-04,  9.1897e-04, -1.1432e-03,  1.6359e-03,  1.1915e-05,\n",
            "        -7.1800e-07, -3.2488e-04,  2.1511e-03,  1.2423e-04, -1.0864e-04,\n",
            "        -4.0631e-04, -6.3958e-04, -8.1242e-04,  1.0085e-03, -2.0504e-03,\n",
            "         7.3807e-04,  5.8342e-05, -1.5737e-03, -8.9898e-04,  1.8393e-03,\n",
            "         2.1106e-04, -1.2167e-03, -2.3936e-03,  2.2236e-04,  1.5020e-04,\n",
            "         1.6562e-03, -1.3286e-03, -5.4880e-04, -9.7696e-04,  8.3311e-04,\n",
            "        -2.0912e-03,  2.0175e-03, -4.0342e-04,  4.1829e-04, -1.6277e-03,\n",
            "        -1.5913e-03, -2.6135e-03, -6.6399e-04, -1.5707e-03, -3.1133e-04,\n",
            "        -2.7192e-03,  6.2006e-04, -1.8350e-03,  5.2359e-04,  6.1191e-04,\n",
            "        -1.4045e-04, -1.0422e-03,  4.0556e-03, -8.8536e-04], device='cuda:0')\n",
            "encoder.layers.2.norm2.weight: tensor([0.9998, 0.9996, 0.9996, 0.9988, 0.9990, 1.0078, 0.9919, 0.9934, 1.0025,\n",
            "        0.9993, 1.0023, 1.0110, 0.9988, 1.0007, 1.0088, 1.0086, 1.0115, 0.9977,\n",
            "        1.0086, 1.0104, 1.0001, 1.0055, 0.9959, 1.0002, 0.9938, 1.0034, 1.0029,\n",
            "        1.0141, 1.0060, 1.0089, 1.0008, 1.0076, 1.0039, 1.0018, 1.0005, 0.9946,\n",
            "        0.9922, 1.0027, 1.0032, 1.0057, 0.9951, 1.0002, 1.0007, 0.9973, 1.0047,\n",
            "        1.0015, 0.9907, 1.0004, 1.0006, 0.9991, 1.0045, 0.9893, 1.0002, 1.0064,\n",
            "        1.0051, 1.0054, 1.0004, 1.0043, 1.0052, 1.0049, 1.0157, 1.0033, 1.0066,\n",
            "        1.0083], device='cuda:0')\n",
            "encoder.layers.2.norm2.bias: tensor([ 1.7587e-03,  1.7341e-03,  2.4632e-03,  2.0847e-04, -3.3796e-04,\n",
            "         2.6077e-03,  1.4189e-03,  1.3216e-03, -1.5183e-03,  4.5701e-04,\n",
            "         8.1419e-04,  8.3327e-04, -6.2961e-04, -2.1531e-05,  6.7024e-05,\n",
            "        -3.3737e-04,  1.4917e-04, -4.5927e-04,  8.5941e-04, -5.4366e-04,\n",
            "         4.0109e-04,  2.9717e-04,  1.5963e-03,  7.7158e-04,  6.8945e-05,\n",
            "        -1.5697e-04, -3.1494e-05, -2.0451e-03, -5.9283e-04, -5.2426e-04,\n",
            "         9.8467e-04, -3.2943e-04,  2.1054e-04, -4.6516e-04,  7.1471e-04,\n",
            "         3.6714e-04, -1.0633e-03, -2.4453e-03,  1.1251e-03,  4.4530e-04,\n",
            "         9.9720e-04, -9.3181e-04,  3.1539e-04, -2.7021e-04,  9.5454e-05,\n",
            "        -7.8161e-04,  1.6305e-03,  1.0522e-04,  1.2791e-03, -9.1725e-04,\n",
            "        -3.4324e-05, -1.2439e-03,  2.3472e-04,  4.2408e-04,  8.2794e-04,\n",
            "        -1.5061e-03,  1.3952e-03,  9.5414e-04,  4.2575e-04,  1.1593e-03,\n",
            "         2.9623e-04, -7.4546e-05,  5.0448e-04, -1.0723e-03], device='cuda:0')\n",
            "encoder.layers.3.attn.w_q.weight: tensor([[ 0.0222,  0.1156,  0.1072,  ...,  0.1030, -0.1117,  0.0192],\n",
            "        [-0.0388, -0.0166,  0.0852,  ..., -0.0123, -0.0760, -0.1000],\n",
            "        [-0.0183, -0.0568, -0.1085,  ..., -0.0228, -0.0177,  0.0451],\n",
            "        ...,\n",
            "        [-0.0674,  0.1054, -0.0498,  ...,  0.0122, -0.0760,  0.0354],\n",
            "        [ 0.1385,  0.0352, -0.0493,  ...,  0.1040, -0.0549,  0.0188],\n",
            "        [ 0.1012, -0.1209,  0.1139,  ..., -0.0096,  0.1111,  0.1155]],\n",
            "       device='cuda:0')\n",
            "encoder.layers.3.attn.w_k.weight: tensor([[-0.0375, -0.0144, -0.0624,  ..., -0.1320, -0.0131, -0.0177],\n",
            "        [-0.0566,  0.0895,  0.0775,  ...,  0.0161,  0.0389,  0.0183],\n",
            "        [ 0.0929, -0.0792, -0.1039,  ..., -0.0722, -0.0032, -0.0855],\n",
            "        ...,\n",
            "        [ 0.1129, -0.0196, -0.0648,  ...,  0.0141,  0.1301, -0.0509],\n",
            "        [ 0.0860, -0.0461,  0.0460,  ...,  0.0571,  0.0413,  0.0651],\n",
            "        [-0.0186, -0.0314,  0.1013,  ..., -0.0181, -0.0020, -0.0931]],\n",
            "       device='cuda:0')\n",
            "encoder.layers.3.attn.w_v.weight: tensor([[ 0.0080, -0.0005,  0.0873,  ...,  0.0337, -0.0542, -0.0442],\n",
            "        [ 0.0736, -0.0796,  0.0109,  ..., -0.0129, -0.0688, -0.0123],\n",
            "        [ 0.0020, -0.0330,  0.0375,  ..., -0.0386,  0.0451,  0.0635],\n",
            "        ...,\n",
            "        [-0.0057,  0.0275, -0.0897,  ..., -0.0335,  0.0346,  0.0589],\n",
            "        [-0.0434,  0.0097,  0.0624,  ..., -0.0240, -0.0574,  0.0326],\n",
            "        [ 0.0027, -0.1174,  0.0231,  ...,  0.0507,  0.0239, -0.1225]],\n",
            "       device='cuda:0')\n",
            "encoder.layers.3.attn.w_o.weight: tensor([[ 0.0297,  0.1195,  0.0576,  ..., -0.0722, -0.0735, -0.0795],\n",
            "        [ 0.1030, -0.0076, -0.0602,  ...,  0.1046,  0.0259, -0.0479],\n",
            "        [ 0.0729,  0.0895, -0.1096,  ...,  0.0650, -0.0167, -0.0507],\n",
            "        ...,\n",
            "        [-0.0218, -0.0148, -0.0066,  ...,  0.0069, -0.0111,  0.0480],\n",
            "        [-0.0799, -0.0737,  0.0632,  ...,  0.0025,  0.0807, -0.0374],\n",
            "        [-0.1014,  0.0976, -0.0237,  ...,  0.0979, -0.0689,  0.1157]],\n",
            "       device='cuda:0')\n",
            "encoder.layers.3.ff.linear1.weight: tensor([[ 0.0900, -0.0729, -0.0241,  ...,  0.0318,  0.0893, -0.1039],\n",
            "        [-0.0414,  0.0415,  0.0862,  ..., -0.0477, -0.0418,  0.1240],\n",
            "        [-0.1065, -0.0736, -0.0042,  ..., -0.1151, -0.0729, -0.0749],\n",
            "        ...,\n",
            "        [-0.0694, -0.0274, -0.0119,  ..., -0.1016, -0.1036, -0.1030],\n",
            "        [-0.0774, -0.1024,  0.0663,  ..., -0.0169,  0.0373, -0.1008],\n",
            "        [-0.0545,  0.0759, -0.0719,  ..., -0.0210, -0.1289, -0.0367]],\n",
            "       device='cuda:0')\n",
            "encoder.layers.3.ff.linear1.bias: tensor([-7.4202e-03,  9.6562e-02, -2.9035e-02,  1.0608e-01, -5.4398e-02,\n",
            "        -3.8564e-02, -2.8425e-02, -3.6006e-03,  5.6022e-02,  3.8914e-02,\n",
            "        -1.0298e-01,  9.6828e-02,  1.0253e-01,  1.6583e-02,  6.1826e-02,\n",
            "         1.2765e-02,  8.5862e-02, -1.7950e-02,  1.4357e-02, -1.0512e-01,\n",
            "         4.8897e-02,  3.1685e-03,  7.8384e-02, -8.1216e-02, -2.3836e-02,\n",
            "         3.5378e-02, -4.5273e-03, -5.5916e-02,  1.1093e-01,  8.1821e-02,\n",
            "        -1.2946e-01, -1.0419e-01, -1.1797e-01, -3.5869e-02, -7.3798e-02,\n",
            "         4.5650e-03, -5.4430e-03, -7.0909e-02,  1.1675e-01, -7.0101e-02,\n",
            "         4.1970e-02, -4.6633e-02,  3.0407e-02,  9.8317e-02, -1.2077e-01,\n",
            "        -3.4807e-02, -5.9503e-02,  4.5403e-02, -3.1773e-03, -7.7280e-02,\n",
            "        -9.7136e-03, -5.7475e-02, -8.9300e-02, -1.1829e-01,  4.2676e-02,\n",
            "        -1.1440e-01,  9.1048e-02, -3.0384e-02,  1.0373e-01, -1.1712e-01,\n",
            "         6.8459e-02, -1.1789e-01, -8.6674e-02, -5.3447e-02, -1.0722e-01,\n",
            "        -1.0979e-01,  1.0716e-01, -1.0414e-01,  7.2285e-02,  1.1818e-01,\n",
            "         6.6908e-02,  1.0186e-02,  5.9690e-02,  2.2094e-02,  1.8239e-02,\n",
            "         7.1337e-02,  1.1369e-01,  7.0158e-02,  3.4758e-02, -8.6219e-02,\n",
            "        -5.2749e-02,  6.9701e-02, -1.4144e-02, -1.0096e-01, -9.8928e-02,\n",
            "         8.3372e-02,  5.0170e-02, -3.0535e-02, -5.2610e-02, -3.5686e-02,\n",
            "         1.0872e-01, -3.2294e-02,  2.8474e-02, -9.7095e-03,  7.6276e-02,\n",
            "         1.0859e-01,  4.5791e-02,  6.6332e-02, -8.3016e-02, -6.3356e-02,\n",
            "         4.9777e-03,  3.5955e-02,  1.8011e-02, -1.1193e-01,  7.2258e-02,\n",
            "         9.8084e-02, -4.8198e-02,  5.4161e-02,  9.5406e-02, -1.1783e-01,\n",
            "         1.0469e-01, -2.2199e-02, -9.1773e-02, -4.3915e-02,  8.2805e-02,\n",
            "        -6.4702e-02,  5.1684e-02, -8.0683e-02, -6.0678e-02, -8.8546e-03,\n",
            "        -1.9509e-02, -1.1446e-01, -6.3046e-02, -7.1860e-02, -6.7484e-02,\n",
            "        -1.1738e-02, -2.8567e-02,  1.1106e-01,  1.0622e-01,  8.5578e-02,\n",
            "         5.2223e-02, -4.2983e-02, -2.9957e-02,  7.9327e-02, -1.4591e-02,\n",
            "         5.2560e-03, -1.2087e-02, -5.3042e-02, -9.1551e-02, -1.0986e-01,\n",
            "        -5.1003e-02,  7.8103e-02, -8.1427e-03,  9.1317e-02,  3.0253e-02,\n",
            "        -1.0707e-01,  2.3827e-02, -7.3586e-02,  6.0042e-02,  1.9229e-03,\n",
            "        -9.0414e-02,  2.7512e-03,  7.2225e-02, -4.4660e-02,  3.4420e-02,\n",
            "         9.7560e-02, -6.3698e-03,  5.4411e-02, -8.2369e-02,  5.9845e-02,\n",
            "         8.8017e-02, -1.2544e-01,  4.7579e-02,  2.5973e-02,  3.0675e-03,\n",
            "        -5.0720e-02, -4.2879e-02, -1.1341e-01, -9.4437e-02, -6.3211e-02,\n",
            "        -2.9834e-02, -1.9255e-02,  9.1242e-03, -8.0947e-02,  9.6509e-02,\n",
            "         6.5278e-03,  6.7812e-02, -8.2457e-02, -6.8019e-02,  4.8962e-02,\n",
            "         5.7044e-02, -6.4015e-02,  5.2423e-02, -4.0491e-02,  3.2870e-02,\n",
            "         1.0348e-01, -7.9008e-02,  8.4938e-02, -1.2476e-01, -1.1040e-01,\n",
            "        -1.1297e-01, -5.3666e-02, -1.6986e-02,  7.5609e-02, -2.8418e-02,\n",
            "         5.5920e-02,  9.9812e-02,  6.9394e-02, -1.0771e-01,  3.0553e-02,\n",
            "        -9.2132e-02, -7.8807e-02,  9.1030e-02,  1.1894e-01, -1.1879e-01,\n",
            "         1.1685e-01, -1.0271e-01,  1.1909e-01,  8.4008e-02, -1.2607e-02,\n",
            "         8.6158e-02, -1.0083e-01,  2.3016e-02, -1.9743e-02,  5.3259e-02,\n",
            "         5.1993e-02,  1.0364e-01, -9.2206e-02,  3.4172e-03,  1.0249e-01,\n",
            "        -8.3716e-02,  1.0274e-02,  4.6235e-02,  3.1916e-02,  5.1948e-02,\n",
            "         9.0765e-02,  9.4896e-02,  3.4908e-04,  7.2647e-02, -3.9161e-02,\n",
            "        -1.0906e-01, -7.6500e-02, -8.9027e-02, -1.1003e-01, -3.8254e-02,\n",
            "        -6.3467e-02,  1.1396e-01, -1.1147e-02, -6.3382e-02,  8.8946e-02,\n",
            "         3.3545e-02,  1.5185e-02, -2.9401e-02,  2.8714e-02, -4.9012e-02,\n",
            "        -9.8468e-02, -5.2969e-02, -1.3930e-03, -2.6366e-02,  3.2877e-02,\n",
            "         1.1394e-01, -2.9326e-02, -1.9695e-02,  7.9561e-02,  7.4971e-02,\n",
            "         1.3219e-02,  6.5235e-02, -6.9588e-02,  1.0563e-01,  1.1297e-01,\n",
            "         1.7302e-02,  1.1848e-02,  9.1510e-02, -7.9389e-02,  6.5148e-02,\n",
            "        -1.0632e-01,  8.7857e-03,  6.8910e-02, -1.2621e-02,  7.0985e-02,\n",
            "        -2.7508e-02,  8.3587e-02,  1.2341e-01, -5.8945e-02,  7.2635e-02,\n",
            "         1.1462e-01, -8.2970e-02, -1.1001e-01, -6.4644e-02, -1.1677e-01,\n",
            "         5.0979e-02,  4.8781e-02,  9.9634e-02,  1.1619e-02,  1.0078e-02,\n",
            "         7.0333e-02,  1.4638e-02,  2.0542e-02, -1.9716e-02, -4.0410e-02,\n",
            "        -8.9666e-02, -2.1957e-02, -2.8839e-03,  2.2937e-02, -1.4824e-02,\n",
            "        -9.7813e-02, -4.3626e-02,  1.1036e-01,  4.2061e-02,  1.1551e-01,\n",
            "        -3.5549e-02,  5.0222e-02, -5.9186e-02, -6.0007e-02,  9.4380e-02,\n",
            "        -8.4817e-02, -2.5223e-02,  8.4766e-03,  8.3964e-02, -3.8009e-02,\n",
            "         3.0975e-02, -4.5525e-02,  5.9583e-03, -7.1581e-02,  1.1539e-01,\n",
            "        -1.0496e-01, -2.7094e-02, -1.0248e-01,  3.2686e-03, -1.1681e-04,\n",
            "         1.1301e-01, -3.4106e-02, -8.3551e-02, -1.0479e-02,  5.1996e-02,\n",
            "         8.1267e-02, -7.4368e-02,  6.8147e-02, -2.7696e-02, -6.2897e-02,\n",
            "        -7.7305e-02,  1.6242e-02, -1.0766e-01, -1.1374e-01, -1.1868e-01,\n",
            "        -5.0371e-02,  2.0870e-02, -2.2516e-02, -1.3027e-01, -1.1427e-01,\n",
            "         4.9304e-02, -1.1974e-01,  3.9822e-02,  8.3336e-02,  1.1258e-01,\n",
            "         7.5149e-02,  9.2950e-02, -1.0678e-01, -8.0819e-02,  9.7571e-02,\n",
            "         7.4618e-02,  2.0946e-02, -3.5500e-02, -9.9216e-02, -1.0055e-01,\n",
            "        -8.0987e-02, -4.3027e-02,  1.2894e-02,  2.2945e-02,  4.1603e-02,\n",
            "        -8.4254e-02,  1.0083e-01,  8.1666e-03, -6.7019e-02,  1.1307e-01,\n",
            "         1.0334e-01,  1.0740e-01, -5.5132e-02,  1.1788e-01,  3.5353e-02,\n",
            "        -1.3242e-02,  7.7589e-02,  9.4510e-02, -7.3927e-02,  3.2652e-02,\n",
            "        -5.5682e-02,  1.1623e-01, -7.0449e-02,  1.1505e-01,  1.0988e-01,\n",
            "         1.2080e-01, -2.4534e-02,  8.3949e-02,  1.0740e-01,  3.8096e-02,\n",
            "        -3.1004e-02, -6.9940e-02,  1.0654e-01,  9.8955e-02, -5.0333e-02,\n",
            "        -5.3791e-02,  2.9334e-02, -9.4541e-02,  3.4617e-02,  1.0390e-01,\n",
            "        -5.2025e-02,  1.0344e-01, -1.2093e-01, -1.2499e-01,  1.1382e-01,\n",
            "        -9.4658e-02, -9.2376e-02, -6.1743e-02, -2.3602e-04, -1.1223e-01,\n",
            "        -4.1365e-02, -5.9147e-02, -7.5317e-02, -1.1402e-01, -8.9840e-02,\n",
            "         3.2820e-02,  4.5158e-02, -1.2352e-01, -2.6113e-02,  1.0258e-01,\n",
            "        -5.4641e-02,  1.1456e-01,  6.3190e-03,  8.3921e-02, -3.0312e-02,\n",
            "        -1.4566e-02,  1.0530e-01, -9.2009e-02, -6.4488e-02,  9.6981e-02,\n",
            "         1.1496e-01,  8.6776e-02,  8.4268e-03, -6.6134e-02, -7.9856e-03,\n",
            "        -9.2543e-02,  7.5482e-02,  8.5725e-02, -8.9205e-02,  1.1290e-01,\n",
            "        -1.1415e-01, -9.2358e-02,  1.0920e-01, -8.1250e-02, -4.3298e-02,\n",
            "        -1.0435e-02, -1.1900e-01,  1.6283e-02,  5.9879e-02, -1.2211e-01,\n",
            "         5.4196e-02,  4.2931e-02,  3.8775e-03, -5.3537e-02, -4.4643e-03,\n",
            "         5.3031e-02,  7.9402e-03,  7.4160e-02,  5.3312e-02,  1.2214e-01,\n",
            "         9.0372e-02, -4.9734e-02,  1.7761e-02,  7.3139e-02,  1.1981e-01,\n",
            "         2.8504e-02, -9.0173e-02, -1.1013e-02,  1.0400e-01, -6.5116e-02,\n",
            "        -3.5149e-02,  1.7311e-02, -7.2331e-02,  8.9076e-02, -1.0643e-01,\n",
            "         1.9002e-03,  8.6102e-02,  4.6102e-02, -8.1909e-02, -1.0208e-01,\n",
            "         2.7689e-02,  6.3823e-02, -1.8783e-02,  7.8370e-02,  1.0205e-01,\n",
            "         4.1473e-02, -1.7692e-02, -8.1823e-02,  1.3274e-02,  8.0189e-02,\n",
            "         7.3162e-02,  3.9577e-02,  8.9166e-02,  6.4308e-02, -1.1950e-01,\n",
            "        -9.3456e-02,  6.8149e-03,  7.5655e-02,  3.0350e-02,  9.9089e-02,\n",
            "        -7.6651e-02,  1.8918e-02,  9.4443e-02,  9.4404e-02, -1.1858e-01,\n",
            "         1.0444e-01, -3.1534e-02,  9.1679e-02,  7.1311e-02,  3.0358e-02,\n",
            "        -9.6356e-02, -4.5251e-02, -2.0810e-02,  4.1470e-02, -2.1332e-02,\n",
            "        -2.9839e-02,  6.4415e-02], device='cuda:0')\n",
            "encoder.layers.3.ff.linear2.weight: tensor([[ 0.0115,  0.0097,  0.0315,  ...,  0.0437,  0.0081, -0.0036],\n",
            "        [-0.0039, -0.0320, -0.0200,  ..., -0.0226, -0.0387, -0.0091],\n",
            "        [-0.0378,  0.0149,  0.0158,  ..., -0.0101, -0.0109,  0.0406],\n",
            "        ...,\n",
            "        [-0.0063,  0.0119,  0.0323,  ...,  0.0113, -0.0151, -0.0117],\n",
            "        [ 0.0132, -0.0195,  0.0295,  ...,  0.0200,  0.0016, -0.0129],\n",
            "        [-0.0288, -0.0170,  0.0264,  ..., -0.0294,  0.0119,  0.0206]],\n",
            "       device='cuda:0')\n",
            "encoder.layers.3.ff.linear2.bias: tensor([-0.0369, -0.0366,  0.0391,  0.0402,  0.0272,  0.0280, -0.0061, -0.0110,\n",
            "         0.0366,  0.0173, -0.0291,  0.0301,  0.0318, -0.0432,  0.0386, -0.0017,\n",
            "        -0.0033, -0.0026, -0.0137,  0.0399, -0.0390, -0.0296, -0.0038, -0.0101,\n",
            "         0.0002, -0.0378,  0.0236, -0.0044,  0.0371, -0.0332, -0.0130,  0.0171,\n",
            "        -0.0294,  0.0425, -0.0183, -0.0385,  0.0084,  0.0123,  0.0340, -0.0026,\n",
            "        -0.0304, -0.0045, -0.0347, -0.0434,  0.0064, -0.0406,  0.0043,  0.0017,\n",
            "         0.0283, -0.0354,  0.0371, -0.0282, -0.0132, -0.0367,  0.0090, -0.0324,\n",
            "        -0.0001, -0.0266,  0.0211, -0.0398,  0.0262,  0.0377,  0.0082, -0.0371],\n",
            "       device='cuda:0')\n",
            "encoder.layers.3.norm1.weight: tensor([0.9970, 0.9954, 0.9981, 0.9972, 0.9985, 1.0052, 0.9930, 0.9919, 0.9986,\n",
            "        0.9982, 0.9987, 1.0068, 0.9963, 1.0018, 1.0062, 1.0063, 1.0128, 0.9965,\n",
            "        1.0048, 1.0069, 1.0027, 1.0073, 1.0001, 0.9953, 0.9958, 0.9997, 1.0037,\n",
            "        1.0039, 1.0075, 1.0049, 1.0022, 1.0064, 1.0024, 1.0028, 1.0002, 0.9891,\n",
            "        0.9936, 0.9983, 1.0017, 1.0052, 0.9987, 1.0021, 0.9897, 0.9986, 1.0051,\n",
            "        1.0038, 0.9887, 1.0022, 1.0014, 1.0012, 1.0039, 0.9935, 0.9974, 1.0040,\n",
            "        1.0047, 0.9978, 0.9976, 1.0023, 1.0043, 1.0036, 1.0141, 1.0001, 1.0033,\n",
            "        1.0069], device='cuda:0')\n",
            "encoder.layers.3.norm1.bias: tensor([ 1.4838e-03,  1.5058e-03,  2.3723e-03,  1.1275e-03, -2.9693e-04,\n",
            "         2.1860e-03,  3.7335e-04,  2.2724e-03, -2.0809e-03,  7.6244e-04,\n",
            "        -1.3830e-03,  7.6508e-04,  1.1940e-04, -1.1172e-03,  4.8547e-04,\n",
            "        -1.1364e-03, -9.1040e-05,  7.5978e-04,  2.5197e-03, -1.7695e-04,\n",
            "         6.2803e-04,  2.3123e-06,  1.6469e-03, -1.9944e-03,  1.1352e-03,\n",
            "        -1.6773e-03,  9.3543e-04, -1.0011e-03,  8.3821e-04, -9.6460e-05,\n",
            "         1.3391e-03,  7.6195e-05, -1.5041e-04,  3.0470e-04,  8.4226e-04,\n",
            "        -8.7065e-04, -3.2456e-04, -1.5244e-03,  1.5685e-03,  2.0440e-04,\n",
            "         1.1355e-04, -6.7987e-04,  1.2695e-03, -1.4699e-03,  1.1001e-03,\n",
            "        -2.1468e-04,  1.3289e-03, -7.1407e-05,  1.8058e-03,  2.6289e-05,\n",
            "         3.8223e-04,  8.8997e-04, -3.5579e-04, -9.1792e-04, -7.6289e-05,\n",
            "        -2.5778e-03,  1.7588e-03, -6.0105e-04,  2.3378e-03,  8.4646e-04,\n",
            "         1.4898e-03,  2.8133e-04,  2.2326e-03, -2.0309e-04], device='cuda:0')\n",
            "encoder.layers.3.norm2.weight: tensor([0.9974, 0.9983, 1.0011, 1.0059, 0.9990, 1.0041, 0.9942, 0.9910, 0.9985,\n",
            "        1.0020, 1.0014, 1.0101, 1.0015, 1.0026, 1.0021, 1.0052, 1.0127, 1.0016,\n",
            "        1.0076, 1.0092, 1.0026, 1.0069, 1.0021, 0.9962, 0.9946, 1.0004, 1.0000,\n",
            "        1.0052, 1.0061, 1.0058, 1.0055, 1.0090, 1.0025, 1.0034, 1.0034, 0.9905,\n",
            "        0.9930, 0.9970, 1.0045, 1.0006, 1.0018, 1.0048, 0.9972, 0.9957, 1.0063,\n",
            "        1.0080, 0.9867, 0.9999, 1.0041, 1.0026, 1.0061, 0.9906, 0.9983, 1.0026,\n",
            "        1.0018, 1.0001, 0.9999, 1.0037, 1.0046, 1.0039, 1.0050, 1.0005, 1.0015,\n",
            "        1.0037], device='cuda:0')\n",
            "encoder.layers.3.norm2.bias: tensor([ 1.4269e-03,  1.2838e-03,  9.9997e-04, -3.7952e-04,  2.2879e-04,\n",
            "         1.5390e-03,  2.6877e-04,  1.5647e-03, -1.0994e-03, -7.8029e-04,\n",
            "        -9.2449e-04,  1.0014e-03, -1.1061e-04,  1.5600e-04, -5.0344e-04,\n",
            "        -1.4383e-03, -1.6741e-03, -6.9150e-04,  2.3639e-04, -7.2790e-04,\n",
            "         2.7274e-05, -9.7347e-04,  1.0213e-03, -2.7817e-03,  1.4317e-03,\n",
            "        -2.1766e-03, -1.3067e-04, -2.9258e-03, -6.1947e-04, -2.3107e-05,\n",
            "         9.7737e-06, -2.2965e-04, -1.0116e-03, -1.7458e-03,  4.9542e-04,\n",
            "         6.7981e-05, -2.3679e-03, -7.1492e-04,  2.1988e-03,  9.1023e-04,\n",
            "         1.0043e-04, -7.3490e-04,  7.6743e-04, -5.0121e-04,  1.2466e-03,\n",
            "         3.6413e-04,  3.3821e-04, -1.0124e-03,  1.2760e-03,  1.1946e-04,\n",
            "        -2.2803e-04,  4.0949e-04, -6.0913e-04, -3.7776e-04, -1.1874e-03,\n",
            "        -2.4077e-03, -2.1159e-04, -1.0485e-03,  1.1210e-03,  5.4717e-04,\n",
            "         3.2310e-04, -1.0861e-03,  6.1481e-05, -4.6964e-04], device='cuda:0')\n",
            "encoder.layers.4.attn.w_q.weight: tensor([[-0.1109, -0.0047, -0.0608,  ..., -0.0839,  0.0469, -0.0004],\n",
            "        [-0.0568, -0.1270, -0.1058,  ..., -0.0081, -0.0608, -0.0657],\n",
            "        [-0.0200, -0.0578, -0.0795,  ..., -0.0886,  0.0290,  0.0762],\n",
            "        ...,\n",
            "        [ 0.0192,  0.0293,  0.0576,  ..., -0.0351, -0.0014, -0.1265],\n",
            "        [ 0.1104, -0.0644,  0.0920,  ..., -0.0656,  0.0965, -0.0941],\n",
            "        [-0.0880, -0.0658, -0.0029,  ...,  0.0952,  0.0393,  0.0564]],\n",
            "       device='cuda:0')\n",
            "encoder.layers.4.attn.w_k.weight: tensor([[ 0.1265,  0.1013,  0.0519,  ..., -0.1358, -0.0007,  0.0525],\n",
            "        [-0.0675,  0.0399,  0.0556,  ..., -0.0914,  0.0011,  0.0612],\n",
            "        [-0.0272,  0.1324,  0.1260,  ...,  0.0085,  0.0218, -0.0198],\n",
            "        ...,\n",
            "        [ 0.1008,  0.0372, -0.0761,  ..., -0.0790,  0.0217,  0.1149],\n",
            "        [-0.0905, -0.0908, -0.0978,  ...,  0.0560, -0.0552, -0.0815],\n",
            "        [ 0.0669,  0.0182, -0.1208,  ..., -0.0589, -0.1110,  0.0173]],\n",
            "       device='cuda:0')\n",
            "encoder.layers.4.attn.w_v.weight: tensor([[-0.0767,  0.1108, -0.0240,  ..., -0.1239, -0.1196, -0.1120],\n",
            "        [-0.0730,  0.0902, -0.0614,  ..., -0.0331,  0.0055, -0.1114],\n",
            "        [-0.0996,  0.0946,  0.0162,  ...,  0.1020, -0.0056,  0.0593],\n",
            "        ...,\n",
            "        [-0.1011, -0.0139, -0.0791,  ..., -0.0584,  0.1120, -0.0597],\n",
            "        [-0.0766, -0.0699,  0.0838,  ..., -0.0231,  0.1153,  0.0690],\n",
            "        [-0.0291,  0.0755, -0.0471,  ..., -0.0719,  0.0804,  0.0580]],\n",
            "       device='cuda:0')\n",
            "encoder.layers.4.attn.w_o.weight: tensor([[-0.0699, -0.0735, -0.0031,  ..., -0.0076,  0.0418, -0.0799],\n",
            "        [-0.0098,  0.0843,  0.0814,  ..., -0.0464,  0.0296, -0.0143],\n",
            "        [-0.0981, -0.0588,  0.1203,  ...,  0.1051, -0.0031, -0.0787],\n",
            "        ...,\n",
            "        [-0.0016, -0.0072,  0.0169,  ...,  0.0524,  0.0952,  0.0836],\n",
            "        [ 0.0848,  0.0165, -0.0109,  ..., -0.1307, -0.0271, -0.0546],\n",
            "        [-0.0644, -0.1195, -0.0122,  ..., -0.1314, -0.1070, -0.1051]],\n",
            "       device='cuda:0')\n",
            "encoder.layers.4.ff.linear1.weight: tensor([[ 0.0505,  0.0006, -0.0013,  ...,  0.1125, -0.0736, -0.0758],\n",
            "        [-0.0901,  0.1140, -0.0549,  ..., -0.1217,  0.1239,  0.1042],\n",
            "        [ 0.0157, -0.1186, -0.0894,  ...,  0.0190, -0.0586, -0.0050],\n",
            "        ...,\n",
            "        [-0.0926,  0.0602,  0.0158,  ..., -0.0247,  0.0303,  0.0258],\n",
            "        [ 0.0463,  0.0421,  0.0496,  ...,  0.0354, -0.0886, -0.0358],\n",
            "        [ 0.0632,  0.0503, -0.0141,  ..., -0.0804, -0.0142,  0.0071]],\n",
            "       device='cuda:0')\n",
            "encoder.layers.4.ff.linear1.bias: tensor([-0.0539,  0.1114,  0.0592, -0.0664, -0.0005,  0.0736,  0.0312,  0.0981,\n",
            "        -0.1197, -0.0531, -0.1211,  0.1078,  0.1025, -0.0011, -0.0111, -0.0943,\n",
            "        -0.0763, -0.0037, -0.1119,  0.0514, -0.0259, -0.0827,  0.1169, -0.1035,\n",
            "        -0.1037,  0.0238,  0.0601, -0.0998, -0.0449, -0.1220,  0.1098,  0.1133,\n",
            "         0.1050, -0.0843, -0.0690,  0.0888,  0.0442,  0.0726, -0.0639, -0.0679,\n",
            "        -0.0622,  0.0557, -0.1215, -0.1020, -0.0334, -0.0156,  0.0593,  0.1028,\n",
            "         0.0513, -0.1142, -0.0725,  0.0915,  0.0668,  0.0689,  0.0766,  0.0889,\n",
            "         0.0914, -0.0801, -0.1096,  0.0261, -0.0323, -0.0457, -0.0605, -0.0533,\n",
            "        -0.0294,  0.0239, -0.1223,  0.0851,  0.1118,  0.0799,  0.1139,  0.0667,\n",
            "        -0.1068, -0.0907,  0.0941,  0.0146, -0.0287,  0.0674, -0.0460, -0.0563,\n",
            "         0.0171, -0.0201, -0.0148, -0.0595, -0.0992, -0.0588, -0.0763, -0.0014,\n",
            "         0.1195,  0.0435,  0.0110,  0.0021, -0.0508,  0.0373, -0.0334, -0.0583,\n",
            "         0.0157,  0.0502,  0.0333, -0.0036, -0.0859,  0.0190, -0.0118,  0.1066,\n",
            "        -0.0467, -0.0347, -0.0433, -0.0291,  0.0610, -0.0045,  0.0469, -0.1110,\n",
            "         0.0495,  0.0835,  0.0307, -0.0858, -0.1161, -0.1170, -0.0131,  0.1088,\n",
            "         0.0668, -0.0104,  0.1167,  0.0768,  0.0703, -0.0350, -0.0783,  0.0166,\n",
            "        -0.1091,  0.1180, -0.0356,  0.1219,  0.0318, -0.1205, -0.0072, -0.0956,\n",
            "         0.0395, -0.0600, -0.0798,  0.0477, -0.0787, -0.0593, -0.0699,  0.0674,\n",
            "        -0.0290,  0.1186, -0.1201, -0.1193,  0.1089, -0.1163, -0.0308, -0.0268,\n",
            "         0.0901,  0.0712,  0.0762,  0.0406, -0.0250,  0.0503, -0.1190,  0.0510,\n",
            "         0.0281,  0.0775,  0.1186,  0.0734, -0.0529, -0.0698, -0.0369, -0.0765,\n",
            "         0.0604,  0.1018, -0.0134, -0.0278, -0.1160, -0.0453,  0.1097,  0.0242,\n",
            "         0.0108,  0.0593,  0.0679,  0.0261,  0.0659,  0.0178, -0.0388,  0.1000,\n",
            "         0.0057,  0.1151,  0.0396, -0.0900,  0.0191, -0.0574, -0.0472, -0.0713,\n",
            "        -0.0488, -0.1189, -0.0448, -0.0446,  0.0651, -0.0012,  0.0262,  0.1230,\n",
            "         0.0730,  0.0028,  0.0176, -0.0179,  0.0734, -0.1224, -0.0537, -0.0859,\n",
            "        -0.0112, -0.1219,  0.0456, -0.0620,  0.0071, -0.0659,  0.0864,  0.0463,\n",
            "         0.0801,  0.1131,  0.0192,  0.0135, -0.0681,  0.0870,  0.0474,  0.1132,\n",
            "        -0.0910,  0.0866,  0.1018,  0.0372,  0.0950, -0.1016,  0.0670,  0.0983,\n",
            "         0.0636,  0.0631, -0.0169,  0.0162,  0.0169, -0.0079, -0.0317, -0.0230,\n",
            "        -0.0254,  0.0244, -0.0865,  0.0050, -0.0960,  0.0401, -0.0670,  0.0079,\n",
            "         0.0128,  0.0534, -0.0994, -0.0784, -0.1173,  0.0148, -0.0589, -0.0711,\n",
            "        -0.1167, -0.0832, -0.0398, -0.0645,  0.0749, -0.0244, -0.0257, -0.0325,\n",
            "        -0.1051,  0.0754,  0.0701,  0.0652,  0.0036,  0.1033, -0.0447,  0.0860,\n",
            "        -0.0070,  0.0477,  0.0350,  0.0888, -0.1133, -0.0321,  0.1091, -0.0928,\n",
            "         0.1010,  0.0024,  0.0346,  0.0090,  0.0934,  0.0095, -0.0279,  0.0555,\n",
            "        -0.0423, -0.1215,  0.0114,  0.0616,  0.0258,  0.0046,  0.0861, -0.1004,\n",
            "         0.0251, -0.0777, -0.0891,  0.1165, -0.0797,  0.0592,  0.1155, -0.0243,\n",
            "        -0.0211,  0.1079, -0.1224, -0.0863,  0.0922,  0.0696,  0.0396, -0.0606,\n",
            "        -0.1084,  0.0381, -0.0925, -0.0314, -0.0751,  0.0486,  0.0147, -0.0598,\n",
            "        -0.0890, -0.0172,  0.0175,  0.0603, -0.0348,  0.0447, -0.0928, -0.1063,\n",
            "        -0.0501,  0.0793, -0.0715, -0.0252, -0.1200, -0.1047, -0.0642,  0.0090,\n",
            "        -0.0177,  0.0781, -0.1060,  0.0782,  0.1104, -0.0954, -0.0188,  0.0017,\n",
            "         0.0990, -0.0097, -0.0606, -0.0278,  0.0739,  0.0572, -0.1130,  0.0700,\n",
            "        -0.0628,  0.0965, -0.1270, -0.0763, -0.0637,  0.0837,  0.0603,  0.0906,\n",
            "        -0.0409, -0.0441, -0.0380, -0.0833,  0.1170, -0.0085, -0.0190, -0.0466,\n",
            "        -0.0418,  0.0003,  0.0887, -0.0744, -0.0573,  0.1205, -0.0956,  0.0136,\n",
            "        -0.0875,  0.0694,  0.1003, -0.0764,  0.0574, -0.0957,  0.0793,  0.0306,\n",
            "         0.0319, -0.0736,  0.0557,  0.0548, -0.1089, -0.0799,  0.1110, -0.0647,\n",
            "         0.0635, -0.1034,  0.0878, -0.0259, -0.0315, -0.0223,  0.0869,  0.0450,\n",
            "        -0.0218, -0.0116,  0.0121,  0.1064,  0.0072, -0.1198,  0.1154, -0.0906,\n",
            "        -0.0010, -0.0860, -0.0837,  0.0400,  0.0053, -0.1021,  0.0886, -0.0736,\n",
            "        -0.0506, -0.1173,  0.0738, -0.0311, -0.1220,  0.1172, -0.0603,  0.0524,\n",
            "         0.1044, -0.0623,  0.1144, -0.0095,  0.0610, -0.0761, -0.1032,  0.0217,\n",
            "         0.0280,  0.0639,  0.1115,  0.0924,  0.0183, -0.0437,  0.1139,  0.0604,\n",
            "         0.0408, -0.0654,  0.0649, -0.0705,  0.0526,  0.0737, -0.0696,  0.0655,\n",
            "        -0.1248,  0.1064, -0.0946,  0.0246,  0.0572, -0.0018, -0.0034, -0.0884,\n",
            "        -0.0771,  0.0090, -0.0960, -0.0848, -0.0914,  0.0229,  0.0565,  0.0824,\n",
            "        -0.0613, -0.1147,  0.0477, -0.0919, -0.1052,  0.0078,  0.0517,  0.0054,\n",
            "        -0.0387, -0.0442, -0.0851, -0.0937,  0.0835, -0.0160,  0.0829, -0.0519,\n",
            "         0.0584, -0.0190, -0.0180, -0.1076, -0.0014,  0.1030,  0.0727, -0.0021,\n",
            "         0.0403, -0.0522,  0.0447, -0.0109, -0.0701,  0.0249, -0.0507,  0.0491,\n",
            "         0.0175,  0.0974,  0.0637,  0.0253, -0.1208,  0.0503,  0.0791, -0.0131,\n",
            "        -0.1014,  0.0159, -0.0177,  0.0188, -0.0131, -0.0874, -0.0158,  0.0024],\n",
            "       device='cuda:0')\n",
            "encoder.layers.4.ff.linear2.weight: tensor([[-0.0107, -0.0430,  0.0339,  ..., -0.0353,  0.0068,  0.0208],\n",
            "        [ 0.0192, -0.0029,  0.0320,  ...,  0.0013,  0.0320,  0.0039],\n",
            "        [-0.0316, -0.0235,  0.0115,  ...,  0.0334, -0.0235, -0.0016],\n",
            "        ...,\n",
            "        [-0.0372, -0.0089, -0.0116,  ...,  0.0130, -0.0094,  0.0368],\n",
            "        [-0.0049, -0.0375, -0.0414,  ..., -0.0214,  0.0358, -0.0150],\n",
            "        [-0.0400, -0.0012,  0.0213,  ...,  0.0262,  0.0279,  0.0244]],\n",
            "       device='cuda:0')\n",
            "encoder.layers.4.ff.linear2.bias: tensor([ 0.0006,  0.0375,  0.0377,  0.0357,  0.0357, -0.0149, -0.0286,  0.0304,\n",
            "         0.0064,  0.0202, -0.0009, -0.0349,  0.0324,  0.0392, -0.0337, -0.0213,\n",
            "        -0.0418, -0.0255,  0.0417, -0.0444,  0.0383,  0.0226,  0.0359,  0.0202,\n",
            "         0.0183, -0.0281,  0.0401, -0.0019,  0.0385, -0.0164, -0.0056,  0.0411,\n",
            "         0.0277,  0.0305, -0.0041, -0.0020, -0.0146,  0.0316, -0.0386,  0.0115,\n",
            "        -0.0200, -0.0188, -0.0416,  0.0173,  0.0271,  0.0144, -0.0191,  0.0217,\n",
            "        -0.0067,  0.0298, -0.0373,  0.0203, -0.0046,  0.0297,  0.0191, -0.0298,\n",
            "        -0.0129,  0.0378,  0.0164, -0.0285,  0.0408, -0.0234,  0.0162, -0.0380],\n",
            "       device='cuda:0')\n",
            "encoder.layers.4.norm1.weight: tensor([0.9969, 0.9964, 1.0001, 1.0089, 0.9978, 1.0071, 0.9938, 0.9913, 0.9981,\n",
            "        1.0003, 1.0000, 1.0046, 0.9986, 1.0030, 0.9998, 1.0037, 1.0142, 0.9970,\n",
            "        1.0063, 1.0100, 1.0044, 1.0092, 1.0010, 0.9951, 0.9982, 1.0023, 1.0015,\n",
            "        1.0015, 1.0028, 1.0064, 1.0028, 1.0039, 1.0123, 0.9992, 1.0060, 0.9906,\n",
            "        0.9985, 0.9954, 1.0058, 0.9991, 0.9996, 1.0030, 1.0013, 0.9963, 1.0026,\n",
            "        1.0060, 0.9888, 1.0021, 1.0040, 1.0008, 1.0040, 0.9920, 1.0002, 0.9974,\n",
            "        0.9979, 0.9994, 0.9948, 1.0036, 1.0002, 1.0031, 1.0021, 1.0003, 0.9999,\n",
            "        1.0028], device='cuda:0')\n",
            "encoder.layers.4.norm1.bias: tensor([-4.5703e-04,  7.5405e-04,  2.0957e-03, -1.6383e-04,  1.2239e-03,\n",
            "         9.9039e-04,  1.6181e-03,  1.1945e-03, -2.9616e-04, -1.0000e-03,\n",
            "        -1.4957e-03,  1.1598e-03,  2.0481e-04, -9.1601e-04,  1.1423e-03,\n",
            "        -3.0652e-04, -5.8541e-04, -1.5745e-04, -6.6925e-04, -4.9100e-04,\n",
            "         3.3582e-04, -9.4653e-04,  9.1684e-04, -5.5935e-04,  1.3846e-03,\n",
            "        -1.3977e-03,  2.4304e-04, -2.1496e-03, -3.5108e-04,  8.8341e-04,\n",
            "        -2.3730e-04,  4.9181e-04, -2.5737e-04, -4.6432e-04,  5.9237e-04,\n",
            "        -5.8114e-04, -3.3693e-05, -2.5399e-04,  1.4769e-03, -9.1888e-04,\n",
            "         7.8001e-05,  4.9922e-04,  2.5397e-03,  7.5579e-04,  1.1956e-03,\n",
            "         6.4152e-04,  5.1342e-04, -6.3561e-05,  1.7372e-03, -1.6772e-03,\n",
            "        -1.2034e-03,  4.9344e-04, -1.1865e-04, -1.4216e-03, -5.0893e-04,\n",
            "        -9.7343e-04,  5.5521e-04, -1.1451e-03,  1.0795e-03, -2.6063e-04,\n",
            "         8.1679e-04, -4.4435e-04,  1.4902e-03, -1.1677e-04], device='cuda:0')\n",
            "encoder.layers.4.norm2.weight: tensor([1.0033, 0.9981, 1.0008, 1.0069, 0.9972, 1.0040, 0.9977, 0.9927, 0.9989,\n",
            "        0.9985, 0.9950, 1.0052, 0.9979, 1.0067, 1.0039, 1.0026, 1.0135, 1.0014,\n",
            "        1.0083, 1.0099, 1.0025, 1.0085, 0.9995, 0.9963, 0.9974, 1.0002, 1.0052,\n",
            "        0.9994, 0.9991, 1.0046, 1.0007, 1.0034, 1.0105, 1.0039, 1.0082, 0.9976,\n",
            "        1.0014, 0.9994, 1.0059, 0.9967, 0.9991, 1.0016, 1.0034, 0.9952, 1.0033,\n",
            "        1.0062, 0.9904, 1.0025, 1.0027, 0.9996, 1.0021, 0.9987, 1.0016, 0.9926,\n",
            "        0.9977, 1.0004, 0.9948, 1.0028, 1.0038, 1.0034, 0.9994, 0.9989, 1.0001,\n",
            "        1.0055], device='cuda:0')\n",
            "encoder.layers.4.norm2.bias: tensor([-4.9252e-04,  6.2940e-04,  1.9870e-03, -1.1687e-03, -1.2917e-03,\n",
            "         9.7740e-05,  7.4563e-04,  1.3924e-03,  2.5954e-04, -2.5726e-05,\n",
            "        -1.0453e-03,  3.3529e-04, -1.0234e-03,  3.6623e-04, -4.5355e-04,\n",
            "        -1.0784e-04, -1.9493e-04,  3.7829e-05, -1.8268e-03, -6.1085e-04,\n",
            "         4.8113e-04, -9.3179e-04,  8.6240e-04, -7.7530e-04, -5.3024e-05,\n",
            "        -2.4022e-03,  8.1677e-05, -1.6542e-03,  8.0521e-05,  8.9125e-04,\n",
            "         1.6848e-04, -1.0035e-04,  8.4966e-04,  7.0773e-05, -8.3893e-04,\n",
            "         9.6943e-06,  7.7772e-04, -1.1128e-03,  9.6573e-05,  1.1203e-05,\n",
            "        -1.1678e-05,  2.6895e-04,  2.1979e-03,  3.0417e-04,  8.9428e-04,\n",
            "         7.0863e-04, -3.5021e-04, -3.2901e-04,  1.3979e-03, -4.1195e-04,\n",
            "         7.6265e-05,  1.1929e-04, -9.3179e-05, -6.9550e-04, -1.1629e-03,\n",
            "        -5.5411e-04, -1.1679e-03, -1.1291e-04,  5.7935e-04, -1.5580e-04,\n",
            "        -3.5793e-05,  1.3521e-04, -1.4976e-03, -8.3833e-04], device='cuda:0')\n",
            "encoder.layers.5.attn.w_q.weight: tensor([[ 0.0044,  0.0617, -0.0238,  ..., -0.1112,  0.0209, -0.0148],\n",
            "        [ 0.1355,  0.0200, -0.0728,  ...,  0.1424,  0.0667, -0.0744],\n",
            "        [-0.0658,  0.0263,  0.0819,  ..., -0.1207, -0.0846, -0.0701],\n",
            "        ...,\n",
            "        [-0.1255,  0.0514,  0.0419,  ..., -0.0250, -0.0235, -0.0799],\n",
            "        [ 0.0230, -0.0049, -0.0176,  ..., -0.0980,  0.0502,  0.0168],\n",
            "        [-0.0132, -0.1277,  0.0584,  ...,  0.1230,  0.1047, -0.0266]],\n",
            "       device='cuda:0')\n",
            "encoder.layers.5.attn.w_k.weight: tensor([[-0.1198,  0.0438, -0.0349,  ..., -0.0270, -0.1007,  0.1266],\n",
            "        [-0.0622, -0.0085, -0.0544,  ..., -0.0055,  0.0150, -0.0629],\n",
            "        [-0.0873, -0.0646,  0.0119,  ...,  0.0975, -0.0799, -0.0570],\n",
            "        ...,\n",
            "        [ 0.0640,  0.1148,  0.0796,  ...,  0.0772, -0.0391, -0.0385],\n",
            "        [-0.0353,  0.0749,  0.0981,  ...,  0.0924, -0.0027,  0.0545],\n",
            "        [-0.0789, -0.0395, -0.0175,  ...,  0.0698,  0.0519,  0.1320]],\n",
            "       device='cuda:0')\n",
            "encoder.layers.5.attn.w_v.weight: tensor([[-7.5963e-02, -4.9304e-02,  1.1570e-01,  ...,  1.1672e-02,\n",
            "         -2.7913e-02, -5.2049e-02],\n",
            "        [ 3.4278e-02, -1.1053e-01, -4.2844e-02,  ..., -8.5976e-02,\n",
            "         -7.9591e-02, -6.6285e-02],\n",
            "        [ 7.5492e-03,  1.3003e-03,  4.8107e-02,  ..., -1.0952e-01,\n",
            "          8.6623e-03, -6.9501e-02],\n",
            "        ...,\n",
            "        [ 3.0030e-02, -6.0343e-02,  8.4016e-02,  ..., -8.8003e-02,\n",
            "          1.0743e-01,  1.1445e-01],\n",
            "        [-9.8678e-02, -7.2157e-02,  1.1835e-01,  ...,  1.0909e-01,\n",
            "         -1.4375e-02,  6.1747e-02],\n",
            "        [ 6.8179e-05,  7.1639e-02,  7.5081e-02,  ...,  6.6112e-02,\n",
            "          5.9401e-02, -5.8896e-02]], device='cuda:0')\n",
            "encoder.layers.5.attn.w_o.weight: tensor([[-0.0168,  0.0298,  0.0236,  ...,  0.0554, -0.0778,  0.0867],\n",
            "        [-0.0382, -0.0611,  0.0954,  ...,  0.0215, -0.0954,  0.0562],\n",
            "        [-0.0317,  0.1095,  0.0336,  ...,  0.0767,  0.1222,  0.0116],\n",
            "        ...,\n",
            "        [ 0.0600,  0.0204, -0.0979,  ..., -0.0387, -0.0585, -0.0792],\n",
            "        [ 0.0261,  0.0858, -0.0312,  ..., -0.1285, -0.0225, -0.0639],\n",
            "        [ 0.0552,  0.0240,  0.0390,  ..., -0.0890,  0.0353, -0.0778]],\n",
            "       device='cuda:0')\n",
            "encoder.layers.5.ff.linear1.weight: tensor([[ 0.0956,  0.0814,  0.0506,  ...,  0.0042, -0.1309, -0.0704],\n",
            "        [ 0.1267,  0.0710, -0.0524,  ...,  0.0795, -0.0102,  0.0470],\n",
            "        [-0.1009,  0.0952, -0.0559,  ..., -0.1013,  0.0867, -0.0422],\n",
            "        ...,\n",
            "        [ 0.0089,  0.0300, -0.0925,  ..., -0.1047,  0.1254, -0.1141],\n",
            "        [-0.0793, -0.0898,  0.0184,  ...,  0.1137, -0.0698, -0.0196],\n",
            "        [-0.0861,  0.0795, -0.0289,  ...,  0.1062,  0.1180,  0.1022]],\n",
            "       device='cuda:0')\n",
            "encoder.layers.5.ff.linear1.bias: tensor([ 5.0519e-02,  1.2175e-01, -1.1630e-01,  1.0495e-02,  1.2424e-02,\n",
            "        -1.2406e-01, -1.1561e-01, -1.2083e-01, -3.5211e-02, -2.5512e-02,\n",
            "         1.0785e-01, -9.8524e-02,  2.8101e-02,  1.0794e-01, -2.4202e-02,\n",
            "        -8.6824e-02, -1.7017e-03, -1.0241e-02,  6.2658e-02, -7.7883e-02,\n",
            "         9.6839e-02,  1.0680e-01,  9.1773e-02,  1.1720e-01, -4.1287e-02,\n",
            "        -5.2913e-02,  5.1953e-02, -7.5534e-02, -1.2557e-01, -6.4512e-02,\n",
            "        -7.0934e-02, -5.2130e-02,  6.1036e-02,  1.9648e-02,  7.0419e-02,\n",
            "        -1.1690e-01, -9.0840e-02, -7.6676e-02,  7.5462e-02,  3.6841e-02,\n",
            "        -6.1249e-02,  3.3215e-02, -1.8438e-02, -9.1913e-03, -2.1853e-02,\n",
            "        -8.8518e-02, -3.5360e-02, -9.0659e-02, -1.1462e-01, -9.8973e-02,\n",
            "         5.7800e-02, -4.1154e-02,  1.2432e-01,  5.1284e-02, -1.1220e-02,\n",
            "        -4.7753e-02, -4.4593e-02, -2.9026e-02, -8.5689e-02, -1.2064e-01,\n",
            "        -6.1979e-02,  4.3911e-03,  7.4023e-02, -9.1083e-02, -9.0979e-03,\n",
            "        -3.1646e-03, -4.1428e-02,  6.1001e-02,  3.3716e-02, -1.4380e-02,\n",
            "        -8.3208e-02, -1.2772e-01, -2.1414e-02,  7.6601e-02, -8.4914e-03,\n",
            "        -4.1086e-02, -8.5909e-02, -7.4759e-02,  1.1296e-01, -8.0351e-03,\n",
            "         9.6990e-02,  8.2198e-02,  2.5438e-02,  1.1173e-01,  1.3124e-02,\n",
            "        -1.8732e-02, -6.5009e-02,  6.9428e-02,  1.0398e-01,  3.4164e-02,\n",
            "        -2.3121e-02, -1.2921e-01,  3.7798e-03, -1.5097e-02, -8.4251e-02,\n",
            "         8.8901e-02,  3.8799e-02, -9.1377e-03,  4.3399e-02,  1.0665e-01,\n",
            "         5.6842e-02,  1.3009e-02,  3.1491e-02, -1.2402e-01, -2.7348e-02,\n",
            "         7.2894e-02,  5.2085e-02, -1.1171e-01, -9.2942e-03, -1.1967e-01,\n",
            "        -6.0211e-03,  6.0902e-02,  2.1006e-02,  1.0035e-02,  7.8751e-02,\n",
            "        -1.0417e-01, -9.3486e-02,  9.6603e-02, -3.0017e-02, -2.2497e-02,\n",
            "         2.6363e-02, -2.0684e-02,  7.6597e-02, -1.1903e-01, -4.5832e-02,\n",
            "         1.5342e-02,  5.4228e-02,  4.4121e-03,  4.7606e-02, -8.2805e-02,\n",
            "         9.9864e-02, -1.0283e-01, -4.9276e-03,  7.3166e-02,  6.0689e-02,\n",
            "         7.3153e-02,  5.8992e-03, -3.7949e-02,  1.0485e-01, -6.8085e-03,\n",
            "         6.2722e-02,  1.0362e-01, -2.3962e-02,  7.1146e-02,  3.4327e-02,\n",
            "        -7.7887e-02,  9.6959e-02,  7.1059e-02,  5.0711e-02,  5.1456e-02,\n",
            "        -9.7343e-02,  4.4913e-02, -1.1530e-01,  1.0987e-01, -5.4042e-02,\n",
            "         7.7040e-02, -9.9527e-02, -6.6435e-02,  4.3627e-03,  1.0655e-01,\n",
            "        -4.4986e-02,  5.4303e-02, -1.2060e-01, -6.2106e-02, -4.5661e-02,\n",
            "         1.9644e-02,  5.0149e-02, -6.6973e-02, -1.1535e-01, -4.3446e-02,\n",
            "        -5.3898e-04, -8.1608e-02, -3.5452e-03,  7.6937e-03,  1.6298e-02,\n",
            "        -4.5850e-02, -1.0569e-01,  9.4921e-02, -6.2873e-02,  1.0423e-01,\n",
            "         1.6171e-02,  4.7585e-02, -5.8610e-02, -5.7951e-03,  5.6488e-02,\n",
            "         9.9791e-02, -5.8343e-02,  8.5750e-02, -5.6123e-02,  2.4276e-02,\n",
            "         6.1516e-04, -7.1709e-02, -7.9432e-02, -3.7821e-02, -1.2529e-01,\n",
            "         1.0402e-01, -9.1456e-02,  1.0607e-01,  9.6482e-02,  8.2457e-02,\n",
            "         7.7520e-02, -2.5787e-02,  2.3429e-02,  9.4073e-03, -1.1963e-01,\n",
            "        -1.9497e-02, -1.1399e-02,  1.2535e-01,  9.3915e-02,  6.7636e-02,\n",
            "        -5.0668e-02,  3.8696e-03,  2.2714e-02, -7.9916e-02,  1.2142e-02,\n",
            "         5.8840e-02, -7.3301e-03, -1.2033e-03, -6.8476e-02, -9.5428e-02,\n",
            "        -4.4704e-02,  1.2214e-01, -5.3895e-02,  1.9544e-02, -7.1611e-03,\n",
            "         3.0680e-03,  3.0193e-02, -1.0506e-01, -1.2236e-02, -2.0054e-02,\n",
            "         1.4734e-02,  7.0400e-02, -1.1069e-01, -1.6912e-02,  3.8506e-02,\n",
            "        -1.1487e-01, -5.3292e-03,  1.0074e-01, -3.9343e-02, -5.8544e-02,\n",
            "         1.1959e-01,  8.7156e-02,  1.0563e-01, -5.3036e-02,  1.0595e-02,\n",
            "         4.1396e-02, -7.5371e-02, -7.4585e-02, -1.2283e-01, -5.6866e-02,\n",
            "         7.8038e-02,  4.7177e-02,  2.5357e-02,  1.1185e-01, -1.8041e-02,\n",
            "        -3.2357e-02, -2.6941e-02, -1.6919e-02,  5.1618e-02, -9.1137e-02,\n",
            "         1.0320e-01, -7.3386e-02, -8.9170e-02, -7.3108e-02,  1.0992e-01,\n",
            "        -2.6879e-02, -8.4050e-02, -1.2007e-01, -1.5783e-02,  7.6307e-02,\n",
            "        -3.9014e-02, -1.6651e-02, -6.7966e-02, -1.2256e-01, -1.1339e-01,\n",
            "        -3.0325e-03,  9.8880e-03, -6.0763e-02,  7.7559e-02, -1.7123e-02,\n",
            "        -7.5356e-03,  9.0108e-02, -4.6658e-03,  6.6190e-03, -6.2185e-02,\n",
            "         4.6376e-03, -8.5503e-02, -1.1496e-01,  9.0393e-02, -1.1541e-01,\n",
            "        -7.0002e-02,  3.7537e-02,  6.6816e-03,  8.1994e-02, -6.6582e-02,\n",
            "         7.9920e-02, -5.7650e-02, -3.0557e-02,  5.3271e-02, -9.6000e-02,\n",
            "         6.8326e-02,  4.5340e-02,  9.9544e-02, -6.0921e-02, -4.2906e-02,\n",
            "         2.9368e-02,  2.9426e-03, -4.8628e-02,  2.3163e-02, -7.0405e-02,\n",
            "        -1.2831e-01, -1.3519e-02,  1.3810e-03,  6.6811e-02, -7.8675e-03,\n",
            "        -1.0288e-01,  2.2744e-02, -1.2808e-01,  3.1834e-02, -6.3170e-02,\n",
            "        -1.2762e-01,  8.2269e-02,  9.8531e-02,  7.7679e-02,  7.9186e-02,\n",
            "         3.2917e-02,  6.5062e-02, -2.9790e-02, -7.7728e-02, -6.0025e-02,\n",
            "        -6.9518e-02, -6.6632e-02,  2.9090e-02, -2.9285e-02,  9.1022e-03,\n",
            "         1.0719e-01, -1.0431e-01,  3.5220e-02,  1.0251e-01, -5.7356e-02,\n",
            "        -3.5662e-03,  6.9345e-02,  1.0648e-01, -7.8116e-02, -8.7536e-02,\n",
            "        -1.1572e-01,  1.2066e-01,  7.0818e-03, -9.6756e-02,  1.0731e-01,\n",
            "         9.2195e-02,  6.0108e-02, -4.7612e-02, -1.0173e-01,  1.3033e-02,\n",
            "         2.4087e-02,  5.8774e-02,  1.1054e-01,  8.5417e-02,  5.2574e-02,\n",
            "        -7.6610e-02,  3.4768e-02,  8.1232e-02,  3.7959e-02, -1.1715e-01,\n",
            "         4.2251e-02,  5.2900e-03,  1.2112e-01, -6.7008e-02, -1.0466e-01,\n",
            "         1.2166e-02, -3.6655e-02, -9.5662e-02, -9.0647e-03,  1.0342e-01,\n",
            "        -5.0131e-02,  1.0069e-01,  3.5534e-02, -6.5625e-02,  1.7088e-02,\n",
            "        -5.6570e-02, -8.7493e-02,  2.8147e-02,  3.4311e-02,  5.3628e-02,\n",
            "         8.9518e-02,  8.0846e-02, -1.1847e-01,  1.0812e-01,  1.1287e-01,\n",
            "        -3.7052e-02, -3.8579e-02,  9.2627e-02,  8.5257e-03, -5.8105e-03,\n",
            "        -2.3827e-02,  9.0524e-02, -7.6487e-03, -8.1599e-02, -1.1084e-01,\n",
            "        -1.1038e-01,  5.8321e-02,  2.6981e-02,  7.8272e-02,  8.5614e-02,\n",
            "        -8.7359e-02,  1.9685e-02, -3.2554e-03, -8.1134e-02, -8.4810e-02,\n",
            "        -6.2334e-03, -5.8410e-02,  1.1759e-01,  3.6863e-02,  5.4812e-02,\n",
            "        -1.1190e-01, -7.1375e-02, -1.1761e-01,  6.2810e-02, -1.1211e-01,\n",
            "         4.0720e-02, -9.0957e-02, -7.0364e-02,  3.9706e-02,  7.4924e-02,\n",
            "        -7.5882e-02,  8.4741e-02, -9.8689e-02, -5.0551e-02,  2.3154e-02,\n",
            "         3.3034e-02, -9.7615e-03, -1.1056e-01,  7.5331e-02,  8.7669e-02,\n",
            "         9.1178e-02, -5.4458e-02, -5.7860e-03, -9.4733e-02, -9.8377e-02,\n",
            "         6.3135e-02,  1.1582e-01,  4.9812e-03,  9.2525e-02, -5.9925e-02,\n",
            "         1.0290e-01,  6.9221e-02, -3.8163e-02, -6.7655e-02,  1.0038e-01,\n",
            "        -7.5182e-02, -6.0102e-02,  1.1911e-01,  9.9987e-02, -2.1632e-02,\n",
            "         7.7797e-02,  1.2166e-01,  6.0508e-05, -4.0310e-02, -9.3028e-02,\n",
            "         7.6720e-03,  1.1918e-02, -2.0253e-02, -1.2449e-01, -3.1745e-02,\n",
            "         8.9100e-02,  5.0687e-02,  1.1418e-02, -1.0245e-01,  6.4986e-02,\n",
            "         1.5573e-02, -8.0978e-02, -5.6694e-02, -2.9832e-03, -1.1267e-01,\n",
            "         1.0845e-01,  6.8714e-02, -9.5989e-02, -1.3254e-02, -1.2218e-01,\n",
            "        -3.4297e-02,  8.6128e-02, -1.0499e-01, -8.6144e-02,  1.5961e-02,\n",
            "         1.2264e-02,  5.5363e-02,  7.3441e-02, -4.3649e-02, -3.6475e-02,\n",
            "         8.0493e-02,  6.1464e-02, -5.7149e-02,  3.5607e-02,  1.0176e-01,\n",
            "        -1.7540e-03,  1.1457e-01,  7.6178e-02, -6.6090e-02, -9.6409e-02,\n",
            "        -8.7637e-02,  1.8371e-02, -3.4771e-02, -1.2303e-01, -1.1260e-01,\n",
            "        -1.0984e-01,  4.4537e-02, -1.2265e-01,  1.0323e-01,  8.1498e-02,\n",
            "        -2.4822e-03, -8.8828e-02], device='cuda:0')\n",
            "encoder.layers.5.ff.linear2.weight: tensor([[-2.8632e-02,  1.9819e-02,  2.2222e-02,  ...,  3.6435e-02,\n",
            "          3.8423e-02,  4.7276e-02],\n",
            "        [-3.8072e-02,  3.6131e-02, -4.0615e-02,  ..., -4.7655e-03,\n",
            "         -2.9657e-02,  2.7249e-02],\n",
            "        [ 1.2423e-02, -1.9883e-03,  2.4627e-02,  ..., -1.1352e-02,\n",
            "          3.1733e-02,  4.8358e-02],\n",
            "        ...,\n",
            "        [ 2.2394e-02,  9.9252e-04, -7.4373e-03,  ...,  6.0619e-03,\n",
            "         -3.2371e-02, -3.9466e-03],\n",
            "        [ 4.1733e-02,  3.8588e-02,  2.8312e-02,  ...,  7.7249e-03,\n",
            "         -8.8374e-03, -9.8186e-03],\n",
            "        [ 1.4058e-05, -3.6542e-02, -3.5404e-02,  ...,  1.6009e-02,\n",
            "          9.5495e-03,  4.2753e-02]], device='cuda:0')\n",
            "encoder.layers.5.ff.linear2.bias: tensor([-0.0373, -0.0185,  0.0434, -0.0135,  0.0251, -0.0168, -0.0309, -0.0288,\n",
            "        -0.0049, -0.0288, -0.0068, -0.0435,  0.0335,  0.0078, -0.0011, -0.0424,\n",
            "        -0.0419,  0.0165, -0.0164,  0.0211, -0.0074,  0.0138,  0.0171, -0.0396,\n",
            "        -0.0146,  0.0393,  0.0345, -0.0138,  0.0431, -0.0112,  0.0076, -0.0286,\n",
            "         0.0203,  0.0094, -0.0363,  0.0242,  0.0300,  0.0086,  0.0001, -0.0010,\n",
            "         0.0185, -0.0313,  0.0048, -0.0094,  0.0382,  0.0229,  0.0110, -0.0162,\n",
            "        -0.0196,  0.0302,  0.0314,  0.0038, -0.0228, -0.0291,  0.0161, -0.0290,\n",
            "        -0.0329, -0.0401,  0.0353, -0.0254, -0.0380, -0.0372, -0.0384,  0.0026],\n",
            "       device='cuda:0')\n",
            "encoder.layers.5.norm1.weight: tensor([0.9991, 0.9980, 1.0036, 1.0073, 0.9934, 1.0020, 0.9973, 0.9960, 0.9977,\n",
            "        1.0008, 0.9941, 1.0047, 0.9959, 1.0087, 1.0005, 0.9988, 1.0145, 1.0022,\n",
            "        1.0082, 1.0098, 1.0006, 1.0085, 0.9995, 0.9947, 0.9982, 0.9984, 1.0042,\n",
            "        1.0011, 0.9973, 1.0066, 1.0002, 1.0019, 1.0067, 1.0039, 1.0090, 1.0012,\n",
            "        1.0019, 0.9979, 1.0059, 0.9930, 0.9956, 1.0012, 1.0009, 0.9942, 1.0040,\n",
            "        1.0037, 0.9902, 1.0043, 0.9999, 0.9971, 1.0027, 0.9966, 1.0037, 0.9960,\n",
            "        0.9926, 0.9962, 0.9965, 1.0011, 1.0037, 1.0034, 1.0023, 0.9954, 0.9988,\n",
            "        1.0047], device='cuda:0')\n",
            "encoder.layers.5.norm1.bias: tensor([ 1.0802e-03,  6.6924e-04,  8.5639e-04, -2.5007e-03,  9.8663e-04,\n",
            "        -6.5113e-04,  1.1535e-03,  1.5222e-03,  8.5527e-04, -5.1860e-04,\n",
            "        -6.1044e-05,  1.1750e-03, -7.1261e-04,  3.0978e-04,  1.1018e-03,\n",
            "        -6.8845e-04,  5.4773e-04, -7.1254e-04, -2.0245e-04, -3.7053e-04,\n",
            "         8.7807e-04, -2.0003e-03,  3.1216e-04, -1.1856e-03,  4.2519e-04,\n",
            "        -1.3356e-03,  5.7137e-04, -1.1883e-03,  6.2517e-04,  1.0626e-04,\n",
            "         4.4366e-04, -1.5167e-03,  4.7462e-04,  5.6204e-04,  3.4587e-05,\n",
            "        -5.4563e-04,  1.7019e-03, -8.0997e-04, -7.6321e-04,  4.3703e-04,\n",
            "         2.4929e-04,  4.7614e-04,  1.0111e-03,  1.0167e-03,  5.9009e-05,\n",
            "        -4.8867e-04,  8.0272e-04, -2.5883e-04,  9.7703e-04,  7.7106e-04,\n",
            "        -5.0646e-04,  3.1942e-04,  1.1591e-03, -1.1726e-03, -1.2914e-03,\n",
            "         4.8099e-04, -5.8901e-04, -6.0172e-04,  1.2536e-03, -6.3388e-05,\n",
            "         4.6348e-04,  2.2471e-04, -5.5657e-04, -9.7643e-04], device='cuda:0')\n",
            "encoder.layers.5.norm2.weight: tensor([1.0018, 0.9998, 1.0043, 1.0080, 0.9941, 1.0005, 0.9988, 0.9969, 0.9978,\n",
            "        0.9998, 0.9951, 1.0063, 0.9994, 1.0069, 1.0007, 0.9998, 1.0158, 1.0031,\n",
            "        1.0012, 1.0101, 1.0025, 1.0084, 0.9992, 0.9917, 0.9963, 0.9974, 1.0055,\n",
            "        0.9997, 1.0006, 1.0061, 0.9993, 1.0025, 1.0024, 1.0034, 1.0066, 0.9992,\n",
            "        1.0034, 0.9992, 1.0096, 0.9895, 0.9983, 1.0011, 1.0019, 0.9952, 1.0049,\n",
            "        1.0053, 0.9934, 1.0029, 0.9999, 0.9983, 1.0029, 0.9982, 1.0033, 0.9933,\n",
            "        0.9917, 0.9935, 0.9985, 1.0023, 1.0070, 1.0015, 1.0027, 0.9978, 0.9917,\n",
            "        1.0030], device='cuda:0')\n",
            "encoder.layers.5.norm2.bias: tensor([-5.6965e-05,  1.0626e-03,  3.8534e-04, -3.1215e-03,  1.2061e-03,\n",
            "         1.3122e-03,  2.3219e-03,  9.2294e-04,  1.6074e-03,  4.8479e-04,\n",
            "        -1.0984e-04,  1.3190e-03,  4.6621e-05, -5.3900e-04,  1.4209e-04,\n",
            "        -4.8401e-05,  1.2255e-03, -8.0408e-05,  1.1409e-04,  3.5406e-04,\n",
            "         6.3682e-04, -1.2407e-03,  1.4493e-04, -1.3559e-03, -7.0853e-05,\n",
            "        -1.7205e-03,  1.7368e-04, -4.5189e-05, -8.8756e-04,  6.1572e-04,\n",
            "         8.8483e-04, -1.6908e-03,  1.0141e-03,  3.2971e-04, -3.4582e-04,\n",
            "        -1.2755e-04,  5.5921e-04, -5.7215e-04, -3.2757e-04,  7.9255e-04,\n",
            "         5.9427e-04,  2.7038e-04, -5.6519e-04, -5.3035e-04, -5.5344e-04,\n",
            "         1.5669e-04, -5.5541e-05,  1.0363e-03,  1.1554e-03, -1.6039e-04,\n",
            "        -6.8508e-04, -6.5483e-04,  2.2365e-03, -2.5505e-03, -2.2860e-04,\n",
            "        -6.8589e-04,  5.7667e-04,  8.1848e-04,  1.7534e-03, -6.0534e-04,\n",
            "         7.8449e-04,  3.1049e-04, -1.1369e-03, -1.7468e-03], device='cuda:0')\n",
            "encoder.layers.6.attn.w_q.weight: tensor([[ 0.0569,  0.0006,  0.0441,  ...,  0.1090, -0.0226, -0.0631],\n",
            "        [ 0.0687,  0.0839,  0.1058,  ..., -0.1109,  0.0469, -0.0048],\n",
            "        [ 0.0694,  0.0138,  0.0529,  ..., -0.0043, -0.0741, -0.0050],\n",
            "        ...,\n",
            "        [ 0.0195,  0.0500,  0.0344,  ...,  0.0036, -0.0902,  0.1020],\n",
            "        [ 0.0645, -0.0297,  0.1157,  ..., -0.0534,  0.0921, -0.0439],\n",
            "        [ 0.1197, -0.0040,  0.0181,  ...,  0.0964, -0.0084,  0.0729]],\n",
            "       device='cuda:0')\n",
            "encoder.layers.6.attn.w_k.weight: tensor([[-0.0783, -0.0831,  0.0488,  ...,  0.0146,  0.0493,  0.0498],\n",
            "        [ 0.0900, -0.0406,  0.0479,  ..., -0.0365,  0.1103, -0.0050],\n",
            "        [ 0.0721,  0.1062,  0.0120,  ..., -0.0691,  0.0154, -0.0072],\n",
            "        ...,\n",
            "        [-0.0464,  0.0102,  0.0652,  ..., -0.0693,  0.0507,  0.0933],\n",
            "        [ 0.0558,  0.0479,  0.0204,  ...,  0.0104,  0.0328,  0.1266],\n",
            "        [ 0.1221,  0.0634,  0.0862,  ...,  0.0069, -0.0171,  0.0456]],\n",
            "       device='cuda:0')\n",
            "encoder.layers.6.attn.w_v.weight: tensor([[-9.0870e-02,  7.7076e-02,  2.7934e-02,  ..., -1.1641e-01,\n",
            "         -4.7041e-02,  1.0107e-01],\n",
            "        [ 1.1789e-01, -7.5363e-02, -1.0342e-01,  ...,  3.5485e-02,\n",
            "          1.1818e-01,  2.3509e-02],\n",
            "        [ 7.0924e-02,  3.3131e-03, -5.1574e-02,  ..., -5.3533e-02,\n",
            "         -1.0894e-01, -1.1428e-01],\n",
            "        ...,\n",
            "        [-7.4880e-02,  1.0153e-01,  1.0463e-01,  ...,  2.0850e-02,\n",
            "          2.1684e-02,  4.8169e-02],\n",
            "        [-2.4121e-02, -6.3969e-02, -7.1977e-02,  ...,  1.1705e-02,\n",
            "         -1.0611e-01, -1.0789e-01],\n",
            "        [-6.5810e-02,  1.0107e-02,  1.2034e-01,  ...,  1.1792e-04,\n",
            "          9.4092e-02,  1.0262e-01]], device='cuda:0')\n",
            "encoder.layers.6.attn.w_o.weight: tensor([[-0.0929,  0.0450, -0.0454,  ..., -0.0304, -0.0057,  0.0482],\n",
            "        [ 0.0078, -0.0155, -0.0059,  ...,  0.0922,  0.0626, -0.0586],\n",
            "        [ 0.0767,  0.0272, -0.0688,  ..., -0.0941, -0.0001, -0.0664],\n",
            "        ...,\n",
            "        [-0.0756, -0.0722, -0.0656,  ...,  0.0275,  0.0280,  0.0690],\n",
            "        [-0.0844, -0.0225,  0.0135,  ...,  0.1098,  0.0573,  0.0843],\n",
            "        [ 0.0299,  0.0863, -0.0060,  ...,  0.0858, -0.0919,  0.1266]],\n",
            "       device='cuda:0')\n",
            "encoder.layers.6.ff.linear1.weight: tensor([[-0.0485,  0.0230, -0.1078,  ...,  0.0666, -0.0543,  0.0440],\n",
            "        [ 0.0863,  0.0821, -0.0354,  ...,  0.0439,  0.0619,  0.0076],\n",
            "        [-0.1334, -0.1111, -0.0818,  ...,  0.0356, -0.0080, -0.0803],\n",
            "        ...,\n",
            "        [-0.0867, -0.0682, -0.1130,  ...,  0.0007,  0.1018, -0.0085],\n",
            "        [ 0.1264,  0.1011,  0.1209,  ...,  0.0094, -0.1155,  0.0467],\n",
            "        [ 0.0211, -0.0611,  0.0275,  ..., -0.0843, -0.0553,  0.0261]],\n",
            "       device='cuda:0')\n",
            "encoder.layers.6.ff.linear1.bias: tensor([-6.9224e-02,  8.7546e-02,  3.2654e-02,  3.6181e-02, -7.5223e-02,\n",
            "         6.0519e-02,  1.1100e-01, -7.3374e-02, -5.0373e-02, -7.1057e-02,\n",
            "         6.6235e-02,  9.3912e-02,  8.0690e-03, -1.2729e-01, -1.0310e-01,\n",
            "         4.0961e-02, -5.2872e-02, -1.1428e-01, -1.4213e-02, -2.4128e-02,\n",
            "        -3.0972e-02, -2.0099e-02, -8.5488e-02, -4.4010e-02, -8.7886e-02,\n",
            "        -7.8079e-02, -8.5329e-02, -1.3036e-01,  4.6127e-02, -1.2173e-01,\n",
            "         8.0400e-02, -7.5790e-02,  1.0368e-01, -1.2145e-01, -5.4582e-02,\n",
            "        -6.8245e-02,  2.5698e-02, -6.7310e-02, -9.2144e-02,  7.7629e-02,\n",
            "        -6.2226e-02,  9.0556e-02,  7.8444e-03, -9.6005e-02, -9.7247e-02,\n",
            "         4.2379e-02, -5.4845e-02, -6.0105e-02, -9.7752e-02, -6.3477e-04,\n",
            "         6.7162e-03,  2.0781e-02, -6.3414e-02, -1.0456e-01, -5.3625e-02,\n",
            "        -5.9378e-03, -1.6392e-02, -3.7390e-02,  3.1701e-02, -9.3850e-02,\n",
            "        -1.1795e-01,  9.0177e-02, -6.2053e-02, -6.7202e-02, -1.1405e-01,\n",
            "         1.0464e-01,  1.2195e-01,  1.1133e-01,  1.1664e-01,  7.4806e-04,\n",
            "        -7.0605e-02,  7.3329e-02,  8.9586e-02,  7.4119e-02,  2.8615e-02,\n",
            "         7.8990e-02, -5.7410e-02, -6.2858e-02, -5.8047e-02, -4.5140e-02,\n",
            "        -9.8705e-02, -8.4814e-02, -1.3779e-02, -1.3236e-01,  8.6226e-02,\n",
            "        -1.2461e-01,  7.0839e-02,  4.9113e-02, -8.0896e-02, -8.1098e-02,\n",
            "        -2.2015e-02, -1.2552e-01,  1.5008e-02,  2.9475e-02, -2.1149e-02,\n",
            "         7.7224e-02,  1.1568e-01, -5.3621e-03, -2.1566e-02, -9.3071e-02,\n",
            "        -9.4715e-02,  3.7776e-02, -1.0353e-01, -3.1654e-02, -8.8948e-02,\n",
            "         1.9848e-02,  1.5749e-02,  9.5772e-03,  1.0731e-01,  1.1300e-01,\n",
            "         3.9864e-02,  4.6261e-02,  4.1292e-02, -1.1357e-02,  5.9077e-02,\n",
            "        -3.5612e-02, -3.1554e-02, -2.9183e-02,  1.0152e-01, -6.1540e-02,\n",
            "        -2.9175e-02, -6.4182e-02, -1.2854e-01, -6.2196e-02, -1.1354e-01,\n",
            "        -4.3585e-02,  9.6875e-04,  7.7016e-02, -1.2030e-01,  1.2688e-02,\n",
            "         9.9566e-02, -2.1233e-02, -1.1394e-01, -4.0372e-02, -3.1535e-02,\n",
            "         4.2692e-02, -1.0492e-01, -1.1425e-02,  3.1063e-02,  3.4105e-02,\n",
            "         3.2318e-02,  2.0980e-02,  2.0671e-03, -3.7144e-02, -6.8887e-02,\n",
            "         2.4068e-02, -2.8307e-02,  3.4858e-02, -6.6155e-02,  3.9749e-02,\n",
            "        -8.7545e-02,  7.4471e-02, -6.0184e-03,  1.2439e-02, -1.2310e-01,\n",
            "        -7.3535e-02, -1.0369e-01, -5.2963e-02,  8.4428e-02,  1.2097e-01,\n",
            "         3.0407e-02, -9.6704e-02, -5.5204e-03, -3.3993e-02,  4.2800e-02,\n",
            "         1.1107e-01,  2.8902e-03,  9.1851e-02,  8.0568e-02, -1.0726e-02,\n",
            "        -9.8657e-02,  9.2697e-02,  1.1761e-01,  6.0795e-03,  2.3472e-02,\n",
            "        -8.6218e-02,  7.5601e-02,  2.4905e-02,  6.7076e-02,  9.4671e-02,\n",
            "        -2.4424e-02, -6.6025e-02,  9.1925e-02, -9.0286e-02, -3.8991e-03,\n",
            "        -1.2721e-01, -2.4100e-02, -3.0246e-02,  1.4963e-02,  3.7281e-02,\n",
            "         1.1609e-03,  2.2589e-02,  8.6066e-02, -1.2367e-01,  1.0778e-02,\n",
            "        -2.2279e-03, -1.0231e-01, -9.0532e-02, -4.1317e-02,  3.9512e-02,\n",
            "        -1.0180e-01,  9.6983e-02,  4.8254e-02,  3.7020e-02, -8.2467e-02,\n",
            "         5.5561e-02,  7.6037e-02,  3.4831e-02, -3.2741e-02,  6.8129e-02,\n",
            "        -6.9322e-03, -8.1940e-02,  9.6499e-02,  3.6172e-02,  1.0317e-01,\n",
            "        -3.0756e-02, -7.5036e-02, -7.3276e-02, -5.0301e-02, -3.1393e-03,\n",
            "        -1.1214e-01, -3.3223e-02, -8.4233e-02,  5.2972e-02, -4.5733e-02,\n",
            "         8.8089e-02, -7.4311e-03, -6.8250e-02,  1.0171e-02,  6.2227e-02,\n",
            "        -1.2021e-01,  7.9775e-02,  6.5527e-02,  1.0609e-01,  5.1159e-04,\n",
            "         4.7153e-02,  2.8329e-02,  3.0147e-02,  4.0594e-02,  2.9210e-02,\n",
            "         4.1981e-02, -3.2772e-02,  3.9983e-02,  1.0450e-01, -1.1941e-01,\n",
            "         2.8600e-02, -9.6533e-02, -9.0011e-02,  4.5915e-02, -1.0240e-01,\n",
            "         4.3308e-02,  1.1465e-01,  1.1040e-01,  4.0561e-03,  5.2279e-02,\n",
            "        -2.1438e-02, -2.4891e-02,  7.9681e-02,  1.8004e-03,  1.1055e-01,\n",
            "         9.7655e-02,  1.8260e-02, -1.0520e-01, -7.5366e-02, -7.7646e-02,\n",
            "         3.0012e-02, -1.0097e-01,  1.1513e-01, -2.2298e-02, -1.0986e-01,\n",
            "        -5.2216e-02, -2.9508e-02, -3.4695e-02,  7.0974e-02,  5.2371e-02,\n",
            "        -1.2079e-01,  5.1035e-02, -8.7624e-02, -1.2833e-01,  3.1168e-02,\n",
            "        -3.6403e-02,  4.9909e-02,  7.0458e-02,  5.7084e-03, -9.9603e-02,\n",
            "        -2.4333e-02, -1.0307e-01, -9.9068e-02,  5.2857e-02,  4.3949e-03,\n",
            "         7.0707e-05,  1.2059e-01, -5.0212e-04,  2.8364e-02, -8.8799e-02,\n",
            "        -2.3013e-03,  5.7630e-02,  2.7754e-02,  1.6349e-02,  1.3861e-02,\n",
            "        -2.2924e-02, -1.6642e-02, -2.7523e-02,  4.1159e-02,  8.5129e-02,\n",
            "         3.0751e-03, -7.6838e-02, -1.1747e-01,  1.1755e-01,  1.1783e-01,\n",
            "        -7.3325e-02, -1.9982e-02, -6.6872e-02,  6.5033e-02, -4.1572e-02,\n",
            "         8.2857e-02,  3.4298e-02, -1.6098e-02, -7.2535e-02, -2.8799e-02,\n",
            "         2.6311e-04, -1.2801e-01, -7.7978e-02, -8.0844e-02,  3.7900e-02,\n",
            "         2.7428e-03,  1.2063e-01, -1.0325e-01, -6.9393e-02,  2.9322e-02,\n",
            "         7.6221e-02, -2.7268e-02, -1.4872e-02,  7.7129e-03, -1.2353e-01,\n",
            "        -5.9555e-02, -2.2167e-02, -1.0209e-01, -1.2357e-01, -9.1138e-02,\n",
            "        -1.2296e-01, -1.1250e-01,  1.0829e-01,  1.1831e-01, -7.4004e-02,\n",
            "         7.6315e-03, -1.4094e-02, -4.8390e-02, -5.6474e-02, -1.6489e-03,\n",
            "        -5.3223e-02, -2.0015e-02,  1.0901e-01,  7.6157e-02, -1.1081e-01,\n",
            "        -1.1792e-01,  7.2615e-02, -7.4526e-02, -1.2876e-01, -3.1374e-02,\n",
            "         4.4364e-02,  3.6085e-02,  1.0590e-01, -1.2917e-01,  1.1926e-01,\n",
            "        -5.2878e-02,  1.1227e-01,  1.1021e-01, -9.0626e-02, -8.2793e-02,\n",
            "        -1.7669e-02, -1.2504e-01,  4.6658e-02, -3.0827e-02,  6.9951e-02,\n",
            "         1.0612e-01,  8.2045e-02,  6.8505e-03, -1.0950e-01,  2.2844e-02,\n",
            "        -1.1096e-01,  1.0221e-01,  4.8318e-02, -3.5004e-02, -1.6972e-03,\n",
            "        -8.4141e-02, -1.0015e-01, -1.0027e-01,  1.9150e-02,  5.5386e-03,\n",
            "        -9.4975e-02, -6.2188e-02, -7.5173e-02,  2.8347e-02,  1.9816e-02,\n",
            "        -5.7791e-02,  1.3403e-02, -1.0530e-01,  3.2638e-02, -3.3914e-02,\n",
            "         5.2880e-02,  6.6690e-02, -3.1403e-02,  9.5504e-02, -8.0727e-02,\n",
            "        -1.2095e-01, -1.0118e-01,  5.1376e-02, -9.2625e-02,  1.0044e-01,\n",
            "         3.8829e-02,  4.0725e-02, -5.9715e-02, -1.0756e-01, -7.3935e-02,\n",
            "         1.0371e-01, -3.0945e-02, -9.2744e-02, -2.4754e-02,  2.0183e-02,\n",
            "        -4.1697e-02,  3.8994e-02,  1.2053e-01,  8.3024e-02, -5.5061e-02,\n",
            "        -1.1273e-01,  8.9457e-03,  3.4723e-02,  4.8275e-02,  2.0556e-02,\n",
            "         8.7264e-02,  1.0333e-02,  2.0847e-02,  2.2395e-02,  9.6038e-02,\n",
            "         9.6384e-02,  2.2644e-03,  1.0705e-01, -1.2145e-01,  1.7644e-02,\n",
            "         1.0807e-01, -2.9189e-02, -4.8328e-02,  7.9917e-03, -6.1158e-02,\n",
            "        -1.0044e-01, -1.1806e-01,  1.0780e-01, -1.1562e-01, -3.0899e-02,\n",
            "        -2.4121e-02, -4.0580e-02,  9.4031e-02,  1.1871e-01,  1.0174e-01,\n",
            "         1.7254e-02,  2.2392e-02,  3.7130e-02, -4.2852e-02,  3.5809e-02,\n",
            "        -6.5107e-02,  3.9959e-02,  1.3160e-02,  6.0294e-02,  3.1914e-02,\n",
            "        -9.1334e-02, -5.6822e-02, -5.3925e-02,  8.8850e-02,  7.9505e-02,\n",
            "        -4.6836e-02, -8.4923e-02, -8.6231e-02, -3.8052e-02, -9.6493e-03,\n",
            "         1.1593e-02, -7.7856e-02, -1.1216e-01, -2.6585e-02, -4.9589e-02,\n",
            "        -1.2130e-01, -4.1594e-02,  1.0527e-01,  9.0367e-02, -1.1827e-01,\n",
            "        -7.7255e-02,  8.0752e-02,  1.0027e-01, -1.0106e-01, -4.4790e-02,\n",
            "         8.4775e-02,  8.3365e-02, -4.7837e-02, -6.0354e-02, -6.0680e-02,\n",
            "         4.0632e-02, -9.7991e-02, -1.0731e-01,  1.2134e-01, -1.0836e-01,\n",
            "         5.3885e-02, -2.7521e-02, -7.8655e-02,  1.4014e-02, -7.1810e-02,\n",
            "        -1.0560e-02, -6.3229e-02,  2.6272e-02,  4.8709e-02,  5.0130e-02,\n",
            "        -7.2784e-02, -1.0068e-01], device='cuda:0')\n",
            "encoder.layers.6.ff.linear2.weight: tensor([[ 0.0432, -0.0237, -0.0039,  ..., -0.0488, -0.0384,  0.0020],\n",
            "        [-0.0032, -0.0240, -0.0390,  ..., -0.0092, -0.0163, -0.0209],\n",
            "        [ 0.0181, -0.0104, -0.0054,  ...,  0.0284, -0.0253,  0.0084],\n",
            "        ...,\n",
            "        [-0.0297,  0.0105, -0.0284,  ...,  0.0409, -0.0234,  0.0275],\n",
            "        [-0.0230,  0.0268, -0.0394,  ...,  0.0067, -0.0329,  0.0081],\n",
            "        [ 0.0174, -0.0207, -0.0166,  ...,  0.0006,  0.0183, -0.0254]],\n",
            "       device='cuda:0')\n",
            "encoder.layers.6.ff.linear2.bias: tensor([-1.4663e-02, -3.1053e-02, -1.9277e-02,  9.2811e-03,  3.0904e-02,\n",
            "         1.4549e-02, -3.0258e-02, -4.6666e-03, -7.8351e-03, -6.2722e-03,\n",
            "         3.2857e-02,  3.0499e-02, -1.1441e-05,  1.8775e-02,  1.6126e-02,\n",
            "        -2.6464e-02,  1.6480e-02, -3.7553e-02,  2.9628e-02, -1.7695e-02,\n",
            "        -1.1288e-03, -9.2107e-04, -1.0104e-02, -2.4768e-03, -3.3252e-02,\n",
            "         3.3559e-02, -1.0789e-02,  1.5822e-02,  3.7133e-03,  1.7857e-02,\n",
            "        -2.7207e-02,  1.8364e-02,  4.1555e-02, -1.4600e-02, -2.1537e-02,\n",
            "         1.3602e-02, -8.5611e-03, -2.1356e-03, -3.9095e-02, -1.8791e-02,\n",
            "         3.8863e-02,  4.0031e-03,  6.1724e-03, -3.2254e-02, -3.4536e-02,\n",
            "        -2.1684e-02, -4.0633e-02,  3.0973e-02, -1.1835e-02,  2.5330e-02,\n",
            "        -1.6895e-02, -8.1988e-03,  3.7333e-02,  2.4860e-03,  2.7364e-02,\n",
            "        -2.6912e-02,  2.4997e-02, -4.1806e-02, -2.0420e-02, -1.5369e-02,\n",
            "         1.6251e-02, -4.1137e-02, -4.1743e-02, -3.5450e-02], device='cuda:0')\n",
            "encoder.layers.6.norm1.weight: tensor([1.0027, 1.0001, 1.0049, 1.0097, 0.9919, 0.9961, 0.9944, 0.9956, 0.9962,\n",
            "        0.9943, 0.9954, 1.0024, 1.0024, 1.0051, 0.9997, 0.9990, 1.0106, 1.0010,\n",
            "        1.0020, 1.0084, 1.0086, 1.0090, 0.9969, 0.9880, 1.0012, 0.9969, 1.0062,\n",
            "        0.9970, 1.0045, 1.0002, 0.9988, 1.0053, 1.0021, 1.0020, 1.0059, 0.9994,\n",
            "        1.0046, 0.9971, 1.0093, 0.9899, 1.0001, 0.9979, 0.9988, 1.0011, 1.0062,\n",
            "        1.0017, 0.9945, 1.0042, 0.9992, 0.9978, 1.0047, 0.9994, 0.9974, 0.9939,\n",
            "        0.9952, 0.9955, 0.9956, 1.0020, 1.0091, 1.0018, 1.0019, 0.9956, 0.9932,\n",
            "        1.0037], device='cuda:0')\n",
            "encoder.layers.6.norm1.bias: tensor([-3.6615e-04,  5.2188e-04,  4.7003e-05, -2.5959e-03, -8.7825e-04,\n",
            "         2.5780e-03,  2.2333e-03,  1.3298e-03,  6.6389e-04, -2.1892e-06,\n",
            "         1.1389e-04,  5.5403e-05, -3.3193e-04, -7.0122e-04,  1.0023e-03,\n",
            "         1.7872e-04,  1.4634e-03,  2.7428e-04, -5.2200e-05,  1.1531e-03,\n",
            "         1.8154e-03, -1.4686e-03, -1.1270e-03, -8.1530e-04, -2.0581e-04,\n",
            "        -1.8575e-03, -2.7326e-04,  3.2022e-05, -9.9859e-04, -9.2874e-05,\n",
            "         1.4583e-03, -2.4873e-04, -4.9083e-04, -1.8860e-04, -5.9424e-04,\n",
            "        -1.7565e-04, -1.9005e-04, -1.6387e-03, -4.5003e-04,  1.5105e-03,\n",
            "         7.2623e-04,  8.7279e-04,  7.1590e-04,  1.4423e-04, -2.0271e-04,\n",
            "        -1.2617e-03, -7.8798e-04, -1.7740e-04,  7.6527e-04, -3.5145e-04,\n",
            "        -1.1156e-03, -8.9653e-04,  1.9590e-03, -1.7295e-03, -2.8547e-04,\n",
            "        -4.5045e-04, -7.2565e-04,  1.5399e-03,  7.8215e-04,  7.3189e-04,\n",
            "         5.2568e-04, -5.7141e-04, -2.1193e-03, -2.3476e-03], device='cuda:0')\n",
            "encoder.layers.6.norm2.weight: tensor([1.0037, 1.0011, 1.0000, 1.0087, 0.9965, 0.9918, 0.9959, 0.9985, 0.9946,\n",
            "        0.9948, 0.9952, 1.0050, 1.0064, 1.0049, 1.0019, 1.0017, 1.0073, 1.0027,\n",
            "        1.0007, 1.0063, 1.0085, 1.0063, 0.9938, 0.9941, 1.0007, 0.9992, 1.0073,\n",
            "        0.9959, 1.0050, 0.9999, 1.0027, 1.0083, 1.0011, 1.0015, 1.0045, 1.0005,\n",
            "        1.0060, 0.9979, 1.0097, 0.9901, 0.9997, 0.9986, 0.9969, 0.9999, 1.0039,\n",
            "        1.0033, 0.9981, 1.0037, 1.0001, 0.9973, 1.0071, 1.0004, 1.0012, 0.9965,\n",
            "        0.9934, 0.9913, 0.9975, 1.0002, 1.0123, 1.0011, 1.0009, 0.9997, 0.9964,\n",
            "        1.0046], device='cuda:0')\n",
            "encoder.layers.6.norm2.bias: tensor([-1.1493e-03,  7.8282e-04, -2.2510e-04, -2.5379e-03,  8.7140e-05,\n",
            "         1.8591e-03,  1.6439e-03,  1.0655e-03, -3.1185e-04,  3.6053e-04,\n",
            "         1.1392e-04, -4.3366e-04, -9.8735e-04,  6.1097e-04, -4.5222e-04,\n",
            "        -1.8645e-04, -9.1168e-05,  1.1428e-03,  7.0697e-04,  1.3673e-03,\n",
            "         1.2812e-03, -1.0907e-03, -1.0574e-04, -7.4390e-04, -1.4233e-04,\n",
            "        -1.6333e-03, -5.7422e-04, -1.8347e-03,  8.0453e-04, -1.4784e-03,\n",
            "         6.7100e-05,  1.4969e-03,  8.0068e-04, -3.5458e-04, -9.1595e-04,\n",
            "         2.2498e-04, -6.8778e-04, -2.4104e-03,  2.8078e-04,  9.1193e-04,\n",
            "         5.1631e-04,  3.9352e-04,  9.5618e-04, -9.2610e-04, -9.1156e-04,\n",
            "         4.6084e-04, -1.1898e-04,  6.9639e-04,  7.1395e-04,  5.7624e-05,\n",
            "        -1.8133e-03, -1.0821e-03,  2.8029e-03, -3.6518e-04,  1.9434e-04,\n",
            "        -4.1560e-04, -1.3463e-03,  1.1488e-03,  2.4023e-04,  3.4358e-04,\n",
            "         7.8785e-04, -5.8006e-04, -1.4781e-03, -1.9887e-03], device='cuda:0')\n",
            "encoder.layers.7.attn.w_q.weight: tensor([[ 0.0738, -0.0653, -0.1075,  ..., -0.0763,  0.1220, -0.1035],\n",
            "        [-0.0986,  0.0490,  0.1113,  ..., -0.0612,  0.1119,  0.1254],\n",
            "        [ 0.0349, -0.0679, -0.0017,  ...,  0.0360,  0.0966,  0.0193],\n",
            "        ...,\n",
            "        [-0.0093, -0.0329, -0.1203,  ...,  0.0226,  0.0309, -0.0627],\n",
            "        [-0.0886, -0.1124,  0.0603,  ...,  0.1171,  0.0596, -0.1148],\n",
            "        [ 0.1217,  0.0666,  0.0059,  ...,  0.0688, -0.0949,  0.0207]],\n",
            "       device='cuda:0')\n",
            "encoder.layers.7.attn.w_k.weight: tensor([[-0.0709, -0.0385,  0.0166,  ..., -0.0437,  0.0807,  0.1024],\n",
            "        [-0.0125, -0.1247, -0.0749,  ...,  0.1112,  0.1183,  0.0960],\n",
            "        [ 0.0299,  0.1224,  0.1083,  ..., -0.0794, -0.0615,  0.0249],\n",
            "        ...,\n",
            "        [ 0.0597,  0.0968,  0.1223,  ...,  0.0662, -0.0935, -0.0203],\n",
            "        [-0.0913, -0.0976, -0.0710,  ..., -0.0165, -0.1001,  0.0695],\n",
            "        [ 0.0309,  0.0432, -0.0830,  ...,  0.0498, -0.0542, -0.0735]],\n",
            "       device='cuda:0')\n",
            "encoder.layers.7.attn.w_v.weight: tensor([[-0.0224, -0.0736,  0.0635,  ...,  0.0619,  0.1026, -0.0938],\n",
            "        [-0.0593, -0.0480,  0.0011,  ..., -0.0568,  0.0878,  0.1018],\n",
            "        [ 0.0363, -0.0646,  0.0074,  ...,  0.0714, -0.0548, -0.0772],\n",
            "        ...,\n",
            "        [-0.0037,  0.0596,  0.0017,  ..., -0.1176,  0.0876, -0.0741],\n",
            "        [ 0.0667,  0.1028,  0.0320,  ..., -0.0921, -0.0842,  0.0998],\n",
            "        [ 0.0295, -0.0048, -0.0310,  ..., -0.0737,  0.0346, -0.0434]],\n",
            "       device='cuda:0')\n",
            "encoder.layers.7.attn.w_o.weight: tensor([[-0.0205, -0.1185, -0.0966,  ...,  0.0467,  0.0528,  0.0406],\n",
            "        [ 0.0877,  0.0917,  0.1198,  ..., -0.0697, -0.0732, -0.0597],\n",
            "        [ 0.1190,  0.0611, -0.0442,  ..., -0.0639, -0.0618, -0.0069],\n",
            "        ...,\n",
            "        [ 0.0731,  0.0534, -0.0524,  ...,  0.0034,  0.0958, -0.0933],\n",
            "        [-0.0740,  0.0565, -0.0650,  ...,  0.0510,  0.1021, -0.0559],\n",
            "        [-0.0430, -0.0319,  0.1041,  ...,  0.0297, -0.0796, -0.0593]],\n",
            "       device='cuda:0')\n",
            "encoder.layers.7.ff.linear1.weight: tensor([[-0.0752,  0.0075,  0.0136,  ...,  0.0347,  0.0048,  0.0746],\n",
            "        [ 0.0956,  0.0671,  0.0049,  ...,  0.0161,  0.0643,  0.0547],\n",
            "        [ 0.1146, -0.0470, -0.0627,  ...,  0.0479,  0.1122,  0.0745],\n",
            "        ...,\n",
            "        [ 0.0126, -0.0387, -0.0311,  ...,  0.0116,  0.0704, -0.0192],\n",
            "        [-0.0686, -0.0894, -0.0444,  ..., -0.0023, -0.0898,  0.0565],\n",
            "        [-0.0554, -0.0632, -0.0840,  ...,  0.0291,  0.0108, -0.0336]],\n",
            "       device='cuda:0')\n",
            "encoder.layers.7.ff.linear1.bias: tensor([ 0.0780,  0.0681, -0.0245,  0.0898,  0.0294,  0.0849,  0.0212,  0.0630,\n",
            "         0.0614,  0.0544, -0.0657,  0.0817, -0.0485, -0.0301,  0.0859, -0.0954,\n",
            "         0.1144, -0.1073,  0.1079, -0.1107,  0.0711,  0.0796, -0.1004,  0.0606,\n",
            "        -0.0119,  0.0042, -0.0206,  0.0743,  0.0340,  0.0444,  0.0937, -0.0859,\n",
            "        -0.0486,  0.0531, -0.0975, -0.0543,  0.1212,  0.1102, -0.0588, -0.0645,\n",
            "         0.1030,  0.0822,  0.0502, -0.0656, -0.1138, -0.1177,  0.0911, -0.0638,\n",
            "        -0.0637, -0.0353,  0.0418, -0.0216,  0.1029,  0.0596,  0.0966, -0.0228,\n",
            "        -0.0573, -0.0599,  0.0715, -0.0017, -0.0968,  0.0986,  0.1250,  0.0325,\n",
            "        -0.1170,  0.0119,  0.0429,  0.0853,  0.0621,  0.0019, -0.0096, -0.0509,\n",
            "        -0.1003, -0.0734, -0.0695,  0.0991, -0.0868, -0.0815,  0.0996, -0.0082,\n",
            "         0.0369, -0.0242, -0.0607,  0.0114, -0.1018,  0.0922,  0.0717,  0.0264,\n",
            "        -0.0794, -0.0871, -0.0202,  0.0091, -0.0949,  0.0967,  0.0769, -0.1148,\n",
            "         0.1107,  0.1116, -0.0004,  0.0854, -0.0409,  0.0100,  0.0855,  0.0831,\n",
            "         0.0781, -0.0918, -0.0231, -0.0932, -0.1282, -0.0863,  0.1168,  0.0811,\n",
            "        -0.1042, -0.0618,  0.0697, -0.0814,  0.0393,  0.0802,  0.0816,  0.0375,\n",
            "         0.0085, -0.0279, -0.0653,  0.0546, -0.1061, -0.0839, -0.0669, -0.0495,\n",
            "        -0.0256, -0.0531, -0.0303, -0.0897, -0.0548, -0.1111,  0.0927, -0.1200,\n",
            "        -0.1165, -0.1107, -0.0610,  0.1160, -0.0007, -0.1121, -0.0782, -0.0950,\n",
            "         0.0339, -0.0312,  0.0166, -0.0877, -0.0314, -0.0268,  0.0979, -0.0282,\n",
            "         0.1015, -0.1016,  0.0897, -0.0115,  0.0020,  0.0907, -0.0862,  0.0965,\n",
            "         0.0762,  0.0114,  0.0881,  0.0938, -0.1061,  0.0320, -0.0303, -0.1149,\n",
            "        -0.0434,  0.0144,  0.0747, -0.1198,  0.0078,  0.0364,  0.0353,  0.0137,\n",
            "        -0.0563, -0.0264, -0.0072,  0.0585, -0.1159, -0.1197, -0.0331, -0.0707,\n",
            "        -0.1090,  0.0704, -0.0691,  0.0121, -0.0363,  0.0456, -0.0802,  0.1011,\n",
            "        -0.0892,  0.0976, -0.0074, -0.0603,  0.0900, -0.0254,  0.1099, -0.0955,\n",
            "         0.1047, -0.1116,  0.0157, -0.0920, -0.1052, -0.0392, -0.0333, -0.0973,\n",
            "        -0.1079, -0.1121,  0.0314, -0.0677,  0.0246,  0.0894,  0.0375,  0.0021,\n",
            "         0.0677, -0.0360,  0.0105,  0.0367, -0.0265, -0.0827,  0.1111,  0.0755,\n",
            "        -0.0462, -0.0961, -0.0607,  0.1152, -0.0337, -0.0472,  0.0934,  0.1037,\n",
            "         0.0658,  0.0644,  0.0171,  0.0856, -0.0430, -0.1056,  0.0302,  0.0290,\n",
            "        -0.0090,  0.0818,  0.0003, -0.0304,  0.0873,  0.1160,  0.0185, -0.0483,\n",
            "        -0.0993,  0.0800, -0.0945,  0.0352, -0.1013,  0.0733, -0.1116, -0.0248,\n",
            "        -0.0694,  0.0085,  0.1064, -0.0291, -0.0597,  0.1171, -0.1202,  0.0940,\n",
            "         0.0092,  0.0895, -0.1248,  0.0291, -0.0301, -0.0669, -0.1240,  0.0140,\n",
            "         0.0595, -0.1213, -0.0156,  0.0712,  0.0696, -0.0065, -0.0425,  0.0016,\n",
            "         0.0999,  0.0111,  0.1116, -0.0472, -0.0042, -0.0282,  0.0530, -0.0944,\n",
            "        -0.0875,  0.0509, -0.0457,  0.0366, -0.0258,  0.0306, -0.0891,  0.0524,\n",
            "         0.1054,  0.1085, -0.0562, -0.0003, -0.0759,  0.0020,  0.0572,  0.0422,\n",
            "        -0.0320, -0.0979,  0.0573, -0.0522,  0.1076, -0.0636,  0.0058,  0.1034,\n",
            "        -0.0283,  0.0657, -0.1013,  0.0635, -0.0691,  0.0963, -0.0782,  0.0030,\n",
            "        -0.0593, -0.1062,  0.0496, -0.0866,  0.0686,  0.0516, -0.0564, -0.0153,\n",
            "        -0.0205,  0.0411, -0.0881, -0.1204, -0.0706,  0.0372, -0.1274,  0.0714,\n",
            "        -0.0245,  0.0667, -0.0303, -0.0938,  0.0160,  0.0928,  0.0467,  0.0946,\n",
            "        -0.0028, -0.0613,  0.0166, -0.0618, -0.0300, -0.0209, -0.0074, -0.0648,\n",
            "         0.1082,  0.1125, -0.0800,  0.1156, -0.0387,  0.1152, -0.0679, -0.0735,\n",
            "        -0.0696,  0.1136, -0.0418,  0.0547,  0.1065,  0.0614, -0.1239, -0.0518,\n",
            "         0.0707,  0.1145, -0.0245, -0.0054, -0.1173, -0.0389,  0.0024,  0.0354,\n",
            "         0.0608, -0.0365,  0.0513, -0.1039,  0.0387, -0.0209,  0.0076,  0.1034,\n",
            "         0.0538, -0.0633, -0.1075,  0.0347, -0.0746,  0.0671, -0.0208, -0.0534,\n",
            "        -0.0732, -0.0283, -0.0388, -0.1192, -0.0464, -0.1172,  0.0557,  0.0059,\n",
            "        -0.0734, -0.0028, -0.0764,  0.0859, -0.1084, -0.0374,  0.0782, -0.0253,\n",
            "         0.0844,  0.0425, -0.0351,  0.0704,  0.0002, -0.0131,  0.0043, -0.1143,\n",
            "         0.0498, -0.0684, -0.0295, -0.0746, -0.0172, -0.0685,  0.0010,  0.0069,\n",
            "         0.0773,  0.0233,  0.0467, -0.1135,  0.0224, -0.0435,  0.0390,  0.0843,\n",
            "        -0.0513, -0.0119,  0.0484,  0.0271,  0.0594,  0.0964, -0.0342, -0.0377,\n",
            "         0.0526, -0.0174, -0.0741, -0.0887,  0.0642, -0.1065,  0.0590, -0.0927,\n",
            "        -0.0445,  0.0026,  0.1059,  0.0772, -0.1179,  0.0942,  0.0705, -0.0444,\n",
            "         0.0283,  0.0283, -0.0951,  0.0632,  0.1167,  0.0964, -0.0009,  0.1001,\n",
            "         0.0178, -0.0520,  0.0103, -0.0433, -0.1174,  0.0722, -0.0598, -0.0197,\n",
            "        -0.1108, -0.0166,  0.0594, -0.0621, -0.0519, -0.0027, -0.1194, -0.1115,\n",
            "        -0.0123, -0.0415, -0.0407,  0.0638, -0.0546, -0.0273, -0.0458,  0.0923,\n",
            "         0.0132, -0.0031,  0.0082,  0.0202,  0.0316,  0.1125, -0.0400,  0.1139,\n",
            "         0.0452, -0.1060, -0.0602, -0.1165,  0.1047,  0.1146,  0.0656,  0.0585,\n",
            "        -0.0894, -0.0314,  0.1008, -0.0842, -0.0835, -0.0020, -0.0897,  0.0813],\n",
            "       device='cuda:0')\n",
            "encoder.layers.7.ff.linear2.weight: tensor([[-0.0095,  0.0145, -0.0352,  ...,  0.0029, -0.0464, -0.0204],\n",
            "        [ 0.0156,  0.0350,  0.0050,  ...,  0.0390,  0.0369,  0.0232],\n",
            "        [-0.0229,  0.0043, -0.0175,  ...,  0.0408,  0.0008,  0.0021],\n",
            "        ...,\n",
            "        [ 0.0300, -0.0322, -0.0302,  ...,  0.0091,  0.0328, -0.0037],\n",
            "        [ 0.0235, -0.0020, -0.0366,  ...,  0.0363, -0.0139, -0.0364],\n",
            "        [-0.0255,  0.0202, -0.0299,  ...,  0.0002, -0.0301, -0.0219]],\n",
            "       device='cuda:0')\n",
            "encoder.layers.7.ff.linear2.bias: tensor([-2.8012e-02, -2.9016e-02, -3.4822e-02,  4.9221e-03,  2.2242e-03,\n",
            "        -2.1017e-02,  2.4450e-02,  2.3957e-03, -1.6882e-02, -4.0634e-02,\n",
            "         2.4709e-02, -2.6997e-02, -5.6178e-03, -1.4721e-02, -1.0367e-03,\n",
            "        -3.0995e-02,  1.7540e-02,  7.5506e-03, -3.3517e-02,  1.7204e-03,\n",
            "        -4.1953e-02, -2.2416e-02,  7.1904e-03,  3.6719e-02,  1.6647e-02,\n",
            "         2.3004e-02, -1.8648e-02,  2.4206e-02,  4.4720e-02,  3.4626e-03,\n",
            "         2.6068e-02,  4.2912e-02, -1.0982e-02, -2.6554e-02, -1.0934e-02,\n",
            "        -2.5197e-02, -5.2979e-03,  9.1655e-05,  3.0477e-02, -1.6165e-02,\n",
            "         3.1754e-02, -3.6823e-02,  1.5006e-02, -2.5555e-02, -3.1126e-02,\n",
            "         2.1814e-02,  4.4100e-02, -4.1715e-02,  1.3001e-02,  3.9671e-02,\n",
            "         4.3309e-02,  4.1723e-02,  2.4309e-02, -3.0790e-02, -3.5986e-02,\n",
            "        -1.0609e-02, -4.0505e-02, -3.8607e-02, -1.8122e-02,  3.5046e-02,\n",
            "         8.1699e-03, -8.7038e-04, -6.0628e-03,  3.7052e-02], device='cuda:0')\n",
            "encoder.layers.7.norm1.weight: tensor([1.0029, 1.0030, 0.9971, 1.0093, 0.9955, 0.9902, 0.9967, 0.9997, 0.9968,\n",
            "        0.9956, 0.9949, 1.0057, 1.0001, 1.0052, 1.0031, 1.0027, 1.0047, 1.0022,\n",
            "        1.0028, 1.0053, 1.0035, 1.0020, 0.9945, 1.0001, 0.9992, 0.9989, 1.0068,\n",
            "        0.9976, 1.0043, 0.9970, 1.0076, 1.0056, 0.9998, 1.0005, 1.0047, 0.9963,\n",
            "        1.0043, 0.9994, 1.0098, 0.9937, 0.9974, 0.9957, 0.9956, 1.0035, 1.0021,\n",
            "        1.0014, 0.9950, 0.9982, 0.9977, 0.9987, 1.0062, 0.9989, 1.0003, 1.0002,\n",
            "        0.9902, 0.9862, 0.9946, 0.9993, 1.0122, 0.9985, 0.9979, 1.0027, 0.9974,\n",
            "        1.0060], device='cuda:0')\n",
            "encoder.layers.7.norm1.bias: tensor([-1.6336e-03,  3.8321e-04, -8.6014e-04, -3.1823e-03,  7.7075e-04,\n",
            "         1.8826e-03,  2.6100e-03,  1.6778e-03,  4.6609e-04,  3.3341e-04,\n",
            "        -7.5161e-05, -1.0271e-03, -2.5640e-04,  4.1905e-04, -1.2388e-04,\n",
            "         3.5358e-04,  5.3332e-04,  8.4585e-04, -4.3164e-04,  1.4285e-03,\n",
            "        -5.4381e-04, -2.0067e-03, -1.0267e-03, -2.8255e-04,  3.3775e-04,\n",
            "        -1.7866e-03,  8.0371e-04, -9.0856e-04,  3.1268e-04, -7.1612e-04,\n",
            "        -9.0703e-04,  3.0779e-03,  3.6030e-04,  8.3365e-04, -1.5901e-03,\n",
            "        -2.4507e-06, -4.0334e-04, -3.7170e-03,  6.3100e-04,  1.5294e-03,\n",
            "        -5.3395e-05,  1.4726e-03,  8.2389e-04,  5.9905e-04, -6.2542e-04,\n",
            "         3.5771e-04, -2.0472e-04,  1.4377e-03,  1.6489e-03, -2.0561e-04,\n",
            "        -1.2679e-03, -2.0790e-03,  2.3612e-03, -1.1768e-03,  1.5733e-03,\n",
            "        -1.5160e-03, -2.2672e-03,  8.1156e-04, -5.7670e-04,  2.3337e-04,\n",
            "         3.1010e-04, -6.5040e-05, -2.4849e-03, -9.5679e-04], device='cuda:0')\n",
            "encoder.layers.7.norm2.weight: tensor([1.0076, 1.0200, 1.0111, 1.0220, 1.0107, 1.0109, 1.0157, 1.0073, 1.0046,\n",
            "        1.0098, 1.0126, 1.0214, 1.0172, 1.0172, 1.0175, 1.0176, 1.0311, 1.0186,\n",
            "        1.0285, 1.0096, 1.0259, 1.0144, 1.0078, 1.0134, 1.0143, 1.0102, 1.0153,\n",
            "        1.0107, 1.0163, 1.0160, 1.0184, 1.0191, 1.0179, 1.0186, 1.0150, 1.0016,\n",
            "        1.0271, 1.0105, 1.0215, 1.0064, 1.0129, 1.0050, 1.0109, 1.0191, 1.0111,\n",
            "        1.0244, 1.0131, 1.0239, 1.0138, 1.0130, 1.0165, 1.0143, 1.0241, 1.0150,\n",
            "        1.0058, 1.0046, 1.0147, 1.0089, 1.0239, 1.0126, 1.0160, 1.0234, 1.0149,\n",
            "        1.0235], device='cuda:0')\n",
            "encoder.layers.7.norm2.bias: tensor([ 2.1744e-03,  5.2625e-03,  2.2140e-03,  2.3813e-03,  4.7683e-03,\n",
            "         4.8583e-03, -6.4965e-04,  4.1248e-03,  4.7302e-06,  2.0015e-03,\n",
            "        -6.2680e-03,  2.6352e-03,  2.5074e-03, -7.1091e-04, -7.4132e-05,\n",
            "        -2.2633e-03, -3.9224e-03,  3.9525e-03,  1.1699e-03,  8.0180e-04,\n",
            "        -5.7180e-04, -1.5143e-03,  1.8006e-03,  2.8842e-03,  2.7189e-03,\n",
            "        -8.6547e-04, -1.5084e-04, -1.9917e-03,  6.3094e-04,  2.4870e-03,\n",
            "         1.7169e-03, -3.3580e-03,  8.6901e-04,  7.1251e-03, -5.5705e-04,\n",
            "         6.7784e-04, -1.8081e-03, -1.5842e-03, -5.2938e-03,  1.2813e-03,\n",
            "        -1.6258e-03, -1.3811e-03,  7.2592e-03, -3.2447e-03,  1.0012e-03,\n",
            "         9.6168e-04, -6.6720e-04, -9.5053e-04,  2.9144e-03,  1.6371e-03,\n",
            "         3.5405e-03, -4.6112e-03,  3.4043e-04,  2.8780e-03,  1.9225e-04,\n",
            "         1.7309e-03, -1.1289e-03, -9.1631e-05, -1.0672e-02,  1.6606e-03,\n",
            "         7.9518e-04,  2.4955e-03,  1.1484e-03,  1.2343e-03], device='cuda:0')\n",
            "decoder.embedding.weight: tensor([[ 0.7267, -1.8694,  0.5902,  ...,  0.1153, -1.7312, -1.9450],\n",
            "        [ 0.1911, -2.1912, -0.2177,  ...,  0.2085,  0.8643,  0.2764],\n",
            "        [ 1.4106,  0.3828, -0.1263,  ..., -0.5693, -0.2987, -0.3673],\n",
            "        ...,\n",
            "        [-0.5909,  0.7206,  1.0587,  ..., -0.7846,  1.4097, -0.6570],\n",
            "        [-0.8559, -0.8682,  1.5666,  ..., -1.2956, -0.7445,  0.8606],\n",
            "        [ 0.1922, -0.8284, -0.0784,  ...,  0.4435,  1.6992, -1.4234]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.0.self_attn.w_q.weight: tensor([[-0.0772, -0.1207,  0.0197,  ..., -0.0526,  0.0079, -0.1120],\n",
            "        [-0.1309,  0.0939, -0.0449,  ..., -0.0006, -0.1310,  0.1190],\n",
            "        [ 0.1094, -0.1028,  0.0110,  ...,  0.0420, -0.0262, -0.0740],\n",
            "        ...,\n",
            "        [ 0.0935,  0.0971,  0.0424,  ..., -0.0659, -0.0276,  0.0278],\n",
            "        [ 0.0540,  0.0788,  0.0452,  ..., -0.1239,  0.0178,  0.0339],\n",
            "        [ 0.0570, -0.0868, -0.0967,  ...,  0.0596,  0.0722, -0.0326]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.0.self_attn.w_k.weight: tensor([[-0.1345, -0.1112,  0.1272,  ...,  0.0413,  0.0784, -0.1047],\n",
            "        [ 0.0438, -0.0708,  0.0356,  ..., -0.1259, -0.0088, -0.0373],\n",
            "        [-0.0309,  0.0691, -0.0799,  ...,  0.0358, -0.0515,  0.0046],\n",
            "        ...,\n",
            "        [ 0.0826,  0.0519, -0.0733,  ..., -0.0632, -0.0035, -0.0867],\n",
            "        [ 0.0572, -0.0579,  0.0333,  ..., -0.0535,  0.0575,  0.0097],\n",
            "        [ 0.0093, -0.0878,  0.0792,  ...,  0.1531, -0.0702, -0.0025]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.0.self_attn.w_v.weight: tensor([[-0.0310, -0.0571,  0.0009,  ..., -0.1322,  0.0649, -0.0482],\n",
            "        [ 0.0216,  0.0145,  0.1038,  ...,  0.0188, -0.0465,  0.0857],\n",
            "        [ 0.1061,  0.0358,  0.0678,  ..., -0.0828,  0.0590, -0.0444],\n",
            "        ...,\n",
            "        [-0.0368, -0.1120,  0.0491,  ...,  0.0996,  0.1220,  0.0349],\n",
            "        [ 0.0934,  0.0722, -0.0720,  ..., -0.0996, -0.0889,  0.0153],\n",
            "        [ 0.1138,  0.0991,  0.0144,  ...,  0.0314,  0.0912,  0.0641]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.0.self_attn.w_o.weight: tensor([[-0.0016,  0.0352, -0.1154,  ...,  0.0223, -0.0651,  0.1060],\n",
            "        [ 0.0981, -0.0065, -0.0737,  ...,  0.0118,  0.0350,  0.0823],\n",
            "        [ 0.0283,  0.1105, -0.0552,  ...,  0.0823, -0.0665,  0.0086],\n",
            "        ...,\n",
            "        [-0.0099, -0.1097, -0.0730,  ..., -0.1005, -0.1001, -0.0639],\n",
            "        [ 0.0730, -0.0109,  0.0234,  ..., -0.0892,  0.0524, -0.0408],\n",
            "        [-0.0117,  0.0674, -0.0823,  ..., -0.1029,  0.0876, -0.0035]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.0.enc_attn.w_q.weight: tensor([[-0.0442,  0.0018, -0.1153,  ...,  0.0599, -0.0461,  0.0990],\n",
            "        [-0.0323, -0.0760, -0.0960,  ..., -0.0217, -0.0838, -0.0298],\n",
            "        [ 0.1094,  0.0743, -0.0202,  ..., -0.0843,  0.0182, -0.0293],\n",
            "        ...,\n",
            "        [-0.0224,  0.1356, -0.0428,  ..., -0.0957,  0.1137, -0.0285],\n",
            "        [ 0.1093, -0.1349,  0.0310,  ..., -0.0461, -0.0259,  0.0706],\n",
            "        [-0.0505, -0.0494,  0.0681,  ..., -0.0437, -0.1197, -0.0986]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.0.enc_attn.w_k.weight: tensor([[-0.0235,  0.0362,  0.0793,  ...,  0.0589, -0.0946,  0.1030],\n",
            "        [ 0.1095, -0.0039, -0.0994,  ..., -0.0185, -0.1084, -0.0999],\n",
            "        [-0.0435,  0.0394,  0.0934,  ..., -0.0763, -0.0894, -0.0999],\n",
            "        ...,\n",
            "        [ 0.0133,  0.0663,  0.0719,  ..., -0.1323, -0.1216,  0.0289],\n",
            "        [-0.0588, -0.1027, -0.0862,  ...,  0.0750,  0.0021, -0.1213],\n",
            "        [-0.0622, -0.0685,  0.0187,  ..., -0.0113,  0.0562, -0.0018]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.0.enc_attn.w_v.weight: tensor([[ 0.0153,  0.1241,  0.0458,  ...,  0.1001,  0.0749, -0.0542],\n",
            "        [ 0.0897,  0.0561,  0.0066,  ...,  0.0064,  0.0324,  0.1057],\n",
            "        [ 0.0230, -0.1018,  0.0975,  ...,  0.0833,  0.0453,  0.0035],\n",
            "        ...,\n",
            "        [-0.0106,  0.0931, -0.0669,  ..., -0.0185,  0.0080, -0.0837],\n",
            "        [-0.0918,  0.0328, -0.0402,  ...,  0.0138,  0.0214,  0.0935],\n",
            "        [ 0.0491,  0.1177, -0.0553,  ...,  0.0211,  0.0828, -0.0109]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.0.enc_attn.w_o.weight: tensor([[-0.0757, -0.0553,  0.0069,  ..., -0.0021,  0.1199,  0.1173],\n",
            "        [-0.0071,  0.1022, -0.0542,  ..., -0.1015, -0.0080, -0.1120],\n",
            "        [ 0.0445,  0.0858, -0.0700,  ..., -0.0641,  0.1228,  0.0963],\n",
            "        ...,\n",
            "        [ 0.0498,  0.0411,  0.0610,  ..., -0.1075, -0.0353, -0.0439],\n",
            "        [ 0.0309, -0.0648, -0.0248,  ...,  0.0287,  0.0597, -0.1021],\n",
            "        [ 0.0014, -0.0993, -0.0946,  ...,  0.0575, -0.0162,  0.0731]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.0.ff.linear1.weight: tensor([[ 0.0895, -0.0999, -0.0505,  ...,  0.0820, -0.0296,  0.0020],\n",
            "        [-0.0794, -0.0419,  0.0614,  ..., -0.0731,  0.0401,  0.0789],\n",
            "        [-0.1250,  0.1157, -0.0528,  ...,  0.0716, -0.0417, -0.1078],\n",
            "        ...,\n",
            "        [-0.0495, -0.0670, -0.1213,  ...,  0.0179, -0.0226, -0.0326],\n",
            "        [ 0.0943,  0.0416,  0.1087,  ..., -0.0272,  0.0954, -0.0721],\n",
            "        [-0.0710,  0.0154,  0.0457,  ..., -0.1302, -0.0456,  0.0716]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.0.ff.linear1.bias: tensor([-0.0240, -0.0901,  0.0976, -0.0715,  0.1224, -0.0107, -0.0789, -0.0363,\n",
            "         0.0507,  0.0115, -0.0453, -0.0706, -0.0651, -0.0429, -0.0468,  0.1003,\n",
            "        -0.0708, -0.1165, -0.0404, -0.0540,  0.0644,  0.1165,  0.0396, -0.1107,\n",
            "        -0.0342,  0.0909, -0.0929, -0.0768, -0.0632,  0.0839,  0.0201, -0.0498,\n",
            "         0.0575, -0.0075,  0.1183,  0.0666,  0.0282,  0.0175, -0.1160, -0.0983,\n",
            "         0.0564,  0.0264,  0.0218, -0.0542,  0.1084, -0.1054, -0.0956,  0.0467,\n",
            "         0.0502,  0.1264,  0.0940,  0.1213,  0.0325,  0.0353,  0.0044, -0.0970,\n",
            "         0.0429,  0.0204,  0.0698,  0.0852, -0.0008, -0.0551,  0.0234,  0.0397,\n",
            "        -0.0296,  0.0724,  0.0244, -0.0785, -0.0904,  0.0599,  0.0101, -0.0436,\n",
            "         0.1042,  0.1041, -0.0287,  0.1116, -0.1106,  0.0522, -0.1155, -0.0514,\n",
            "        -0.0528, -0.1098,  0.1314,  0.0406,  0.0649,  0.0393, -0.0684,  0.1184,\n",
            "        -0.0767,  0.0580,  0.0032,  0.0626, -0.0172,  0.0712, -0.1081,  0.0278,\n",
            "        -0.0273, -0.0433,  0.0223, -0.0101, -0.0377,  0.0263,  0.0574, -0.0718,\n",
            "         0.1140, -0.0857,  0.0911, -0.0748,  0.0132,  0.0456, -0.0676, -0.0781,\n",
            "        -0.0465, -0.0293, -0.0847, -0.0454, -0.0002, -0.0701, -0.0122, -0.0656,\n",
            "        -0.0496, -0.0315,  0.0646,  0.0126, -0.0831, -0.0023,  0.0674,  0.0573,\n",
            "         0.0031,  0.0541, -0.0505, -0.0473,  0.0248, -0.0841, -0.0929,  0.0332,\n",
            "         0.1209, -0.1109,  0.0468,  0.0588, -0.0301, -0.0005, -0.0078,  0.0566,\n",
            "         0.1046,  0.0534, -0.1184, -0.0397, -0.1022,  0.0794, -0.0239, -0.0908,\n",
            "         0.0853,  0.0705,  0.0957,  0.0518,  0.0865, -0.0904,  0.1361,  0.0115,\n",
            "         0.0306,  0.0392,  0.0940, -0.0577, -0.0011,  0.0162,  0.0025,  0.0138,\n",
            "        -0.1026, -0.0319, -0.0841,  0.0209,  0.0124,  0.0945, -0.1032, -0.0916,\n",
            "         0.0882,  0.1065, -0.0406,  0.0923,  0.0141,  0.0905, -0.1237,  0.0110,\n",
            "         0.1205,  0.0519, -0.1011,  0.0983,  0.0039,  0.0148, -0.0743, -0.1106,\n",
            "        -0.0088, -0.0016, -0.0730, -0.0183, -0.0045,  0.0649,  0.1159,  0.1206,\n",
            "         0.1117,  0.0696, -0.0881, -0.0311,  0.0926, -0.0189,  0.1401,  0.0341,\n",
            "         0.1247,  0.1052,  0.0577,  0.0042,  0.1177, -0.0517, -0.1054, -0.0937,\n",
            "        -0.0925, -0.0600, -0.0013, -0.1054,  0.0158,  0.1093,  0.0358, -0.0052,\n",
            "        -0.0295, -0.0735, -0.0413,  0.0537,  0.0881, -0.0126,  0.1093,  0.0020,\n",
            "         0.0378,  0.0514, -0.0639,  0.1041, -0.1227,  0.0560,  0.0980,  0.0421,\n",
            "         0.0647, -0.0008, -0.0072,  0.0522,  0.0239,  0.0314,  0.0935,  0.0560,\n",
            "         0.0861, -0.1047, -0.0948, -0.0763, -0.0878,  0.0561, -0.0621, -0.0159,\n",
            "         0.1048,  0.1027,  0.0271, -0.0768, -0.0976,  0.0679, -0.0834,  0.0434,\n",
            "        -0.1053, -0.0033, -0.0856, -0.0500, -0.0735, -0.0285,  0.0003,  0.0342,\n",
            "         0.0453, -0.0149, -0.0831, -0.0298, -0.0717,  0.0817, -0.1092, -0.0038,\n",
            "         0.0393,  0.0886,  0.0213,  0.0065,  0.0507, -0.0640,  0.0088, -0.0693,\n",
            "         0.0162, -0.0060, -0.1112,  0.0846,  0.0186,  0.0573, -0.0770, -0.0572,\n",
            "         0.0942,  0.1087, -0.1035, -0.0040,  0.0426,  0.0555,  0.0909,  0.0531,\n",
            "        -0.0348,  0.0176,  0.0828,  0.0470,  0.0654, -0.0098,  0.0561,  0.0455,\n",
            "         0.0279,  0.0249, -0.1091, -0.1162,  0.1089,  0.0900, -0.0370, -0.0998,\n",
            "        -0.0565,  0.0775, -0.0610, -0.0773,  0.1086,  0.0471,  0.0695, -0.0193,\n",
            "        -0.0400, -0.0985, -0.0611,  0.0075,  0.0802, -0.0988,  0.0614, -0.0984,\n",
            "         0.1081, -0.0628,  0.0676, -0.0482, -0.0353,  0.0199, -0.0249, -0.0115,\n",
            "         0.0172,  0.1187,  0.0181,  0.0025,  0.0674,  0.0857, -0.0764, -0.0698,\n",
            "        -0.0542, -0.0941,  0.0409,  0.1203, -0.0149,  0.0149,  0.0003,  0.1214,\n",
            "        -0.1062, -0.0258, -0.0620, -0.0072, -0.0780,  0.0816,  0.0187, -0.0200,\n",
            "        -0.0122, -0.0637, -0.0831,  0.0209,  0.1079,  0.0571, -0.1031,  0.0354,\n",
            "         0.0996,  0.1219, -0.0610,  0.0165, -0.0506, -0.0941, -0.0781, -0.0247,\n",
            "        -0.0816, -0.0076, -0.0311,  0.1267, -0.0256,  0.1066, -0.0414,  0.0529,\n",
            "         0.0257, -0.0709,  0.0153, -0.0855,  0.0847,  0.1206, -0.0467,  0.0201,\n",
            "        -0.0626, -0.0795,  0.0072,  0.1036,  0.0995, -0.1134, -0.0074, -0.0463,\n",
            "         0.0290, -0.0477,  0.0829, -0.0525,  0.0598,  0.0678,  0.0979, -0.1200,\n",
            "         0.0213, -0.1056, -0.0652,  0.0956,  0.0107,  0.0788,  0.0107,  0.0904,\n",
            "         0.0499, -0.0883, -0.0112, -0.1163, -0.0992,  0.0881,  0.1117, -0.0103,\n",
            "         0.0844, -0.0231, -0.0410, -0.1050, -0.1145, -0.0229, -0.0468,  0.0019,\n",
            "         0.0408, -0.0377,  0.0392,  0.1004, -0.0736,  0.0599,  0.0771, -0.0533,\n",
            "         0.0430, -0.1039,  0.0449,  0.0658, -0.0809, -0.0982, -0.1240, -0.1244,\n",
            "         0.0351, -0.1324,  0.0843,  0.1013, -0.0853, -0.0181,  0.0060, -0.0785,\n",
            "        -0.0316,  0.1011, -0.0614, -0.0731, -0.0995,  0.0934,  0.0149,  0.1183,\n",
            "        -0.0160, -0.0178,  0.1116,  0.0923,  0.0390,  0.0352, -0.1114,  0.0406,\n",
            "         0.0054,  0.0515, -0.0082, -0.0301,  0.0728, -0.0304, -0.0958,  0.1245,\n",
            "        -0.1167, -0.0331,  0.0068,  0.1040,  0.0130, -0.0917, -0.0372,  0.0881,\n",
            "        -0.0226,  0.0598, -0.1150,  0.0636,  0.0045,  0.0239,  0.0977,  0.0122,\n",
            "         0.1251, -0.0079,  0.1206, -0.0817, -0.0498, -0.0040,  0.1154,  0.0822],\n",
            "       device='cuda:0')\n",
            "decoder.layers.0.ff.linear2.weight: tensor([[-0.0140, -0.0461, -0.0205,  ...,  0.0420, -0.0070,  0.0093],\n",
            "        [-0.0303,  0.0161,  0.0060,  ..., -0.0189, -0.0165,  0.0560],\n",
            "        [ 0.0023, -0.0237,  0.0063,  ..., -0.0279,  0.0220,  0.0284],\n",
            "        ...,\n",
            "        [-0.0245, -0.0371,  0.0336,  ..., -0.0340, -0.0391,  0.0256],\n",
            "        [ 0.0072, -0.0246, -0.0417,  ...,  0.0085, -0.0354,  0.0288],\n",
            "        [-0.0148,  0.0342,  0.0480,  ...,  0.0250,  0.0205, -0.0028]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.0.ff.linear2.bias: tensor([-0.0069, -0.0427,  0.0107, -0.0141, -0.0298,  0.0355,  0.0358, -0.0022,\n",
            "        -0.0250, -0.0023, -0.0331, -0.0129, -0.0138,  0.0113,  0.0170, -0.0418,\n",
            "        -0.0141, -0.0014,  0.0222, -0.0410,  0.0363, -0.0203,  0.0074,  0.0392,\n",
            "         0.0365,  0.0277,  0.0085, -0.0202, -0.0200, -0.0211, -0.0177, -0.0111,\n",
            "        -0.0085,  0.0183, -0.0396,  0.0415, -0.0186,  0.0051,  0.0309,  0.0238,\n",
            "         0.0017, -0.0323,  0.0402,  0.0024,  0.0135,  0.0037, -0.0108, -0.0350,\n",
            "        -0.0208,  0.0027, -0.0121, -0.0366, -0.0250,  0.0296, -0.0079,  0.0255,\n",
            "         0.0402,  0.0142,  0.0247,  0.0393, -0.0211, -0.0034, -0.0102, -0.0381],\n",
            "       device='cuda:0')\n",
            "decoder.layers.0.norm1.weight: tensor([0.9930, 0.9942, 0.9924, 1.0032, 0.9977, 1.0003, 1.0128, 1.0027, 0.9958,\n",
            "        1.0103, 1.0035, 1.0063, 0.9978, 1.0174, 1.0140, 0.9826, 1.0117, 1.0043,\n",
            "        0.9904, 1.0099, 1.0097, 0.9910, 0.9872, 1.0130, 1.0176, 0.9950, 1.0111,\n",
            "        1.0043, 0.9934, 0.9971, 0.9877, 0.9980, 1.0108, 1.0118, 1.0097, 1.0261,\n",
            "        1.0105, 1.0025, 1.0095, 1.0150, 1.0121, 1.0010, 1.0023, 1.0118, 0.9857,\n",
            "        1.0035, 1.0240, 1.0077, 0.9995, 0.9957, 0.9988, 1.0031, 1.0108, 0.9905,\n",
            "        1.0017, 1.0082, 1.0032, 0.9893, 1.0030, 1.0133, 1.0056, 1.0002, 1.0055,\n",
            "        1.0111], device='cuda:0')\n",
            "decoder.layers.0.norm1.bias: tensor([-0.0004, -0.0012,  0.0055, -0.0011,  0.0034, -0.0005,  0.0039,  0.0019,\n",
            "        -0.0062,  0.0039,  0.0029, -0.0009, -0.0040, -0.0048, -0.0016, -0.0093,\n",
            "        -0.0003, -0.0082,  0.0087, -0.0024, -0.0032, -0.0103, -0.0025, -0.0021,\n",
            "        -0.0004, -0.0048,  0.0085, -0.0033,  0.0082, -0.0034,  0.0045, -0.0083,\n",
            "         0.0094, -0.0118,  0.0048, -0.0025,  0.0020, -0.0078, -0.0026,  0.0004,\n",
            "         0.0049, -0.0004,  0.0039, -0.0040,  0.0159, -0.0109, -0.0007, -0.0049,\n",
            "         0.0009, -0.0094,  0.0080, -0.0074, -0.0051, -0.0027,  0.0092,  0.0037,\n",
            "        -0.0033, -0.0063,  0.0097, -0.0003,  0.0029,  0.0023,  0.0054,  0.0010],\n",
            "       device='cuda:0')\n",
            "decoder.layers.0.norm2.weight: tensor([0.9913, 0.9916, 0.9915, 1.0002, 0.9970, 1.0014, 1.0128, 1.0000, 0.9964,\n",
            "        1.0038, 1.0050, 1.0037, 0.9944, 1.0134, 1.0105, 0.9821, 1.0094, 1.0041,\n",
            "        0.9891, 1.0069, 1.0076, 0.9907, 0.9913, 1.0110, 1.0124, 0.9950, 1.0123,\n",
            "        1.0027, 0.9966, 0.9934, 0.9881, 0.9950, 1.0094, 1.0135, 1.0096, 1.0233,\n",
            "        1.0099, 1.0030, 1.0067, 1.0114, 1.0127, 1.0002, 1.0009, 1.0110, 0.9845,\n",
            "        1.0031, 1.0193, 1.0113, 0.9988, 0.9931, 0.9974, 0.9998, 1.0099, 0.9909,\n",
            "        0.9975, 1.0059, 1.0005, 0.9876, 1.0014, 1.0106, 1.0033, 1.0007, 1.0057,\n",
            "        1.0045], device='cuda:0')\n",
            "decoder.layers.0.norm2.bias: tensor([-4.7194e-04, -1.4969e-03,  5.3512e-03, -1.0579e-03,  3.7256e-03,\n",
            "        -9.6660e-04,  3.8837e-03,  2.2108e-03, -6.3410e-03,  3.5655e-03,\n",
            "         3.0825e-03, -7.2384e-04, -3.5705e-03, -4.6230e-03, -1.0063e-03,\n",
            "        -9.1966e-03, -5.5089e-04, -8.9851e-03,  9.0864e-03, -2.3532e-03,\n",
            "        -3.2123e-03, -1.0758e-02, -2.5625e-03, -2.3459e-03, -9.1858e-04,\n",
            "        -4.7700e-03,  8.7358e-03, -3.6598e-03,  8.5391e-03, -3.9209e-03,\n",
            "         5.1797e-03, -8.4749e-03,  8.9825e-03, -1.1306e-02,  4.2236e-03,\n",
            "        -2.1459e-03,  1.8449e-03, -7.9661e-03, -2.7634e-03,  8.3224e-04,\n",
            "         4.2385e-03, -8.7164e-05,  3.2457e-03, -4.9710e-03,  1.5846e-02,\n",
            "        -1.1010e-02, -1.2010e-03, -5.4862e-03,  1.5016e-03, -9.6426e-03,\n",
            "         8.0703e-03, -7.0640e-03, -4.9270e-03, -2.8015e-03,  1.0050e-02,\n",
            "         3.2035e-03, -3.7080e-03, -5.9001e-03,  1.0079e-02,  3.6156e-04,\n",
            "         2.5752e-03,  2.1916e-03,  5.1683e-03,  1.4629e-03], device='cuda:0')\n",
            "decoder.layers.0.norm3.weight: tensor([0.9933, 1.0062, 1.0022, 1.0083, 0.9999, 1.0089, 1.0038, 1.0075, 0.9995,\n",
            "        1.0075, 1.0056, 1.0042, 0.9977, 1.0137, 1.0058, 0.9822, 1.0022, 0.9906,\n",
            "        0.9907, 0.9986, 1.0025, 0.9979, 0.9930, 1.0073, 1.0077, 0.9907, 1.0077,\n",
            "        1.0053, 1.0007, 0.9937, 0.9948, 1.0008, 1.0141, 1.0153, 1.0095, 1.0087,\n",
            "        1.0025, 1.0068, 1.0012, 1.0120, 1.0037, 0.9951, 0.9957, 1.0115, 0.9923,\n",
            "        0.9967, 1.0081, 1.0103, 0.9996, 0.9957, 0.9983, 1.0013, 1.0122, 0.9981,\n",
            "        0.9954, 1.0064, 1.0052, 0.9938, 1.0114, 1.0105, 1.0053, 1.0006, 1.0078,\n",
            "        1.0061], device='cuda:0')\n",
            "decoder.layers.0.norm3.bias: tensor([-8.4691e-04, -4.4738e-03,  2.2632e-03, -2.1362e-03,  6.4738e-03,\n",
            "        -3.8018e-03,  3.1586e-03,  4.6901e-03, -3.4689e-03,  4.7137e-03,\n",
            "         2.2588e-03, -2.0170e-03, -1.4872e-03, -1.9687e-03,  3.4025e-04,\n",
            "        -5.4417e-03, -3.1903e-03, -1.2799e-02,  6.7763e-03,  1.3500e-03,\n",
            "        -2.6195e-03, -6.8603e-03, -6.5398e-04, -4.2800e-04, -1.0420e-03,\n",
            "        -3.1813e-03,  3.9399e-03, -4.0925e-03,  5.3288e-03, -2.5391e-03,\n",
            "         3.2307e-03, -2.6489e-03,  5.6403e-03, -2.5341e-03,  6.8747e-04,\n",
            "         2.9150e-03,  4.4240e-04, -6.9008e-03, -3.1364e-03,  1.9078e-03,\n",
            "         5.1742e-03,  1.6523e-03, -1.9415e-03, -6.9698e-04,  1.0808e-02,\n",
            "        -9.5396e-03,  1.7199e-03, -4.4595e-03, -6.1670e-05, -3.4437e-03,\n",
            "         5.7485e-03, -2.7405e-03, -3.7988e-03, -1.0193e-03,  4.3699e-03,\n",
            "         4.7622e-03, -2.4386e-03, -5.4842e-03,  6.4208e-03,  2.8840e-03,\n",
            "         4.1742e-03,  2.0895e-03,  3.7501e-03,  1.9048e-03], device='cuda:0')\n",
            "decoder.layers.1.self_attn.w_q.weight: tensor([[-0.1034, -0.1277, -0.0514,  ...,  0.0080, -0.1121,  0.0704],\n",
            "        [-0.1101,  0.0047, -0.0169,  ..., -0.1225, -0.0045, -0.0397],\n",
            "        [-0.0870, -0.0951,  0.0779,  ...,  0.0978, -0.0948,  0.0909],\n",
            "        ...,\n",
            "        [-0.0969, -0.0968, -0.0429,  ...,  0.0556,  0.0527, -0.0528],\n",
            "        [-0.0398, -0.0874,  0.0356,  ...,  0.0460, -0.0883,  0.1254],\n",
            "        [-0.0208,  0.0771,  0.0366,  ..., -0.0024,  0.1004, -0.0632]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.1.self_attn.w_k.weight: tensor([[ 0.0427, -0.0162,  0.0655,  ..., -0.1189, -0.0141, -0.0863],\n",
            "        [ 0.1135, -0.0404,  0.0226,  ...,  0.0945,  0.1049,  0.0908],\n",
            "        [ 0.0370,  0.1151,  0.0390,  ..., -0.0142,  0.1329, -0.0136],\n",
            "        ...,\n",
            "        [ 0.0366,  0.0826,  0.0917,  ..., -0.0763,  0.1247,  0.1003],\n",
            "        [ 0.0090,  0.0987,  0.0527,  ..., -0.1416,  0.0034, -0.1310],\n",
            "        [ 0.1193,  0.1164, -0.0362,  ..., -0.0124, -0.0221, -0.1138]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.1.self_attn.w_v.weight: tensor([[-0.0006,  0.0783,  0.1122,  ...,  0.0133, -0.0336, -0.0953],\n",
            "        [ 0.0968,  0.0730,  0.0635,  ..., -0.0718, -0.0976,  0.0075],\n",
            "        [ 0.0710,  0.1311,  0.0628,  ..., -0.0419,  0.0701,  0.0620],\n",
            "        ...,\n",
            "        [ 0.0036, -0.0891,  0.1172,  ...,  0.0062,  0.0815, -0.0622],\n",
            "        [-0.1192, -0.0652,  0.0633,  ..., -0.0143, -0.0527, -0.0334],\n",
            "        [-0.0324,  0.1132,  0.0097,  ...,  0.0977,  0.0017, -0.0860]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.1.self_attn.w_o.weight: tensor([[ 0.0920, -0.0889, -0.0846,  ...,  0.0788,  0.0384,  0.1056],\n",
            "        [-0.0475, -0.1155,  0.0928,  ..., -0.0997, -0.0009, -0.0520],\n",
            "        [ 0.0182,  0.0712,  0.0059,  ..., -0.0031,  0.0659, -0.0895],\n",
            "        ...,\n",
            "        [ 0.0992,  0.0916,  0.0735,  ..., -0.0485,  0.0225,  0.0168],\n",
            "        [ 0.0011,  0.0763, -0.0877,  ...,  0.1199,  0.0923,  0.0770],\n",
            "        [-0.0885, -0.0212, -0.0939,  ..., -0.0116, -0.0827, -0.1186]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.1.enc_attn.w_q.weight: tensor([[-0.0510, -0.0837, -0.0211,  ..., -0.0116,  0.0142,  0.0234],\n",
            "        [ 0.0275, -0.0505,  0.0428,  ..., -0.0707, -0.0975,  0.0526],\n",
            "        [ 0.0268,  0.0152, -0.0487,  ...,  0.0524,  0.0879,  0.0533],\n",
            "        ...,\n",
            "        [-0.0381,  0.0282, -0.0103,  ..., -0.0118, -0.0018, -0.0972],\n",
            "        [-0.0537,  0.0213, -0.0806,  ...,  0.0027, -0.1081,  0.0536],\n",
            "        [-0.1153, -0.0454,  0.1147,  ...,  0.0649,  0.1164,  0.1030]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.1.enc_attn.w_k.weight: tensor([[ 0.0870, -0.0930,  0.0075,  ..., -0.0557,  0.0842, -0.0577],\n",
            "        [-0.0470,  0.0799,  0.1097,  ..., -0.0900, -0.0495,  0.0796],\n",
            "        [ 0.0995,  0.0189,  0.0795,  ...,  0.1123, -0.0718,  0.0779],\n",
            "        ...,\n",
            "        [-0.0576,  0.0628, -0.0247,  ..., -0.0640,  0.0062,  0.0362],\n",
            "        [-0.0431, -0.1033, -0.0404,  ..., -0.0411, -0.0610, -0.0174],\n",
            "        [ 0.0307,  0.0350,  0.0480,  ...,  0.0951,  0.0457,  0.0788]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.1.enc_attn.w_v.weight: tensor([[ 0.0603,  0.0272, -0.0815,  ..., -0.1051,  0.0986, -0.0563],\n",
            "        [ 0.0212,  0.0818, -0.0706,  ..., -0.0233, -0.0422,  0.0168],\n",
            "        [ 0.0859,  0.1068,  0.0735,  ..., -0.0357, -0.0394, -0.1237],\n",
            "        ...,\n",
            "        [ 0.0435,  0.0637,  0.0346,  ..., -0.0484,  0.0037, -0.0152],\n",
            "        [ 0.0519,  0.1031,  0.0543,  ...,  0.0929, -0.1009, -0.0097],\n",
            "        [ 0.0787, -0.0517, -0.1014,  ..., -0.0455,  0.1202, -0.1138]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.1.enc_attn.w_o.weight: tensor([[-0.0471, -0.1091,  0.0771,  ..., -0.0561, -0.0109, -0.0280],\n",
            "        [ 0.0887, -0.0140,  0.0883,  ...,  0.0791, -0.0548, -0.1036],\n",
            "        [-0.0355,  0.0770, -0.0677,  ...,  0.0060, -0.1098,  0.0843],\n",
            "        ...,\n",
            "        [-0.1137,  0.0019, -0.0492,  ..., -0.0767,  0.0621, -0.1204],\n",
            "        [ 0.1136, -0.0078, -0.0712,  ..., -0.0110,  0.0868,  0.1056],\n",
            "        [ 0.0562, -0.0867,  0.1008,  ...,  0.1002, -0.0344,  0.0756]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.1.ff.linear1.weight: tensor([[-0.0874,  0.1103,  0.0437,  ..., -0.0824, -0.1265, -0.1051],\n",
            "        [-0.0224, -0.1223, -0.0677,  ..., -0.1023, -0.1051,  0.0812],\n",
            "        [ 0.0416, -0.0338,  0.1243,  ...,  0.0204,  0.1411,  0.1332],\n",
            "        ...,\n",
            "        [ 0.0616,  0.1368,  0.0021,  ...,  0.0758,  0.0287,  0.1006],\n",
            "        [ 0.1016,  0.1105,  0.0516,  ..., -0.0734, -0.0999,  0.0541],\n",
            "        [ 0.0999,  0.1189, -0.1239,  ...,  0.0725,  0.0299, -0.0870]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.1.ff.linear1.bias: tensor([ 0.0684, -0.0170,  0.0385, -0.0685, -0.0420,  0.1044,  0.0573,  0.0822,\n",
            "         0.0810,  0.0267,  0.1101, -0.0989,  0.0613, -0.0181, -0.0816, -0.0080,\n",
            "         0.0570,  0.0353, -0.0737,  0.0487, -0.0673,  0.1153, -0.0314,  0.0747,\n",
            "         0.1007,  0.1098,  0.0512, -0.0237,  0.0636, -0.0920, -0.1306,  0.1195,\n",
            "         0.0467,  0.0836, -0.0917, -0.0123, -0.1085,  0.0070, -0.0412, -0.1213,\n",
            "        -0.0832, -0.0410, -0.0411, -0.1047,  0.0277,  0.0173, -0.0268, -0.1201,\n",
            "         0.1106,  0.0894, -0.0270,  0.0509,  0.0767,  0.0079,  0.0836,  0.0982,\n",
            "        -0.0577,  0.0156,  0.0129,  0.0833,  0.1115, -0.1042, -0.0844, -0.0625,\n",
            "         0.0284, -0.0316,  0.0841,  0.0846,  0.0333,  0.0981, -0.0576, -0.1129,\n",
            "        -0.0735,  0.0553,  0.1116, -0.1045,  0.0460, -0.0039,  0.0624,  0.0052,\n",
            "         0.1208,  0.0965, -0.0345,  0.0636,  0.0349,  0.0766,  0.0421, -0.0940,\n",
            "        -0.0591, -0.0514,  0.0441,  0.0013,  0.0909, -0.0393,  0.0601, -0.0168,\n",
            "        -0.0915, -0.0928, -0.1136,  0.0744, -0.1059,  0.0121, -0.0857, -0.0348,\n",
            "        -0.0347, -0.0016, -0.0913, -0.0386, -0.0324,  0.0805,  0.0712, -0.1016,\n",
            "        -0.0333,  0.0307,  0.0324,  0.1169, -0.0698,  0.0396,  0.1178,  0.0239,\n",
            "        -0.0101,  0.0212, -0.0582, -0.0854, -0.0162, -0.0659, -0.0051,  0.0798,\n",
            "         0.0291,  0.0194, -0.0451, -0.1024, -0.0901,  0.0602,  0.0474,  0.1055,\n",
            "         0.0322, -0.0409, -0.0540, -0.0827, -0.0719,  0.1074,  0.0454, -0.0815,\n",
            "         0.0130, -0.0766, -0.1236,  0.1035, -0.1010, -0.1230,  0.0397, -0.0821,\n",
            "        -0.1121, -0.0362,  0.1084, -0.0535, -0.0896, -0.0630, -0.0468,  0.1207,\n",
            "        -0.0190, -0.0688,  0.0963, -0.0434, -0.0693,  0.0814,  0.0576,  0.0778,\n",
            "        -0.0547,  0.1150, -0.0598, -0.1109, -0.1118, -0.0531,  0.0265,  0.0565,\n",
            "         0.1013, -0.0601,  0.0644,  0.0890,  0.0599,  0.1254,  0.0103, -0.0612,\n",
            "        -0.1052, -0.1153, -0.0192, -0.1027,  0.1154,  0.1366, -0.0491, -0.1037,\n",
            "        -0.1087,  0.0355,  0.0442, -0.1203,  0.0234, -0.0930, -0.0271,  0.1145,\n",
            "         0.0847,  0.0681, -0.0686,  0.0686,  0.0735,  0.0954,  0.1044, -0.1075,\n",
            "         0.0299,  0.0043,  0.0367,  0.0688,  0.0138, -0.1094,  0.0660, -0.1166,\n",
            "        -0.0968, -0.0526, -0.0549,  0.0209,  0.1255,  0.0624, -0.1130, -0.0018,\n",
            "        -0.1106, -0.0206, -0.0762,  0.0440,  0.0999, -0.0161,  0.0537, -0.0262,\n",
            "         0.0241,  0.0153, -0.1030, -0.0621,  0.0015,  0.1088,  0.0339,  0.0892,\n",
            "         0.0909,  0.0423,  0.0535, -0.1108,  0.0492,  0.0261,  0.1188, -0.1296,\n",
            "         0.0936, -0.0768, -0.0872, -0.0959,  0.0125,  0.0930, -0.0821, -0.1191,\n",
            "        -0.0422,  0.0366,  0.0463, -0.0161, -0.0990, -0.0004,  0.0128,  0.0901,\n",
            "         0.0311,  0.0271,  0.0294, -0.0174,  0.0146, -0.0978, -0.0015,  0.1234,\n",
            "         0.0861,  0.0065, -0.0727,  0.1121, -0.0640, -0.0876,  0.0458, -0.0962,\n",
            "         0.0197, -0.0017,  0.0608, -0.0596, -0.0184,  0.1229,  0.1339,  0.0098,\n",
            "         0.0020, -0.1129, -0.0470,  0.0725,  0.0852, -0.0982,  0.0818, -0.0237,\n",
            "        -0.0488,  0.1144, -0.0464, -0.1005,  0.0494,  0.0922,  0.0549, -0.0399,\n",
            "         0.0834, -0.0309, -0.0417, -0.0375, -0.0421,  0.0737,  0.0733, -0.0252,\n",
            "        -0.0484, -0.0772,  0.0991, -0.0967,  0.1174,  0.0565, -0.0521, -0.0269,\n",
            "         0.0310, -0.0550,  0.0695,  0.0587,  0.0218,  0.1138, -0.0525,  0.1097,\n",
            "        -0.0537,  0.0026,  0.0297,  0.0365, -0.0925, -0.0881,  0.0507,  0.0405,\n",
            "        -0.0470,  0.0386,  0.1182,  0.0732, -0.0888, -0.0006, -0.0408, -0.0299,\n",
            "         0.0911,  0.1096,  0.0940,  0.0743,  0.0766,  0.0035, -0.1168,  0.1033,\n",
            "        -0.0269,  0.0970,  0.0193,  0.0836, -0.1012, -0.0352, -0.0022, -0.1034,\n",
            "         0.1090, -0.0787, -0.0889, -0.0881,  0.0739,  0.0858,  0.1029,  0.0216,\n",
            "         0.0015, -0.0060, -0.0528,  0.1242, -0.0287, -0.0799, -0.0157,  0.0860,\n",
            "        -0.0783, -0.0018,  0.0703,  0.0648,  0.0793, -0.0320, -0.0190,  0.0327,\n",
            "         0.1077, -0.0494, -0.0950,  0.0662,  0.1106, -0.1002, -0.0015, -0.0777,\n",
            "         0.0634, -0.0394,  0.0731, -0.0964, -0.0778,  0.0940,  0.0866,  0.0094,\n",
            "        -0.1153, -0.0563, -0.0271, -0.1121, -0.1130, -0.0121,  0.0352, -0.0922,\n",
            "        -0.0948,  0.0329,  0.0456,  0.0129, -0.0869,  0.0345, -0.0667, -0.1196,\n",
            "         0.1069,  0.0371,  0.0999, -0.0335, -0.1038,  0.1064, -0.0709,  0.1252,\n",
            "         0.0046,  0.0753,  0.1304, -0.0440,  0.0807,  0.0104, -0.1019,  0.0068,\n",
            "        -0.0533,  0.0311,  0.1127, -0.0297, -0.0982,  0.1015, -0.0633,  0.0748,\n",
            "        -0.1190, -0.0437,  0.0212,  0.0694,  0.1358,  0.0146,  0.0502, -0.0210,\n",
            "         0.0834,  0.0131,  0.0981, -0.0224, -0.0978, -0.0140,  0.0730, -0.0428,\n",
            "        -0.0289,  0.0431, -0.0281, -0.0195,  0.0258,  0.0114, -0.1032, -0.1172,\n",
            "         0.1108, -0.0518,  0.1223, -0.0581, -0.0394,  0.1039, -0.1169, -0.0019,\n",
            "         0.0135,  0.0930, -0.0883, -0.0280, -0.1153, -0.0603, -0.1225, -0.0564,\n",
            "        -0.0519,  0.0203,  0.0764,  0.0680, -0.0597, -0.1222,  0.0625, -0.0764,\n",
            "        -0.1178, -0.0300, -0.0175,  0.1078, -0.0124,  0.1200, -0.1086, -0.1142,\n",
            "         0.0476, -0.0378, -0.0772, -0.0138,  0.0875,  0.0790, -0.0478, -0.1192,\n",
            "         0.0106, -0.0276, -0.1083, -0.1142,  0.1025, -0.0017,  0.1023,  0.0240],\n",
            "       device='cuda:0')\n",
            "decoder.layers.1.ff.linear2.weight: tensor([[-0.0302, -0.0433,  0.0430,  ..., -0.0306,  0.0422,  0.0185],\n",
            "        [-0.0534, -0.0325,  0.0294,  ..., -0.0022,  0.0030, -0.0136],\n",
            "        [ 0.0091, -0.0036,  0.0089,  ...,  0.0425, -0.0227, -0.0027],\n",
            "        ...,\n",
            "        [-0.0030, -0.0291, -0.0483,  ..., -0.0221, -0.0019,  0.0349],\n",
            "        [-0.0422,  0.0236, -0.0095,  ..., -0.0387, -0.0087,  0.0130],\n",
            "        [-0.0205, -0.0400, -0.0235,  ..., -0.0415,  0.0006,  0.0512]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.1.ff.linear2.bias: tensor([ 0.0055, -0.0174, -0.0301, -0.0016,  0.0277,  0.0225, -0.0013, -0.0149,\n",
            "        -0.0024, -0.0218, -0.0155, -0.0307, -0.0183,  0.0033, -0.0208,  0.0252,\n",
            "         0.0398, -0.0319, -0.0255, -0.0085,  0.0050,  0.0086,  0.0139, -0.0332,\n",
            "         0.0332, -0.0346, -0.0094,  0.0026,  0.0131,  0.0178, -0.0380,  0.0145,\n",
            "        -0.0012, -0.0338, -0.0105,  0.0081,  0.0322,  0.0203, -0.0263,  0.0076,\n",
            "        -0.0221,  0.0205, -0.0330, -0.0320, -0.0222,  0.0057,  0.0277,  0.0179,\n",
            "        -0.0065,  0.0349,  0.0191, -0.0086,  0.0238,  0.0053, -0.0373, -0.0123,\n",
            "        -0.0203,  0.0220, -0.0051,  0.0335, -0.0410,  0.0365,  0.0238,  0.0391],\n",
            "       device='cuda:0')\n",
            "decoder.layers.1.norm1.weight: tensor([0.9980, 1.0068, 0.9988, 1.0045, 0.9966, 1.0001, 1.0071, 1.0035, 0.9975,\n",
            "        1.0048, 1.0011, 1.0035, 1.0013, 1.0073, 1.0026, 0.9862, 1.0046, 0.9947,\n",
            "        0.9950, 1.0018, 1.0049, 1.0001, 0.9930, 1.0090, 1.0112, 0.9878, 1.0099,\n",
            "        1.0045, 1.0034, 0.9973, 0.9955, 1.0029, 1.0134, 1.0188, 1.0129, 1.0019,\n",
            "        1.0008, 1.0118, 0.9972, 1.0115, 1.0002, 0.9979, 0.9963, 1.0065, 0.9917,\n",
            "        0.9983, 1.0063, 1.0127, 1.0011, 0.9972, 1.0003, 0.9977, 1.0122, 1.0028,\n",
            "        0.9980, 1.0025, 1.0023, 0.9974, 1.0113, 1.0075, 1.0107, 1.0022, 1.0050,\n",
            "        1.0098], device='cuda:0')\n",
            "decoder.layers.1.norm1.bias: tensor([ 7.6690e-04, -4.5460e-03,  5.5368e-03, -5.8398e-04,  4.3436e-03,\n",
            "        -2.9614e-03,  2.8296e-03,  3.9048e-03, -2.6981e-03,  4.4935e-03,\n",
            "         1.4288e-03,  7.1019e-04, -3.6239e-03, -6.5505e-07, -9.4613e-04,\n",
            "         2.9005e-04, -2.4164e-03, -1.0230e-02,  3.4764e-03,  1.7159e-03,\n",
            "        -2.3984e-03, -1.8744e-03, -4.8399e-04, -4.1390e-03, -1.3080e-03,\n",
            "        -3.5376e-03,  7.7872e-04, -1.6563e-03,  2.0751e-03, -3.6425e-03,\n",
            "         4.7555e-03, -1.2668e-03,  2.7759e-03,  9.0895e-04, -1.5640e-04,\n",
            "        -4.4090e-03,  2.6459e-03, -4.8064e-03,  3.8441e-03, -2.6953e-04,\n",
            "         3.3935e-03, -1.5405e-04,  5.6666e-05, -2.3181e-03,  8.8273e-03,\n",
            "        -2.1153e-03, -1.8934e-04, -4.7674e-03, -1.5694e-03, -4.5039e-03,\n",
            "         5.0973e-03, -3.5987e-03, -3.7148e-03, -2.6734e-03,  2.9326e-03,\n",
            "         2.8691e-03, -1.1150e-04, -4.9600e-03,  4.0893e-03,  1.4987e-03,\n",
            "        -2.4002e-03,  1.1499e-03,  1.5894e-03,  2.5604e-04], device='cuda:0')\n",
            "decoder.layers.1.norm2.weight: tensor([0.9965, 1.0053, 1.0003, 1.0023, 0.9959, 0.9987, 1.0047, 1.0037, 0.9966,\n",
            "        1.0013, 1.0005, 1.0051, 0.9991, 1.0062, 1.0013, 0.9867, 1.0020, 0.9988,\n",
            "        0.9913, 1.0009, 1.0026, 0.9994, 0.9907, 1.0090, 1.0090, 0.9856, 1.0079,\n",
            "        1.0022, 1.0024, 0.9958, 0.9936, 1.0029, 1.0112, 1.0187, 1.0130, 1.0012,\n",
            "        0.9979, 1.0080, 0.9963, 1.0103, 0.9996, 0.9958, 0.9950, 0.9999, 0.9923,\n",
            "        0.9957, 1.0058, 1.0118, 0.9980, 0.9957, 1.0032, 0.9973, 1.0093, 1.0009,\n",
            "        1.0009, 1.0012, 0.9999, 0.9954, 1.0060, 1.0054, 1.0071, 1.0006, 1.0053,\n",
            "        1.0079], device='cuda:0')\n",
            "decoder.layers.1.norm2.bias: tensor([-9.7852e-05, -5.2970e-03,  6.0307e-03, -7.5757e-04,  3.1168e-03,\n",
            "        -1.9589e-03,  2.8683e-03,  3.1763e-03, -2.8722e-03,  4.0987e-03,\n",
            "         1.5740e-03,  3.5705e-04, -3.1791e-03, -1.5631e-03, -1.3946e-03,\n",
            "         8.3234e-05, -2.1664e-03, -9.5519e-03,  3.7178e-03, -9.3105e-04,\n",
            "        -2.4113e-03, -2.7848e-03, -5.5288e-04, -4.9391e-03, -1.0049e-03,\n",
            "        -4.9309e-03,  9.8634e-04, -1.3810e-03,  2.5378e-03, -3.3176e-03,\n",
            "         4.8519e-03, -1.0946e-03,  3.2632e-03,  1.1853e-03,  1.0801e-04,\n",
            "        -5.6078e-03,  2.5795e-03, -4.7257e-03,  4.0979e-03, -1.8259e-03,\n",
            "         1.9841e-03,  2.6122e-04,  1.0924e-03, -1.9847e-03,  8.4867e-03,\n",
            "        -2.1305e-03, -9.2531e-04, -4.7894e-03, -1.5426e-03, -4.3226e-03,\n",
            "         4.7585e-03, -3.0238e-03, -3.4809e-03, -2.8828e-03,  3.2803e-03,\n",
            "         3.1319e-03, -2.1752e-04, -5.4257e-03,  3.6475e-03,  2.0440e-03,\n",
            "        -2.8854e-03,  6.7113e-04,  1.3011e-03,  6.9779e-04], device='cuda:0')\n",
            "decoder.layers.1.norm3.weight: tensor([0.9989, 1.0086, 1.0017, 1.0060, 1.0022, 1.0033, 0.9982, 0.9940, 1.0002,\n",
            "        1.0030, 0.9987, 1.0017, 0.9955, 1.0077, 1.0024, 0.9916, 0.9975, 0.9914,\n",
            "        0.9983, 0.9991, 0.9977, 0.9992, 0.9990, 1.0104, 1.0050, 0.9939, 1.0130,\n",
            "        1.0063, 0.9991, 1.0011, 0.9970, 1.0051, 1.0171, 1.0047, 1.0108, 0.9933,\n",
            "        0.9985, 1.0018, 0.9974, 1.0114, 1.0007, 0.9992, 0.9930, 1.0025, 0.9942,\n",
            "        0.9963, 1.0054, 1.0046, 0.9984, 0.9958, 1.0012, 0.9974, 1.0044, 1.0014,\n",
            "        1.0056, 0.9982, 1.0036, 0.9961, 0.9951, 1.0024, 1.0048, 1.0010, 1.0128,\n",
            "        1.0075], device='cuda:0')\n",
            "decoder.layers.1.norm3.bias: tensor([ 3.7914e-04, -4.4082e-03,  6.6354e-03, -1.0430e-03,  9.3635e-03,\n",
            "        -3.5050e-03,  8.2284e-04,  9.1793e-04, -1.0431e-03,  3.8888e-03,\n",
            "         2.4381e-03,  2.9007e-03, -4.4532e-05, -1.3426e-05, -2.5570e-03,\n",
            "         3.3745e-03, -4.1206e-03, -9.0258e-03, -1.9345e-04,  4.8776e-03,\n",
            "        -2.1709e-03, -9.6773e-04,  2.6486e-03, -3.4979e-03, -2.3831e-03,\n",
            "        -5.1043e-03,  6.2914e-04, -1.8322e-03,  7.8769e-04, -3.4934e-03,\n",
            "         3.1109e-03,  1.0293e-03,  3.8792e-04,  2.1812e-03, -4.2438e-04,\n",
            "        -3.3767e-03,  2.2138e-03, -4.3715e-03,  3.5840e-03,  4.9668e-04,\n",
            "         3.5646e-03,  9.3820e-04, -3.0719e-03,  8.7228e-05,  4.7553e-03,\n",
            "        -3.6217e-03,  1.1543e-03, -2.3569e-03, -3.7949e-04, -4.2424e-03,\n",
            "         3.5347e-03, -1.7787e-03, -2.8495e-03, -1.3678e-03,  2.1266e-03,\n",
            "         4.3502e-03, -7.4036e-06, -1.0488e-03,  1.0833e-03,  1.9541e-03,\n",
            "        -2.5525e-03,  1.1415e-03,  2.8155e-03,  2.3829e-04], device='cuda:0')\n",
            "decoder.layers.2.self_attn.w_q.weight: tensor([[-0.1004, -0.0769,  0.0620,  ..., -0.0356,  0.0870,  0.1360],\n",
            "        [-0.0031, -0.0991,  0.0489,  ...,  0.0287,  0.1150, -0.1011],\n",
            "        [-0.0638,  0.0605,  0.0441,  ..., -0.1072,  0.1208,  0.0496],\n",
            "        ...,\n",
            "        [-0.0898,  0.1169, -0.1012,  ..., -0.1148, -0.1065,  0.0717],\n",
            "        [ 0.0138, -0.0284, -0.0226,  ...,  0.0637,  0.1094, -0.0304],\n",
            "        [ 0.0081, -0.0257,  0.0619,  ...,  0.0527,  0.0276,  0.0618]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.2.self_attn.w_k.weight: tensor([[ 0.1032,  0.0945, -0.1000,  ...,  0.0096,  0.0592,  0.0879],\n",
            "        [ 0.1110, -0.0360, -0.0932,  ..., -0.0073, -0.0559,  0.0591],\n",
            "        [ 0.0816,  0.0383, -0.1046,  ..., -0.0140, -0.1184,  0.0225],\n",
            "        ...,\n",
            "        [-0.0035, -0.0893,  0.0105,  ...,  0.0843,  0.0541,  0.0600],\n",
            "        [ 0.0454,  0.0511,  0.0629,  ...,  0.1288,  0.0015,  0.1164],\n",
            "        [ 0.0723, -0.0642, -0.0870,  ..., -0.1193, -0.0481,  0.1152]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.2.self_attn.w_v.weight: tensor([[ 0.0789, -0.1069, -0.1175,  ..., -0.1058, -0.0042, -0.0641],\n",
            "        [ 0.0350,  0.0422, -0.0144,  ...,  0.0289, -0.1001, -0.0021],\n",
            "        [ 0.0763, -0.0715,  0.0253,  ..., -0.0537, -0.0332, -0.0375],\n",
            "        ...,\n",
            "        [-0.0772, -0.1305, -0.0513,  ...,  0.0289,  0.1206, -0.0117],\n",
            "        [-0.0464,  0.0174,  0.0630,  ..., -0.0876,  0.0454, -0.0083],\n",
            "        [-0.0196, -0.0575,  0.0129,  ..., -0.0337,  0.0691, -0.0055]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.2.self_attn.w_o.weight: tensor([[-0.0801, -0.1089, -0.0927,  ..., -0.0776, -0.0185, -0.0004],\n",
            "        [-0.0660, -0.0926,  0.0622,  ...,  0.1227, -0.0718, -0.0166],\n",
            "        [ 0.0930,  0.0278,  0.0326,  ..., -0.0872,  0.1237, -0.0035],\n",
            "        ...,\n",
            "        [-0.0441, -0.0788, -0.1045,  ...,  0.0290,  0.0451,  0.0649],\n",
            "        [-0.0308, -0.0154,  0.0195,  ..., -0.1251, -0.0807,  0.1244],\n",
            "        [ 0.0137, -0.0004, -0.0967,  ..., -0.1135, -0.0949,  0.0256]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.2.enc_attn.w_q.weight: tensor([[-0.1008, -0.0537, -0.1232,  ..., -0.0447,  0.1082,  0.0762],\n",
            "        [-0.0582,  0.0972, -0.0013,  ...,  0.0446, -0.0072,  0.0947],\n",
            "        [-0.0682,  0.1187, -0.0701,  ...,  0.0818,  0.1126,  0.0566],\n",
            "        ...,\n",
            "        [-0.0769,  0.1290,  0.0015,  ...,  0.0082, -0.0116,  0.0136],\n",
            "        [ 0.0462,  0.0901, -0.0105,  ..., -0.0980,  0.0856,  0.0184],\n",
            "        [-0.1066, -0.0589, -0.0497,  ..., -0.1052, -0.1052, -0.0377]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.2.enc_attn.w_k.weight: tensor([[ 0.0644,  0.0773, -0.1083,  ...,  0.0775,  0.0312, -0.0467],\n",
            "        [-0.0115,  0.0290,  0.0277,  ...,  0.0360, -0.0139, -0.0261],\n",
            "        [-0.0926,  0.0887,  0.0778,  ...,  0.0450,  0.0746,  0.1391],\n",
            "        ...,\n",
            "        [ 0.1069,  0.1026,  0.0761,  ..., -0.0999,  0.0389, -0.0086],\n",
            "        [ 0.0203,  0.0012, -0.1251,  ..., -0.1141, -0.0746,  0.0318],\n",
            "        [-0.0988,  0.0201, -0.1026,  ..., -0.0384, -0.0220, -0.0751]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.2.enc_attn.w_v.weight: tensor([[ 0.0156, -0.0948, -0.0409,  ..., -0.0906,  0.1022,  0.0049],\n",
            "        [-0.0215,  0.1189,  0.0324,  ..., -0.1171, -0.0266,  0.0488],\n",
            "        [-0.0968,  0.0863, -0.0207,  ...,  0.0901, -0.0129,  0.0108],\n",
            "        ...,\n",
            "        [ 0.0173,  0.0298, -0.0030,  ..., -0.0973,  0.0727, -0.0666],\n",
            "        [-0.0558, -0.0245,  0.1086,  ...,  0.1240, -0.0266, -0.0454],\n",
            "        [-0.0009, -0.0326,  0.0298,  ..., -0.0752,  0.0331,  0.0911]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.2.enc_attn.w_o.weight: tensor([[-0.0072, -0.0538, -0.1266,  ...,  0.1099,  0.0457, -0.0127],\n",
            "        [ 0.0779, -0.0958,  0.0886,  ..., -0.0581,  0.0074, -0.0174],\n",
            "        [ 0.1104,  0.0308, -0.1029,  ..., -0.1003,  0.0520,  0.0019],\n",
            "        ...,\n",
            "        [-0.0785, -0.0147, -0.0334,  ..., -0.0426, -0.0006, -0.0232],\n",
            "        [-0.0669,  0.0116,  0.0026,  ...,  0.0879, -0.0219, -0.0422],\n",
            "        [-0.0179,  0.1183, -0.0398,  ..., -0.1038, -0.0562, -0.0039]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.2.ff.linear1.weight: tensor([[ 0.0596,  0.1003,  0.0138,  ..., -0.0972,  0.1407, -0.0380],\n",
            "        [ 0.0007,  0.0765,  0.1234,  ...,  0.0968,  0.0303,  0.0914],\n",
            "        [-0.0247,  0.0710,  0.0417,  ..., -0.0190, -0.0373,  0.0620],\n",
            "        ...,\n",
            "        [ 0.0575,  0.0912,  0.0874,  ..., -0.0619,  0.1022,  0.0454],\n",
            "        [ 0.1385,  0.0647, -0.0510,  ..., -0.0308,  0.0440, -0.1189],\n",
            "        [-0.0031,  0.0970,  0.0924,  ...,  0.1123, -0.0330,  0.1231]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.2.ff.linear1.bias: tensor([-0.1242, -0.1256, -0.0267, -0.0631,  0.0987, -0.0310,  0.0698, -0.0190,\n",
            "        -0.0526, -0.0967, -0.0127,  0.1028, -0.1130, -0.0517, -0.0466, -0.0280,\n",
            "         0.0546, -0.1080,  0.0861, -0.0074, -0.0423,  0.0841,  0.0460, -0.0800,\n",
            "         0.0742, -0.0957, -0.0376, -0.0708,  0.0002, -0.0647,  0.1238, -0.0254,\n",
            "        -0.1137, -0.0030, -0.0572, -0.0190, -0.0956, -0.0489, -0.0974,  0.0796,\n",
            "        -0.0889, -0.0472,  0.0553, -0.1234,  0.0411, -0.1058, -0.1144, -0.0255,\n",
            "         0.0564,  0.0825, -0.1213, -0.0700,  0.1063,  0.0938, -0.0062, -0.0971,\n",
            "         0.0632, -0.0859, -0.0052,  0.1266, -0.1161, -0.0796,  0.0800,  0.0321,\n",
            "        -0.1183,  0.0344,  0.0389, -0.0630, -0.0004,  0.0948, -0.0298, -0.0438,\n",
            "        -0.0253, -0.1246, -0.0537, -0.0538, -0.0022, -0.1174, -0.0358,  0.0125,\n",
            "        -0.0279,  0.1194,  0.0427, -0.0683,  0.1139,  0.0424, -0.0851, -0.0959,\n",
            "        -0.1072, -0.0176,  0.0522, -0.1133,  0.0404,  0.1127, -0.0930, -0.0433,\n",
            "         0.0936, -0.1213,  0.0490, -0.0762,  0.0191, -0.0008, -0.0716, -0.0580,\n",
            "         0.1042,  0.0994,  0.0658, -0.0495, -0.1099,  0.0491,  0.1081, -0.0473,\n",
            "        -0.0808,  0.0598, -0.1013,  0.0120,  0.0477,  0.0664,  0.1053,  0.1293,\n",
            "         0.1119,  0.1095,  0.0499, -0.1133, -0.0267, -0.0883,  0.0966, -0.0036,\n",
            "        -0.1114, -0.0203,  0.0598, -0.0089, -0.0146,  0.0316,  0.0731,  0.0159,\n",
            "         0.0956,  0.0359, -0.0052, -0.0392,  0.0822, -0.0438,  0.0167,  0.0660,\n",
            "         0.1222,  0.1066,  0.0414,  0.1200, -0.0215, -0.1119,  0.1171,  0.1035,\n",
            "        -0.1165,  0.0794,  0.0411,  0.0954, -0.0444, -0.0749,  0.1004,  0.0872,\n",
            "         0.1114,  0.0038, -0.0849, -0.0311,  0.0249,  0.0866,  0.1027,  0.0781,\n",
            "        -0.0118,  0.0950, -0.0583, -0.0771,  0.1163,  0.0894,  0.0824, -0.1231,\n",
            "         0.0496, -0.0014,  0.0197,  0.0635,  0.0844,  0.0455,  0.1145,  0.1101,\n",
            "        -0.0025, -0.0157,  0.0374,  0.0251, -0.1110, -0.0156,  0.0103,  0.0118,\n",
            "         0.0022,  0.0870,  0.1118, -0.0833, -0.0717,  0.0222, -0.1227,  0.0790,\n",
            "        -0.1043, -0.1113, -0.0734, -0.0190,  0.0354,  0.1226, -0.1135,  0.0771,\n",
            "         0.1003, -0.1042, -0.0869, -0.0883,  0.0291, -0.1098,  0.0525, -0.0967,\n",
            "        -0.0873, -0.0378,  0.1047, -0.0374, -0.0285,  0.1098, -0.0469,  0.1056,\n",
            "        -0.0276,  0.0483, -0.0730, -0.0070, -0.0598, -0.0289,  0.1322, -0.1113,\n",
            "         0.0726, -0.0316,  0.0797,  0.1213,  0.0981,  0.0118, -0.1377,  0.1048,\n",
            "        -0.0344, -0.0880,  0.0769, -0.0691,  0.0647, -0.0024,  0.0712, -0.0545,\n",
            "         0.0033,  0.0587,  0.0378,  0.1129, -0.0468, -0.1052,  0.0257,  0.0922,\n",
            "         0.0574,  0.0980, -0.0364,  0.1050,  0.0562,  0.0176,  0.0873, -0.0532,\n",
            "        -0.1005,  0.0505,  0.0390, -0.0860, -0.0722,  0.0538, -0.0619,  0.0733,\n",
            "        -0.0815, -0.1023, -0.1152, -0.0954,  0.0250,  0.0673,  0.0048, -0.0040,\n",
            "         0.0034,  0.1026, -0.0351, -0.0362, -0.0661, -0.0337, -0.0785,  0.0570,\n",
            "        -0.1252,  0.0969, -0.0741,  0.0966,  0.0154,  0.0712,  0.0509, -0.0436,\n",
            "         0.0747,  0.0486, -0.0337,  0.0639,  0.0502,  0.0348, -0.1164, -0.0950,\n",
            "         0.1172,  0.0875, -0.0276, -0.0640, -0.0115, -0.1155,  0.0411, -0.0409,\n",
            "        -0.0775,  0.0879,  0.0789,  0.0898,  0.1189, -0.0271,  0.0712, -0.1069,\n",
            "        -0.0758, -0.0382, -0.0986,  0.0598, -0.1216,  0.0848, -0.0567, -0.0819,\n",
            "        -0.0474, -0.0002, -0.0706,  0.0525,  0.1089, -0.1131,  0.0247, -0.0097,\n",
            "         0.1012,  0.0279, -0.0622, -0.0689,  0.0354, -0.0311, -0.0212,  0.0984,\n",
            "        -0.0319,  0.0017,  0.1083,  0.0969, -0.0049, -0.0852,  0.1099,  0.0432,\n",
            "         0.0063,  0.0259,  0.0337, -0.0554,  0.0484, -0.0230, -0.1129, -0.0585,\n",
            "        -0.0745,  0.0952, -0.0052, -0.0297, -0.0684, -0.0854, -0.0548,  0.0311,\n",
            "        -0.0680, -0.0693, -0.0151,  0.0219, -0.0605, -0.0428, -0.0755, -0.0885,\n",
            "         0.0141,  0.1256, -0.0129,  0.1158,  0.1052, -0.0565, -0.0233, -0.0362,\n",
            "         0.0894,  0.0852,  0.0187, -0.0751,  0.0410,  0.1010,  0.0974,  0.0635,\n",
            "        -0.1020,  0.0915,  0.0752, -0.1045,  0.0210, -0.0948, -0.0284, -0.1233,\n",
            "        -0.0672, -0.0353,  0.1172,  0.1212,  0.1029, -0.1077,  0.0810, -0.0294,\n",
            "         0.0922,  0.0621,  0.0026,  0.0745,  0.0804,  0.0281, -0.1148,  0.0102,\n",
            "        -0.0844,  0.0417,  0.1209, -0.1057,  0.0441,  0.0868, -0.0268,  0.0440,\n",
            "         0.0960,  0.0321,  0.1073, -0.0146, -0.1017,  0.1050,  0.0243, -0.0646,\n",
            "        -0.0994, -0.0405,  0.1083, -0.1019,  0.1166, -0.0190,  0.0513,  0.0625,\n",
            "         0.0085,  0.0366,  0.0208, -0.0671,  0.0179,  0.0830,  0.1193,  0.0589,\n",
            "         0.0206, -0.0469,  0.0142, -0.0595, -0.0986,  0.0879,  0.0980, -0.0288,\n",
            "         0.0373, -0.0794,  0.0024, -0.0773,  0.0915,  0.0382, -0.0173, -0.0626,\n",
            "        -0.0086, -0.0666,  0.0521,  0.0121,  0.1013, -0.1094,  0.0537,  0.0142,\n",
            "         0.0503, -0.1078,  0.0062, -0.0709, -0.0360,  0.0944, -0.0147, -0.0374,\n",
            "        -0.0434, -0.0028, -0.0189, -0.1050,  0.0477, -0.0149, -0.0708,  0.0848,\n",
            "         0.0325, -0.0963, -0.0316,  0.0493, -0.0948, -0.1165,  0.0074, -0.0787,\n",
            "        -0.0947, -0.0106, -0.0343, -0.1047, -0.0354,  0.0011, -0.0429,  0.1037,\n",
            "        -0.0200, -0.0139,  0.1042, -0.0995, -0.0884,  0.0342, -0.0879, -0.0630],\n",
            "       device='cuda:0')\n",
            "decoder.layers.2.ff.linear2.weight: tensor([[ 0.0064, -0.0006,  0.0343,  ...,  0.0021,  0.0157,  0.0294],\n",
            "        [ 0.0094,  0.0280,  0.0324,  ...,  0.0361, -0.0339, -0.0016],\n",
            "        [-0.0331,  0.0293, -0.0304,  ..., -0.0462, -0.0226,  0.0027],\n",
            "        ...,\n",
            "        [-0.0070, -0.0081,  0.0118,  ...,  0.0381, -0.0211,  0.0377],\n",
            "        [ 0.0223,  0.0245, -0.0433,  ...,  0.0012,  0.0502, -0.0410],\n",
            "        [ 0.0420,  0.0152,  0.0058,  ..., -0.0427, -0.0629, -0.0032]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.2.ff.linear2.bias: tensor([-0.0254, -0.0082,  0.0038,  0.0327,  0.0206,  0.0341,  0.0039,  0.0024,\n",
            "        -0.0097,  0.0264,  0.0321,  0.0115,  0.0173, -0.0362, -0.0072,  0.0365,\n",
            "         0.0066,  0.0010, -0.0424,  0.0161,  0.0354,  0.0301,  0.0027, -0.0326,\n",
            "        -0.0324,  0.0364,  0.0191,  0.0282,  0.0362, -0.0231,  0.0326,  0.0299,\n",
            "         0.0214, -0.0411, -0.0418, -0.0286,  0.0086,  0.0130,  0.0044, -0.0225,\n",
            "         0.0299,  0.0165,  0.0058,  0.0263,  0.0355, -0.0071, -0.0158, -0.0082,\n",
            "        -0.0389, -0.0278,  0.0268, -0.0135, -0.0264, -0.0247,  0.0297, -0.0290,\n",
            "         0.0104, -0.0186,  0.0028, -0.0315,  0.0343, -0.0249,  0.0233,  0.0263],\n",
            "       device='cuda:0')\n",
            "decoder.layers.2.norm1.weight: tensor([0.9952, 1.0046, 1.0009, 0.9969, 1.0001, 1.0020, 1.0024, 0.9979, 1.0001,\n",
            "        1.0058, 0.9955, 1.0069, 0.9999, 1.0099, 0.9979, 0.9905, 0.9959, 0.9900,\n",
            "        1.0002, 0.9990, 0.9978, 0.9952, 1.0005, 1.0087, 1.0049, 0.9960, 1.0068,\n",
            "        1.0109, 1.0005, 1.0047, 1.0078, 1.0064, 1.0122, 1.0123, 1.0133, 0.9971,\n",
            "        0.9985, 1.0122, 1.0011, 1.0094, 0.9988, 0.9964, 0.9958, 1.0023, 0.9996,\n",
            "        0.9982, 1.0088, 1.0042, 0.9986, 0.9966, 1.0002, 1.0013, 1.0018, 1.0077,\n",
            "        1.0060, 1.0025, 1.0021, 0.9975, 0.9957, 1.0083, 1.0035, 1.0036, 1.0129,\n",
            "        1.0060], device='cuda:0')\n",
            "decoder.layers.2.norm1.bias: tensor([ 5.1136e-03,  2.8952e-05,  1.0481e-03,  2.0525e-04,  7.3181e-04,\n",
            "        -2.1733e-03,  1.7607e-04,  5.4473e-04, -3.0963e-03,  5.4328e-03,\n",
            "        -9.9914e-04,  3.5934e-03,  5.7013e-04, -4.3086e-03, -1.5832e-03,\n",
            "         7.1812e-04, -2.4859e-03, -4.6993e-03, -2.4638e-03,  3.2204e-03,\n",
            "        -2.2653e-04,  7.4258e-04,  6.0500e-03, -1.6906e-03, -3.5085e-03,\n",
            "        -3.4569e-03,  1.2387e-03, -3.7216e-03,  1.0230e-04, -3.1663e-03,\n",
            "         2.7099e-03, -4.2998e-04, -1.5959e-04,  4.0740e-04, -1.8281e-03,\n",
            "         9.1967e-06,  3.1054e-03, -4.1480e-03,  2.7759e-03, -1.2007e-03,\n",
            "        -9.1626e-04, -2.1368e-03, -2.9086e-03, -4.7477e-04,  1.7726e-03,\n",
            "        -1.6756e-03,  3.1973e-03, -8.7571e-04,  4.0972e-03, -3.7613e-03,\n",
            "         2.0721e-03, -8.1404e-05,  9.2047e-04,  2.2179e-03,  1.7398e-03,\n",
            "         8.1340e-04,  3.0239e-03,  1.1521e-03, -3.0627e-04,  2.3065e-05,\n",
            "        -3.7994e-03,  7.9239e-04, -4.4279e-04, -2.2773e-03], device='cuda:0')\n",
            "decoder.layers.2.norm2.weight: tensor([0.9940, 1.0037, 1.0007, 0.9989, 0.9985, 1.0012, 1.0011, 0.9983, 1.0005,\n",
            "        1.0059, 0.9963, 1.0062, 0.9979, 1.0063, 0.9985, 0.9909, 0.9947, 0.9902,\n",
            "        0.9997, 0.9967, 0.9964, 0.9961, 1.0026, 1.0086, 1.0020, 0.9964, 1.0067,\n",
            "        1.0068, 0.9984, 1.0042, 1.0048, 1.0074, 1.0116, 1.0144, 1.0139, 0.9946,\n",
            "        0.9966, 1.0088, 1.0008, 1.0093, 1.0005, 0.9945, 0.9956, 1.0023, 0.9968,\n",
            "        0.9959, 1.0073, 1.0052, 0.9944, 0.9970, 0.9987, 1.0011, 0.9991, 1.0067,\n",
            "        1.0054, 1.0006, 1.0024, 0.9965, 0.9940, 1.0097, 1.0039, 1.0017, 1.0101,\n",
            "        1.0047], device='cuda:0')\n",
            "decoder.layers.2.norm2.bias: tensor([ 5.3986e-03,  5.3680e-04,  7.8869e-04,  1.6602e-04,  8.1912e-05,\n",
            "        -2.2407e-03,  3.1333e-04,  5.6562e-04, -2.8671e-03,  4.9272e-03,\n",
            "        -6.0722e-04,  3.6510e-03,  1.2056e-03, -5.3567e-03, -8.9107e-04,\n",
            "         7.0421e-04, -2.2106e-03, -4.9106e-03, -1.8819e-03,  2.3874e-03,\n",
            "         4.0478e-04,  5.8312e-04,  5.6533e-03, -1.7143e-03, -2.6683e-03,\n",
            "        -3.1536e-03,  1.6206e-03, -2.9237e-03,  3.9788e-04, -1.9788e-03,\n",
            "         2.8647e-03,  3.4690e-05,  1.3633e-04,  1.3483e-03, -1.4400e-03,\n",
            "        -1.3892e-04,  2.6777e-03, -3.0469e-03,  2.9650e-03, -2.4785e-03,\n",
            "        -9.5680e-04, -2.1398e-03, -2.4994e-03, -2.6288e-04,  1.5892e-03,\n",
            "        -1.2758e-03,  2.8850e-03, -1.2103e-03,  4.4236e-03, -3.9849e-03,\n",
            "         9.2689e-04, -7.2975e-05,  2.1278e-03,  2.2079e-03,  1.8274e-03,\n",
            "         8.6589e-04,  3.5828e-03,  7.8934e-04, -3.0292e-04,  9.3028e-04,\n",
            "        -2.4827e-03,  1.0394e-03, -5.7817e-04, -2.2122e-03], device='cuda:0')\n",
            "decoder.layers.2.norm3.weight: tensor([0.9990, 1.0058, 0.9994, 0.9987, 0.9980, 1.0013, 0.9975, 0.9947, 0.9960,\n",
            "        1.0083, 0.9958, 0.9973, 0.9953, 1.0020, 1.0040, 0.9903, 0.9990, 0.9890,\n",
            "        0.9979, 0.9959, 0.9993, 0.9990, 0.9985, 1.0031, 1.0037, 0.9980, 1.0047,\n",
            "        1.0067, 1.0009, 1.0026, 1.0011, 1.0058, 1.0093, 1.0075, 1.0123, 0.9957,\n",
            "        1.0014, 1.0020, 1.0068, 1.0070, 1.0002, 0.9985, 0.9954, 1.0018, 0.9985,\n",
            "        0.9953, 1.0051, 1.0032, 0.9937, 1.0024, 1.0005, 0.9985, 0.9997, 1.0132,\n",
            "        1.0022, 0.9975, 1.0043, 0.9940, 0.9954, 1.0117, 1.0059, 1.0018, 1.0080,\n",
            "        1.0060], device='cuda:0')\n",
            "decoder.layers.2.norm3.bias: tensor([ 3.5895e-03, -2.6730e-03,  2.9072e-03, -1.3290e-03,  5.4181e-04,\n",
            "        -2.4481e-03,  1.1343e-03, -2.2853e-03, -1.6325e-03,  6.4458e-03,\n",
            "        -1.7455e-03,  3.5485e-03, -5.2718e-04, -1.3386e-03, -2.7289e-03,\n",
            "         1.2534e-04, -1.8711e-03, -6.8541e-03, -2.0163e-03,  4.8792e-03,\n",
            "        -1.3635e-03, -5.0710e-04,  9.8517e-04, -2.3211e-03, -2.2637e-03,\n",
            "        -1.9565e-03,  2.1366e-03, -2.0186e-03, -8.5974e-04,  9.8759e-05,\n",
            "         3.0574e-03,  1.8499e-04, -2.2375e-03,  7.4786e-04, -2.6034e-03,\n",
            "         8.9277e-04,  2.0524e-03, -4.8338e-03,  2.3040e-03,  6.0538e-04,\n",
            "        -7.1847e-04, -3.6043e-03, -3.5588e-03,  1.5319e-03,  2.6801e-04,\n",
            "        -1.0646e-03,  2.6555e-03,  1.4117e-05,  4.1621e-03, -4.4842e-03,\n",
            "         3.1249e-03,  2.5206e-03, -3.2388e-04,  3.1775e-03,  2.0985e-03,\n",
            "        -5.6032e-04,  2.4306e-03,  1.5092e-03, -1.1281e-03,  1.9037e-03,\n",
            "        -1.5293e-03,  5.5952e-04, -1.4737e-03, -2.3420e-03], device='cuda:0')\n",
            "decoder.layers.3.self_attn.w_q.weight: tensor([[-0.1129, -0.0483,  0.1232,  ..., -0.0127,  0.0746, -0.0540],\n",
            "        [-0.0380,  0.0599,  0.0793,  ..., -0.0832, -0.0803,  0.0549],\n",
            "        [-0.0900, -0.0363, -0.0343,  ...,  0.0690,  0.0829, -0.0526],\n",
            "        ...,\n",
            "        [-0.0180,  0.0286,  0.0892,  ..., -0.1021, -0.0495, -0.0857],\n",
            "        [-0.0594,  0.0618,  0.1234,  ...,  0.0614, -0.1015,  0.0264],\n",
            "        [ 0.0792,  0.0262,  0.0906,  ..., -0.1220,  0.1061, -0.0263]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.3.self_attn.w_k.weight: tensor([[-0.0093,  0.0762, -0.0497,  ..., -0.0709, -0.0710,  0.0120],\n",
            "        [ 0.0773,  0.0857,  0.0643,  ...,  0.0354,  0.0514,  0.0915],\n",
            "        [ 0.1111, -0.0932, -0.0502,  ..., -0.0559, -0.0727,  0.0013],\n",
            "        ...,\n",
            "        [-0.0048, -0.0574,  0.0951,  ..., -0.0943, -0.0504, -0.0376],\n",
            "        [-0.1019, -0.0127,  0.0742,  ..., -0.1164, -0.0491, -0.0725],\n",
            "        [ 0.0878,  0.0039,  0.0973,  ..., -0.1095, -0.0339,  0.0002]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.3.self_attn.w_v.weight: tensor([[-0.0928,  0.0606,  0.0959,  ...,  0.1121,  0.0164, -0.0469],\n",
            "        [ 0.1028,  0.1002, -0.0156,  ...,  0.1245,  0.0194, -0.0459],\n",
            "        [ 0.1058,  0.0180,  0.1072,  ...,  0.1145,  0.0665,  0.0854],\n",
            "        ...,\n",
            "        [-0.0229,  0.0338, -0.1233,  ..., -0.0208, -0.0161, -0.0707],\n",
            "        [ 0.1024,  0.0595,  0.0176,  ...,  0.0322,  0.0973,  0.0388],\n",
            "        [ 0.0513, -0.0663,  0.0747,  ...,  0.1196,  0.0634, -0.0527]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.3.self_attn.w_o.weight: tensor([[ 0.0753, -0.0222, -0.1229,  ..., -0.0269, -0.0138,  0.0839],\n",
            "        [-0.0523,  0.1009, -0.0781,  ..., -0.0305,  0.1131,  0.1048],\n",
            "        [-0.1185,  0.1180, -0.0884,  ...,  0.0641, -0.0041, -0.0237],\n",
            "        ...,\n",
            "        [ 0.0177, -0.0321, -0.0301,  ..., -0.0353, -0.0157,  0.0667],\n",
            "        [-0.0297, -0.1252,  0.0983,  ...,  0.0476,  0.0833,  0.1028],\n",
            "        [ 0.0782,  0.1190, -0.0399,  ..., -0.1201, -0.1209,  0.0646]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.3.enc_attn.w_q.weight: tensor([[-0.0483,  0.0281,  0.0937,  ...,  0.1010,  0.1247, -0.0097],\n",
            "        [-0.0129,  0.0905,  0.0559,  ...,  0.0603,  0.1131, -0.0819],\n",
            "        [-0.1024,  0.1217,  0.0140,  ...,  0.1091,  0.0692,  0.0553],\n",
            "        ...,\n",
            "        [-0.0023,  0.0515,  0.0532,  ...,  0.1141,  0.1009, -0.0103],\n",
            "        [ 0.0503, -0.0051,  0.1257,  ...,  0.0452,  0.0364, -0.1258],\n",
            "        [-0.0060, -0.1183,  0.0334,  ...,  0.1292, -0.0972,  0.1366]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.3.enc_attn.w_k.weight: tensor([[ 0.0303, -0.0154,  0.0913,  ..., -0.0103, -0.0343, -0.0800],\n",
            "        [ 0.1062,  0.0768, -0.0072,  ...,  0.0140,  0.0795,  0.0305],\n",
            "        [-0.0016, -0.0564,  0.0395,  ...,  0.0713,  0.0230,  0.0890],\n",
            "        ...,\n",
            "        [-0.0438,  0.1028, -0.0640,  ..., -0.0726, -0.0961, -0.0469],\n",
            "        [-0.1273, -0.0779, -0.0107,  ..., -0.1074, -0.0820,  0.1089],\n",
            "        [-0.0601, -0.1050, -0.1276,  ...,  0.0619, -0.0022,  0.0708]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.3.enc_attn.w_v.weight: tensor([[-0.0343,  0.0815,  0.0754,  ...,  0.1205, -0.0129,  0.1102],\n",
            "        [ 0.0139,  0.1165, -0.0645,  ...,  0.1263, -0.0615,  0.0812],\n",
            "        [-0.0616, -0.0264, -0.0308,  ...,  0.1227,  0.0671, -0.0580],\n",
            "        ...,\n",
            "        [-0.0187,  0.0268,  0.0457,  ..., -0.0322, -0.0935,  0.0004],\n",
            "        [ 0.1014,  0.0296,  0.0877,  ..., -0.0162, -0.0719,  0.0559],\n",
            "        [-0.1101, -0.1284,  0.1014,  ...,  0.0227, -0.0885, -0.1041]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.3.enc_attn.w_o.weight: tensor([[ 0.0397, -0.0244, -0.0415,  ..., -0.0053, -0.1011,  0.1136],\n",
            "        [-0.0143, -0.0044, -0.0827,  ..., -0.0887, -0.0148, -0.0253],\n",
            "        [ 0.1093, -0.0449, -0.0811,  ...,  0.0014, -0.0246,  0.0660],\n",
            "        ...,\n",
            "        [ 0.0200, -0.0306, -0.0983,  ..., -0.0747,  0.0757, -0.0728],\n",
            "        [ 0.0827, -0.0069, -0.1148,  ...,  0.0315,  0.0988,  0.0304],\n",
            "        [ 0.0749, -0.0789, -0.1093,  ..., -0.1079, -0.0678,  0.0576]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.3.ff.linear1.weight: tensor([[-0.0759, -0.0397, -0.1232,  ..., -0.0418,  0.0784, -0.0529],\n",
            "        [ 0.0956,  0.1068,  0.0106,  ..., -0.0894,  0.0613,  0.0316],\n",
            "        [ 0.0891,  0.0240,  0.0355,  ...,  0.1018,  0.0140,  0.0807],\n",
            "        ...,\n",
            "        [-0.0677,  0.1049,  0.0635,  ..., -0.0082,  0.0278,  0.0904],\n",
            "        [ 0.0059,  0.1159,  0.0065,  ...,  0.1306, -0.1287, -0.1020],\n",
            "        [ 0.0105,  0.0891, -0.0172,  ...,  0.0986, -0.0408,  0.1296]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.3.ff.linear1.bias: tensor([ 9.8072e-02,  4.6606e-03, -4.5880e-02,  1.6123e-02, -1.1040e-01,\n",
            "        -1.0817e-01,  2.4105e-02, -1.1265e-01,  8.2964e-02,  1.6178e-02,\n",
            "         2.9687e-02,  7.5615e-02, -7.4787e-02,  7.7454e-02, -9.8391e-03,\n",
            "        -1.4785e-02,  1.0032e-01, -3.9216e-02, -1.2735e-01,  1.4637e-02,\n",
            "         7.4410e-02,  5.2625e-02, -4.0544e-03,  1.4311e-02, -1.4939e-02,\n",
            "         9.1054e-03, -7.0981e-02,  1.3011e-03,  2.5060e-02, -2.6513e-02,\n",
            "         1.3187e-02,  6.7677e-02, -8.9548e-02,  1.1513e-01,  1.1709e-02,\n",
            "        -6.5824e-02, -1.0729e-01,  7.4792e-02, -7.2122e-02,  8.2173e-03,\n",
            "         8.8169e-05,  4.0241e-02,  7.3601e-03, -6.0901e-02,  1.2512e-02,\n",
            "         3.6381e-02,  1.0407e-01, -1.9596e-02, -4.6604e-02, -1.8074e-02,\n",
            "         7.4249e-02,  1.0393e-01, -9.1191e-02,  6.7917e-02,  5.9638e-02,\n",
            "         3.4335e-02,  6.9089e-02, -8.5582e-02, -8.8740e-02,  5.1842e-02,\n",
            "        -4.0305e-02, -6.6606e-03, -7.7122e-02, -7.0132e-02,  1.0858e-01,\n",
            "        -1.0819e-01, -1.0457e-01,  8.4543e-03, -1.9568e-02, -5.0799e-02,\n",
            "         1.0434e-01,  1.1807e-01,  3.9802e-02, -8.0134e-02,  2.9608e-02,\n",
            "         9.4938e-02,  3.5419e-02,  1.0288e-01,  7.8374e-03,  1.1644e-01,\n",
            "        -7.0956e-02, -3.5662e-02, -1.1278e-01,  1.0455e-01, -6.3906e-03,\n",
            "        -1.6004e-02, -1.2480e-01, -9.5263e-02, -4.2535e-02, -9.9986e-02,\n",
            "        -8.4016e-02, -1.5439e-02, -7.8670e-02,  5.8790e-02, -2.9406e-02,\n",
            "        -5.0483e-02, -2.9861e-02, -1.0345e-01,  1.2356e-01,  9.5361e-02,\n",
            "         4.9119e-02, -9.9510e-02,  1.0812e-01,  4.8041e-02,  6.2115e-02,\n",
            "         1.5459e-02,  8.7117e-02,  9.3983e-02, -1.0763e-01,  6.1424e-03,\n",
            "         1.6620e-02,  4.9901e-02,  9.1952e-03,  7.8491e-02,  1.1979e-01,\n",
            "         6.1918e-03,  1.5218e-02, -8.7423e-02,  7.8065e-02, -1.1630e-01,\n",
            "         1.1915e-01,  6.2601e-02,  3.8738e-02, -1.0231e-01, -9.2277e-02,\n",
            "         5.2802e-03, -1.1700e-01,  1.5449e-02,  7.3093e-02, -2.9499e-02,\n",
            "         8.0689e-03, -7.1391e-02,  7.3445e-02,  3.0499e-02,  2.4194e-02,\n",
            "         8.1148e-02,  1.1322e-02,  4.8623e-02, -2.0354e-02,  1.1964e-01,\n",
            "         1.5806e-02, -1.2286e-01,  1.1916e-01, -2.6586e-02, -1.1075e-01,\n",
            "        -1.0269e-01, -5.3418e-02, -4.5480e-03,  2.0796e-02,  4.5418e-02,\n",
            "        -7.5389e-02,  9.4282e-02,  5.8726e-02, -7.1127e-02,  5.2449e-02,\n",
            "        -9.2442e-02,  1.1314e-01, -3.5516e-02,  3.9671e-02,  8.7226e-03,\n",
            "         7.1729e-02, -5.7442e-02, -1.1337e-01, -1.2023e-01, -1.2503e-01,\n",
            "        -6.6741e-02, -5.3078e-03, -1.1108e-01, -8.9385e-02,  6.3148e-02,\n",
            "        -5.2321e-02, -1.0021e-01,  1.3151e-02,  9.2686e-02,  6.9781e-02,\n",
            "         4.6255e-02,  9.3367e-02, -3.2858e-02,  5.9385e-02,  8.6373e-02,\n",
            "        -1.1984e-01, -1.1414e-01,  1.0315e-02, -7.9126e-02, -1.0248e-01,\n",
            "        -2.7857e-02, -1.0753e-01, -5.1676e-02,  1.0686e-01,  6.7386e-02,\n",
            "        -1.2420e-01, -7.4129e-02, -1.9375e-02,  3.2273e-02,  1.5905e-02,\n",
            "        -6.3429e-02,  6.7360e-02,  1.0540e-01, -9.0077e-02,  1.0229e-01,\n",
            "        -1.0206e-01, -1.3563e-02,  2.3177e-02, -1.0002e-01, -8.2392e-02,\n",
            "        -2.0934e-02,  1.0960e-01,  3.1625e-02,  1.7608e-02,  9.0570e-02,\n",
            "        -1.2373e-01, -5.6174e-02, -1.0406e-01, -6.7343e-02,  3.9159e-02,\n",
            "        -1.2546e-01,  4.6478e-03, -9.4595e-02, -3.4394e-02,  4.8438e-02,\n",
            "        -9.6796e-02, -3.7323e-02, -5.6031e-02,  6.3687e-03, -7.9402e-03,\n",
            "        -1.1325e-01, -1.2134e-01, -3.0762e-02, -9.8452e-02, -1.0637e-01,\n",
            "         7.3614e-02,  4.9683e-02,  5.4954e-02,  1.1646e-01, -9.0202e-02,\n",
            "         7.2377e-02,  1.0274e-02,  3.9674e-02,  4.6408e-02,  1.1030e-01,\n",
            "         2.3814e-02, -1.2178e-01,  1.0715e-01,  2.9562e-02,  2.4092e-02,\n",
            "        -1.9995e-02,  4.7679e-02, -1.7714e-02,  1.4636e-03, -6.4112e-02,\n",
            "        -1.6866e-02,  5.5195e-02,  9.0647e-03, -9.9931e-02,  6.2333e-02,\n",
            "         1.0461e-01, -1.2282e-01, -2.7171e-02,  1.5968e-02,  5.7802e-03,\n",
            "        -1.5554e-02, -7.7446e-02, -4.5311e-02, -3.8952e-02, -4.7248e-03,\n",
            "         4.8055e-02, -3.9218e-03,  5.9505e-02, -4.5185e-02, -5.7436e-02,\n",
            "         5.8529e-02,  7.7234e-02,  2.5413e-02, -1.1307e-01, -2.3206e-02,\n",
            "        -2.6642e-02,  1.5086e-02, -9.3694e-02, -2.0067e-02,  1.1316e-01,\n",
            "        -6.9672e-02,  3.6050e-02,  8.7005e-02, -3.8286e-02,  5.8295e-02,\n",
            "        -5.4938e-02, -4.7951e-02, -1.1233e-01, -1.0592e-01,  6.3650e-03,\n",
            "        -2.9196e-02, -6.4345e-02, -1.1201e-03, -4.1717e-03, -6.0271e-02,\n",
            "        -2.7616e-02, -8.3658e-02,  5.2160e-02, -1.2495e-01, -3.7506e-02,\n",
            "        -4.9330e-02, -7.1847e-02,  7.8164e-02,  4.0408e-02,  1.0434e-02,\n",
            "        -3.0787e-02, -3.8605e-02, -2.7520e-02, -4.3468e-02,  6.2644e-02,\n",
            "         7.1781e-02, -3.5914e-02,  6.2295e-02,  1.1201e-01, -3.4915e-02,\n",
            "        -4.2031e-03,  9.0729e-02, -2.8028e-03,  1.0730e-01, -9.5424e-02,\n",
            "        -5.5046e-02,  7.6528e-02, -2.7765e-02,  9.2313e-03, -1.0224e-01,\n",
            "         6.1282e-02,  8.4528e-02,  9.3839e-02,  1.0933e-01, -1.1868e-02,\n",
            "        -6.3434e-02, -1.0716e-02,  1.0044e-01, -8.5669e-02,  9.9422e-02,\n",
            "        -4.1409e-02,  3.1104e-03,  4.7388e-02,  1.1877e-01,  1.8125e-02,\n",
            "         9.9607e-02,  6.8646e-02,  5.2849e-03,  6.9149e-03, -9.2276e-02,\n",
            "        -7.1027e-02, -6.3279e-02, -8.0482e-02, -8.8076e-03,  8.5375e-02,\n",
            "        -8.0602e-03, -1.1710e-01,  6.3893e-02,  1.0343e-01, -2.0690e-02,\n",
            "         1.0551e-01,  3.7067e-02, -4.9906e-02, -1.0737e-02, -5.0608e-02,\n",
            "         8.1031e-02,  1.0276e-01,  4.9097e-03,  1.0368e-01,  5.2772e-02,\n",
            "        -6.6911e-02, -9.5671e-02,  1.1027e-01,  1.1168e-01,  9.7504e-02,\n",
            "         6.5822e-02, -1.0384e-05,  4.5710e-02,  5.6150e-02,  6.6427e-02,\n",
            "        -6.7286e-02,  2.3512e-02,  1.2299e-01,  2.7510e-02,  6.9993e-02,\n",
            "        -1.0082e-01,  4.6226e-02,  1.1080e-01, -1.0044e-02,  6.9549e-02,\n",
            "        -4.3222e-02,  1.2760e-02, -5.6084e-02,  1.1022e-01, -1.1498e-01,\n",
            "        -1.1798e-01, -3.0721e-02,  9.3029e-02, -1.8855e-02,  1.1437e-01,\n",
            "         3.4438e-03,  1.0472e-01, -1.1929e-01,  1.0702e-01, -1.1099e-01,\n",
            "         4.9725e-02,  3.5684e-02,  9.2278e-02,  4.3536e-02,  1.2415e-01,\n",
            "        -2.7790e-02, -1.8588e-02, -1.1612e-01, -1.1868e-01,  3.2884e-02,\n",
            "        -8.4802e-02, -1.0891e-01,  1.2171e-01, -6.6759e-02, -6.3247e-02,\n",
            "         6.1132e-03, -7.0928e-02, -3.0174e-02, -6.2061e-02,  5.0765e-02,\n",
            "         4.1997e-04, -9.7871e-02, -1.1054e-01,  5.2845e-02, -9.5263e-02,\n",
            "        -8.0848e-02,  8.6060e-02,  6.4075e-02, -9.6381e-02,  9.3658e-03,\n",
            "         3.6100e-02,  9.4585e-02, -1.1372e-01,  3.7305e-02, -5.6360e-03,\n",
            "        -9.6003e-03,  5.7791e-02,  5.5529e-02, -1.9519e-02,  7.5262e-02,\n",
            "         6.0504e-02, -6.6544e-02, -4.1944e-02,  6.3458e-02,  1.4104e-02,\n",
            "        -1.2536e-01, -1.3921e-02, -4.4379e-02, -4.8264e-02, -8.7386e-02,\n",
            "         3.5669e-02, -1.0736e-01, -1.9369e-02,  2.9023e-02,  7.3611e-02,\n",
            "        -8.8107e-02, -4.1626e-02, -6.8155e-02, -5.3716e-02,  1.2252e-01,\n",
            "        -1.3847e-02, -7.3602e-03,  1.2598e-02,  1.2224e-01,  9.3144e-02,\n",
            "        -4.4650e-02, -4.7908e-03,  8.3721e-02,  7.1198e-02, -9.3883e-02,\n",
            "        -6.3137e-02, -6.7874e-02, -1.0239e-01, -3.0472e-03,  2.4233e-02,\n",
            "         4.8221e-02,  4.8278e-02,  9.4975e-02,  5.6839e-02, -7.8759e-02,\n",
            "        -9.5177e-02, -1.7663e-02,  1.1774e-01, -7.4027e-02,  9.0189e-02,\n",
            "         9.4784e-03,  6.0682e-02, -1.0936e-01,  4.0699e-02,  1.7290e-02,\n",
            "         6.0842e-02, -3.5267e-02,  1.4054e-02, -4.6685e-02,  3.1395e-02,\n",
            "         9.1402e-02, -5.5682e-02, -6.5918e-02, -1.1039e-01, -8.7095e-03,\n",
            "         7.5536e-02, -2.3499e-03, -1.1224e-01,  1.9747e-02, -8.2513e-02,\n",
            "        -1.2849e-01,  3.8884e-02, -2.8038e-02, -1.0760e-01,  6.0503e-02,\n",
            "        -2.7623e-03, -1.1232e-01], device='cuda:0')\n",
            "decoder.layers.3.ff.linear2.weight: tensor([[-0.0283,  0.0128,  0.0362,  ...,  0.0334,  0.0087, -0.0004],\n",
            "        [ 0.0416,  0.0413, -0.0417,  ...,  0.0223, -0.0013,  0.0344],\n",
            "        [-0.0436,  0.0136,  0.0129,  ...,  0.0371,  0.0269,  0.0460],\n",
            "        ...,\n",
            "        [ 0.0082, -0.0128, -0.0479,  ...,  0.0200, -0.0437,  0.0257],\n",
            "        [-0.0082, -0.0100, -0.0492,  ..., -0.0030, -0.0371,  0.0046],\n",
            "        [ 0.0257, -0.0345, -0.0308,  ..., -0.0084,  0.0458, -0.0221]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.3.ff.linear2.bias: tensor([ 0.0073, -0.0049, -0.0415, -0.0220,  0.0029,  0.0199,  0.0379, -0.0069,\n",
            "         0.0203, -0.0169,  0.0093, -0.0152,  0.0009,  0.0122,  0.0134, -0.0089,\n",
            "        -0.0161, -0.0425,  0.0099,  0.0192, -0.0258, -0.0265,  0.0183,  0.0320,\n",
            "        -0.0261, -0.0203, -0.0303,  0.0185, -0.0401,  0.0149, -0.0153, -0.0054,\n",
            "        -0.0424,  0.0187, -0.0368, -0.0005, -0.0205,  0.0253, -0.0275, -0.0393,\n",
            "         0.0335,  0.0183, -0.0010, -0.0230, -0.0112, -0.0310, -0.0237, -0.0074,\n",
            "        -0.0218, -0.0333,  0.0347,  0.0023, -0.0030,  0.0185,  0.0009,  0.0142,\n",
            "         0.0376,  0.0119,  0.0121, -0.0032,  0.0150,  0.0073,  0.0191,  0.0317],\n",
            "       device='cuda:0')\n",
            "decoder.layers.3.norm1.weight: tensor([0.9989, 1.0045, 0.9989, 0.9970, 0.9968, 0.9998, 0.9952, 0.9959, 0.9977,\n",
            "        1.0065, 0.9979, 0.9975, 0.9998, 1.0006, 1.0054, 0.9905, 1.0012, 0.9927,\n",
            "        1.0007, 0.9943, 0.9971, 1.0065, 1.0019, 0.9994, 1.0033, 1.0004, 1.0094,\n",
            "        1.0091, 1.0012, 1.0026, 0.9997, 1.0049, 1.0091, 1.0098, 1.0050, 0.9922,\n",
            "        1.0023, 1.0011, 1.0063, 1.0096, 0.9992, 0.9978, 0.9948, 1.0003, 0.9968,\n",
            "        0.9921, 1.0082, 1.0024, 0.9944, 1.0082, 1.0010, 0.9957, 1.0001, 1.0121,\n",
            "        0.9995, 1.0021, 1.0038, 0.9960, 0.9961, 1.0091, 1.0028, 0.9999, 1.0091,\n",
            "        1.0076], device='cuda:0')\n",
            "decoder.layers.3.norm1.bias: tensor([ 6.9446e-03,  1.9365e-03,  5.3962e-03, -2.8606e-03,  1.1225e-03,\n",
            "        -6.8309e-04,  1.2603e-03, -4.2771e-03, -1.2941e-03,  6.2268e-03,\n",
            "        -2.4458e-03,  3.8531e-03, -5.4967e-04, -5.0599e-03, -3.1959e-03,\n",
            "         8.9607e-04, -2.2815e-03, -7.4889e-03, -3.1074e-03,  3.0654e-03,\n",
            "        -2.0620e-03,  9.5883e-04, -9.2153e-05, -7.9529e-04, -1.9949e-03,\n",
            "        -2.5714e-03,  2.0273e-03, -2.6914e-03, -2.0361e-03,  3.5017e-03,\n",
            "         2.0946e-03,  1.2429e-03, -1.2761e-03,  1.9196e-03, -4.4839e-03,\n",
            "        -3.5953e-03,  3.1633e-03, -5.2767e-03,  2.2006e-03,  1.5482e-03,\n",
            "         4.0882e-03, -5.2024e-03, -2.1309e-03, -6.5507e-04,  8.5322e-05,\n",
            "        -1.1839e-03,  3.6284e-03,  1.8814e-03,  4.3965e-03, -2.9244e-03,\n",
            "         3.1120e-03,  1.6980e-03,  2.0722e-03,  3.9186e-03,  1.0045e-03,\n",
            "        -4.0571e-04,  2.7767e-03,  6.3332e-03, -2.2168e-03,  1.9597e-03,\n",
            "        -2.4265e-03, -1.2749e-03, -9.8964e-04, -3.0296e-03], device='cuda:0')\n",
            "decoder.layers.3.norm2.weight: tensor([1.0006, 1.0011, 0.9966, 0.9984, 0.9967, 0.9991, 0.9948, 0.9968, 0.9995,\n",
            "        1.0059, 0.9991, 0.9931, 0.9980, 1.0025, 1.0056, 0.9906, 0.9976, 0.9908,\n",
            "        1.0009, 0.9938, 0.9982, 1.0103, 0.9993, 0.9998, 1.0011, 1.0023, 1.0062,\n",
            "        1.0102, 1.0015, 1.0020, 0.9960, 1.0041, 1.0088, 1.0125, 1.0094, 0.9850,\n",
            "        1.0051, 1.0015, 1.0057, 1.0086, 1.0002, 0.9975, 0.9977, 0.9994, 0.9994,\n",
            "        0.9936, 1.0073, 1.0015, 0.9933, 1.0031, 0.9999, 0.9945, 1.0004, 1.0110,\n",
            "        1.0001, 1.0047, 1.0013, 0.9918, 0.9960, 1.0082, 1.0045, 0.9994, 1.0106,\n",
            "        1.0047], device='cuda:0')\n",
            "decoder.layers.3.norm2.bias: tensor([ 6.0081e-03,  3.7923e-03,  4.6275e-03, -1.4747e-03, -1.2081e-03,\n",
            "        -7.8573e-04,  1.0182e-03, -4.3011e-03, -1.1418e-03,  5.2559e-03,\n",
            "        -2.4573e-03,  2.6320e-03,  1.1015e-06, -5.6427e-03, -3.6210e-03,\n",
            "         3.1554e-04, -2.1976e-03, -4.8891e-03, -2.1929e-03,  2.3787e-03,\n",
            "        -3.6473e-04,  2.4962e-03, -4.8317e-04, -1.1540e-03, -2.9614e-04,\n",
            "        -2.0707e-03,  1.6611e-03, -2.5568e-03, -1.5641e-03,  3.5980e-03,\n",
            "         2.2603e-03,  1.7522e-03, -1.3060e-03,  1.2778e-03, -3.1530e-03,\n",
            "        -3.7120e-03,  2.8358e-03, -4.9843e-03,  1.9326e-03,  1.2697e-04,\n",
            "         2.3566e-03, -6.0668e-03, -9.6504e-04, -1.4508e-03, -1.0500e-03,\n",
            "         2.0954e-04,  3.6439e-03,  2.7921e-03,  5.4526e-03, -4.4453e-03,\n",
            "         1.1798e-03,  1.9862e-03,  2.4405e-03,  3.1934e-03,  1.1332e-03,\n",
            "        -1.2511e-03,  2.5957e-03,  6.6681e-03, -2.2091e-03,  7.2744e-04,\n",
            "        -2.1922e-03, -6.2791e-04, -2.2209e-03, -2.7325e-03], device='cuda:0')\n",
            "decoder.layers.3.norm3.weight: tensor([1.0017, 1.0000, 0.9967, 0.9997, 0.9957, 0.9999, 0.9937, 0.9967, 0.9924,\n",
            "        1.0128, 0.9973, 1.0044, 0.9969, 1.0075, 1.0103, 0.9909, 0.9967, 0.9940,\n",
            "        0.9997, 0.9933, 0.9988, 1.0105, 1.0047, 1.0019, 1.0011, 1.0001, 1.0086,\n",
            "        1.0108, 1.0040, 0.9996, 0.9947, 0.9991, 1.0103, 1.0020, 1.0088, 0.9848,\n",
            "        1.0070, 1.0010, 1.0100, 1.0053, 0.9957, 1.0008, 0.9985, 0.9967, 1.0005,\n",
            "        0.9961, 1.0039, 1.0025, 0.9923, 1.0088, 0.9996, 0.9953, 1.0002, 1.0128,\n",
            "        0.9995, 1.0058, 1.0032, 0.9987, 0.9952, 1.0057, 1.0027, 1.0001, 1.0066,\n",
            "        0.9977], device='cuda:0')\n",
            "decoder.layers.3.norm3.bias: tensor([ 5.1130e-03,  2.1617e-03,  4.3794e-03, -1.4411e-03, -1.3372e-04,\n",
            "        -6.3180e-05,  7.1367e-04, -5.0740e-03,  8.9401e-05,  5.9583e-03,\n",
            "        -1.5372e-03,  4.8564e-03,  8.2489e-05, -1.2830e-03, -2.7657e-03,\n",
            "         1.6754e-03, -3.2063e-03, -5.3781e-03, -3.1761e-03,  1.7413e-03,\n",
            "        -4.5587e-03, -5.9759e-05,  1.8856e-03, -2.9552e-03, -1.6649e-03,\n",
            "        -2.7691e-03,  2.5777e-03, -3.8542e-03, -3.3721e-03,  1.8245e-03,\n",
            "         2.4344e-03,  1.7530e-03, -2.4503e-04,  2.3048e-03, -3.4970e-03,\n",
            "        -3.2905e-03,  3.1552e-03, -5.4243e-03,  3.4898e-04,  5.7462e-04,\n",
            "         1.6162e-03, -5.4367e-03, -2.5078e-03, -1.1308e-03, -1.9497e-03,\n",
            "         1.7485e-03,  4.8085e-03,  2.3536e-03,  3.3070e-03, -2.6401e-03,\n",
            "         2.0923e-03,  9.9426e-04,  1.3649e-03,  4.2343e-03,  5.2330e-04,\n",
            "        -2.2687e-03,  1.8990e-03,  7.9467e-03, -2.4095e-03,  4.2090e-05,\n",
            "        -2.3810e-03, -1.8274e-03, -8.3384e-04, -2.6475e-03], device='cuda:0')\n",
            "decoder.layers.4.self_attn.w_q.weight: tensor([[ 0.1272, -0.1109, -0.0010,  ..., -0.0641, -0.0081, -0.1205],\n",
            "        [ 0.0273,  0.0293, -0.0967,  ...,  0.0339,  0.0353,  0.1119],\n",
            "        [-0.0308,  0.0701, -0.1276,  ...,  0.0147, -0.1173, -0.0078],\n",
            "        ...,\n",
            "        [-0.0538,  0.0871, -0.0068,  ..., -0.0122, -0.0367, -0.0251],\n",
            "        [-0.1229,  0.1069, -0.0788,  ...,  0.0866,  0.0542, -0.1105],\n",
            "        [-0.0547, -0.0189,  0.1146,  ...,  0.0021, -0.0811,  0.0377]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.4.self_attn.w_k.weight: tensor([[-0.0656,  0.0470, -0.0932,  ...,  0.0802, -0.0268, -0.0205],\n",
            "        [-0.1077,  0.1269,  0.0276,  ...,  0.0510,  0.1199,  0.0725],\n",
            "        [-0.1003, -0.0724,  0.0980,  ..., -0.0924, -0.0753,  0.1174],\n",
            "        ...,\n",
            "        [-0.0718, -0.0758, -0.0981,  ..., -0.1271,  0.1089,  0.1087],\n",
            "        [ 0.0791, -0.0768,  0.0866,  ...,  0.1119,  0.1022,  0.0108],\n",
            "        [-0.0320,  0.1105,  0.0248,  ..., -0.0924, -0.0620, -0.0857]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.4.self_attn.w_v.weight: tensor([[ 0.0698, -0.0759, -0.1039,  ..., -0.0140,  0.1203,  0.0721],\n",
            "        [-0.0723,  0.0244, -0.0066,  ...,  0.0638, -0.0377, -0.0681],\n",
            "        [-0.1159,  0.0147, -0.1120,  ..., -0.0322, -0.0637, -0.0655],\n",
            "        ...,\n",
            "        [ 0.0507, -0.0154, -0.0750,  ..., -0.0337,  0.0684, -0.1146],\n",
            "        [ 0.1179,  0.0075, -0.0147,  ..., -0.1176,  0.0704,  0.0485],\n",
            "        [-0.0472, -0.0757, -0.0222,  ...,  0.0522, -0.1014,  0.0018]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.4.self_attn.w_o.weight: tensor([[-0.0297, -0.0818,  0.0623,  ...,  0.1063,  0.0939, -0.0554],\n",
            "        [ 0.0324, -0.0540, -0.0632,  ..., -0.0310,  0.0853,  0.0814],\n",
            "        [ 0.0740,  0.0095,  0.0985,  ...,  0.1273, -0.0852, -0.1000],\n",
            "        ...,\n",
            "        [ 0.0798, -0.1159,  0.0562,  ...,  0.0022,  0.1188,  0.0643],\n",
            "        [-0.1072, -0.0798, -0.0562,  ...,  0.0044,  0.0663,  0.0425],\n",
            "        [-0.1073,  0.0584,  0.1153,  ...,  0.0807,  0.1174,  0.0387]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.4.enc_attn.w_q.weight: tensor([[-0.0412,  0.0208,  0.0968,  ..., -0.0595,  0.0594,  0.0590],\n",
            "        [-0.0485,  0.1096,  0.0841,  ...,  0.0212,  0.1196, -0.0221],\n",
            "        [ 0.1266, -0.0141,  0.0381,  ..., -0.1089,  0.0020, -0.0146],\n",
            "        ...,\n",
            "        [ 0.0109, -0.1064,  0.0337,  ...,  0.0921, -0.0245, -0.0116],\n",
            "        [ 0.0910, -0.0085,  0.0485,  ...,  0.0799,  0.0845,  0.0988],\n",
            "        [-0.0649,  0.0869,  0.0642,  ...,  0.0735,  0.1111,  0.0665]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.4.enc_attn.w_k.weight: tensor([[-0.0664, -0.0991,  0.0984,  ..., -0.0657,  0.0871,  0.0724],\n",
            "        [ 0.1029,  0.0997, -0.0290,  ...,  0.0255, -0.0664,  0.0941],\n",
            "        [-0.0226, -0.1238,  0.0797,  ..., -0.0487, -0.0681,  0.0503],\n",
            "        ...,\n",
            "        [-0.0219,  0.0484,  0.0361,  ...,  0.0652,  0.0027,  0.0547],\n",
            "        [ 0.0721, -0.0192,  0.0706,  ..., -0.1135, -0.1103,  0.0894],\n",
            "        [ 0.0999,  0.0521, -0.0414,  ...,  0.0039, -0.0196, -0.0464]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.4.enc_attn.w_v.weight: tensor([[-0.0412, -0.1151, -0.0151,  ..., -0.1208, -0.0494, -0.0843],\n",
            "        [-0.0341, -0.0368,  0.0447,  ..., -0.0856,  0.0552, -0.0731],\n",
            "        [ 0.1040,  0.0191,  0.0988,  ..., -0.0935,  0.0083, -0.0075],\n",
            "        ...,\n",
            "        [ 0.0309,  0.0361, -0.0846,  ...,  0.0697, -0.1130, -0.0419],\n",
            "        [ 0.0228,  0.0936, -0.1004,  ..., -0.1127, -0.0012,  0.0983],\n",
            "        [-0.1099,  0.0397, -0.0261,  ...,  0.1197,  0.0152, -0.0437]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.4.enc_attn.w_o.weight: tensor([[-7.0644e-02, -1.2689e-01, -2.6009e-02,  ...,  1.1309e-01,\n",
            "         -7.9295e-02, -1.3237e-01],\n",
            "        [ 7.5050e-02, -9.4399e-02,  1.8198e-02,  ..., -8.1965e-02,\n",
            "          6.1724e-02,  1.2155e-01],\n",
            "        [-1.2616e-02, -1.1257e-03, -4.5330e-02,  ..., -3.2949e-03,\n",
            "         -9.0069e-02,  7.3526e-02],\n",
            "        ...,\n",
            "        [ 8.8183e-02,  7.6080e-02,  3.4518e-02,  ...,  7.0221e-02,\n",
            "         -2.8095e-02,  6.1559e-02],\n",
            "        [-9.8127e-02,  5.7661e-02, -2.8675e-02,  ..., -2.5817e-02,\n",
            "         -4.3799e-02,  7.4428e-02],\n",
            "        [-3.3153e-05,  3.0147e-02, -2.2074e-02,  ...,  8.3231e-02,\n",
            "          1.7989e-03, -8.5435e-02]], device='cuda:0')\n",
            "decoder.layers.4.ff.linear1.weight: tensor([[-0.0327, -0.0745,  0.1257,  ..., -0.0039,  0.0470, -0.0349],\n",
            "        [ 0.1038, -0.0654, -0.0817,  ...,  0.0422, -0.1214,  0.0568],\n",
            "        [-0.0758,  0.0705,  0.0782,  ..., -0.0574,  0.0607, -0.1389],\n",
            "        ...,\n",
            "        [ 0.0156,  0.0425, -0.0335,  ...,  0.1035, -0.0036, -0.0825],\n",
            "        [-0.1243,  0.0973, -0.0507,  ...,  0.1312, -0.1033,  0.0835],\n",
            "        [-0.0264,  0.0744, -0.0731,  ...,  0.0909, -0.0863, -0.1011]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.4.ff.linear1.bias: tensor([ 8.2334e-02,  1.0657e-01, -1.0106e-01, -8.3393e-02,  1.2790e-01,\n",
            "        -2.6478e-02,  4.1252e-02, -1.0964e-01, -7.4313e-02,  1.5040e-03,\n",
            "        -7.1989e-02, -6.2551e-03, -3.4683e-02, -3.3424e-02, -1.3316e-01,\n",
            "        -4.3039e-02, -8.4976e-02, -9.8722e-02,  3.3958e-02, -1.2318e-01,\n",
            "        -6.5871e-02,  1.2167e-01,  1.0254e-01, -1.8927e-03,  2.5748e-02,\n",
            "         9.3716e-02, -5.5683e-02, -7.2669e-02, -1.1353e-01,  1.0235e-01,\n",
            "         3.3630e-02,  3.3531e-02, -2.8027e-02,  1.1741e-01, -1.0891e-01,\n",
            "        -1.0959e-01, -8.3034e-02, -5.9192e-02,  7.5480e-02,  2.2429e-03,\n",
            "        -9.2332e-02, -3.9855e-02,  3.2079e-02, -8.1429e-03, -6.1156e-03,\n",
            "         9.8392e-04,  7.4648e-02,  9.8105e-02,  1.0932e-01,  1.2362e-01,\n",
            "         1.1665e-01,  2.7112e-03,  7.1132e-02,  9.8624e-02, -9.0160e-02,\n",
            "         6.9070e-02, -1.8133e-02, -9.5065e-02, -6.4284e-02,  1.1292e-01,\n",
            "         3.2356e-02,  3.9640e-02,  1.2449e-01, -1.0918e-01,  5.5681e-03,\n",
            "        -4.4669e-02, -1.1248e-01,  3.5900e-02, -1.3034e-03,  6.4663e-04,\n",
            "        -1.1154e-01,  5.8096e-02,  6.7123e-02,  5.6184e-02,  6.9544e-02,\n",
            "         7.7181e-02,  4.9057e-02, -1.1017e-01, -1.3070e-03, -9.1369e-02,\n",
            "         1.1308e-01, -8.2437e-02,  7.7995e-02, -4.1216e-03,  4.6747e-02,\n",
            "         2.0515e-02,  3.1337e-04, -9.7363e-02, -3.1934e-02, -9.0498e-02,\n",
            "        -1.2388e-01, -9.3235e-02,  2.5731e-02, -1.1441e-01, -1.2306e-01,\n",
            "         5.6605e-03, -8.3368e-02,  2.3556e-02,  5.5401e-02, -1.1578e-01,\n",
            "         1.0200e-01,  1.1661e-01, -6.8304e-02, -5.2457e-02,  1.0597e-02,\n",
            "        -1.2631e-02,  2.8396e-02,  9.2650e-02, -5.6738e-02,  1.6014e-02,\n",
            "        -4.6993e-02,  7.9420e-02,  6.1322e-03, -7.3393e-02,  5.0598e-02,\n",
            "        -2.1664e-02,  6.9603e-02, -4.7927e-02, -9.2593e-02,  6.8002e-02,\n",
            "        -8.8417e-02, -2.6705e-02, -6.2248e-02,  3.7552e-02, -8.6703e-02,\n",
            "         7.2212e-02, -1.0077e-01,  1.2013e-01, -8.6377e-02, -6.4606e-03,\n",
            "        -4.7390e-02,  4.2997e-02, -5.5427e-02,  5.1352e-02, -5.0558e-02,\n",
            "        -1.0985e-01,  1.0421e-01, -1.3380e-01, -2.0720e-04, -4.7216e-02,\n",
            "         7.6188e-02, -1.0707e-01, -6.0905e-02,  1.9274e-02,  2.9769e-02,\n",
            "         2.7904e-02, -1.0008e-01, -6.2448e-02, -8.5785e-02,  8.3476e-02,\n",
            "        -4.1071e-02, -4.6495e-02, -1.8095e-02, -6.3381e-02,  7.8379e-02,\n",
            "         7.8575e-02, -7.8705e-02,  1.0461e-01, -1.1100e-01,  2.6934e-02,\n",
            "         5.5704e-02,  7.2196e-02,  8.8463e-03, -1.2258e-01,  6.3429e-02,\n",
            "         6.4621e-02,  9.1651e-02,  9.9005e-02,  4.1793e-02, -1.0545e-01,\n",
            "         5.3053e-02, -8.0210e-02, -1.2152e-01,  8.9290e-02,  1.1154e-01,\n",
            "         6.2040e-02,  7.9396e-02, -3.0103e-03, -2.9474e-02,  1.2096e-01,\n",
            "        -1.2847e-02, -6.3376e-02,  8.6811e-02,  3.1685e-02, -2.7450e-02,\n",
            "        -7.4035e-02, -9.3480e-02, -3.6120e-02,  3.2883e-02,  2.4632e-02,\n",
            "         7.7146e-02, -1.8027e-03,  7.2825e-02, -1.1042e-01, -4.9382e-02,\n",
            "         1.0097e-01, -4.4135e-02,  1.2245e-01,  6.5798e-02, -3.0183e-02,\n",
            "         1.2457e-01,  1.0661e-01,  1.2935e-01, -5.4381e-04,  8.1337e-03,\n",
            "         2.7914e-02,  4.4002e-02, -9.0703e-02,  4.7722e-02,  7.3487e-02,\n",
            "        -7.0080e-02, -7.5015e-02, -9.9199e-02, -4.0382e-04,  5.5081e-02,\n",
            "        -2.1531e-02,  3.5514e-02, -3.4456e-02,  3.9471e-02, -1.2303e-01,\n",
            "        -2.3368e-02,  9.8873e-02, -3.3329e-02, -3.7445e-02,  7.3969e-02,\n",
            "         2.2621e-02,  1.0745e-01,  5.6286e-03,  3.4938e-02,  9.4274e-02,\n",
            "         9.0470e-02,  9.3396e-03,  5.0239e-02,  3.7452e-02, -9.9704e-02,\n",
            "        -1.0246e-01,  9.8323e-02,  1.0614e-01,  4.1810e-03,  1.1825e-01,\n",
            "        -9.4493e-02, -8.2055e-02,  4.2147e-02, -5.3203e-02,  6.0078e-03,\n",
            "        -3.2090e-04,  6.5561e-02,  4.2624e-03, -5.5566e-02,  4.9508e-02,\n",
            "        -6.0807e-02,  5.6112e-02,  5.0431e-03, -5.8630e-02, -6.4741e-02,\n",
            "        -2.0166e-02,  1.0320e-01,  4.7425e-02, -1.2171e-01,  7.3409e-02,\n",
            "        -2.7183e-03, -5.3987e-02,  3.8022e-03,  4.7568e-03,  2.3955e-02,\n",
            "         8.4759e-02,  9.2893e-02, -1.6149e-02, -1.9118e-02,  6.0218e-03,\n",
            "        -4.9656e-02, -9.3933e-02, -6.7993e-02, -8.2179e-02, -7.0879e-02,\n",
            "         5.3484e-03,  8.3636e-02, -1.1166e-01, -7.3235e-03, -4.2485e-02,\n",
            "         8.5477e-03, -1.1838e-01, -5.1350e-02,  3.4974e-02,  7.8353e-02,\n",
            "         7.5717e-02,  8.0090e-02,  1.2941e-01,  1.0807e-01,  9.6593e-02,\n",
            "         8.9082e-02, -5.0631e-03,  1.0127e-02, -6.8897e-02,  6.8652e-02,\n",
            "         7.0486e-02, -3.1423e-02,  9.4073e-02,  1.1042e-01,  1.0529e-01,\n",
            "         2.8519e-02, -8.1655e-02,  1.1278e-01, -6.6708e-02, -4.2100e-02,\n",
            "         6.6786e-02,  5.7645e-02,  1.1553e-01,  7.0533e-02, -1.1510e-01,\n",
            "        -9.5240e-02, -4.9171e-02, -3.2382e-02,  1.0343e-01,  7.6984e-02,\n",
            "         7.7463e-04, -7.0324e-02,  1.6726e-02,  2.7942e-02, -7.1933e-02,\n",
            "         8.1140e-02, -7.1324e-02, -6.7040e-02, -3.6548e-02,  1.0010e-01,\n",
            "         2.9336e-02, -2.2568e-06,  5.6779e-03, -1.1700e-02, -5.8647e-02,\n",
            "        -7.6329e-02,  7.3634e-03, -4.0429e-02,  1.1793e-01, -9.9513e-02,\n",
            "        -9.5089e-02,  7.4057e-02, -1.3670e-03,  7.8259e-02, -1.0918e-01,\n",
            "         8.4982e-02, -5.0171e-02, -4.1457e-02, -1.1351e-01, -5.3448e-02,\n",
            "         5.3716e-02, -9.8236e-02, -6.9682e-02,  6.9107e-02,  1.0513e-01,\n",
            "        -2.4658e-02, -4.8874e-02,  8.2872e-02,  8.6009e-02, -7.0811e-02,\n",
            "         1.1513e-01, -1.0339e-01, -9.6937e-02,  1.1809e-01, -7.3024e-02,\n",
            "        -1.1049e-01, -3.1143e-02,  1.2676e-01,  8.1874e-02,  3.8526e-02,\n",
            "        -2.7360e-02, -1.4833e-03, -3.1259e-02,  6.3796e-02, -1.0139e-01,\n",
            "         7.2720e-02,  4.4976e-02,  2.5632e-02,  7.4884e-02,  1.5889e-02,\n",
            "        -1.2167e-01,  6.1287e-02, -5.7973e-02,  2.4316e-02, -7.2230e-02,\n",
            "        -2.5249e-02, -7.8914e-02, -1.2075e-01, -1.2665e-01, -1.1175e-01,\n",
            "        -1.4517e-02, -1.1568e-01, -7.3700e-02,  5.2015e-02, -5.9898e-03,\n",
            "         7.3961e-02,  1.0963e-01,  3.5077e-02,  1.0316e-02,  4.5589e-02,\n",
            "        -1.1985e-01, -8.5525e-02,  5.3007e-02, -5.6938e-02, -5.0631e-02,\n",
            "         1.1205e-01, -9.6936e-02,  3.9363e-02, -5.7988e-02, -1.2237e-01,\n",
            "         1.0765e-01, -6.1913e-02, -4.4520e-02,  2.4131e-02,  9.3296e-02,\n",
            "        -1.0077e-01, -8.4687e-02,  6.5395e-03, -1.4100e-02, -7.6564e-02,\n",
            "        -1.2076e-01,  9.5958e-02,  1.0715e-01, -9.3690e-02, -4.7989e-02,\n",
            "        -1.1191e-01, -8.5885e-02,  1.3656e-02, -2.5624e-02, -1.1009e-01,\n",
            "        -9.2268e-02, -7.1464e-02, -4.1446e-02, -1.6375e-02,  9.1807e-02,\n",
            "        -9.3019e-02,  1.4729e-02,  5.0980e-02, -7.0111e-02, -5.3006e-03,\n",
            "        -4.7701e-02, -7.5725e-02,  8.8472e-02, -3.4881e-03,  1.2814e-01,\n",
            "        -6.8089e-02, -1.6550e-02,  3.3902e-02,  1.0859e-01, -1.3057e-02,\n",
            "        -3.2669e-02,  8.2931e-02,  1.2291e-01, -1.2244e-01, -7.1639e-02,\n",
            "        -1.1744e-02, -1.1927e-01,  5.8361e-02,  9.6265e-02, -1.3717e-02,\n",
            "        -1.2589e-02, -8.2851e-02, -7.5320e-02, -9.1401e-02, -6.5000e-02,\n",
            "         5.2029e-02, -7.4133e-02, -6.4539e-02, -6.4227e-02,  5.9863e-02,\n",
            "        -2.6497e-02,  6.0680e-02,  2.9104e-02, -2.5487e-02,  4.6854e-02,\n",
            "        -1.4715e-02,  2.6542e-02,  7.7155e-02, -1.2084e-01, -4.8170e-02,\n",
            "        -6.6287e-02,  3.8876e-02, -3.2358e-02,  7.8342e-03, -1.1347e-01,\n",
            "        -3.8423e-02, -6.5732e-02,  7.6489e-02,  1.0550e-01, -9.6641e-03,\n",
            "         8.2325e-02,  2.0049e-02,  5.2402e-02, -6.3596e-02, -1.1203e-01,\n",
            "         2.6206e-02, -9.3373e-02, -5.8145e-02, -1.1565e-01,  2.2555e-02,\n",
            "        -2.6708e-02, -2.2580e-02,  7.3093e-02, -1.1237e-01, -1.1410e-01,\n",
            "        -1.0330e-01,  1.2285e-01,  8.0643e-02,  1.8278e-02,  6.0682e-03,\n",
            "        -1.2375e-01, -2.8451e-02,  4.7410e-02,  1.0188e-01,  1.1590e-01,\n",
            "         1.1504e-01, -7.9158e-02], device='cuda:0')\n",
            "decoder.layers.4.ff.linear2.weight: tensor([[ 0.0187, -0.0349, -0.0175,  ..., -0.0207,  0.0208,  0.0300],\n",
            "        [ 0.0166, -0.0069, -0.0189,  ..., -0.0293,  0.0287, -0.0084],\n",
            "        [-0.0357,  0.0256, -0.0177,  ..., -0.0329, -0.0003,  0.0014],\n",
            "        ...,\n",
            "        [-0.0229,  0.0310, -0.0482,  ...,  0.0433, -0.0113, -0.0020],\n",
            "        [-0.0496,  0.0192, -0.0191,  ..., -0.0169,  0.0255, -0.0351],\n",
            "        [-0.0079,  0.0253,  0.0401,  ..., -0.0243,  0.0189, -0.0105]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.4.ff.linear2.bias: tensor([-0.0395,  0.0416, -0.0297,  0.0212, -0.0122, -0.0395,  0.0245, -0.0445,\n",
            "        -0.0397,  0.0368,  0.0031,  0.0293, -0.0255,  0.0209, -0.0236, -0.0255,\n",
            "        -0.0040, -0.0195, -0.0371,  0.0227,  0.0056,  0.0271, -0.0186, -0.0017,\n",
            "         0.0419,  0.0060, -0.0245, -0.0170, -0.0387, -0.0186, -0.0350,  0.0196,\n",
            "        -0.0256, -0.0160,  0.0438,  0.0106, -0.0382, -0.0434,  0.0244,  0.0230,\n",
            "         0.0138, -0.0146,  0.0253, -0.0289,  0.0374,  0.0033,  0.0431,  0.0054,\n",
            "         0.0285, -0.0401, -0.0023, -0.0327,  0.0377, -0.0168, -0.0364,  0.0288,\n",
            "         0.0432,  0.0226,  0.0356, -0.0394, -0.0297,  0.0030,  0.0165,  0.0327],\n",
            "       device='cuda:0')\n",
            "decoder.layers.4.norm1.weight: tensor([1.0009, 1.0013, 0.9944, 0.9973, 0.9942, 0.9995, 0.9981, 1.0003, 0.9941,\n",
            "        1.0107, 1.0011, 1.0085, 1.0010, 1.0046, 1.0101, 0.9936, 0.9939, 0.9956,\n",
            "        1.0051, 0.9910, 0.9912, 1.0111, 1.0018, 1.0005, 0.9985, 1.0018, 1.0062,\n",
            "        1.0127, 1.0041, 1.0023, 0.9951, 1.0005, 1.0098, 0.9995, 1.0077, 0.9840,\n",
            "        1.0096, 0.9984, 1.0056, 1.0089, 0.9963, 1.0003, 1.0002, 0.9992, 0.9988,\n",
            "        0.9967, 1.0007, 1.0099, 0.9988, 1.0079, 1.0046, 0.9919, 1.0008, 1.0112,\n",
            "        0.9994, 1.0100, 1.0044, 0.9974, 0.9946, 1.0051, 1.0021, 1.0032, 1.0067,\n",
            "        0.9965], device='cuda:0')\n",
            "decoder.layers.4.norm1.bias: tensor([ 0.0055,  0.0053,  0.0053, -0.0006,  0.0038,  0.0017,  0.0008, -0.0101,\n",
            "         0.0037,  0.0042, -0.0019,  0.0040,  0.0002, -0.0024, -0.0033,  0.0036,\n",
            "        -0.0033, -0.0037, -0.0024,  0.0029, -0.0058,  0.0040,  0.0048, -0.0034,\n",
            "        -0.0028, -0.0049,  0.0017, -0.0044, -0.0037,  0.0019,  0.0018,  0.0017,\n",
            "        -0.0018,  0.0003, -0.0047, -0.0025,  0.0037, -0.0025,  0.0036,  0.0017,\n",
            "         0.0004, -0.0071, -0.0029, -0.0028,  0.0007, -0.0004,  0.0032,  0.0006,\n",
            "         0.0028, -0.0037,  0.0040,  0.0026, -0.0018,  0.0030,  0.0021, -0.0008,\n",
            "         0.0077,  0.0061, -0.0037, -0.0010, -0.0026, -0.0015, -0.0028, -0.0033],\n",
            "       device='cuda:0')\n",
            "decoder.layers.4.norm2.weight: tensor([0.9992, 1.0002, 0.9941, 0.9994, 0.9939, 0.9993, 0.9985, 1.0033, 0.9980,\n",
            "        1.0108, 1.0025, 1.0093, 0.9992, 1.0000, 1.0082, 0.9962, 0.9929, 0.9953,\n",
            "        1.0030, 0.9963, 0.9887, 1.0097, 1.0036, 1.0028, 0.9987, 0.9998, 1.0035,\n",
            "        1.0081, 1.0012, 0.9991, 0.9965, 1.0031, 1.0046, 1.0017, 1.0050, 0.9850,\n",
            "        1.0072, 0.9980, 1.0042, 1.0111, 0.9973, 1.0026, 0.9999, 0.9980, 0.9976,\n",
            "        0.9967, 1.0034, 1.0086, 0.9992, 1.0066, 1.0041, 0.9883, 1.0010, 1.0060,\n",
            "        1.0007, 1.0086, 1.0024, 0.9944, 0.9949, 1.0009, 1.0055, 1.0017, 1.0052,\n",
            "        0.9956], device='cuda:0')\n",
            "decoder.layers.4.norm2.bias: tensor([ 0.0051,  0.0052,  0.0045, -0.0006,  0.0037,  0.0016,  0.0012, -0.0097,\n",
            "         0.0030,  0.0038, -0.0007,  0.0024,  0.0013, -0.0008, -0.0023,  0.0027,\n",
            "        -0.0035, -0.0020, -0.0016,  0.0021, -0.0075,  0.0034,  0.0041, -0.0038,\n",
            "        -0.0015, -0.0049,  0.0019, -0.0025, -0.0039,  0.0013,  0.0024,  0.0010,\n",
            "        -0.0019,  0.0005, -0.0036, -0.0020,  0.0028, -0.0010,  0.0031,  0.0029,\n",
            "         0.0007, -0.0054, -0.0030, -0.0028,  0.0011,  0.0008,  0.0031,  0.0008,\n",
            "         0.0035, -0.0032,  0.0032,  0.0027, -0.0024,  0.0014,  0.0019, -0.0017,\n",
            "         0.0073,  0.0042, -0.0036, -0.0025, -0.0029, -0.0010, -0.0028, -0.0026],\n",
            "       device='cuda:0')\n",
            "decoder.layers.4.norm3.weight: tensor([0.9970, 1.0032, 0.9958, 0.9990, 0.9951, 1.0008, 0.9975, 0.9982, 0.9966,\n",
            "        1.0114, 1.0033, 1.0050, 0.9987, 1.0032, 1.0040, 0.9940, 0.9947, 0.9972,\n",
            "        1.0006, 1.0002, 0.9945, 1.0126, 1.0022, 0.9986, 0.9970, 1.0002, 1.0084,\n",
            "        1.0082, 1.0022, 0.9954, 0.9966, 1.0051, 1.0048, 0.9999, 1.0063, 0.9840,\n",
            "        1.0038, 0.9998, 1.0060, 1.0101, 0.9948, 1.0011, 0.9968, 0.9995, 0.9998,\n",
            "        0.9989, 1.0035, 1.0057, 1.0061, 1.0023, 1.0077, 0.9939, 1.0025, 1.0048,\n",
            "        0.9986, 1.0034, 1.0085, 0.9954, 0.9993, 1.0050, 1.0079, 1.0025, 1.0036,\n",
            "        0.9973], device='cuda:0')\n",
            "decoder.layers.4.norm3.bias: tensor([ 0.0055,  0.0054,  0.0033, -0.0030,  0.0057,  0.0014,  0.0017, -0.0092,\n",
            "         0.0023,  0.0070,  0.0010,  0.0022,  0.0017, -0.0018, -0.0026,  0.0036,\n",
            "        -0.0044, -0.0034, -0.0008,  0.0022, -0.0076,  0.0044,  0.0046, -0.0025,\n",
            "        -0.0009, -0.0051,  0.0027, -0.0036, -0.0034, -0.0005,  0.0043,  0.0024,\n",
            "        -0.0064,  0.0020, -0.0030, -0.0022,  0.0032, -0.0020,  0.0046,  0.0040,\n",
            "         0.0002, -0.0073, -0.0024, -0.0026,  0.0031, -0.0002,  0.0034,  0.0003,\n",
            "         0.0024, -0.0039,  0.0037,  0.0064, -0.0040,  0.0017,  0.0039, -0.0018,\n",
            "         0.0072,  0.0038, -0.0048, -0.0019, -0.0063, -0.0002, -0.0038, -0.0026],\n",
            "       device='cuda:0')\n",
            "decoder.layers.5.self_attn.w_q.weight: tensor([[-0.0738,  0.0346,  0.0454,  ...,  0.0450,  0.0594, -0.0915],\n",
            "        [-0.0422,  0.1432,  0.1215,  ..., -0.1022,  0.0279,  0.1019],\n",
            "        [-0.0938,  0.0132, -0.0313,  ...,  0.1275, -0.0705,  0.0917],\n",
            "        ...,\n",
            "        [ 0.0239,  0.0461,  0.0213,  ...,  0.1078,  0.0603, -0.0341],\n",
            "        [-0.1061,  0.0427,  0.0108,  ...,  0.0668,  0.0744, -0.1171],\n",
            "        [ 0.1103,  0.0050,  0.0048,  ..., -0.0303, -0.0042,  0.0776]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.5.self_attn.w_k.weight: tensor([[-0.0375, -0.0390,  0.0034,  ...,  0.0443, -0.0042, -0.0187],\n",
            "        [ 0.0734, -0.0787, -0.0604,  ..., -0.0714,  0.1107,  0.1263],\n",
            "        [ 0.1047,  0.1043,  0.0799,  ..., -0.0291,  0.1190, -0.0194],\n",
            "        ...,\n",
            "        [-0.0580,  0.1208,  0.0173,  ..., -0.1175,  0.0284, -0.0645],\n",
            "        [-0.0815, -0.1238, -0.1117,  ..., -0.0240, -0.0420,  0.0268],\n",
            "        [ 0.0499,  0.0650, -0.0321,  ...,  0.0008, -0.0470, -0.0769]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.5.self_attn.w_v.weight: tensor([[ 0.0133, -0.0806,  0.0796,  ...,  0.1119,  0.0190, -0.0203],\n",
            "        [ 0.0980, -0.0838, -0.0688,  ...,  0.1221, -0.0737,  0.1242],\n",
            "        [ 0.0297, -0.0482,  0.0037,  ..., -0.1169,  0.1191, -0.0955],\n",
            "        ...,\n",
            "        [ 0.0708,  0.0973,  0.0674,  ..., -0.0994,  0.0206,  0.0986],\n",
            "        [ 0.1146,  0.0081, -0.1350,  ...,  0.0222, -0.0401, -0.0950],\n",
            "        [-0.0082,  0.1052,  0.0860,  ..., -0.0174, -0.0449,  0.0024]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.5.self_attn.w_o.weight: tensor([[ 0.0429,  0.1200,  0.0031,  ...,  0.0978,  0.0157,  0.1176],\n",
            "        [-0.0433, -0.0015, -0.1173,  ...,  0.0308,  0.0191, -0.1238],\n",
            "        [-0.0990, -0.0632,  0.0879,  ...,  0.1210, -0.0045,  0.0889],\n",
            "        ...,\n",
            "        [ 0.0742,  0.0302,  0.0296,  ..., -0.0498,  0.0051, -0.0582],\n",
            "        [ 0.1128, -0.0421,  0.0472,  ...,  0.0345, -0.0871,  0.0418],\n",
            "        [-0.0089,  0.0972,  0.0527,  ..., -0.0253,  0.0226,  0.0535]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.5.enc_attn.w_q.weight: tensor([[-0.0769, -0.0623,  0.0682,  ..., -0.0754,  0.0387,  0.0519],\n",
            "        [-0.0625, -0.0519,  0.0447,  ..., -0.1210, -0.0280, -0.0048],\n",
            "        [-0.0288,  0.0724, -0.0575,  ...,  0.0417,  0.0055, -0.0050],\n",
            "        ...,\n",
            "        [-0.0080, -0.1425,  0.1362,  ...,  0.0576, -0.1107, -0.0093],\n",
            "        [ 0.0853, -0.0192,  0.0219,  ...,  0.0596,  0.0696,  0.0919],\n",
            "        [ 0.0328, -0.0269,  0.1213,  ..., -0.0015, -0.0015, -0.0413]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.5.enc_attn.w_k.weight: tensor([[ 0.0494,  0.0450, -0.0183,  ...,  0.0416, -0.0241, -0.0815],\n",
            "        [ 0.0454, -0.1188,  0.1393,  ...,  0.0475, -0.0065,  0.1324],\n",
            "        [ 0.0328,  0.0593, -0.0219,  ...,  0.0067, -0.0897, -0.0156],\n",
            "        ...,\n",
            "        [-0.0317,  0.0574,  0.0228,  ..., -0.0057,  0.0826,  0.0588],\n",
            "        [-0.1298, -0.0643, -0.0773,  ..., -0.1225,  0.0858,  0.0075],\n",
            "        [ 0.0684,  0.0345, -0.0735,  ..., -0.0086, -0.0488,  0.0783]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.5.enc_attn.w_v.weight: tensor([[ 0.0161, -0.1087,  0.1162,  ..., -0.0098,  0.0179,  0.1326],\n",
            "        [ 0.0168,  0.0045, -0.0332,  ..., -0.1199,  0.0453,  0.0082],\n",
            "        [ 0.0620, -0.1101,  0.0871,  ...,  0.1067,  0.0332, -0.0955],\n",
            "        ...,\n",
            "        [ 0.0705,  0.1006, -0.0356,  ...,  0.0264,  0.0286,  0.0300],\n",
            "        [ 0.0633,  0.0656,  0.0540,  ...,  0.1180,  0.0637,  0.1199],\n",
            "        [-0.1111, -0.0346,  0.0246,  ..., -0.0022,  0.1111,  0.0856]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.5.enc_attn.w_o.weight: tensor([[-0.0385,  0.0283, -0.0933,  ...,  0.0797, -0.0573,  0.0322],\n",
            "        [-0.0927, -0.0576, -0.0165,  ...,  0.0055,  0.0047,  0.0240],\n",
            "        [ 0.0387, -0.0587,  0.1043,  ..., -0.0898, -0.0395,  0.1091],\n",
            "        ...,\n",
            "        [-0.1207,  0.0597,  0.0016,  ...,  0.0981, -0.0947,  0.0150],\n",
            "        [-0.0041, -0.1354, -0.1216,  ..., -0.1139, -0.0262,  0.1035],\n",
            "        [-0.0487,  0.1197,  0.0971,  ..., -0.0256,  0.0636,  0.0555]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.5.ff.linear1.weight: tensor([[ 0.1016,  0.0521,  0.0197,  ..., -0.0393,  0.0202,  0.1175],\n",
            "        [-0.0380,  0.0125,  0.0964,  ..., -0.0558, -0.0555,  0.0185],\n",
            "        [ 0.0368, -0.1045, -0.0326,  ..., -0.0618,  0.0574,  0.0904],\n",
            "        ...,\n",
            "        [ 0.0750,  0.0950, -0.0975,  ..., -0.0564,  0.1137, -0.1072],\n",
            "        [ 0.0636,  0.0484, -0.1074,  ..., -0.0959, -0.0672, -0.0071],\n",
            "        [ 0.0763, -0.1035, -0.0770,  ..., -0.0329, -0.0670,  0.0596]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.5.ff.linear1.bias: tensor([ 0.0177,  0.1191,  0.0442, -0.0021, -0.0561, -0.0790,  0.0568, -0.0148,\n",
            "        -0.0098, -0.0782,  0.0343, -0.0148, -0.0482,  0.0888, -0.0302, -0.1038,\n",
            "         0.0797, -0.0453, -0.0909,  0.1100,  0.0020, -0.0857, -0.1192,  0.0032,\n",
            "         0.0476, -0.0362, -0.0966, -0.0314,  0.0841,  0.0195, -0.0923,  0.1036,\n",
            "        -0.0563, -0.0554, -0.1052,  0.1115,  0.0568,  0.0408, -0.0138, -0.0596,\n",
            "         0.0673, -0.0564, -0.0392, -0.0114, -0.0180,  0.0680, -0.0963,  0.1217,\n",
            "         0.1158, -0.0682,  0.0475, -0.0141,  0.0936, -0.0315, -0.0039, -0.0775,\n",
            "        -0.0384,  0.0565,  0.0748, -0.0730, -0.1257,  0.0062, -0.0958,  0.0010,\n",
            "        -0.0032,  0.0987,  0.0005,  0.0832, -0.0297,  0.0844,  0.0694,  0.0840,\n",
            "        -0.0918, -0.1205,  0.0228, -0.0029,  0.0282,  0.1230,  0.0483,  0.0819,\n",
            "         0.0338,  0.1021,  0.0080, -0.0601, -0.0257, -0.0698, -0.0058, -0.0180,\n",
            "        -0.0650,  0.0864, -0.0123, -0.0852, -0.0141, -0.0062, -0.0272,  0.0704,\n",
            "        -0.0800, -0.0531, -0.0379,  0.0844,  0.0175, -0.0646, -0.0664,  0.0807,\n",
            "         0.0251, -0.0599, -0.0868,  0.0357,  0.0830, -0.1138, -0.0007,  0.1184,\n",
            "        -0.0751, -0.0990, -0.1036, -0.0736,  0.0071, -0.0906,  0.0053,  0.0151,\n",
            "         0.0708, -0.0900, -0.0211, -0.0266, -0.0101, -0.0343,  0.1097, -0.0524,\n",
            "         0.0287, -0.1189, -0.1079,  0.1143,  0.0838, -0.0407,  0.0381,  0.1159,\n",
            "         0.0085,  0.1087, -0.0513, -0.0638,  0.1243, -0.0477,  0.0894,  0.0672,\n",
            "        -0.0737,  0.0152, -0.1011,  0.0678, -0.1132,  0.1141,  0.1202,  0.1026,\n",
            "        -0.0346,  0.0444,  0.1166,  0.1053, -0.0357, -0.0836, -0.0968,  0.0398,\n",
            "         0.0970, -0.0334, -0.0626,  0.0681,  0.0063,  0.0879,  0.0057,  0.0113,\n",
            "         0.0919,  0.0283,  0.0925, -0.1181, -0.0964,  0.1004, -0.1187,  0.0240,\n",
            "        -0.0200, -0.0456, -0.0169, -0.0710,  0.0418, -0.0179, -0.0487,  0.0655,\n",
            "        -0.1156,  0.0593,  0.0376, -0.0385,  0.1138,  0.0233,  0.1018,  0.0422,\n",
            "         0.1073,  0.1335,  0.0622, -0.1069,  0.0483, -0.0572,  0.0317, -0.0717,\n",
            "         0.0845,  0.0977, -0.0814, -0.0410, -0.1129,  0.0961,  0.1057,  0.0579,\n",
            "         0.1132, -0.0207, -0.1113, -0.0245, -0.0572, -0.0277,  0.0652,  0.1047,\n",
            "         0.0474, -0.0604, -0.0739,  0.1012, -0.0989,  0.0392, -0.0378,  0.0796,\n",
            "        -0.1195,  0.0215,  0.0457,  0.0177, -0.0118,  0.1012, -0.0635,  0.0319,\n",
            "         0.0201, -0.0026,  0.0461, -0.0458,  0.1097,  0.0624, -0.0502,  0.0756,\n",
            "         0.0199, -0.0723, -0.0111, -0.0185,  0.0744,  0.0414, -0.0238,  0.0517,\n",
            "         0.0047,  0.0738,  0.0110,  0.0510,  0.0736, -0.0971,  0.1245,  0.0492,\n",
            "         0.1010, -0.0336,  0.0706,  0.0564, -0.1086,  0.0584, -0.0325,  0.1064,\n",
            "         0.0578,  0.1025, -0.0973, -0.1152, -0.0369,  0.0122, -0.0316,  0.1160,\n",
            "        -0.0254,  0.0642, -0.0528,  0.0862, -0.0163, -0.0708,  0.0480, -0.0177,\n",
            "         0.0225, -0.0830,  0.0540, -0.0017, -0.0087,  0.0242, -0.0337, -0.1148,\n",
            "         0.1070, -0.0976,  0.0224, -0.0171,  0.0621, -0.0549,  0.0353,  0.0930,\n",
            "         0.0808, -0.0769, -0.0919, -0.0338,  0.0669,  0.0680, -0.0600,  0.0662,\n",
            "         0.0922,  0.0548,  0.0809, -0.0769, -0.0805,  0.0673,  0.0438,  0.0922,\n",
            "        -0.1009,  0.0116,  0.0510, -0.0091, -0.1142, -0.0782,  0.0146, -0.1310,\n",
            "        -0.1188,  0.0604, -0.0779, -0.0584, -0.1221,  0.1200,  0.1119,  0.0173,\n",
            "        -0.0003, -0.0306, -0.0424, -0.1049, -0.0496,  0.1227,  0.0548,  0.1135,\n",
            "         0.0128,  0.0998,  0.0782,  0.0186, -0.0503, -0.0747,  0.1223,  0.0833,\n",
            "        -0.0393, -0.0550, -0.0669, -0.0221, -0.0518, -0.0138, -0.0207, -0.1278,\n",
            "        -0.0071, -0.0527, -0.0924,  0.0220,  0.0467,  0.0415,  0.0452, -0.0170,\n",
            "        -0.0410, -0.1185, -0.0698, -0.1067,  0.0904, -0.0715, -0.1108, -0.1036,\n",
            "        -0.0026,  0.1155, -0.0463, -0.0657, -0.0759, -0.0264, -0.0364,  0.0156,\n",
            "        -0.0792,  0.0028,  0.0008,  0.0154, -0.0308, -0.0970,  0.0580,  0.0668,\n",
            "        -0.0673,  0.0045,  0.0394,  0.0410,  0.0531,  0.0883, -0.0600, -0.1167,\n",
            "         0.0617,  0.0992, -0.0070,  0.0587, -0.0338, -0.0292,  0.0941, -0.1047,\n",
            "        -0.0403,  0.0161, -0.0222,  0.0105,  0.0241,  0.0156,  0.1213,  0.0349,\n",
            "         0.0468, -0.0494,  0.0854, -0.0138, -0.0040, -0.0695,  0.0134,  0.0468,\n",
            "        -0.0735, -0.0336,  0.0632,  0.0247, -0.0169, -0.0124,  0.0206,  0.0231,\n",
            "         0.0538, -0.0789, -0.0045, -0.0271,  0.0810, -0.0539,  0.0562, -0.0315,\n",
            "        -0.0931,  0.0886,  0.0719, -0.1128,  0.0144, -0.0033,  0.0708,  0.0922,\n",
            "        -0.0702,  0.0627,  0.0249,  0.1183, -0.0185,  0.0025, -0.0089,  0.0475,\n",
            "        -0.0486, -0.0850, -0.0214,  0.0952,  0.1138,  0.0587, -0.0219,  0.0098,\n",
            "         0.0056, -0.0148, -0.0314, -0.1008, -0.0835,  0.0544, -0.0706, -0.0679,\n",
            "         0.0597, -0.1065, -0.0480, -0.1162,  0.0800, -0.0866, -0.1104,  0.0566,\n",
            "         0.0884,  0.0032,  0.0515,  0.1150, -0.0552, -0.0956, -0.0798, -0.0267,\n",
            "         0.1048,  0.0468,  0.1143, -0.1135,  0.0335,  0.0364,  0.0391, -0.0216,\n",
            "        -0.0116,  0.0345, -0.0956, -0.0230,  0.0327, -0.0008,  0.0204,  0.0946,\n",
            "         0.1116,  0.0922,  0.1052, -0.0959, -0.0177,  0.0400,  0.0094,  0.1025,\n",
            "        -0.0159, -0.0396,  0.0059, -0.0669, -0.0285,  0.0500, -0.0169,  0.1073],\n",
            "       device='cuda:0')\n",
            "decoder.layers.5.ff.linear2.weight: tensor([[-0.0123,  0.0255, -0.0434,  ...,  0.0487, -0.0381,  0.0469],\n",
            "        [-0.0069, -0.0418,  0.0060,  ..., -0.0375, -0.0212, -0.0274],\n",
            "        [ 0.0398,  0.0368,  0.0247,  ...,  0.0287, -0.0090,  0.0056],\n",
            "        ...,\n",
            "        [ 0.0367,  0.0158, -0.0143,  ...,  0.0349,  0.0176, -0.0031],\n",
            "        [ 0.0129,  0.0053, -0.0221,  ..., -0.0390, -0.0308,  0.0111],\n",
            "        [ 0.0079,  0.0348, -0.0205,  ..., -0.0461, -0.0472, -0.0208]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.5.ff.linear2.bias: tensor([-0.0430, -0.0024, -0.0151, -0.0030, -0.0396, -0.0077,  0.0128,  0.0023,\n",
            "         0.0149,  0.0313, -0.0279, -0.0021,  0.0334,  0.0342, -0.0062,  0.0452,\n",
            "        -0.0313, -0.0176,  0.0175,  0.0112, -0.0424,  0.0398,  0.0089,  0.0264,\n",
            "         0.0423, -0.0273,  0.0161, -0.0110, -0.0003, -0.0381,  0.0025, -0.0233,\n",
            "        -0.0320,  0.0329, -0.0263, -0.0112, -0.0415,  0.0083,  0.0104,  0.0101,\n",
            "        -0.0423,  0.0231, -0.0154, -0.0040, -0.0033,  0.0415,  0.0300, -0.0356,\n",
            "         0.0002, -0.0119, -0.0393, -0.0027, -0.0387, -0.0234, -0.0274,  0.0189,\n",
            "        -0.0258,  0.0281, -0.0131, -0.0059,  0.0237, -0.0046, -0.0075,  0.0038],\n",
            "       device='cuda:0')\n",
            "decoder.layers.5.norm1.weight: tensor([0.9910, 1.0045, 0.9947, 0.9969, 0.9954, 1.0000, 0.9946, 1.0003, 0.9962,\n",
            "        1.0083, 1.0001, 1.0029, 0.9979, 1.0040, 1.0020, 0.9933, 0.9957, 0.9952,\n",
            "        0.9984, 1.0000, 0.9938, 1.0092, 0.9992, 0.9954, 0.9947, 1.0012, 1.0043,\n",
            "        1.0092, 1.0039, 0.9966, 0.9982, 1.0064, 0.9995, 1.0004, 1.0071, 0.9845,\n",
            "        1.0037, 0.9992, 1.0006, 1.0096, 0.9940, 0.9980, 0.9965, 0.9931, 1.0010,\n",
            "        0.9988, 1.0039, 1.0039, 0.9999, 1.0030, 1.0070, 0.9931, 1.0008, 0.9997,\n",
            "        0.9979, 1.0050, 1.0086, 0.9971, 0.9940, 1.0030, 1.0046, 0.9994, 0.9963,\n",
            "        0.9978], device='cuda:0')\n",
            "decoder.layers.5.norm1.bias: tensor([ 0.0064,  0.0058,  0.0040, -0.0036,  0.0035,  0.0003,  0.0050, -0.0104,\n",
            "         0.0045,  0.0068,  0.0008,  0.0085, -0.0003, -0.0035, -0.0047,  0.0042,\n",
            "        -0.0051, -0.0041, -0.0010,  0.0045, -0.0074,  0.0032,  0.0067, -0.0043,\n",
            "        -0.0009, -0.0049,  0.0011, -0.0074, -0.0029, -0.0034,  0.0025,  0.0023,\n",
            "        -0.0045,  0.0067, -0.0035, -0.0022,  0.0058, -0.0026,  0.0036,  0.0035,\n",
            "         0.0036, -0.0074, -0.0029, -0.0028,  0.0063, -0.0016,  0.0061, -0.0054,\n",
            "         0.0030, -0.0036,  0.0041,  0.0068, -0.0077,  0.0029,  0.0050, -0.0016,\n",
            "         0.0062,  0.0054, -0.0050, -0.0022, -0.0075,  0.0013, -0.0022, -0.0098],\n",
            "       device='cuda:0')\n",
            "decoder.layers.5.norm2.weight: tensor([0.9975, 1.0035, 0.9979, 0.9964, 0.9962, 1.0017, 1.0011, 1.0003, 1.0072,\n",
            "        1.0081, 0.9999, 1.0048, 0.9972, 1.0076, 1.0059, 0.9955, 0.9941, 1.0012,\n",
            "        0.9972, 1.0010, 0.9955, 1.0055, 0.9988, 0.9959, 0.9986, 1.0068, 1.0043,\n",
            "        1.0050, 1.0029, 0.9948, 0.9976, 1.0061, 0.9981, 1.0027, 1.0071, 0.9912,\n",
            "        1.0011, 0.9989, 0.9991, 1.0125, 0.9922, 0.9996, 1.0019, 0.9965, 1.0018,\n",
            "        1.0019, 1.0057, 1.0051, 1.0006, 1.0025, 1.0021, 0.9934, 1.0028, 0.9988,\n",
            "        1.0037, 1.0070, 1.0027, 1.0008, 0.9958, 1.0010, 1.0000, 0.9988, 0.9917,\n",
            "        1.0001], device='cuda:0')\n",
            "decoder.layers.5.norm2.bias: tensor([ 0.0060,  0.0069,  0.0041, -0.0016,  0.0019, -0.0011,  0.0052, -0.0070,\n",
            "         0.0046,  0.0056,  0.0012,  0.0057,  0.0038, -0.0005, -0.0047,  0.0038,\n",
            "        -0.0048, -0.0042,  0.0005,  0.0038, -0.0065,  0.0029,  0.0049, -0.0057,\n",
            "         0.0002, -0.0046,  0.0022, -0.0064, -0.0006, -0.0044,  0.0043,  0.0039,\n",
            "        -0.0024,  0.0049, -0.0027,  0.0007,  0.0043, -0.0029,  0.0048,  0.0036,\n",
            "         0.0026, -0.0061, -0.0031, -0.0024,  0.0070, -0.0041,  0.0043, -0.0046,\n",
            "         0.0014, -0.0046,  0.0012,  0.0055, -0.0049,  0.0020,  0.0055, -0.0039,\n",
            "         0.0018,  0.0041, -0.0039, -0.0023, -0.0056,  0.0026,  0.0017, -0.0085],\n",
            "       device='cuda:0')\n",
            "decoder.layers.5.norm3.weight: tensor([0.9995, 0.9995, 0.9997, 0.9960, 0.9968, 1.0033, 1.0041, 1.0009, 1.0025,\n",
            "        1.0040, 0.9987, 1.0064, 0.9981, 1.0085, 1.0044, 0.9964, 0.9979, 1.0017,\n",
            "        1.0014, 1.0033, 0.9988, 1.0019, 0.9978, 0.9919, 0.9986, 1.0022, 1.0015,\n",
            "        1.0056, 1.0043, 0.9980, 0.9984, 1.0014, 0.9962, 1.0002, 1.0052, 0.9919,\n",
            "        0.9970, 1.0036, 0.9998, 1.0095, 0.9963, 0.9969, 1.0013, 0.9957, 1.0016,\n",
            "        1.0031, 1.0043, 1.0041, 1.0046, 1.0011, 1.0011, 0.9935, 1.0025, 1.0020,\n",
            "        1.0035, 1.0066, 1.0049, 1.0006, 0.9991, 1.0008, 1.0045, 0.9996, 0.9944,\n",
            "        0.9999], device='cuda:0')\n",
            "decoder.layers.5.norm3.bias: tensor([ 0.0101,  0.0078,  0.0046, -0.0031,  0.0037, -0.0015,  0.0063, -0.0082,\n",
            "         0.0078,  0.0046, -0.0006,  0.0085,  0.0057, -0.0029, -0.0058,  0.0047,\n",
            "        -0.0066, -0.0045, -0.0005,  0.0044, -0.0070,  0.0060,  0.0067, -0.0064,\n",
            "        -0.0001, -0.0032,  0.0033, -0.0053, -0.0005, -0.0057,  0.0074,  0.0052,\n",
            "        -0.0043,  0.0056, -0.0045,  0.0045,  0.0055, -0.0050,  0.0060,  0.0039,\n",
            "         0.0043, -0.0076, -0.0062, -0.0046,  0.0072, -0.0048,  0.0042, -0.0072,\n",
            "         0.0034, -0.0052,  0.0018,  0.0050, -0.0043,  0.0024,  0.0063, -0.0040,\n",
            "         0.0017,  0.0061, -0.0053, -0.0041, -0.0077,  0.0033, -0.0002, -0.0086],\n",
            "       device='cuda:0')\n",
            "decoder.layers.6.self_attn.w_q.weight: tensor([[-0.0715, -0.1024, -0.0909,  ...,  0.0146,  0.0239, -0.0523],\n",
            "        [ 0.0883,  0.0516, -0.0477,  ...,  0.0839,  0.1172,  0.0359],\n",
            "        [ 0.0643, -0.0338,  0.0434,  ...,  0.0055,  0.0572,  0.0228],\n",
            "        ...,\n",
            "        [ 0.0736,  0.0057, -0.1380,  ..., -0.0982,  0.1191, -0.1039],\n",
            "        [ 0.0280, -0.0785,  0.0201,  ...,  0.0301,  0.0577, -0.0378],\n",
            "        [-0.1054,  0.1049, -0.0924,  ...,  0.1192,  0.0063, -0.0198]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.6.self_attn.w_k.weight: tensor([[ 0.0345, -0.0419, -0.0253,  ...,  0.0892, -0.0546, -0.1190],\n",
            "        [-0.0414, -0.0822, -0.0902,  ..., -0.0165,  0.0299, -0.0962],\n",
            "        [-0.0758, -0.0149, -0.1263,  ..., -0.0715, -0.1056, -0.1055],\n",
            "        ...,\n",
            "        [ 0.0428, -0.0674,  0.0438,  ..., -0.0114, -0.0733,  0.1216],\n",
            "        [ 0.0374, -0.0650, -0.0028,  ..., -0.0606,  0.1103,  0.0092],\n",
            "        [ 0.0877, -0.1092,  0.0512,  ..., -0.0939, -0.1114, -0.0598]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.6.self_attn.w_v.weight: tensor([[ 0.0088,  0.1136, -0.0402,  ..., -0.0805,  0.0034,  0.0854],\n",
            "        [ 0.0718, -0.0412, -0.0521,  ...,  0.0019,  0.0299,  0.0399],\n",
            "        [ 0.0305,  0.0586, -0.0978,  ...,  0.0255, -0.1035,  0.0113],\n",
            "        ...,\n",
            "        [ 0.0104,  0.0647,  0.0440,  ..., -0.0747,  0.0627, -0.0712],\n",
            "        [ 0.0697, -0.0475,  0.0302,  ...,  0.0831, -0.0435, -0.1075],\n",
            "        [ 0.0069, -0.0470,  0.0479,  ...,  0.0214, -0.1105,  0.0219]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.6.self_attn.w_o.weight: tensor([[-0.0531, -0.0163, -0.0531,  ..., -0.0085, -0.0940, -0.0353],\n",
            "        [ 0.0670,  0.0376, -0.0042,  ...,  0.0066,  0.0080, -0.0146],\n",
            "        [ 0.0123, -0.0473,  0.0432,  ..., -0.0261,  0.0514, -0.0414],\n",
            "        ...,\n",
            "        [-0.0402, -0.1275,  0.0364,  ..., -0.0926, -0.0852, -0.1019],\n",
            "        [-0.0099,  0.0517, -0.1056,  ..., -0.0791, -0.1046,  0.0302],\n",
            "        [ 0.0941, -0.0400,  0.0379,  ...,  0.0033,  0.0132,  0.0124]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.6.enc_attn.w_q.weight: tensor([[ 0.0393, -0.1342, -0.0232,  ...,  0.0495, -0.0201, -0.0978],\n",
            "        [-0.0084,  0.1071, -0.0912,  ...,  0.0712, -0.0864,  0.0880],\n",
            "        [ 0.0708, -0.0958, -0.0075,  ...,  0.0825,  0.0307, -0.0750],\n",
            "        ...,\n",
            "        [-0.0223, -0.1209,  0.1144,  ...,  0.0313, -0.0209,  0.0988],\n",
            "        [-0.0473,  0.0740,  0.0832,  ..., -0.0556,  0.1059, -0.0228],\n",
            "        [ 0.0536, -0.0893, -0.0665,  ..., -0.0747,  0.0096,  0.0339]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.6.enc_attn.w_k.weight: tensor([[ 0.0147, -0.0136,  0.0438,  ..., -0.0558, -0.0673,  0.1091],\n",
            "        [-0.0787,  0.0852, -0.0370,  ...,  0.0404, -0.0698, -0.1143],\n",
            "        [ 0.1509,  0.0068,  0.0531,  ...,  0.0089, -0.1158,  0.1260],\n",
            "        ...,\n",
            "        [-0.0939, -0.0211,  0.0174,  ...,  0.0935, -0.0737, -0.1183],\n",
            "        [-0.0495,  0.0105, -0.0983,  ..., -0.1197,  0.0208,  0.0347],\n",
            "        [-0.1185,  0.0085,  0.0213,  ...,  0.0985, -0.0746,  0.0212]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.6.enc_attn.w_v.weight: tensor([[ 0.0174,  0.0625, -0.0697,  ..., -0.1318, -0.0489, -0.0149],\n",
            "        [-0.0207,  0.0674, -0.0595,  ..., -0.0696,  0.0768, -0.0250],\n",
            "        [-0.0105,  0.1175, -0.0074,  ..., -0.0903,  0.1046,  0.0870],\n",
            "        ...,\n",
            "        [-0.1212, -0.1287,  0.0189,  ...,  0.0467, -0.1152,  0.0610],\n",
            "        [-0.0688,  0.0413, -0.1191,  ...,  0.1055,  0.0863,  0.0289],\n",
            "        [-0.0281, -0.0267,  0.0776,  ..., -0.0307, -0.0421, -0.1072]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.6.enc_attn.w_o.weight: tensor([[ 0.0513, -0.0978,  0.0915,  ..., -0.0718,  0.0654,  0.0268],\n",
            "        [-0.0059, -0.0874, -0.1453,  ..., -0.0132,  0.0958,  0.0043],\n",
            "        [ 0.0324,  0.0238,  0.0345,  ...,  0.0894,  0.0823, -0.0523],\n",
            "        ...,\n",
            "        [-0.1260,  0.0388,  0.0958,  ...,  0.0469, -0.0762, -0.0852],\n",
            "        [-0.0057,  0.0501,  0.0737,  ..., -0.0924,  0.0159,  0.1236],\n",
            "        [-0.0718,  0.1157,  0.0985,  ..., -0.0153, -0.0553,  0.0622]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.6.ff.linear1.weight: tensor([[ 0.1250, -0.0081, -0.0631,  ..., -0.1033,  0.0155, -0.0606],\n",
            "        [-0.0816,  0.0639,  0.0154,  ..., -0.0834,  0.0281,  0.1008],\n",
            "        [-0.0272,  0.0314,  0.1087,  ...,  0.0879, -0.0820, -0.0255],\n",
            "        ...,\n",
            "        [ 0.1104, -0.1114,  0.0739,  ..., -0.0967,  0.0283, -0.0146],\n",
            "        [ 0.0205, -0.0925, -0.0800,  ..., -0.0375, -0.0844, -0.0349],\n",
            "        [ 0.0136,  0.0448,  0.0314,  ..., -0.0077, -0.1141, -0.1132]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.6.ff.linear1.bias: tensor([ 0.0307, -0.0429, -0.0931, -0.0274, -0.0399, -0.1078, -0.0006,  0.0853,\n",
            "        -0.0002,  0.0169, -0.0300, -0.0046, -0.1199, -0.1196, -0.0281, -0.0921,\n",
            "         0.1074,  0.0224, -0.0148, -0.0678,  0.0538,  0.0732,  0.0114,  0.0564,\n",
            "         0.0246,  0.0015,  0.1038, -0.1255, -0.1328, -0.0489, -0.0928,  0.0826,\n",
            "        -0.0028,  0.0706, -0.0119, -0.0047, -0.0935, -0.1023,  0.0201,  0.0356,\n",
            "         0.1102,  0.1166,  0.0398,  0.0982, -0.1208,  0.0362,  0.0603,  0.0159,\n",
            "        -0.0164, -0.0669,  0.1216,  0.1222, -0.0061, -0.1062,  0.0887,  0.0234,\n",
            "         0.1028, -0.0587, -0.0086, -0.1012, -0.1141,  0.0456, -0.1057,  0.1174,\n",
            "        -0.0471, -0.0983,  0.0528, -0.0099,  0.0765, -0.0433, -0.0998, -0.0399,\n",
            "        -0.0899,  0.0484, -0.0430,  0.0913, -0.0193,  0.0704,  0.1034,  0.0036,\n",
            "        -0.0844, -0.0722, -0.0974,  0.1088, -0.0113, -0.1216, -0.0791,  0.0098,\n",
            "         0.0314,  0.0625, -0.0686,  0.0788,  0.0082, -0.0509,  0.0949, -0.0808,\n",
            "         0.0308, -0.0825, -0.0452,  0.1065, -0.0502,  0.1031, -0.0219, -0.1194,\n",
            "        -0.0861,  0.0988,  0.0519,  0.1097, -0.0134,  0.0143, -0.0933, -0.0395,\n",
            "        -0.0419, -0.1219,  0.0925,  0.0378, -0.0734, -0.0207,  0.0399,  0.0241,\n",
            "         0.0234, -0.0049,  0.0962,  0.0860,  0.0023,  0.0796, -0.0986,  0.0381,\n",
            "        -0.0688,  0.0458,  0.0489, -0.0145, -0.0174,  0.0727, -0.0344, -0.0170,\n",
            "         0.0464,  0.0335,  0.1026,  0.0041,  0.1103,  0.1149, -0.0030, -0.0293,\n",
            "        -0.0564, -0.0431, -0.1235,  0.0299, -0.1122,  0.0900, -0.1197,  0.0640,\n",
            "         0.0471, -0.0516, -0.0045, -0.1053, -0.1145,  0.0569,  0.1167,  0.1251,\n",
            "         0.1038,  0.0201,  0.0648, -0.0880,  0.0848,  0.0421,  0.1122,  0.0773,\n",
            "         0.0163,  0.0200, -0.0344,  0.1097, -0.0724, -0.1067, -0.0080,  0.0095,\n",
            "        -0.0295, -0.0472,  0.1170, -0.0253, -0.0095, -0.0914, -0.1048,  0.0595,\n",
            "        -0.0827,  0.0970,  0.1228,  0.0269, -0.0174, -0.0677, -0.0036,  0.1126,\n",
            "         0.0457, -0.0430, -0.0676, -0.0010,  0.0865,  0.0274,  0.0518, -0.0534,\n",
            "        -0.0042,  0.0912,  0.1144, -0.0621, -0.0893, -0.0348,  0.1050, -0.0446,\n",
            "        -0.0397, -0.0011, -0.0560,  0.0099,  0.0922, -0.0553,  0.0835, -0.0492,\n",
            "         0.0426, -0.0168,  0.1193, -0.1050,  0.1027, -0.0567,  0.0584,  0.0838,\n",
            "        -0.0381, -0.0147,  0.0007, -0.1254,  0.0419,  0.1170,  0.0427,  0.1205,\n",
            "         0.0484, -0.0916,  0.0825,  0.1164,  0.0744, -0.0312, -0.0694,  0.0802,\n",
            "        -0.0139,  0.1105,  0.0789, -0.1254,  0.0449,  0.0140, -0.0934,  0.1102,\n",
            "         0.0665, -0.0356, -0.0063,  0.0962, -0.1078, -0.1171, -0.0868,  0.0772,\n",
            "         0.1145,  0.1209,  0.0426,  0.1019, -0.1077,  0.0076, -0.1084, -0.0466,\n",
            "         0.0014, -0.0900, -0.0289, -0.0900,  0.0286, -0.0979, -0.0134,  0.1019,\n",
            "         0.0641,  0.1005, -0.0494,  0.1005, -0.0079, -0.1282,  0.0596,  0.0152,\n",
            "        -0.0725,  0.0128, -0.0325,  0.0773,  0.0074,  0.0221,  0.0646,  0.0592,\n",
            "         0.0897,  0.1025, -0.0820,  0.0917,  0.1119, -0.1257, -0.0501, -0.0876,\n",
            "        -0.0588, -0.1110,  0.0619, -0.1059,  0.1029,  0.1044, -0.0987, -0.0789,\n",
            "        -0.0013, -0.0901,  0.0742, -0.0906, -0.0296, -0.0717,  0.0444, -0.0562,\n",
            "        -0.0114, -0.0318, -0.0859,  0.1101,  0.0359,  0.0935,  0.1024,  0.0477,\n",
            "        -0.0797,  0.0440,  0.0072, -0.0668,  0.0574, -0.0687,  0.0248, -0.0432,\n",
            "        -0.1214,  0.1049, -0.1180,  0.0555,  0.0695,  0.0936,  0.0851, -0.0449,\n",
            "        -0.0665,  0.0097,  0.0169,  0.0699, -0.1168, -0.0194,  0.0533, -0.0103,\n",
            "         0.0780, -0.0007,  0.0923, -0.0894, -0.0491,  0.0526,  0.1094, -0.0330,\n",
            "        -0.0792, -0.0808,  0.1015, -0.0767, -0.0193, -0.0041, -0.0406,  0.0781,\n",
            "        -0.0529,  0.0110, -0.0277,  0.0882,  0.0702, -0.0440, -0.0017, -0.0232,\n",
            "         0.1019,  0.0559, -0.0489,  0.1163,  0.0332, -0.0879, -0.0639,  0.1125,\n",
            "         0.0876, -0.0346, -0.0390,  0.0433, -0.0194,  0.0475,  0.0061,  0.0782,\n",
            "         0.0139, -0.0011,  0.1006, -0.0522,  0.0928,  0.0201, -0.0660, -0.1173,\n",
            "        -0.0990,  0.0941,  0.0033,  0.0863, -0.0783, -0.0474, -0.0809,  0.0716,\n",
            "         0.0342,  0.0293, -0.0145,  0.0445,  0.0891,  0.0485,  0.0634,  0.0217,\n",
            "        -0.0143,  0.0576,  0.0558,  0.0131, -0.1149, -0.0621, -0.0131,  0.0960,\n",
            "         0.0210, -0.0686, -0.0347, -0.0208, -0.0050,  0.0539, -0.0332,  0.0197,\n",
            "        -0.0967,  0.0747, -0.1277, -0.0077,  0.0508, -0.0936, -0.1108, -0.0612,\n",
            "        -0.1071,  0.0558,  0.0782, -0.1262, -0.0443, -0.1015,  0.0031,  0.0547,\n",
            "        -0.0571,  0.0147,  0.0393,  0.0122,  0.1093, -0.0877, -0.0338,  0.1139,\n",
            "        -0.0404,  0.0881,  0.1022, -0.0902,  0.0246,  0.0987, -0.0713, -0.0512,\n",
            "         0.0243, -0.0468,  0.0999, -0.0589, -0.0948, -0.0527, -0.0446, -0.0091,\n",
            "         0.0292,  0.0245,  0.1067, -0.1200, -0.1078, -0.0396, -0.0232, -0.0314,\n",
            "        -0.0367,  0.0915,  0.0109,  0.0780, -0.0973, -0.0913,  0.0049,  0.0606,\n",
            "         0.0117,  0.0936, -0.1281,  0.0538,  0.0203, -0.0639,  0.0437, -0.0764,\n",
            "         0.0490,  0.1025,  0.0022,  0.1306,  0.0241, -0.0242, -0.0482,  0.1130,\n",
            "         0.0906,  0.0271,  0.1009, -0.0890,  0.0596,  0.0366, -0.0696, -0.0009,\n",
            "        -0.0015,  0.0608, -0.1216, -0.0953, -0.0440,  0.1113, -0.0400, -0.0367],\n",
            "       device='cuda:0')\n",
            "decoder.layers.6.ff.linear2.weight: tensor([[ 0.0147,  0.0035,  0.0322,  ..., -0.0393,  0.0065,  0.0097],\n",
            "        [ 0.0195,  0.0016, -0.0175,  ..., -0.0068, -0.0394, -0.0352],\n",
            "        [ 0.0149,  0.0222,  0.0311,  ..., -0.0378,  0.0350, -0.0159],\n",
            "        ...,\n",
            "        [ 0.0451,  0.0273, -0.0031,  ...,  0.0229, -0.0437, -0.0255],\n",
            "        [ 0.0388, -0.0492, -0.0154,  ...,  0.0416,  0.0110, -0.0162],\n",
            "        [-0.0404, -0.0334, -0.0058,  ..., -0.0123, -0.0263, -0.0067]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.6.ff.linear2.bias: tensor([ 0.0242, -0.0158, -0.0328,  0.0317, -0.0402, -0.0335,  0.0018, -0.0416,\n",
            "         0.0026,  0.0437,  0.0164,  0.0266, -0.0104,  0.0372, -0.0327, -0.0392,\n",
            "        -0.0368, -0.0002, -0.0014, -0.0038,  0.0049, -0.0369, -0.0154, -0.0411,\n",
            "        -0.0273,  0.0152, -0.0338,  0.0094, -0.0424,  0.0348, -0.0273, -0.0164,\n",
            "        -0.0189, -0.0223, -0.0329, -0.0352, -0.0301,  0.0157,  0.0129,  0.0012,\n",
            "         0.0127, -0.0433,  0.0135,  0.0172,  0.0149, -0.0194,  0.0282, -0.0350,\n",
            "        -0.0015,  0.0077, -0.0282, -0.0087,  0.0456,  0.0305, -0.0260,  0.0237,\n",
            "        -0.0432, -0.0402,  0.0036,  0.0042,  0.0321,  0.0119, -0.0355, -0.0157],\n",
            "       device='cuda:0')\n",
            "decoder.layers.6.norm1.weight: tensor([0.9967, 0.9943, 0.9983, 0.9965, 0.9956, 1.0032, 1.0010, 1.0040, 1.0016,\n",
            "        1.0003, 0.9985, 1.0064, 0.9963, 1.0058, 0.9997, 0.9942, 0.9970, 0.9967,\n",
            "        1.0057, 1.0013, 0.9988, 0.9991, 0.9983, 0.9891, 0.9972, 0.9982, 0.9995,\n",
            "        1.0026, 0.9999, 0.9994, 0.9986, 1.0007, 0.9954, 0.9986, 1.0051, 0.9951,\n",
            "        0.9955, 1.0034, 0.9983, 1.0082, 0.9954, 0.9950, 0.9976, 0.9944, 0.9948,\n",
            "        1.0036, 1.0016, 1.0034, 1.0053, 1.0048, 1.0039, 0.9882, 1.0013, 0.9986,\n",
            "        1.0017, 1.0051, 1.0081, 0.9981, 0.9974, 0.9952, 1.0020, 1.0037, 0.9954,\n",
            "        0.9989], device='cuda:0')\n",
            "decoder.layers.6.norm1.bias: tensor([ 8.9506e-03,  7.1206e-03,  1.0041e-02, -2.8778e-03,  4.1144e-03,\n",
            "        -1.9858e-03,  6.5844e-03, -1.0640e-02,  9.0404e-03,  4.7168e-03,\n",
            "        -5.0776e-03,  9.0762e-03,  5.8733e-03, -4.7990e-03, -6.1766e-03,\n",
            "         6.6989e-03, -4.5696e-03, -1.8044e-03, -4.6231e-03,  4.3511e-03,\n",
            "        -8.3531e-03,  6.1056e-03,  7.5037e-03, -6.5563e-03, -2.2729e-03,\n",
            "        -5.4285e-03,  5.0814e-03, -9.0588e-03, -1.1944e-05, -7.4472e-03,\n",
            "         6.6443e-03,  6.0630e-03, -4.2960e-03,  5.8550e-03, -4.5400e-03,\n",
            "         8.5877e-03,  4.3965e-03, -6.3409e-03,  8.6381e-03,  4.9109e-03,\n",
            "         7.2444e-03, -8.7102e-03, -4.7825e-03, -5.3378e-03,  4.5722e-03,\n",
            "        -7.7616e-03,  4.3895e-03, -1.2541e-02,  7.0995e-03, -5.2327e-03,\n",
            "         1.1785e-03,  2.9230e-03, -4.7301e-03,  1.0134e-03,  5.2707e-03,\n",
            "        -9.3619e-03,  4.2486e-04,  5.8291e-03, -8.3290e-03, -4.8680e-03,\n",
            "        -8.6018e-03,  4.5741e-03, -3.2536e-03, -9.0319e-03], device='cuda:0')\n",
            "decoder.layers.6.norm2.weight: tensor([0.9949, 0.9940, 1.0004, 0.9948, 0.9982, 1.0071, 1.0083, 1.0042, 1.0084,\n",
            "        0.9997, 0.9960, 1.0022, 0.9974, 1.0094, 1.0032, 1.0011, 0.9993, 1.0020,\n",
            "        1.0062, 1.0000, 0.9968, 0.9987, 0.9988, 0.9938, 1.0012, 1.0020, 1.0015,\n",
            "        1.0052, 0.9957, 0.9970, 1.0034, 1.0011, 0.9872, 1.0009, 1.0085, 1.0024,\n",
            "        0.9996, 0.9994, 1.0001, 1.0061, 0.9967, 0.9954, 0.9963, 0.9931, 0.9954,\n",
            "        1.0107, 1.0005, 1.0017, 1.0089, 1.0030, 1.0020, 0.9942, 1.0061, 0.9984,\n",
            "        1.0099, 1.0028, 1.0055, 0.9998, 0.9930, 0.9966, 1.0004, 1.0045, 0.9986,\n",
            "        0.9969], device='cuda:0')\n",
            "decoder.layers.6.norm2.bias: tensor([ 0.0072,  0.0093,  0.0089, -0.0013,  0.0039, -0.0029,  0.0064, -0.0077,\n",
            "         0.0094,  0.0025, -0.0056,  0.0079,  0.0078, -0.0033, -0.0057,  0.0054,\n",
            "        -0.0049, -0.0021, -0.0038,  0.0045, -0.0067,  0.0062,  0.0070, -0.0064,\n",
            "        -0.0040, -0.0058,  0.0053, -0.0094,  0.0024, -0.0082,  0.0077,  0.0065,\n",
            "        -0.0026,  0.0060, -0.0046,  0.0102,  0.0035, -0.0065,  0.0091,  0.0032,\n",
            "         0.0064, -0.0079, -0.0052, -0.0048,  0.0028, -0.0088,  0.0030, -0.0127,\n",
            "         0.0065, -0.0062, -0.0004,  0.0033, -0.0045, -0.0009,  0.0069, -0.0104,\n",
            "        -0.0018,  0.0045, -0.0077, -0.0042, -0.0069,  0.0066, -0.0030, -0.0077],\n",
            "       device='cuda:0')\n",
            "decoder.layers.6.norm3.weight: tensor([0.9958, 0.9941, 1.0015, 0.9932, 0.9963, 1.0068, 1.0027, 1.0013, 1.0088,\n",
            "        0.9982, 0.9972, 1.0011, 1.0013, 1.0076, 1.0053, 1.0016, 0.9993, 1.0026,\n",
            "        1.0090, 1.0034, 0.9958, 0.9977, 0.9989, 0.9920, 1.0057, 1.0026, 0.9997,\n",
            "        1.0033, 0.9936, 0.9954, 1.0049, 1.0038, 0.9875, 0.9984, 1.0051, 1.0039,\n",
            "        1.0002, 1.0009, 1.0006, 1.0105, 0.9987, 0.9993, 1.0042, 0.9892, 0.9934,\n",
            "        1.0096, 0.9979, 1.0050, 1.0052, 1.0019, 1.0027, 0.9951, 1.0086, 1.0026,\n",
            "        1.0064, 1.0019, 1.0044, 0.9996, 0.9965, 0.9963, 1.0029, 0.9989, 1.0013,\n",
            "        0.9947], device='cuda:0')\n",
            "decoder.layers.6.norm3.bias: tensor([ 0.0064,  0.0118,  0.0093, -0.0036,  0.0028, -0.0047,  0.0079, -0.0089,\n",
            "         0.0118,  0.0034, -0.0102,  0.0067,  0.0091, -0.0059, -0.0087,  0.0063,\n",
            "        -0.0060, -0.0052, -0.0049,  0.0058, -0.0085,  0.0075,  0.0092, -0.0100,\n",
            "        -0.0069, -0.0089,  0.0065, -0.0092,  0.0026, -0.0114,  0.0107,  0.0087,\n",
            "        -0.0056,  0.0073, -0.0030,  0.0103,  0.0033, -0.0080,  0.0091,  0.0059,\n",
            "         0.0063, -0.0083, -0.0087, -0.0068,  0.0038, -0.0114,  0.0012, -0.0139,\n",
            "         0.0090, -0.0082,  0.0012,  0.0057, -0.0065,  0.0017,  0.0059, -0.0117,\n",
            "        -0.0024,  0.0056, -0.0108, -0.0069, -0.0089,  0.0084, -0.0059, -0.0092],\n",
            "       device='cuda:0')\n",
            "decoder.layers.7.self_attn.w_q.weight: tensor([[ 0.1142,  0.0185, -0.0375,  ...,  0.0838,  0.0114,  0.0311],\n",
            "        [ 0.0967, -0.0937, -0.1350,  ..., -0.0555,  0.1163,  0.1245],\n",
            "        [ 0.0766,  0.0803,  0.0313,  ...,  0.0672, -0.0059,  0.0293],\n",
            "        ...,\n",
            "        [-0.0100,  0.0372,  0.1120,  ...,  0.0292,  0.0623,  0.1095],\n",
            "        [-0.0944,  0.0583,  0.0571,  ..., -0.0504, -0.0433,  0.0267],\n",
            "        [-0.1109,  0.0779, -0.0894,  ..., -0.0741, -0.0008, -0.0120]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.7.self_attn.w_k.weight: tensor([[-0.0702,  0.0968, -0.1037,  ...,  0.0871,  0.0337, -0.1074],\n",
            "        [-0.0978,  0.0423,  0.1155,  ..., -0.0842, -0.1122,  0.1035],\n",
            "        [-0.0300, -0.0909,  0.0927,  ..., -0.0272,  0.0902,  0.1056],\n",
            "        ...,\n",
            "        [-0.0628,  0.1198,  0.0787,  ..., -0.0808, -0.0266,  0.1315],\n",
            "        [ 0.0240,  0.0451,  0.0366,  ..., -0.1190,  0.0043,  0.1377],\n",
            "        [ 0.0680,  0.0374,  0.0102,  ...,  0.0109, -0.1313, -0.0323]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.7.self_attn.w_v.weight: tensor([[-0.0527,  0.1077, -0.0811,  ..., -0.0069,  0.0811, -0.0278],\n",
            "        [-0.0362, -0.0826,  0.0648,  ...,  0.0124, -0.0296, -0.1193],\n",
            "        [-0.0172, -0.0295,  0.0261,  ...,  0.0807,  0.0099, -0.0350],\n",
            "        ...,\n",
            "        [-0.0658, -0.0427, -0.0078,  ...,  0.0420,  0.0787,  0.0665],\n",
            "        [-0.0005,  0.0399, -0.1109,  ...,  0.0059,  0.1232,  0.0504],\n",
            "        [-0.0377,  0.0235,  0.0555,  ...,  0.0146, -0.0965,  0.0768]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.7.self_attn.w_o.weight: tensor([[-0.0269, -0.0496, -0.0582,  ..., -0.1077, -0.0416, -0.0122],\n",
            "        [ 0.0981, -0.0194, -0.0881,  ..., -0.0209, -0.0924,  0.0540],\n",
            "        [-0.0139, -0.0727,  0.0660,  ...,  0.1014,  0.1058, -0.1136],\n",
            "        ...,\n",
            "        [ 0.1066,  0.1048, -0.0748,  ..., -0.0402, -0.0420, -0.1010],\n",
            "        [ 0.0052,  0.0683, -0.0666,  ...,  0.1047,  0.0472,  0.0108],\n",
            "        [ 0.0865, -0.0794, -0.0503,  ..., -0.0977, -0.1177,  0.0129]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.7.enc_attn.w_q.weight: tensor([[-0.1254, -0.1037, -0.1078,  ..., -0.0250,  0.0458, -0.0598],\n",
            "        [-0.0682, -0.0846,  0.0515,  ..., -0.0742, -0.0612, -0.0170],\n",
            "        [-0.1149,  0.1032, -0.0507,  ...,  0.1134, -0.0988,  0.0513],\n",
            "        ...,\n",
            "        [-0.0826, -0.0491,  0.0858,  ..., -0.0267, -0.0738,  0.0913],\n",
            "        [-0.1211,  0.0458, -0.0132,  ...,  0.0007,  0.1270,  0.1463],\n",
            "        [-0.1192, -0.0593, -0.0957,  ..., -0.0956,  0.0738, -0.0485]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.7.enc_attn.w_k.weight: tensor([[-0.1422,  0.0979, -0.0639,  ...,  0.0459,  0.0320,  0.1372],\n",
            "        [ 0.0648,  0.0397, -0.0766,  ...,  0.0634,  0.1001,  0.0534],\n",
            "        [ 0.0297,  0.0408,  0.0075,  ...,  0.0770, -0.0118, -0.1018],\n",
            "        ...,\n",
            "        [ 0.0027,  0.0917,  0.0289,  ..., -0.0430,  0.0214, -0.0017],\n",
            "        [-0.1137,  0.0762,  0.0763,  ..., -0.0686,  0.0600, -0.1429],\n",
            "        [-0.1489, -0.0235, -0.0987,  ...,  0.0021, -0.0170, -0.1448]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.7.enc_attn.w_v.weight: tensor([[-0.0550,  0.0168,  0.0129,  ..., -0.0830, -0.0354, -0.0321],\n",
            "        [-0.0088,  0.0448,  0.0547,  ..., -0.0042, -0.0151, -0.1126],\n",
            "        [ 0.0715, -0.1236,  0.1224,  ...,  0.0329, -0.0546,  0.1329],\n",
            "        ...,\n",
            "        [-0.0201, -0.0827, -0.0070,  ..., -0.0289,  0.0243,  0.0961],\n",
            "        [ 0.0183, -0.0619,  0.0457,  ...,  0.0242, -0.0807,  0.0097],\n",
            "        [ 0.1057,  0.0234, -0.0498,  ...,  0.0302, -0.0345, -0.1075]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.7.enc_attn.w_o.weight: tensor([[ 0.0684, -0.1039,  0.0248,  ...,  0.0987, -0.0150, -0.0294],\n",
            "        [ 0.0772,  0.0808, -0.0896,  ...,  0.0170,  0.0579,  0.0576],\n",
            "        [-0.0961, -0.0950, -0.0269,  ..., -0.1079,  0.0177, -0.0405],\n",
            "        ...,\n",
            "        [-0.0830, -0.0567,  0.1036,  ...,  0.0514, -0.0529, -0.1013],\n",
            "        [-0.0875,  0.1327,  0.0501,  ..., -0.0414,  0.0872, -0.0513],\n",
            "        [-0.0308, -0.1160, -0.0897,  ...,  0.0705, -0.0396, -0.0921]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.7.ff.linear1.weight: tensor([[ 0.0057, -0.1199, -0.1074,  ...,  0.0167,  0.0958, -0.0478],\n",
            "        [ 0.0876,  0.0195,  0.0461,  ...,  0.0958,  0.0968,  0.0028],\n",
            "        [ 0.0151,  0.0692,  0.1016,  ...,  0.0647, -0.0560, -0.0769],\n",
            "        ...,\n",
            "        [-0.0058,  0.1115, -0.0296,  ..., -0.0202,  0.1249, -0.0873],\n",
            "        [ 0.0988, -0.0918, -0.0568,  ...,  0.0893, -0.0103,  0.1015],\n",
            "        [-0.0833,  0.1140, -0.0476,  ..., -0.1210,  0.1257, -0.1156]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.7.ff.linear1.bias: tensor([-0.0862, -0.0981,  0.0555, -0.0299,  0.0322, -0.0419,  0.0325, -0.1220,\n",
            "         0.0733,  0.0941, -0.0074, -0.0212,  0.0262,  0.1164,  0.0708,  0.1072,\n",
            "         0.1034, -0.0916, -0.1000, -0.0321,  0.0881, -0.1035,  0.0332, -0.0572,\n",
            "         0.1197, -0.0207,  0.0290, -0.0437,  0.0412, -0.0094,  0.0640,  0.1149,\n",
            "         0.0671,  0.1039, -0.0186, -0.0578, -0.0765, -0.1370, -0.0886, -0.0647,\n",
            "        -0.0427,  0.0965,  0.0091, -0.0448,  0.0674,  0.0298,  0.1039,  0.0447,\n",
            "         0.0716,  0.0493,  0.0698,  0.0018,  0.0669,  0.0803,  0.0362,  0.0757,\n",
            "         0.0503, -0.1199,  0.0526, -0.0487, -0.0372, -0.0451, -0.0499, -0.0296,\n",
            "        -0.0361,  0.0445, -0.1035, -0.0527,  0.0993, -0.0521, -0.0635,  0.0740,\n",
            "         0.0363,  0.0110, -0.0510, -0.0409,  0.1113, -0.0622,  0.0944,  0.0661,\n",
            "         0.0495,  0.0195,  0.0230,  0.0158,  0.0829,  0.0568,  0.0496,  0.1126,\n",
            "         0.0920,  0.1000, -0.0168,  0.0160,  0.1187,  0.0379, -0.0638, -0.0989,\n",
            "        -0.0898,  0.0075, -0.0744,  0.0139,  0.0944, -0.0042, -0.0049, -0.0287,\n",
            "        -0.0377,  0.0712,  0.0921,  0.0396, -0.0887, -0.0567,  0.0561,  0.0676,\n",
            "         0.0617,  0.0291,  0.0165, -0.0439,  0.0736, -0.0858,  0.0450, -0.0289,\n",
            "         0.0972,  0.0551,  0.1138,  0.0657,  0.0658,  0.0960,  0.1268,  0.0714,\n",
            "        -0.0992, -0.1119,  0.0587, -0.0383, -0.0153,  0.1239, -0.0535,  0.0690,\n",
            "         0.0167,  0.0218,  0.0533, -0.0792, -0.0911, -0.0806, -0.0643,  0.0694,\n",
            "        -0.1072,  0.1163, -0.0165, -0.0849,  0.1086, -0.0349, -0.0048, -0.0825,\n",
            "         0.0999, -0.1096,  0.0140,  0.0138, -0.0367, -0.0405,  0.0356, -0.0866,\n",
            "        -0.0898, -0.0252,  0.0241, -0.0596,  0.0663, -0.0387,  0.0644, -0.0562,\n",
            "         0.0251,  0.0599, -0.0953, -0.1072,  0.0957, -0.0738, -0.0241, -0.0596,\n",
            "        -0.0682,  0.0671,  0.0465, -0.0675,  0.0561, -0.1033, -0.0406,  0.0005,\n",
            "         0.0588,  0.0956,  0.0418, -0.0197, -0.0909,  0.1158, -0.0091,  0.0093,\n",
            "        -0.1196,  0.0077, -0.0770,  0.0279, -0.0629, -0.0609, -0.0271,  0.0981,\n",
            "         0.0672, -0.0686, -0.0762,  0.0790, -0.0333,  0.0326, -0.0962, -0.1057,\n",
            "        -0.0336, -0.0961, -0.1235, -0.0152,  0.0525,  0.0431, -0.0539, -0.1201,\n",
            "         0.0502,  0.1057, -0.0040,  0.1190, -0.0756,  0.0569, -0.1232,  0.0196,\n",
            "         0.0061, -0.0517,  0.0792,  0.0477, -0.0512, -0.0619,  0.0872, -0.0829,\n",
            "         0.1240, -0.0708,  0.1056,  0.1097, -0.0739, -0.0309, -0.0001, -0.0109,\n",
            "        -0.1085,  0.0707, -0.0985, -0.0807,  0.0699,  0.0788,  0.0765,  0.0810,\n",
            "        -0.0772,  0.0107, -0.1229, -0.0488,  0.1187,  0.0582, -0.0174,  0.1105,\n",
            "         0.0496,  0.0727, -0.1167,  0.0548, -0.0767, -0.0499,  0.0171, -0.0166,\n",
            "        -0.0317,  0.0392, -0.1127,  0.0840, -0.0226, -0.0597, -0.0858, -0.0985,\n",
            "        -0.0059,  0.1056, -0.0598, -0.0716,  0.0959, -0.0208,  0.1223, -0.0389,\n",
            "        -0.0027,  0.1053, -0.0009, -0.0185, -0.0071, -0.0294,  0.0758, -0.0127,\n",
            "         0.0415, -0.0647,  0.0504,  0.0897, -0.0823,  0.0064,  0.1214,  0.0938,\n",
            "         0.0490, -0.0516, -0.1211,  0.0709,  0.0004,  0.0078,  0.0813,  0.1088,\n",
            "         0.0024, -0.0599,  0.0941, -0.0758, -0.0623,  0.0091,  0.0260,  0.0475,\n",
            "         0.1125, -0.0285, -0.0263, -0.0758,  0.0290,  0.0954,  0.0918,  0.0879,\n",
            "         0.0946, -0.0270, -0.0974, -0.0445, -0.1255, -0.0300,  0.0659, -0.0644,\n",
            "         0.0569,  0.0161, -0.0232, -0.1044,  0.0640, -0.0532,  0.1117, -0.0788,\n",
            "         0.0995, -0.0937, -0.0871, -0.0536,  0.0037,  0.0525, -0.0857, -0.0148,\n",
            "        -0.0834,  0.0461, -0.0881,  0.0590,  0.0800,  0.0431,  0.0520,  0.0019,\n",
            "         0.0555,  0.0964,  0.0323,  0.0878,  0.0638,  0.0080,  0.0890, -0.0747,\n",
            "         0.0438, -0.0599, -0.0616, -0.0107, -0.0217,  0.0089, -0.0101,  0.0372,\n",
            "        -0.0585, -0.1133,  0.0924, -0.0793, -0.0410, -0.0594,  0.0668,  0.0411,\n",
            "        -0.0851, -0.0716,  0.0450,  0.0872,  0.0821, -0.0746, -0.0969, -0.0790,\n",
            "        -0.0832,  0.0658, -0.0328,  0.0720, -0.0254, -0.0169,  0.0174,  0.0665,\n",
            "        -0.0188,  0.0225,  0.0953, -0.0279, -0.0303, -0.1096,  0.0499, -0.0796,\n",
            "        -0.1019, -0.0924, -0.0487,  0.0364, -0.0829,  0.0050, -0.0101,  0.0998,\n",
            "        -0.0443,  0.0531,  0.0405, -0.0214,  0.0362,  0.1180,  0.1171, -0.0220,\n",
            "         0.0257,  0.0554,  0.0044,  0.0564, -0.1054,  0.0433,  0.0087, -0.0888,\n",
            "         0.0663,  0.0209,  0.1158,  0.0093, -0.0902,  0.0317,  0.0924,  0.0004,\n",
            "        -0.1180,  0.0332,  0.1250,  0.1195,  0.0915,  0.0352, -0.0163,  0.0916,\n",
            "        -0.0006, -0.0548,  0.0253,  0.0155,  0.0922, -0.1103,  0.0820, -0.0458,\n",
            "        -0.0769,  0.0002, -0.0020,  0.0410, -0.1008,  0.0621,  0.0599, -0.0770,\n",
            "        -0.0589,  0.0551, -0.0921,  0.1187,  0.0443, -0.0104, -0.0827,  0.1146,\n",
            "         0.1050, -0.0391, -0.0404, -0.0759, -0.1093, -0.0586, -0.0552,  0.0875,\n",
            "         0.1228, -0.0120,  0.0390,  0.0774, -0.1117, -0.0538, -0.0908, -0.1159,\n",
            "         0.0010, -0.1059,  0.0337, -0.0817, -0.0910, -0.0955,  0.0882, -0.0463,\n",
            "        -0.0973, -0.0155, -0.0866, -0.1116, -0.0778, -0.0535,  0.0137,  0.0292,\n",
            "        -0.0288, -0.0176, -0.1183, -0.1032, -0.0105, -0.0481,  0.0339, -0.0964,\n",
            "         0.0795, -0.0022,  0.0294, -0.0980, -0.0286,  0.0578,  0.1174, -0.0177],\n",
            "       device='cuda:0')\n",
            "decoder.layers.7.ff.linear2.weight: tensor([[-0.0054, -0.0245,  0.0140,  ...,  0.0164, -0.0363, -0.0034],\n",
            "        [ 0.0024, -0.0493,  0.0430,  ..., -0.0290, -0.0350,  0.0074],\n",
            "        [ 0.0083,  0.0266,  0.0358,  ...,  0.0359, -0.0302,  0.0096],\n",
            "        ...,\n",
            "        [ 0.0292, -0.0379,  0.0411,  ...,  0.0010,  0.0050,  0.0217],\n",
            "        [-0.0419,  0.0161,  0.0291,  ...,  0.0308, -0.0202, -0.0288],\n",
            "        [-0.0413, -0.0081, -0.0135,  ..., -0.0381, -0.0359, -0.0235]],\n",
            "       device='cuda:0')\n",
            "decoder.layers.7.ff.linear2.bias: tensor([-0.0167,  0.0063, -0.0436,  0.0332, -0.0059, -0.0439, -0.0260, -0.0100,\n",
            "         0.0079, -0.0087, -0.0020, -0.0420, -0.0218, -0.0176,  0.0151, -0.0420,\n",
            "        -0.0086, -0.0057, -0.0078, -0.0180,  0.0466,  0.0445, -0.0243, -0.0218,\n",
            "         0.0360, -0.0298, -0.0238, -0.0177, -0.0280,  0.0340, -0.0325,  0.0332,\n",
            "        -0.0367, -0.0152,  0.0053,  0.0278,  0.0296,  0.0377, -0.0434, -0.0025,\n",
            "         0.0248,  0.0392, -0.0001, -0.0086, -0.0089, -0.0380, -0.0265,  0.0035,\n",
            "        -0.0313, -0.0282, -0.0348, -0.0440,  0.0067,  0.0126,  0.0107,  0.0198,\n",
            "        -0.0171, -0.0149, -0.0260,  0.0345, -0.0143, -0.0152, -0.0396, -0.0079],\n",
            "       device='cuda:0')\n",
            "decoder.layers.7.norm1.weight: tensor([0.9949, 0.9933, 0.9960, 0.9904, 0.9968, 1.0046, 1.0005, 0.9971, 1.0070,\n",
            "        0.9929, 0.9982, 1.0022, 1.0023, 1.0109, 1.0016, 1.0015, 1.0019, 1.0001,\n",
            "        0.9996, 1.0054, 0.9936, 0.9953, 0.9983, 0.9939, 1.0059, 0.9994, 0.9971,\n",
            "        0.9982, 0.9894, 0.9994, 1.0051, 1.0046, 0.9813, 0.9945, 1.0062, 0.9995,\n",
            "        1.0009, 0.9998, 1.0014, 1.0087, 1.0005, 0.9997, 1.0009, 0.9888, 0.9946,\n",
            "        1.0033, 0.9953, 0.9995, 1.0020, 1.0056, 0.9945, 0.9926, 1.0041, 1.0007,\n",
            "        1.0059, 1.0001, 1.0053, 0.9977, 0.9926, 0.9957, 0.9953, 1.0004, 1.0028,\n",
            "        0.9948], device='cuda:0')\n",
            "decoder.layers.7.norm1.bias: tensor([ 0.0079,  0.0162,  0.0107, -0.0059,  0.0029, -0.0069,  0.0098, -0.0066,\n",
            "         0.0130,  0.0006, -0.0132,  0.0094,  0.0123, -0.0080, -0.0091,  0.0075,\n",
            "        -0.0076, -0.0021,  0.0060,  0.0083, -0.0097,  0.0099,  0.0089, -0.0100,\n",
            "        -0.0077, -0.0093,  0.0103, -0.0074,  0.0040, -0.0123,  0.0155,  0.0102,\n",
            "        -0.0074,  0.0058, -0.0095,  0.0116,  0.0078, -0.0065,  0.0106,  0.0053,\n",
            "         0.0091, -0.0114, -0.0092, -0.0105,  0.0095, -0.0125,  0.0024, -0.0107,\n",
            "         0.0102, -0.0079, -0.0044,  0.0077, -0.0081,  0.0071,  0.0094, -0.0118,\n",
            "        -0.0033,  0.0058, -0.0110, -0.0111, -0.0059,  0.0139, -0.0107, -0.0106],\n",
            "       device='cuda:0')\n",
            "decoder.layers.7.norm2.weight: tensor([0.9939, 1.0000, 0.9991, 0.9910, 0.9928, 1.0098, 1.0059, 0.9949, 1.0103,\n",
            "        0.9919, 1.0002, 1.0008, 0.9979, 1.0119, 0.9999, 1.0051, 1.0030, 1.0026,\n",
            "        0.9948, 1.0097, 0.9900, 1.0007, 0.9984, 0.9915, 1.0108, 1.0039, 0.9990,\n",
            "        0.9947, 0.9887, 0.9999, 1.0058, 1.0079, 0.9850, 0.9974, 1.0068, 1.0022,\n",
            "        1.0022, 1.0060, 1.0062, 1.0143, 1.0081, 1.0005, 1.0063, 0.9981, 0.9940,\n",
            "        1.0068, 0.9945, 1.0007, 1.0075, 1.0069, 0.9930, 0.9991, 1.0062, 1.0005,\n",
            "        1.0098, 1.0068, 1.0034, 0.9962, 0.9944, 0.9949, 0.9967, 1.0048, 1.0067,\n",
            "        0.9928], device='cuda:0')\n",
            "decoder.layers.7.norm2.bias: tensor([ 0.0027,  0.0167,  0.0080, -0.0032, -0.0005, -0.0090,  0.0087, -0.0037,\n",
            "         0.0131, -0.0035, -0.0126,  0.0034,  0.0133, -0.0081, -0.0070,  0.0069,\n",
            "        -0.0065, -0.0007,  0.0095,  0.0061, -0.0044,  0.0080,  0.0068, -0.0085,\n",
            "        -0.0063, -0.0086,  0.0097, -0.0059,  0.0052, -0.0151,  0.0136,  0.0096,\n",
            "        -0.0067,  0.0042, -0.0078,  0.0116,  0.0053, -0.0070,  0.0109,  0.0052,\n",
            "         0.0091, -0.0082, -0.0086, -0.0105,  0.0064, -0.0129, -0.0008, -0.0110,\n",
            "         0.0096, -0.0093, -0.0073,  0.0056, -0.0063,  0.0047,  0.0105, -0.0133,\n",
            "        -0.0061,  0.0029, -0.0074, -0.0080, -0.0027,  0.0137, -0.0105, -0.0079],\n",
            "       device='cuda:0')\n",
            "decoder.layers.7.norm3.weight: tensor([1.1443, 1.1544, 1.1922, 1.1691, 1.1566, 1.1719, 1.1735, 1.1708, 1.1781,\n",
            "        1.1488, 1.1721, 1.2062, 1.1856, 1.1765, 1.1879, 1.1898, 1.1756, 1.1901,\n",
            "        1.2190, 1.1888, 1.1636, 1.1949, 1.1449, 1.1458, 1.1738, 1.1876, 1.1658,\n",
            "        1.1550, 1.1892, 1.1606, 1.1793, 1.1922, 1.1508, 1.1933, 1.1945, 1.1809,\n",
            "        1.1649, 1.1640, 1.1749, 1.1870, 1.1936, 1.1639, 1.1574, 1.1734, 1.1295,\n",
            "        1.1744, 1.1694, 1.1706, 1.1723, 1.1931, 1.1888, 1.1905, 1.1752, 1.1919,\n",
            "        1.1818, 1.1854, 1.2188, 1.1580, 1.1580, 1.1856, 1.1631, 1.1721, 1.1699,\n",
            "        1.1592], device='cuda:0')\n",
            "decoder.layers.7.norm3.bias: tensor([ 0.1323,  0.1233,  0.1626, -0.1346,  0.1352, -0.0977,  0.1371, -0.1489,\n",
            "         0.1276,  0.1418, -0.1336,  0.1625,  0.0873, -0.1396, -0.1486,  0.1414,\n",
            "        -0.1288, -0.1298, -0.0651,  0.1460, -0.1527,  0.1385,  0.1324, -0.1346,\n",
            "        -0.1246, -0.1544,  0.1266, -0.1436, -0.0118, -0.0915,  0.1257,  0.1362,\n",
            "        -0.1379,  0.1489, -0.1527,  0.1406,  0.1449, -0.1428,  0.1257,  0.1410,\n",
            "         0.1349, -0.1440, -0.1341, -0.1325,  0.1268, -0.1281,  0.1350, -0.1450,\n",
            "         0.1264, -0.1381,  0.1470,  0.1411, -0.1361,  0.1567,  0.1255, -0.1434,\n",
            "         0.0180,  0.1296, -0.1444, -0.1364, -0.1356,  0.1236, -0.1369, -0.1423],\n",
            "       device='cuda:0')\n",
            "decoder.fc_out.weight: tensor([[-0.1573, -0.0753, -0.1087,  ..., -0.1014,  0.2158,  0.2837],\n",
            "        [-0.2946, -0.1626, -0.1775,  ..., -0.0189,  0.2723,  0.2947],\n",
            "        [-0.1990, -0.2113, -0.2130,  ..., -0.0553,  0.1001,  0.2784],\n",
            "        ...,\n",
            "        [-0.1074,  0.0152, -0.0387,  ..., -0.1563,  0.0146,  0.0900],\n",
            "        [-0.0245, -0.0508, -0.0492,  ..., -0.0643,  0.1172,  0.0892],\n",
            "        [-0.1696, -0.1493, -0.0926,  ..., -0.0918,  0.1174,  0.1383]],\n",
            "       device='cuda:0')\n",
            "decoder.fc_out.bias: tensor([-0.0979, -0.3096, -0.1116,  ..., -0.1370, -0.0843, -0.0035],\n",
            "       device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(\"Model_Params.pth\"))\n",
        "for name, param in model.named_parameters():\n",
        "    print(f\"{name}: {param.data}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "  PREDICTED:<SOS> விமான நிலையத்திற்கு எப்படி முயற்சி செய்யுங்கள் <EOS>\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import os\n",
        "\n",
        "def causal_mask(size, device):\n",
        "    mask = torch.triu(torch.ones((1, size, size), device=device), diagonal=1).int()\n",
        "    return mask == 0\n",
        "\n",
        "def greedy_decode1(model, source, source_mask, max_len, device):\n",
        "    sos_idx, eos_idx = 2, 3\n",
        "    # Move encoder input to device\n",
        "    encoder_output = model.encoder(source, source_mask)\n",
        "    decoder_input = torch.empty(1, 1, device=device).fill_(sos_idx).long()\n",
        "\n",
        "    while decoder_input.size(1) < max_len:\n",
        "        decoder_mask = causal_mask(decoder_input.size(1), device)\n",
        "        out = model.decoder(decoder_input, encoder_output, source_mask, decoder_mask)\n",
        "        next_word = torch.max(out[:, -1], dim=1)[1]\n",
        "        decoder_input = torch.cat([decoder_input, next_word.view(1, 1)], dim=1)\n",
        "        if next_word.item() == eos_idx:\n",
        "            break\n",
        "\n",
        "    return decoder_input.squeeze(0)\n",
        "\n",
        "def run_validation1(model, encoder_input, encoder_mask, max_len, device):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    predicted = []\n",
        "    \n",
        "    try:\n",
        "        console_width = os.get_terminal_size().columns\n",
        "    except OSError:\n",
        "        console_width = 80\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Ensure encoder input and mask are on the device\n",
        "        encoder_input = encoder_input.to(device)\n",
        "        encoder_mask = encoder_mask.to(device)\n",
        "        \n",
        "        assert encoder_input.size(0) == 1, \"Batch size must be 1 for validation\"\n",
        "        model_out = greedy_decode1(model, encoder_input, encoder_mask, max_len, device)\n",
        "    \n",
        "        model_out_text = tamil_tokenizer.decode(model_out.detach().cpu().numpy())\n",
        "        predicted.append(model_out_text)\n",
        "\n",
        "        print(f\"{'-'*console_width}\\n{'PREDICTED:':>12}{model_out_text}\")\n",
        "\n",
        "# Example sentence and pre-processing\n",
        "sentence = \"how much time does it take to reach the airport\"\n",
        "sentence = english_tokenizer.encode(sentence)\n",
        "sentence = pad_sequence_source(sentence, 20, cls_token=2, sep_token=3)\n",
        "sentence = torch.tensor(sentence, dtype=torch.long).to('cuda')  # Move tensor to CUDA\n",
        "encoder_input = sentence.unsqueeze(0).to('cuda')  # Ensure batch dimension and move to CUDA\n",
        "encoder_mask = (sentence != 1).unsqueeze(0).unsqueeze(0).int().to('cuda')  # Move mask to CUDA\n",
        "\n",
        "# Running validation on CUDA\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "run_validation1(model, encoder_input, encoder_mask, 24, device)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

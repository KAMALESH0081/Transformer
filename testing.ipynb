{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "WASYCq5LYyF0",
        "outputId": "1e7b6e81-b3c0-4d0d-d1dd-f2277df6c5d0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('C:\\\\Users\\\\Kamal\\\\Downloads\\\\pre_translation2.csv')\n",
        "df.to_csv(\"final_translation.csv\", index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ujPMEJzVeYWG",
        "outputId": "545d91d6-5e1f-49f8-820e-86a5af8de06a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 11104 entries, 0 to 11103\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   Tamil    11104 non-null  object\n",
            " 1   English  11104 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 173.6+ KB\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    # Keep only Tamil/English letters and numbers, remove all other characters\n",
        "    return re.sub(r'[^a-zA-Z0-9\\u0B80-\\u0BFF\\s]', '', text)\n",
        "\n",
        "# Apply cleaning function to English and Tamil columns\n",
        "df['English'] = df['English'].apply(clean_text)  # Clean English column\n",
        "df['Tamil'] = df['Tamil'].apply(clean_text)  # Clean Tamil column\n",
        "\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "pTatalI-feBW",
        "outputId": "7994308b-cc3e-4b42-f4bf-ba197d26607d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tamil</th>\n",
              "      <th>English</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Tamil, English]\n",
              "Index: []"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define a function to check if any English character is present in the Tamil text\n",
        "def contains_english(text):\n",
        "    # This regex checks if the text contains any character from the English alphabet\n",
        "    return bool(re.search(r'[a-zA-Z]', text))\n",
        "\n",
        "# Apply the function to filter out rows where Tamil contains English words\n",
        "df = df[~df['Tamil'].apply(contains_english)]\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "iXfU6sXgf81u"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the WordLevelTokenizer class (use the class from the previous answer)\n",
        "class WordLevelTokenizer:\n",
        "    def __init__(self, special_tokens=None):\n",
        "        self.word_to_id = {}\n",
        "        self.id_to_word = {}\n",
        "        self.special_tokens = special_tokens or []\n",
        "        self.build_vocab(self.special_tokens)\n",
        "\n",
        "    def build_vocab(self, tokens):\n",
        "        for token in tokens:\n",
        "            self.add_token(token)\n",
        "\n",
        "    def add_token(self, token):\n",
        "        if token not in self.word_to_id:\n",
        "            idx = len(self.word_to_id)\n",
        "            self.word_to_id[token] = idx\n",
        "            self.id_to_word[idx] = token\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        return text.split()\n",
        "\n",
        "    def encode(self, text):\n",
        "        tokens = self.tokenize(text)\n",
        "        return [self.word_to_id.get(token, self.word_to_id.get(\"<UNK>\")) for token in tokens]\n",
        "\n",
        "    def decode(self, token_ids):\n",
        "        return \" \".join(self.id_to_word.get(idx, \"<UNK>\") for idx in token_ids)\n",
        "\n",
        "    def fit_on_texts(self, texts):\n",
        "        for text in texts:\n",
        "            tokens = self.tokenize(text)\n",
        "            self.build_vocab(tokens)\n",
        "\n",
        "    def vocab_size(self):\n",
        "        return len(self.word_to_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "25rq3UOXgEbW"
      },
      "outputs": [],
      "source": [
        "# Initialize tokenizer with special tokens\n",
        "special_tokens = [\"<UNK>\", \"<PAD>\", \"<SOS>\", \"<EOS>\"]\n",
        "tamil_tokenizer = WordLevelTokenizer(special_tokens=special_tokens)\n",
        "english_tokenizer = WordLevelTokenizer(special_tokens=special_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtxzmjXxgHIN",
        "outputId": "95eaa114-f315-4c4b-a484-61ba430ba9a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary: 4\n"
          ]
        }
      ],
      "source": [
        "# Fit tokenizer on the 'text' column\n",
        "tamil_tokenizer.fit_on_texts(df['Tamil'])\n",
        "print(\"Vocabulary:\", len(tamil_tokenizer.word_to_id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZnfG-dVgMYG",
        "outputId": "83a45f87-d297-4eac-9d25-42554f8538ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary: 4\n"
          ]
        }
      ],
      "source": [
        "english_tokenizer.fit_on_texts(df['English'])\n",
        "print(\"Vocabulary:\", len(english_tokenizer.word_to_id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "XIpneaZhgRs2",
        "outputId": "86f633c2-6b73-43e8-ba5b-c6e1d48a5549"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tamil</th>\n",
              "      <th>English</th>\n",
              "      <th>Tokenized_Tamil</th>\n",
              "      <th>Tokenized_English</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Lets try something</td>\n",
              "      <td>ஏதாவது முயற்சி செய்யலாம்</td>\n",
              "      <td>[0, 0, 0]</td>\n",
              "      <td>[0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I have to go to sleep</td>\n",
              "      <td>நான் தூங்க செல்ல வேண்டும்</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Today is June 18th and it is Muiriels birthday</td>\n",
              "      <td>இன்று ஜூன் 18 மற்றும் முரியலின் பிறந்த நாள்</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Muiriel is 20 now</td>\n",
              "      <td>முரியலுக்கு இப்போது 20 வயது</td>\n",
              "      <td>[0, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The password is Muiriel</td>\n",
              "      <td>கடவுச்சொல் முரியல்</td>\n",
              "      <td>[0, 0, 0, 0]</td>\n",
              "      <td>[0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11099</th>\n",
              "      <td>Dont speak to the driver while he is driving</td>\n",
              "      <td>வாகனம் ஓட்டும் போது ஓட்டுனரிடம் பேச வேண்டாம்</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11100</th>\n",
              "      <td>The driver was inattentive and could not stop ...</td>\n",
              "      <td>டிரைவர் கவனக்குறைவாக இருந்ததால் சரியான நேரத்தி...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11101</th>\n",
              "      <td>The driver could not distinguish the signal in...</td>\n",
              "      <td>டிரைவரால் மூடுபனியில் சிக்னலை வேறுபடுத்திப் பா...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11102</th>\n",
              "      <td>The driver tipped his cap</td>\n",
              "      <td>டிரைவர் தொப்பியை சாய்த்தார்</td>\n",
              "      <td>[0, 0, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11103</th>\n",
              "      <td>The driver gestured him out</td>\n",
              "      <td>ஓட்டுனர் சைகையால் வெளியே காட்டினார்</td>\n",
              "      <td>[0, 0, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11104 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Tamil  \\\n",
              "0                                     Lets try something   \n",
              "1                                  I have to go to sleep   \n",
              "2         Today is June 18th and it is Muiriels birthday   \n",
              "3                                      Muiriel is 20 now   \n",
              "4                                The password is Muiriel   \n",
              "...                                                  ...   \n",
              "11099       Dont speak to the driver while he is driving   \n",
              "11100  The driver was inattentive and could not stop ...   \n",
              "11101  The driver could not distinguish the signal in...   \n",
              "11102                          The driver tipped his cap   \n",
              "11103                        The driver gestured him out   \n",
              "\n",
              "                                                 English  \\\n",
              "0                               ஏதாவது முயற்சி செய்யலாம்   \n",
              "1                              நான் தூங்க செல்ல வேண்டும்   \n",
              "2            இன்று ஜூன் 18 மற்றும் முரியலின் பிறந்த நாள்   \n",
              "3                            முரியலுக்கு இப்போது 20 வயது   \n",
              "4                                     கடவுச்சொல் முரியல்   \n",
              "...                                                  ...   \n",
              "11099       வாகனம் ஓட்டும் போது ஓட்டுனரிடம் பேச வேண்டாம்   \n",
              "11100  டிரைவர் கவனக்குறைவாக இருந்ததால் சரியான நேரத்தி...   \n",
              "11101  டிரைவரால் மூடுபனியில் சிக்னலை வேறுபடுத்திப் பா...   \n",
              "11102                        டிரைவர் தொப்பியை சாய்த்தார்   \n",
              "11103                ஓட்டுனர் சைகையால் வெளியே காட்டினார்   \n",
              "\n",
              "                      Tokenized_Tamil      Tokenized_English  \n",
              "0                           [0, 0, 0]              [0, 0, 0]  \n",
              "1                  [0, 0, 0, 0, 0, 0]           [0, 0, 0, 0]  \n",
              "2         [0, 0, 0, 0, 0, 0, 0, 0, 0]  [0, 0, 0, 0, 0, 0, 0]  \n",
              "3                        [0, 0, 0, 0]           [0, 0, 0, 0]  \n",
              "4                        [0, 0, 0, 0]                 [0, 0]  \n",
              "...                               ...                    ...  \n",
              "11099     [0, 0, 0, 0, 0, 0, 0, 0, 0]     [0, 0, 0, 0, 0, 0]  \n",
              "11100  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  [0, 0, 0, 0, 0, 0, 0]  \n",
              "11101  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]     [0, 0, 0, 0, 0, 0]  \n",
              "11102                 [0, 0, 0, 0, 0]              [0, 0, 0]  \n",
              "11103                 [0, 0, 0, 0, 0]           [0, 0, 0, 0]  \n",
              "\n",
              "[11104 rows x 4 columns]"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Tokenize the Tamil text in your dataframe\n",
        "df['Tokenized_Tamil'] = df['Tamil'].apply(lambda x: tamil_tokenizer.encode(x))\n",
        "df['Tokenized_English'] = df['English'].apply(lambda x: english_tokenizer.encode(x))\n",
        "# Print the dataframe with tokenized Tamil text\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWTVc0hVhHk-",
        "outputId": "52ac6bbe-5811-450a-dab7-f62e1ddfaa45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "89835\n"
          ]
        }
      ],
      "source": [
        "z = 0\n",
        "t = 0\n",
        "for i in df['Tokenized_Tamil']:\n",
        "    for j in i:\n",
        "        t = t +1\n",
        "        if j == 0:\n",
        "           z=z+1\n",
        "print(z)\n",
        "print(t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmrG-vynhPWG",
        "outputId": "d6d355d4-95c0-4260-a2c9-4496f4cbf4d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "284\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(11104, 4)"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tamil_idx = []\n",
        "for idx , i in enumerate(df['Tokenized_Tamil']):\n",
        "    if len(i) > 24:\n",
        "        tamil_idx.append(idx)\n",
        "\n",
        "print(len(tamil_idx))\n",
        "\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJmWY13dhi_m",
        "outputId": "0d629e89-5d92-49e2-d92c-a9c3fb842c54"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10820, 4)"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df.drop(index=df.index[tamil_idx])\n",
        "\n",
        "df = df.reset_index(drop=True)\n",
        "\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eti-ogtEhr82",
        "outputId": "926badb7-6ce8-47e8-f06e-527ebfd39300"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(10820, 4)"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "english_idx = []\n",
        "for idx , i in enumerate(df['Tokenized_English']):\n",
        "    if len(i) > 24:\n",
        "        english_idx.append(idx)\n",
        "\n",
        "print(len(english_idx))\n",
        "\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZi-SXFvh2xW",
        "outputId": "ad09a3bc-5ab0-411e-b025-ffe318e6bbf5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10819, 4)"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df.drop(index=df.index[english_idx])\n",
        "\n",
        "df = df.reset_index(drop=True)\n",
        "\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "WPcwIR4eiHF1",
        "outputId": "3b7c9403-3a72-40f2-e82e-d3ce051c71b8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tamil</th>\n",
              "      <th>English</th>\n",
              "      <th>Tokenized_Tamil</th>\n",
              "      <th>Tokenized_English</th>\n",
              "      <th>Padded_English</th>\n",
              "      <th>Padded_Tamil</th>\n",
              "      <th>Padded_Tamil_Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Let's try something.</td>\n",
              "      <td>ஏதாவது முயற்சி செய்யலாம்.</td>\n",
              "      <td>[4, 5, 6]</td>\n",
              "      <td>[4, 5, 6]</td>\n",
              "      <td>[2, 4, 5, 6, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[2, 4, 5, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[4, 5, 6, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I have to go to sleep.</td>\n",
              "      <td>நான் தூங்க செல்ல வேண்டும்.</td>\n",
              "      <td>[7, 8, 9, 10, 9, 11]</td>\n",
              "      <td>[7, 8, 9, 10]</td>\n",
              "      <td>[2, 7, 8, 9, 10, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
              "      <td>[2, 7, 8, 9, 10, 9, 11, 1, 1, 1, 1, 1, 1, 1, 1...</td>\n",
              "      <td>[7, 8, 9, 10, 9, 11, 3, 1, 1, 1, 1, 1, 1, 1, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Today is June 18th and it is Muiriel's birthday!</td>\n",
              "      <td>இன்று ஜூன் 18 மற்றும் முரியலின் பிறந்த நாள்!</td>\n",
              "      <td>[12, 13, 14, 15, 16, 17, 13, 18, 19]</td>\n",
              "      <td>[11, 12, 13, 14, 15, 16, 17]</td>\n",
              "      <td>[2, 11, 12, 13, 14, 15, 16, 17, 3, 1, 1, 1, 1,...</td>\n",
              "      <td>[2, 12, 13, 14, 15, 16, 17, 13, 18, 19, 1, 1, ...</td>\n",
              "      <td>[12, 13, 14, 15, 16, 17, 13, 18, 19, 3, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Muiriel is 20 now.</td>\n",
              "      <td>முரியலுக்கு இப்போது 20 வயது.</td>\n",
              "      <td>[20, 13, 21, 22]</td>\n",
              "      <td>[18, 19, 20, 21]</td>\n",
              "      <td>[2, 18, 19, 20, 21, 3, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
              "      <td>[2, 20, 13, 21, 22, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
              "      <td>[20, 13, 21, 22, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The password is \"Muiriel\".</td>\n",
              "      <td>கடவுச்சொல் \"முரியல்\".</td>\n",
              "      <td>[23, 24, 13, 25]</td>\n",
              "      <td>[22, 23]</td>\n",
              "      <td>[2, 22, 23, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1...</td>\n",
              "      <td>[2, 23, 24, 13, 25, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
              "      <td>[23, 24, 13, 25, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10814</th>\n",
              "      <td>Don't speak to the driver while he is driving.</td>\n",
              "      <td>வாகனம் ஓட்டும் போது ஓட்டுனரிடம் பேச வேண்டாம்.</td>\n",
              "      <td>[557, 561, 9, 51, 10083, 548, 91, 13, 3303]</td>\n",
              "      <td>[4045, 17131, 939, 17135, 1311, 848]</td>\n",
              "      <td>[2, 4045, 17131, 939, 17135, 1311, 848, 3, 1, ...</td>\n",
              "      <td>[2, 557, 561, 9, 51, 10083, 548, 91, 13, 3303,...</td>\n",
              "      <td>[557, 561, 9, 51, 10083, 548, 91, 13, 3303, 3,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10815</th>\n",
              "      <td>The driver was inattentive and could not stop ...</td>\n",
              "      <td>டிரைவர் கவனக்குறைவாக இருந்ததால் சரியான நேரத்தி...</td>\n",
              "      <td>[23, 10083, 46, 11730, 16, 156, 98, 2538, 50, 57]</td>\n",
              "      <td>[17136, 4181, 798, 486, 3395, 2521, 2446]</td>\n",
              "      <td>[2, 17136, 4181, 798, 486, 3395, 2521, 2446, 3...</td>\n",
              "      <td>[2, 23, 10083, 46, 11730, 16, 156, 98, 2538, 5...</td>\n",
              "      <td>[23, 10083, 46, 11730, 16, 156, 98, 2538, 50, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10816</th>\n",
              "      <td>The driver could not distinguish the signal in...</td>\n",
              "      <td>டிரைவரால் மூடுபனியில் சிக்னலை வேறுபடுத்திப் பா...</td>\n",
              "      <td>[23, 10083, 156, 98, 3230, 51, 11731, 50, 51, ...</td>\n",
              "      <td>[17137, 17138, 17139, 3926, 526, 2446]</td>\n",
              "      <td>[2, 17137, 17138, 17139, 3926, 526, 2446, 3, 1...</td>\n",
              "      <td>[2, 23, 10083, 156, 98, 3230, 51, 11731, 50, 5...</td>\n",
              "      <td>[23, 10083, 156, 98, 3230, 51, 11731, 50, 51, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10817</th>\n",
              "      <td>The driver tipped his cap.</td>\n",
              "      <td>டிரைவர் தொப்பியை சாய்த்தார்.</td>\n",
              "      <td>[23, 10083, 11732, 1059, 11733]</td>\n",
              "      <td>[17136, 17140, 17141]</td>\n",
              "      <td>[2, 17136, 17140, 17141, 3, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[2, 23, 10083, 11732, 1059, 11733, 1, 1, 1, 1,...</td>\n",
              "      <td>[23, 10083, 11732, 1059, 11733, 3, 1, 1, 1, 1,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10818</th>\n",
              "      <td>The driver gestured him out.</td>\n",
              "      <td>ஓட்டுனர் சைகையால் வெளியே காட்டினார்.</td>\n",
              "      <td>[23, 10083, 11734, 1057, 1904]</td>\n",
              "      <td>[17142, 17143, 805, 9548]</td>\n",
              "      <td>[2, 17142, 17143, 805, 9548, 3, 1, 1, 1, 1, 1,...</td>\n",
              "      <td>[2, 23, 10083, 11734, 1057, 1904, 1, 1, 1, 1, ...</td>\n",
              "      <td>[23, 10083, 11734, 1057, 1904, 3, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10819 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Tamil  \\\n",
              "0                                   Let's try something.   \n",
              "1                                 I have to go to sleep.   \n",
              "2       Today is June 18th and it is Muiriel's birthday!   \n",
              "3                                     Muiriel is 20 now.   \n",
              "4                             The password is \"Muiriel\".   \n",
              "...                                                  ...   \n",
              "10814     Don't speak to the driver while he is driving.   \n",
              "10815  The driver was inattentive and could not stop ...   \n",
              "10816  The driver could not distinguish the signal in...   \n",
              "10817                         The driver tipped his cap.   \n",
              "10818                       The driver gestured him out.   \n",
              "\n",
              "                                                 English  \\\n",
              "0                              ஏதாவது முயற்சி செய்யலாம்.   \n",
              "1                             நான் தூங்க செல்ல வேண்டும்.   \n",
              "2           இன்று ஜூன் 18 மற்றும் முரியலின் பிறந்த நாள்!   \n",
              "3                           முரியலுக்கு இப்போது 20 வயது.   \n",
              "4                                  கடவுச்சொல் \"முரியல்\".   \n",
              "...                                                  ...   \n",
              "10814      வாகனம் ஓட்டும் போது ஓட்டுனரிடம் பேச வேண்டாம்.   \n",
              "10815  டிரைவர் கவனக்குறைவாக இருந்ததால் சரியான நேரத்தி...   \n",
              "10816  டிரைவரால் மூடுபனியில் சிக்னலை வேறுபடுத்திப் பா...   \n",
              "10817                       டிரைவர் தொப்பியை சாய்த்தார்.   \n",
              "10818               ஓட்டுனர் சைகையால் வெளியே காட்டினார்.   \n",
              "\n",
              "                                         Tokenized_Tamil  \\\n",
              "0                                              [4, 5, 6]   \n",
              "1                                   [7, 8, 9, 10, 9, 11]   \n",
              "2                   [12, 13, 14, 15, 16, 17, 13, 18, 19]   \n",
              "3                                       [20, 13, 21, 22]   \n",
              "4                                       [23, 24, 13, 25]   \n",
              "...                                                  ...   \n",
              "10814        [557, 561, 9, 51, 10083, 548, 91, 13, 3303]   \n",
              "10815  [23, 10083, 46, 11730, 16, 156, 98, 2538, 50, 57]   \n",
              "10816  [23, 10083, 156, 98, 3230, 51, 11731, 50, 51, ...   \n",
              "10817                    [23, 10083, 11732, 1059, 11733]   \n",
              "10818                     [23, 10083, 11734, 1057, 1904]   \n",
              "\n",
              "                               Tokenized_English  \\\n",
              "0                                      [4, 5, 6]   \n",
              "1                                  [7, 8, 9, 10]   \n",
              "2                   [11, 12, 13, 14, 15, 16, 17]   \n",
              "3                               [18, 19, 20, 21]   \n",
              "4                                       [22, 23]   \n",
              "...                                          ...   \n",
              "10814       [4045, 17131, 939, 17135, 1311, 848]   \n",
              "10815  [17136, 4181, 798, 486, 3395, 2521, 2446]   \n",
              "10816     [17137, 17138, 17139, 3926, 526, 2446]   \n",
              "10817                      [17136, 17140, 17141]   \n",
              "10818                  [17142, 17143, 805, 9548]   \n",
              "\n",
              "                                          Padded_English  \\\n",
              "0      [2, 4, 5, 6, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
              "1      [2, 7, 8, 9, 10, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n",
              "2      [2, 11, 12, 13, 14, 15, 16, 17, 3, 1, 1, 1, 1,...   \n",
              "3      [2, 18, 19, 20, 21, 3, 1, 1, 1, 1, 1, 1, 1, 1,...   \n",
              "4      [2, 22, 23, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1...   \n",
              "...                                                  ...   \n",
              "10814  [2, 4045, 17131, 939, 17135, 1311, 848, 3, 1, ...   \n",
              "10815  [2, 17136, 4181, 798, 486, 3395, 2521, 2446, 3...   \n",
              "10816  [2, 17137, 17138, 17139, 3926, 526, 2446, 3, 1...   \n",
              "10817  [2, 17136, 17140, 17141, 3, 1, 1, 1, 1, 1, 1, ...   \n",
              "10818  [2, 17142, 17143, 805, 9548, 3, 1, 1, 1, 1, 1,...   \n",
              "\n",
              "                                            Padded_Tamil  \\\n",
              "0      [2, 4, 5, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
              "1      [2, 7, 8, 9, 10, 9, 11, 1, 1, 1, 1, 1, 1, 1, 1...   \n",
              "2      [2, 12, 13, 14, 15, 16, 17, 13, 18, 19, 1, 1, ...   \n",
              "3      [2, 20, 13, 21, 22, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n",
              "4      [2, 23, 24, 13, 25, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n",
              "...                                                  ...   \n",
              "10814  [2, 557, 561, 9, 51, 10083, 548, 91, 13, 3303,...   \n",
              "10815  [2, 23, 10083, 46, 11730, 16, 156, 98, 2538, 5...   \n",
              "10816  [2, 23, 10083, 156, 98, 3230, 51, 11731, 50, 5...   \n",
              "10817  [2, 23, 10083, 11732, 1059, 11733, 1, 1, 1, 1,...   \n",
              "10818  [2, 23, 10083, 11734, 1057, 1904, 1, 1, 1, 1, ...   \n",
              "\n",
              "                                     Padded_Tamil_Target  \n",
              "0      [4, 5, 6, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "1      [7, 8, 9, 10, 9, 11, 3, 1, 1, 1, 1, 1, 1, 1, 1...  \n",
              "2      [12, 13, 14, 15, 16, 17, 13, 18, 19, 3, 1, 1, ...  \n",
              "3      [20, 13, 21, 22, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1,...  \n",
              "4      [23, 24, 13, 25, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1,...  \n",
              "...                                                  ...  \n",
              "10814  [557, 561, 9, 51, 10083, 548, 91, 13, 3303, 3,...  \n",
              "10815  [23, 10083, 46, 11730, 16, 156, 98, 2538, 50, ...  \n",
              "10816  [23, 10083, 156, 98, 3230, 51, 11731, 50, 51, ...  \n",
              "10817  [23, 10083, 11732, 1059, 11733, 3, 1, 1, 1, 1,...  \n",
              "10818  [23, 10083, 11734, 1057, 1904, 3, 1, 1, 1, 1, ...  \n",
              "\n",
              "[10819 rows x 7 columns]"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Example of the maximum padding length\n",
        "max_pad = 24\n",
        "cls_token = 2\n",
        "sep_token = 3\n",
        "\n",
        "# Function to pad sequences\n",
        "def pad_sequence_source(tokens, max_len, cls_token=2,sep_token = 3):\n",
        "    # Add the cls token at the beginning\n",
        "    padded_tokens = [cls_token] + tokens + [sep_token]\n",
        "    #padded_tokens = padded_tokens + [sep_token]\n",
        "\n",
        "    # Pad the sequence if it's shorter than max_len\n",
        "    if len(padded_tokens) < max_len:\n",
        "        padded_tokens.extend([1] * (max_len - len(padded_tokens)))\n",
        "    # Truncate if it's longer than max_len\n",
        "    else:\n",
        "        padded_tokens = padded_tokens[:max_len]\n",
        "\n",
        "    return padded_tokens\n",
        "\n",
        "def pad_sequence_target(tokens, max_len, cls_token = 2):\n",
        "    # Add the cls token at the beginning\n",
        "    padded_tokens = [cls_token] + tokens\n",
        "\n",
        "    # Pad the sequence if it's shorter than max_len\n",
        "    if len(padded_tokens) < max_len:\n",
        "        padded_tokens.extend([1] * (max_len - len(padded_tokens)))\n",
        "    # Truncate if it's longer than max_len\n",
        "    else:\n",
        "        padded_tokens = padded_tokens[:max_len]\n",
        "\n",
        "    return padded_tokens\n",
        "\n",
        "def pad_sequence_label(tokens, max_len, sep_token = 3):\n",
        "    # Add the cls token at the beginning\n",
        "    padded_tokens = tokens + [sep_token]\n",
        "\n",
        "    # Pad the sequence if it's shorter than max_len\n",
        "    if len(padded_tokens) < max_len:\n",
        "        padded_tokens.extend([1] * (max_len - len(padded_tokens)))\n",
        "    # Truncate if it's longer than max_len\n",
        "    else:\n",
        "        padded_tokens = padded_tokens[:max_len]\n",
        "\n",
        "    return padded_tokens\n",
        "\n",
        "# Apply padding and add CLS token to both English and Tamil columns\n",
        "df['Padded_English'] = df['Tokenized_English'].apply(lambda x: pad_sequence_source(x, max_pad, cls_token,sep_token))\n",
        "df['Padded_Tamil'] = df['Tokenized_Tamil'].apply(lambda x: pad_sequence_target(x, max_pad, cls_token))\n",
        "df['Padded_Tamil_Target'] = df['Tokenized_Tamil'].apply(lambda x: pad_sequence_label(x, max_pad,sep_token))\n",
        "# Verify the result\n",
        "#print(df[['Padded_English', 'Padded_Tamil','Padded_Tamil_Target']].head(-10))\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EF922fPPCCM8",
        "outputId": "3ce6581d-bf06-4fcb-c73d-f56524c16b9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train DataFrame:\n",
            "356\n",
            "\n",
            "Test DataFrame:\n",
            "89\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Find the midpoint\n",
        "threshold = int(len(df)*0.8)\n",
        "\n",
        "# Split into two halves\n",
        "train = df.iloc[:threshold]\n",
        "test = df.iloc[threshold:]\n",
        "\n",
        "print(\"Train DataFrame:\")\n",
        "print(len(train))\n",
        "print(\"\\nTest DataFrame:\")\n",
        "print(len(test))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "xhaYFGS8kUXX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, dataframe, pad_token=1):\n",
        "        self.dataframe = dataframe\n",
        "        self.pad_token = pad_token  # Padding value, typically 0\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get the tokenized sequences for English and Tamil\n",
        "        english =  self.dataframe.iloc[idx][\"English\"]\n",
        "        tamil =  self.dataframe.iloc[idx][\"Tamil\"]\n",
        "        english_tokens =  torch.tensor(self.dataframe.iloc[idx][\"Padded_English\"],  dtype=torch.long)  # Shape: (T_english,)\n",
        "        tamil_tokens = torch.tensor(self.dataframe.iloc[idx][\"Padded_Tamil\"],  dtype=torch.long)   # Shape: (T_tamil,)\n",
        "        tamil_target_tokens = torch.tensor(self.dataframe.iloc[idx][\"Padded_Tamil_Target\"],  dtype=torch.long)   # Shape: (T_tamil_target,)\n",
        "\n",
        "\n",
        "        def causal_mask(size):\n",
        "              mask = torch.triu(torch.ones((1, size, size)), diagonal=1).type(torch.int)\n",
        "              return mask == 0\n",
        "    # Return the sequence and masks in a dictionary\n",
        "        return {\n",
        "            \"english\": english,\n",
        "            \"tamil\": tamil,\n",
        "            \"english_token\": english_tokens.clone(),\n",
        "            \"tamil_token\": tamil_tokens.clone(),\n",
        "            \"tamil_target\": tamil_target_tokens.clone(),\n",
        "            \"encoder_mask\": (english_tokens != self.pad_token).unsqueeze(0).unsqueeze(0).int().clone(),\n",
        "            \"decoder_mask\": (tamil_tokens != self.pad_token).unsqueeze(0).int() & causal_mask(tamil_tokens.size(0)).clone(),\n",
        "\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueABUeLQkaJe",
        "outputId": "dc969332-1755-433e-bfb5-c448861ac309"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 1:\n",
            "  English sequence shape: I didnt want this to happen\n",
            "  Tamil sequence shape: இது நடக்க நான் விரும்பவில்லை\n",
            "  English token shape: tensor([  2,   7, 327,  77,  50,   9,  80,   3,   1,   1,   1,   1,   1,   1,\n",
            "          1,   1,   1,   1])\n",
            "  tamil token shape: torch.Size([1, 18])\n",
            "  Tamil target sequence shape: tensor([ 21, 524,   7,  68,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "          1,   1,   1,   1])\n",
            "  English pad mask shape: tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]],\n",
            "       dtype=torch.int32)\n",
            "  Combined Tamil mask shape: tensor([[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]],\n",
            "       dtype=torch.int32)\n",
            "Batch 1:\n",
            "  English sequence shape: We went to London last year\n",
            "  Tamil sequence shape: போன வருஷம் லண்டன் போயிருந்தோம்\n",
            "  English token shape: tensor([   2,  569,  709,    9, 1030,  136, 1031,    3,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1])\n",
            "  tamil token shape: torch.Size([1, 18])\n",
            "  Tamil target sequence shape: tensor([1357, 1358, 1359, 1360,    3,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1])\n",
            "  English pad mask shape: tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]],\n",
            "       dtype=torch.int32)\n",
            "  Combined Tamil mask shape: tensor([[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]],\n",
            "       dtype=torch.int32)\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Assuming you have your Dataset class `TranslationDataset` and DataLoader defined\n",
        "# Example DataLoader for your dataset\n",
        "train_dataset = TranslationDataset(train)  # Your dataframe should be defined\n",
        "train_dataloader = DataLoader(train_dataset, batch_size = 1, shuffle=True)  # Set batch_size as needed\n",
        "test_dataset = TranslationDataset(test)  # Your dataframe should be defined\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True)  # Set batch_size as needed\n",
        "\n",
        "# Iterate through batches\n",
        "for batch_idx, batch in enumerate(train_dataloader):\n",
        "    print(f\"Batch {batch_idx + 1}:\")\n",
        "\n",
        "    # Check the shapes of each tensor in the batch\n",
        "    print(f\"  English sequence shape: {batch['english'][0]}\")  # Expected: (batch_size, T_english)\n",
        "    print(f\"  Tamil sequence shape: {batch['tamil'][0]}\")  # Expected: (batch_size, T_tamil)\n",
        "    print(f\"  English token shape: {batch['english_token'][0]}\")  # Expected: (batch_size, T_english)\n",
        "    print(f\"  tamil token shape: {batch['tamil_token'].shape}\")  # Expected: (batch_size, T_english)\n",
        "    print(f\"  Tamil target sequence shape: {batch['tamil_target'][0]}\")  # Expected: (batch_size, T_tamil_target)\n",
        "    print(f\"  English pad mask shape: {batch['encoder_mask'][0]}\")  # Expected: (batch_size, T_english, T_english)\n",
        "    print(f\"  Combined Tamil mask shape: {batch['decoder_mask'][0]}\")  # Expected: (batch_size, T_tamil_target, T_tamil_target)\n",
        "    break\n",
        "    print(\"\\n\")  # Add a newline for better readability between batches\n",
        "\n",
        "# Iterate through batches\n",
        "for batch_idx, batch in enumerate(test_dataloader):\n",
        "    print(f\"Batch {batch_idx + 1}:\")\n",
        "\n",
        "    # Check the shapes of each tensor in the batch\n",
        "    print(f\"  English sequence shape: {batch['english'][0]}\")  # Expected: (batch_size, T_english)\n",
        "    print(f\"  Tamil sequence shape: {batch['tamil'][0]}\")  # Expected: (batch_size, T_tamil)\n",
        "    print(f\"  English token shape: {batch['english_token'][0]}\")  # Expected: (batch_size, T_english)\n",
        "    print(f\"  tamil token shape: {batch['tamil_token'].shape}\")  # Expected: (batch_size, T_english)\n",
        "    print(f\"  Tamil target sequence shape: {batch['tamil_target'][0]}\")  # Expected: (batch_size, T_tamil_target)\n",
        "    print(f\"  English pad mask shape: {batch['encoder_mask'][0]}\")  # Expected: (batch_size, T_english, T_english)\n",
        "    print(f\"  Combined Tamil mask shape: {batch['decoder_mask'][0]}\")  # Expected: (batch_size, T_tamil_target, T_tamil_target)\n",
        "    break\n",
        "    print(\"\\n\")  # Add a newline for better readability between batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSLGhcoFmxla",
        "outputId": "d6dadb1f-6676-484a-90d2-91f0009991ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Check if CUDA is available and set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "omdKlJ5Emxla"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)]\n",
        "\n",
        "class MultiHeadSelfAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model: int, h: int, dropout: float) -> None:\n",
        "        super().__init__()\n",
        "        self.d_model = d_model # Embedding vector size\n",
        "        self.h = h # Number of heads\n",
        "        # Make sure d_model is divisible by h\n",
        "        assert d_model % h == 0, \"d_model is not divisible by h\"\n",
        "\n",
        "        self.d_k = d_model // h # Dimension of vector seen by each head\n",
        "        self.w_q = nn.Linear(d_model, d_model, bias=False) # Wq\n",
        "        self.w_k = nn.Linear(d_model, d_model, bias=False) # Wk\n",
        "        self.w_v = nn.Linear(d_model, d_model, bias=False) # Wv\n",
        "        self.w_o = nn.Linear(d_model, d_model, bias=False) # Wo\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    @staticmethod\n",
        "    def attention(query, key, value, mask, dropout: nn.Dropout):\n",
        "        d_k = query.shape[-1]\n",
        "        # Just apply the formula from the paper\n",
        "        # (batch, h, seq_len, d_k) --> (batch, h, seq_len, seq_len)\n",
        "        attention_scores = (query @ key.transpose(-2, -1)) / math.sqrt(d_k)\n",
        "        if mask is not None:\n",
        "            # Write a very low value (indicating -inf) to the positions where mask == 0\n",
        "            attention_scores.masked_fill_(mask == 0, -1e9)\n",
        "        attention_scores = attention_scores.softmax(dim=-1) # (batch, h, seq_len, seq_len) # Apply softmax\n",
        "        if dropout is not None:\n",
        "            attention_scores = dropout(attention_scores)\n",
        "        # (batch, h, seq_len, seq_len) --> (batch, h, seq_len, d_k)\n",
        "        # return attention scores which can be used for visualization\n",
        "        return (attention_scores @ value), attention_scores\n",
        "\n",
        "    def forward(self, q, k, v, mask):\n",
        "        query = self.w_q(q) # (batch, seq_len, d_model) --> (batch, seq_len, d_model)\n",
        "        key = self.w_k(k) # (batch, seq_len, d_model) --> (batch, seq_len, d_model)\n",
        "        value = self.w_v(v) # (batch, seq_len, d_model) --> (batch, seq_len, d_model)\n",
        "\n",
        "        # (batch, seq_len, d_model) --> (batch, seq_len, h, d_k) --> (batch, h, seq_len, d_k)\n",
        "        query = query.view(query.shape[0], query.shape[1], self.h, self.d_k).transpose(1, 2)\n",
        "        key = key.view(key.shape[0], key.shape[1], self.h, self.d_k).transpose(1, 2)\n",
        "        value = value.view(value.shape[0], value.shape[1], self.h, self.d_k).transpose(1, 2)\n",
        "\n",
        "        # Calculate attention\n",
        "        x, self.attention_scores = MultiHeadSelfAttention.attention(query, key, value, mask, self.dropout)\n",
        "\n",
        "        # Combine all the heads together\n",
        "        # (batch, h, seq_len, d_k) --> (batch, seq_len, h, d_k) --> (batch, seq_len, d_model)\n",
        "        x = x.transpose(1, 2).contiguous().view(x.shape[0], -1, self.h * self.d_k)\n",
        "\n",
        "        # Multiply by Wo\n",
        "        # (batch, seq_len, d_model) --> (batch, seq_len, d_model)\n",
        "        return self.w_o(x)\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff):\n",
        "        super(FeedForward, self).__init__()\n",
        "        self.linear1 = nn.Linear(d_model, d_ff)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(d_ff, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear2(self.relu(self.linear1(x)))\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, n_heads, d_ff, dropout=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.attn = MultiHeadSelfAttention(d_model, n_heads, dropout)\n",
        "        self.ff = FeedForward(d_model, d_ff)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        attn_output = self.attn(x,x,x, mask)\n",
        "        x = self.norm1(x + self.dropout(attn_output))\n",
        "        ff_output = self.ff(x)\n",
        "        x = self.norm2(x + self.dropout(ff_output))\n",
        "        return x\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, n_heads, d_ff, dropout=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.self_attn = MultiHeadSelfAttention(d_model, n_heads, dropout)\n",
        "        self.enc_attn = MultiHeadSelfAttention(d_model, n_heads, dropout)\n",
        "        self.ff = FeedForward(d_model, d_ff)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
        "        self_attn_output = self.self_attn(x ,x, x, tgt_mask)\n",
        "        x = self.norm1(x + self.dropout(self_attn_output))\n",
        "        enc_attn_output = self.enc_attn(x, enc_output, enc_output, src_mask)\n",
        "        x = self.norm2(x + self.dropout(enc_attn_output))\n",
        "        ff_output = self.ff(x)\n",
        "        x = self.norm3(x + self.dropout(ff_output))\n",
        "        return x\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, d_model, n_heads, d_ff, n_layers, dropout=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, d_model)\n",
        "        self.positional_encoding = PositionalEncoding(d_model)\n",
        "        self.layers = nn.ModuleList([EncoderLayer(d_model, n_heads, d_ff, dropout) for _ in range(n_layers)])\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        x = self.embedding(src)\n",
        "        x = self.positional_encoding(x)\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, src_mask)\n",
        "        return x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, d_model, n_heads, d_ff, n_layers, dropout=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_dim, d_model)\n",
        "        self.positional_encoding = PositionalEncoding(d_model)\n",
        "        self.layers = nn.ModuleList([DecoderLayer(d_model, n_heads, d_ff, dropout) for _ in range(n_layers)])\n",
        "        self.fc_out = nn.Linear(d_model, output_dim)\n",
        "\n",
        "    def forward(self, tgt, enc_output, src_mask, tgt_mask):\n",
        "        x = self.embedding(tgt)\n",
        "        x = self.positional_encoding(x)\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, enc_output, src_mask, tgt_mask)\n",
        "\n",
        "        return self.fc_out(x)\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, n_heads, d_ff, n_enc_layers, n_dec_layers, dropout=0.1):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.encoder = Encoder(src_vocab_size, d_model, n_heads, d_ff, n_enc_layers, dropout)\n",
        "        self.decoder = Decoder(tgt_vocab_size, d_model, n_heads, d_ff, n_dec_layers, dropout)\n",
        "\n",
        "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
        "        enc_output = self.encoder(src, src_mask)\n",
        "        output = self.decoder(tgt, enc_output, src_mask, tgt_mask)\n",
        "        return output\n",
        "\n",
        "src_vocab_size = 1442\n",
        "tgt_vocab_size = 1917\n",
        "d_model = 512\n",
        "n_heads = 8\n",
        "d_ff = 1024\n",
        "n_enc_layers = 8\n",
        "n_dec_layers = 8\n",
        "dropout = 0.1\n",
        "\n",
        "model = Transformer(src_vocab_size, tgt_vocab_size, d_model, n_heads, d_ff, n_enc_layers, n_dec_layers, dropout).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avIaJ4h0mxla",
        "outputId": "6fff38d7-6a9e-41ec-fb89-993c5d214bb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total model parameters: 44711805\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters())\n",
        "# Assuming 'model' is your PyTorch model\n",
        "total_params = count_parameters(model)\n",
        "print(f\"Total model parameters: {total_params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_tolnaPmxlb",
        "outputId": "e2369c78-8233-47ea-d5e9-a8b990e15001"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "English Vocabulary: 1442\n",
            "Tamil Vocabulary: 1917\n"
          ]
        }
      ],
      "source": [
        "print(\"English Vocabulary:\", len(english_tokenizer.word_to_id))\n",
        "print(\"Tamil Vocabulary:\", len(tamil_tokenizer.word_to_id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRq93fGu84Fs",
        "outputId": "e8bcaafe-089a-4e36-c957-ee6ad055a0d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Device name: Tesla T4\n",
            "Device memory: 14.74810791015625 GB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 00: 100%|██████████| 356/356 [00:24<00:00, 14.76it/s, loss=7.588]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:Most people only want to hear their own truth\n",
            "     TARGET:பெரும்பாலான மக்கள் தங்கள் சொந்த உண்மையை மட்டுமே கேட்க விரும்புகிறார்கள்\n",
            "  PREDICTED:<SOS> நான் நான் நான் நான் நான் நான் நான் நான் நான் நான் நான் நான் நான் நான் நான் நான் நான்\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 01: 100%|██████████| 356/356 [00:24<00:00, 14.41it/s, loss=6.281]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:I slept a little during lunch break because I was so tired\n",
            "     TARGET:நான் மிகவும் சோர்வாக இருந்ததால் மதிய உணவு இடைவேளையின் போது சிறிது தூங்கினேன்\n",
            "  PREDICTED:<SOS> நான் நான் நான் நான் நான் நான் நான் நான் நான் நான் நான் நான் நான் நான் நான் நான் நான்\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 02: 100%|██████████| 356/356 [00:24<00:00, 14.75it/s, loss=5.569]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:I dont want to go to school\n",
            "     TARGET:நான் பள்ளிக்கு செல்ல விரும்பவில்லை\n",
            "  PREDICTED:<SOS> நான் நான் நான் நான் நான் <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 03: 100%|██████████| 356/356 [00:24<00:00, 14.74it/s, loss=6.705]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:What is your greatest source of inspiration\n",
            "     TARGET:உங்கள் உத்வேகத்தின் மிகப்பெரிய ஆதாரம் என்ன\n",
            "  PREDICTED:<SOS> <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 04: 100%|██████████| 356/356 [00:24<00:00, 14.72it/s, loss=6.513]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:Freuds insights into human behavior led to him being honored as a profound thinker\n",
            "     TARGET:மனித நடத்தை பற்றிய பிராய்டின் நுண்ணறிவு அவரை ஒரு ஆழ்ந்த சிந்தனையாளராக கௌரவிக்க வழிவகுத்தது\n",
            "  PREDICTED:<SOS> <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 05: 100%|██████████| 356/356 [00:23<00:00, 14.90it/s, loss=5.344]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:Close the door when you leave\n",
            "     TARGET:நீங்கள் வெளியேறும்போது கதவை மூடு\n",
            "  PREDICTED:<SOS> <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 06: 100%|██████████| 356/356 [00:23<00:00, 14.92it/s, loss=6.475]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:Even people who dont believe in the Catholic church venerate the Pope as a symbolic leader\n",
            "     TARGET:கத்தோலிக்க திருச்சபையின் மீது நம்பிக்கை இல்லாத மக்கள் கூட போப்பை ஒரு அடையாளத் தலைவராக மதிக்கிறார்கள்\n",
            "  PREDICTED:<SOS> <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 07: 100%|██████████| 356/356 [00:23<00:00, 14.96it/s, loss=6.025]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:If Spenser doesnt keep adding and translating sentences the other contributors will surely surpass him\n",
            "     TARGET:ஸ்பென்சர் வாக்கியங்களைச் சேர்த்து மொழிபெயர்க்கவில்லை என்றால் மற்ற பங்களிப்பாளர்கள் நிச்சயமாக அவரை மிஞ்சுவார்கள்\n",
            "  PREDICTED:<SOS> <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 08: 100%|██████████| 356/356 [00:23<00:00, 14.96it/s, loss=6.535]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:From the moment that I knew that the university existed Ive wanted to go there\n",
            "     TARGET:பல்கலைக்கழகம் இருப்பதை அறிந்த தருணத்திலிருந்து நான் அங்கு செல்ல விரும்பினேன்\n",
            "  PREDICTED:<SOS> <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 09: 100%|██████████| 356/356 [00:23<00:00, 14.95it/s, loss=5.103]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:Jason was a taciturn individual so it was always a real surprise when he said anything\n",
            "     TARGET:ஜேஸன் அதிகம் பேசாமல் இருப்பவர் அதனால் அவர் ஏதாவது சொன்னால் அது எப்போதுமே ஆச்சரியமாகவே இருக்கும்\n",
            "  PREDICTED:<SOS> <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 10: 100%|██████████| 356/356 [00:23<00:00, 15.29it/s, loss=5.235]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:To him hunger was an abstract concept he always had enough to eat\n",
            "     TARGET:அவரைப் பொறுத்தவரை பசி என்பது ஒரு அருவமான கருத்தாக்கம் அவனுக்கு எப்போதும் போதுமான அளவு சாப்பாடு இருந்தது\n",
            "  PREDICTED:<SOS> <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 11: 100%|██████████| 356/356 [00:23<00:00, 15.15it/s, loss=5.637]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:It requires wisdom to understand wisdom the music is nothing if the audience is deaf\n",
            "     TARGET:ஞானத்தைப் புரிந்துகொள்ள ஞானம் தேவை பார்வையாளர்கள் காது கேளாதவர்களாக இருந்தால் இசை ஒன்றுமில்லை\n",
            "  PREDICTED:<SOS> <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 12: 100%|██████████| 356/356 [00:23<00:00, 14.97it/s, loss=3.823]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:Too late\n",
            "     TARGET:மிகவும் தாமதமாக\n",
            "  PREDICTED:<SOS> <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 13: 100%|██████████| 356/356 [00:23<00:00, 14.99it/s, loss=6.306]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:Anything that is too stupid to be spoken is sung\n",
            "     TARGET:பேச முடியாத முட்டாள்தனமான எதுவும் பாடப்படுகிறது\n",
            "  PREDICTED:<SOS> <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 14: 100%|██████████| 356/356 [00:23<00:00, 14.95it/s, loss=5.586]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "     SOURCE:Politicians are always censured for outrageous or inappropriate behavior\n",
            "     TARGET:அரசியல்வாதிகள் எப்போதும் மூர்க்கத்தனமான அல்லது பொருத்தமற்ற நடத்தைக்காக கண்டிக்கப்படுகிறார்கள்\n",
            "  PREDICTED:<SOS> <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Epoch 15:  27%|██▋       | 96/356 [00:06<00:17, 14.63it/s, loss=5.123]"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "from torch.utils.data import random_split\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import WordLevel\n",
        "from tokenizers.trainers import WordLevelTrainer\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "\n",
        "\n",
        "\n",
        "epochs = 30\n",
        "lr = 10**-4\n",
        "\n",
        "def causal_mask(size):\n",
        "    mask = torch.triu(torch.ones((1, size, size)), diagonal=1).type(torch.int)\n",
        "    return mask == 0\n",
        "\n",
        "def greedy_decode(model, source, source_mask, tokenizer_src, tokenizer_tgt, max_len, device):\n",
        "    sos_idx, eos_idx = 2, 3\n",
        "    encoder_output = model.encoder(source.to(device), source_mask.to(device))\n",
        "    decoder_input = torch.empty(1, 1).fill_(sos_idx).type_as(source).to(device)\n",
        "\n",
        "    while decoder_input.size(1) < max_len:\n",
        "        decoder_mask = causal_mask(decoder_input.size(1)).type_as(source_mask).to(device)\n",
        "        out = model.decoder(decoder_input, encoder_output, source_mask, decoder_mask)\n",
        "        next_word = torch.max(out[:, -1], dim=1)[1]\n",
        "        decoder_input = torch.cat([decoder_input, next_word.view(1, 1).to(device)], dim=1)\n",
        "        if next_word == eos_idx: break\n",
        "\n",
        "    return decoder_input.squeeze(0)\n",
        "\n",
        "\n",
        "def run_validation(model, validation_ds, tokenizer_src, tokenizer_tgt, max_len, device, print_msg, num_examples=1):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    source_texts, expected, predicted = [], [], []\n",
        "    try:\n",
        "      console_width = os.get_terminal_size().columns\n",
        "    except OSError:\n",
        "      console_width = 80\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for count, batch in enumerate(validation_ds, start=1):\n",
        "            encoder_input, encoder_mask = batch[\"english_token\"].to(device), batch[\"encoder_mask\"].to(device)\n",
        "            assert encoder_input.size(0) == 1, \"Batch size must be 1 for validation\"\n",
        "            model_out = greedy_decode(model, encoder_input, encoder_mask, tokenizer_src, tokenizer_tgt, max_len, device)\n",
        "\n",
        "            source_text = batch[\"english\"][0]\n",
        "            target_text = batch[\"tamil\"][0]\n",
        "            model_out_text = tokenizer_tgt.decode(model_out.detach().cpu().numpy())\n",
        "\n",
        "            source_texts.append(source_text)\n",
        "            expected.append(target_text)\n",
        "            predicted.append(model_out_text)\n",
        "\n",
        "            print_msg(f\"{'-'*console_width}\\n{'SOURCE:':>12}{source_text}\\n{'TARGET:':>12}{target_text}\\n{'PREDICTED:':>12}{model_out_text}\")\n",
        "            if count == num_examples: break\n",
        "\n",
        "def train_model():\n",
        "\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.has_mps or torch.backends.mps.is_available() else \"cpu\"\n",
        "    print(\"Using device:\", device)\n",
        "    if device == 'cuda':\n",
        "        print(f\"Device name: {torch.cuda.get_device_name(device.index)}\")\n",
        "        print(f\"Device memory: {torch.cuda.get_device_properties(device.index).total_memory / 1024 ** 3} GB\")\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = lr, eps=1e-9)\n",
        "\n",
        "    initial_epoch = 0\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss(ignore_index= 1).to(device)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        torch.cuda.empty_cache()\n",
        "        model.train()\n",
        "        batch_iterator = tqdm(train_dataloader, desc=f\"Processing Epoch {epoch:02d}\")\n",
        "        for batch in batch_iterator:\n",
        "            encoder_input = batch['english_token'].to(device)\n",
        "            decoder_input = batch['tamil_token'].to(device)\n",
        "            encoder_mask = batch['encoder_mask'].to(device)\n",
        "            decoder_mask = batch['decoder_mask'].to(device)\n",
        "\n",
        "            output = model(encoder_input, decoder_input, encoder_mask, decoder_mask)\n",
        "\n",
        "            label = batch['tamil_target'].to(device)\n",
        "\n",
        "            loss = loss_fn(output.view(-1, (len(tamil_tokenizer.word_to_id))), label.view(-1))\n",
        "            batch_iterator.set_postfix({\"loss\": f\"{loss.item():6.3f}\"})\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        run_validation(model, test_dataloader, english_tokenizer, tamil_tokenizer, 18, device, lambda msg: batch_iterator.write(msg))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "    train_model()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVhUJM7VKoH9"
      },
      "outputs": [],
      "source": [
        "'''\"english\": english,\n",
        "\"tamil\": tamil,\n",
        "\"english_token\": english_tokens.clone(),\n",
        "\"tamil_token\": tamil_tokens.clone(),\n",
        "\"tamil_target\": tamil_target_tokens.clone(),\n",
        "\"encoder_mask\": (english_tokens != self.pad_token).unsqueeze(0).unsqueeze(0).int().clone(),\n",
        "\"decoder_mask\": (tamil_tokens != self.pad_token).unsqueeze(0).int() & causal_mask(tamil_tokens.size(0)).clone(), '''\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
